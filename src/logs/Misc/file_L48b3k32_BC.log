[2017-12-11 15:05:25,554, PHOCNetTrainer] --- Training Parameter: ---
[2017-12-11 15:05:25,554, PHOCNetTrainer] self = <phocnet.training.phocnet_trainer.PHOCNetTrainer object at 0x7f99f29510d0>
[2017-12-11 15:05:25,554, PHOCNetTrainer] doc_img_dir = /vol/corpora/document-image-analysis/gw/pages/
[2017-12-11 15:05:25,554, PHOCNetTrainer] train_annotation_file = /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_train.xml
[2017-12-11 15:05:25,554, PHOCNetTrainer] test_annotation_file = /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_test.xml
[2017-12-11 15:05:25,554, PHOCNetTrainer] proto_dir = /home/fwolf/Workspace/DensePHOCNet/data/models/exp/
[2017-12-11 15:05:25,554, PHOCNetTrainer] n_train_images = 500000
[2017-12-11 15:05:25,554, PHOCNetTrainer] lmdb_dir = /data/fwolf/min26/
[2017-12-11 15:05:25,554, PHOCNetTrainer] save_net_dir = /home/fwolf/Workspace/DensePHOCNet/data/results/
[2017-12-11 15:05:25,555, PHOCNetTrainer] phoc_unigram_levels = [2, 3, 4, 5]
[2017-12-11 15:05:25,555, PHOCNetTrainer] recreate_lmdbs = False
[2017-12-11 15:05:25,555, PHOCNetTrainer] gpu_id = 1
[2017-12-11 15:05:25,555, PHOCNetTrainer] learning_rate = 0.0001
[2017-12-11 15:05:25,555, PHOCNetTrainer] momentum = 0.9
[2017-12-11 15:05:25,555, PHOCNetTrainer] weight_decay = 5e-05
[2017-12-11 15:05:25,555, PHOCNetTrainer] batch_size = 10
[2017-12-11 15:05:25,555, PHOCNetTrainer] test_interval = 500
[2017-12-11 15:05:25,555, PHOCNetTrainer] display = 100
[2017-12-11 15:05:25,555, PHOCNetTrainer] max_iter = 100000
[2017-12-11 15:05:25,555, PHOCNetTrainer] step_size = 70000
[2017-12-11 15:05:25,555, PHOCNetTrainer] gamma = 0.1
[2017-12-11 15:05:25,555, PHOCNetTrainer] debug_mode = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] metric = cosine
[2017-12-11 15:05:25,555, PHOCNetTrainer] annotation_delimiter = None
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_lower_case_only = False
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_bigrams = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_dense = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_tpp = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] nblocks = 3
[2017-12-11 15:05:25,555, PHOCNetTrainer] growth_rate = 32
[2017-12-11 15:05:25,555, PHOCNetTrainer] nlayers = 48
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_bottleneck = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] use_compression = True
[2017-12-11 15:05:25,555, PHOCNetTrainer] pool_init = False
[2017-12-11 15:05:25,555, PHOCNetTrainer] dropout_ratio = 0.2
[2017-12-11 15:05:25,555, PHOCNetTrainer] max_out = -1
[2017-12-11 15:05:25,555, PHOCNetTrainer] config = [3, 6, 12]
[2017-12-11 15:05:25,555, PHOCNetTrainer] dense_net_file = None
[2017-12-11 15:05:25,555, PHOCNetTrainer] weights = None
[2017-12-11 15:05:25,555, PHOCNetTrainer] min_image_width = 26
[2017-12-11 15:05:25,555, PHOCNetTrainer] min_image_height = 26
[2017-12-11 15:05:25,555, PHOCNetTrainer] --- Running PHOCNet Training ---
[2017-12-11 15:05:25,555, XMLReader] Loading training XML at /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_train.xml
[2017-12-11 15:05:25,556, XMLReader] Using XML-File at /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_train.xml and image directory /vol/corpora/document-image-analysis/gw/pages/...
[2017-12-11 15:05:26,153, XMLReader] Loading test XML at /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_test.xml
[2017-12-11 15:05:26,195, XMLReader] Using XML-File at /home/fwolf/Workspace/phocnet-master/experiments/gw/gw_cv1_test.xml and image directory /vol/corpora/document-image-analysis/gw/pages/...
[2017-12-11 15:05:26,387, PHOCNetTrainer] PHOC unigrams: 0 1 2 3 4 5 6 7 8 9 a b c d e f g h i j k l m n o p q r s t u v w x y z
[2017-12-11 15:05:26,387, PHOCNetTrainer] Using dataset 'gw_cv1'
[2017-12-11 15:05:26,397, PHOCNetTrainer] Found LMDBs...
[2017-12-11 15:05:26,397, PHOCNetTrainer] Saving proto files...
[2017-12-11 15:05:27,170, PHOCNetTrainer] Starting SGD...
[2017-12-11 15:05:27,170, PHOCNetTrainer] Setting Caffe to GPU mode using device 1
[2017-12-11 15:05:29,773, PHOCNetTrainer] Using solver protofile at /home/fwolf/Workspace/DensePHOCNet/data/models/exp/solver_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1211 15:05:29.874718 15749 solver.cpp:44] Initializing solver from parameters: 
train_net: "/home/fwolf/Workspace/DensePHOCNet/data/models/exp/train_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt"
test_net: "/home/fwolf/Workspace/DensePHOCNet/data/models/exp/test_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt"
test_iter: 1215
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 5e-05
stepsize: 70000
solver_mode: GPU
average_loss: 100
iter_size: 10
I1211 15:05:29.874747 15749 solver.cpp:77] Creating training net from train_net file: /home/fwolf/Workspace/DensePHOCNet/data/models/exp/train_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt
I1211 15:05:29.888334 15749 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/fwolf/Workspace/DensePHOCNet/data/models/exp/train_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt
I1211 15:05:29.888375 15749 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 15:05:29.888777 15749 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer sigmoid
I1211 15:05:29.888787 15749 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer silence
I1211 15:05:29.890789 15749 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "word_images"
  type: "Data"
  top: "word_images"
  top: "label"
  transform_param {
    scale: -0.0039215689
    mean_value: 255
  }
  data_param {
    source: "/data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_train_word_images_lmdb"
    batch_size: 1
    backend: LMDB
    prefetch: 20
  }
}
layer {
  name: "phocs"
  type: "Data"
  top: "phocs"
  top: "label_phocs"
  data_param {
    source: "/data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_train_phocs_lmdb"
    batch_size: 1
    backend: LMDB
    prefetch: 20
  }
}
layer {
  name: "conv_init"
  type: "Convolution"
  bottom: "word_images"
  top: "conv_init"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_0/x1/bn"
  type: "BatchNorm"
  bottom: "conv_init"
  top: "conv0_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_0/x1/scale"
  type: "Scale"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_0/x1"
  type: "ReLU"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1/bn"
}
layer {
  name: "conv0_0/x1"
  type: "Convolution"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_0/x1"
  top: "conv0_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_0/x2/scale"
  type: "Scale"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_0/x2"
  type: "ReLU"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2/bn"
}
layer {
  name: "conv0_0/x2"
  type: "Convolution"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_0"
  type: "Concat"
  bottom: "conv_init"
  bottom: "conv0_0/x2"
  top: "concat0_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv0_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat0_0"
  top: "conv0_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_1/x1/scale"
  type: "Scale"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_1/x1"
  type: "ReLU"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1/bn"
}
layer {
  name: "conv0_1/x1"
  type: "Convolution"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_1/x1"
  top: "conv0_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_1/x2/scale"
  type: "Scale"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_1/x2"
  type: "ReLU"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2/bn"
}
layer {
  name: "conv0_1/x2"
  type: "Convolution"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_1"
  type: "Concat"
  bottom: "concat0_0"
  bottom: "conv0_1/x2"
  top: "concat0_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv0_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat0_1"
  top: "conv0_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_2/x1/scale"
  type: "Scale"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_2/x1"
  type: "ReLU"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1/bn"
}
layer {
  name: "conv0_2/x1"
  type: "Convolution"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_2/x1"
  top: "conv0_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_2/x2/scale"
  type: "Scale"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_2/x2"
  type: "ReLU"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2/bn"
}
layer {
  name: "conv0_2/x2"
  type: "Convolution"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_2"
  type: "Concat"
  bottom: "concat0_1"
  bottom: "conv0_2/x2"
  top: "concat0_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "concat0_2"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "conv0_blk"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "conv0_blk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0_blk"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_0/x1/bn"
  type: "BatchNorm"
  bottom: "pool0"
  top: "conv1_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_0/x1/scale"
  type: "Scale"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_0/x1"
  type: "ReLU"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1/bn"
}
layer {
  name: "conv1_0/x1"
  type: "Convolution"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_0/x1"
  top: "conv1_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_0/x2/scale"
  type: "Scale"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_0/x2"
  type: "ReLU"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2/bn"
}
layer {
  name: "conv1_0/x2"
  type: "Convolution"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_0"
  type: "Concat"
  bottom: "pool0"
  bottom: "conv1_0/x2"
  top: "concat1_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_0"
  top: "conv1_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/x1/scale"
  type: "Scale"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/x1"
  type: "ReLU"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1/bn"
}
layer {
  name: "conv1_1/x1"
  type: "Convolution"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_1/x1"
  top: "conv1_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/x2/scale"
  type: "Scale"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/x2"
  type: "ReLU"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2/bn"
}
layer {
  name: "conv1_1/x2"
  type: "Convolution"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_1"
  type: "Concat"
  bottom: "concat1_0"
  bottom: "conv1_1/x2"
  top: "concat1_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_1"
  top: "conv1_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/x1/scale"
  type: "Scale"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/x1"
  type: "ReLU"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1/bn"
}
layer {
  name: "conv1_2/x1"
  type: "Convolution"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_2/x1"
  top: "conv1_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/x2/scale"
  type: "Scale"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/x2"
  type: "ReLU"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2/bn"
}
layer {
  name: "conv1_2/x2"
  type: "Convolution"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_2"
  type: "Concat"
  bottom: "concat1_1"
  bottom: "conv1_2/x2"
  top: "concat1_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_2"
  top: "conv1_3/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_3/x1/scale"
  type: "Scale"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_3/x1"
  type: "ReLU"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1/bn"
}
layer {
  name: "conv1_3/x1"
  type: "Convolution"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_3/x1"
  top: "conv1_3/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_3/x2/scale"
  type: "Scale"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_3/x2"
  type: "ReLU"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2/bn"
}
layer {
  name: "conv1_3/x2"
  type: "Convolution"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_3"
  type: "Concat"
  bottom: "concat1_2"
  bottom: "conv1_3/x2"
  top: "concat1_3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_3"
  top: "conv1_4/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_4/x1/scale"
  type: "Scale"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_4/x1"
  type: "ReLU"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1/bn"
}
layer {
  name: "conv1_4/x1"
  type: "Convolution"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_4/x1"
  top: "conv1_4/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_4/x2/scale"
  type: "Scale"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_4/x2"
  type: "ReLU"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2/bn"
}
layer {
  name: "conv1_4/x2"
  type: "Convolution"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_4"
  type: "Concat"
  bottom: "concat1_3"
  bottom: "conv1_4/x2"
  top: "concat1_4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_4"
  top: "conv1_5/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_5/x1/scale"
  type: "Scale"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_5/x1"
  type: "ReLU"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1/bn"
}
layer {
  name: "conv1_5/x1"
  type: "Convolution"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_5/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_5/x1"
  top: "conv1_5/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_5/x2/scale"
  type: "Scale"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_5/x2"
  type: "ReLU"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2/bn"
}
layer {
  name: "conv1_5/x2"
  type: "Convolution"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_5"
  type: "Concat"
  bottom: "concat1_4"
  bottom: "conv1_5/x2"
  top: "concat1_5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "concat1_5"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "conv1_blk"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "conv1_blk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_blk"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_0/x1/bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv2_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_0/x1/scale"
  type: "Scale"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_0/x1"
  type: "ReLU"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1/bn"
}
layer {
  name: "conv2_0/x1"
  type: "Convolution"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_0/x1"
  top: "conv2_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_0/x2/scale"
  type: "Scale"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_0/x2"
  type: "ReLU"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2/bn"
}
layer {
  name: "conv2_0/x2"
  type: "Convolution"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_0"
  type: "Concat"
  bottom: "pool1"
  bottom: "conv2_0/x2"
  top: "concat2_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_0"
  top: "conv2_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/x1/scale"
  type: "Scale"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/x1"
  type: "ReLU"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
}
layer {
  name: "conv2_1/x1"
  type: "Convolution"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_1/x1"
  top: "conv2_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/x2/scale"
  type: "Scale"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/x2"
  type: "ReLU"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
}
layer {
  name: "conv2_1/x2"
  type: "Convolution"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_1"
  type: "Concat"
  bottom: "concat2_0"
  bottom: "conv2_1/x2"
  top: "concat2_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_1"
  top: "conv2_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/x1/scale"
  type: "Scale"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/x1"
  type: "ReLU"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
}
layer {
  name: "conv2_2/x1"
  type: "Convolution"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_2/x1"
  top: "conv2_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/x2/scale"
  type: "Scale"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/x2"
  type: "ReLU"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
}
layer {
  name: "conv2_2/x2"
  type: "Convolution"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_2"
  type: "Concat"
  bottom: "concat2_1"
  bottom: "conv2_2/x2"
  top: "concat2_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_2"
  top: "conv2_3/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3/x1/scale"
  type: "Scale"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_3/x1"
  type: "ReLU"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
}
layer {
  name: "conv2_3/x1"
  type: "Convolution"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_3/x1"
  top: "conv2_3/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3/x2/scale"
  type: "Scale"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_3/x2"
  type: "ReLU"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
}
layer {
  name: "conv2_3/x2"
  type: "Convolution"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_3"
  type: "Concat"
  bottom: "concat2_2"
  bottom: "conv2_3/x2"
  top: "concat2_3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_3"
  top: "conv2_4/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4/x1/scale"
  type: "Scale"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_4/x1"
  type: "ReLU"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
}
layer {
  name: "conv2_4/x1"
  type: "Convolution"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_4/x1"
  top: "conv2_4/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4/x2/scale"
  type: "Scale"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_4/x2"
  type: "ReLU"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
}
layer {
  name: "conv2_4/x2"
  type: "Convolution"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_4"
  type: "Concat"
  bottom: "concat2_3"
  bottom: "conv2_4/x2"
  top: "concat2_4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_4"
  top: "conv2_5/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_5/x1/scale"
  type: "Scale"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_5/x1"
  type: "ReLU"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
}
layer {
  name: "conv2_5/x1"
  type: "Convolution"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    ke
I1211 15:05:29.891724 15749 layer_factory.hpp:77] Creating layer word_images
I1211 15:05:29.901530 15749 db_lmdb.cpp:35] Opened lmdb /data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_train_word_images_lmdb
I1211 15:05:29.901590 15749 net.cpp:84] Creating Layer word_images
I1211 15:05:29.901604 15749 net.cpp:380] word_images -> word_images
I1211 15:05:29.901619 15749 net.cpp:380] word_images -> label
I1211 15:05:29.902925 15749 data_layer.cpp:44] output data size: 1,1,72,422
I1211 15:05:29.915596 15749 net.cpp:122] Setting up word_images
I1211 15:05:29.915629 15749 net.cpp:129] Top shape: 1 1 72 422 (30384)
I1211 15:05:29.915634 15749 net.cpp:129] Top shape: 1 (1)
I1211 15:05:29.915637 15749 net.cpp:137] Memory required for data: 121540
I1211 15:05:29.915644 15749 layer_factory.hpp:77] Creating layer phocs
I1211 15:05:29.915715 15749 db_lmdb.cpp:35] Opened lmdb /data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_train_phocs_lmdb
I1211 15:05:29.915762 15749 net.cpp:84] Creating Layer phocs
I1211 15:05:29.915771 15749 net.cpp:380] phocs -> phocs
I1211 15:05:29.915781 15749 net.cpp:380] phocs -> label_phocs
I1211 15:05:29.916128 15749 data_layer.cpp:44] output data size: 1,1,1,604
I1211 15:05:29.919064 15749 net.cpp:122] Setting up phocs
I1211 15:05:29.919093 15749 net.cpp:129] Top shape: 1 1 1 604 (604)
I1211 15:05:29.919100 15749 net.cpp:129] Top shape: 1 (1)
I1211 15:05:29.919103 15749 net.cpp:137] Memory required for data: 123960
I1211 15:05:29.919108 15749 layer_factory.hpp:77] Creating layer conv_init
I1211 15:05:29.919123 15749 net.cpp:84] Creating Layer conv_init
I1211 15:05:29.919127 15749 net.cpp:406] conv_init <- word_images
I1211 15:05:29.919136 15749 net.cpp:380] conv_init -> conv_init
I1211 15:05:31.584120 15749 net.cpp:122] Setting up conv_init
I1211 15:05:31.584151 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.584153 15749 net.cpp:137] Memory required for data: 4013112
I1211 15:05:31.584164 15749 layer_factory.hpp:77] Creating layer conv_init_conv_init_0_split
I1211 15:05:31.584172 15749 net.cpp:84] Creating Layer conv_init_conv_init_0_split
I1211 15:05:31.584177 15749 net.cpp:406] conv_init_conv_init_0_split <- conv_init
I1211 15:05:31.584182 15749 net.cpp:380] conv_init_conv_init_0_split -> conv_init_conv_init_0_split_0
I1211 15:05:31.584188 15749 net.cpp:380] conv_init_conv_init_0_split -> conv_init_conv_init_0_split_1
I1211 15:05:31.584235 15749 net.cpp:122] Setting up conv_init_conv_init_0_split
I1211 15:05:31.584241 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.584244 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.584246 15749 net.cpp:137] Memory required for data: 11791416
I1211 15:05:31.584249 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/bn
I1211 15:05:31.584255 15749 net.cpp:84] Creating Layer conv0_0/x1/bn
I1211 15:05:31.584259 15749 net.cpp:406] conv0_0/x1/bn <- conv_init_conv_init_0_split_0
I1211 15:05:31.584262 15749 net.cpp:380] conv0_0/x1/bn -> conv0_0/x1/bn
I1211 15:05:31.584547 15749 net.cpp:122] Setting up conv0_0/x1/bn
I1211 15:05:31.584553 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.584556 15749 net.cpp:137] Memory required for data: 15680568
I1211 15:05:31.584564 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/scale
I1211 15:05:31.584571 15749 net.cpp:84] Creating Layer conv0_0/x1/scale
I1211 15:05:31.584573 15749 net.cpp:406] conv0_0/x1/scale <- conv0_0/x1/bn
I1211 15:05:31.584578 15749 net.cpp:367] conv0_0/x1/scale -> conv0_0/x1/bn (in-place)
I1211 15:05:31.584625 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/scale
I1211 15:05:31.584810 15749 net.cpp:122] Setting up conv0_0/x1/scale
I1211 15:05:31.584818 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.584820 15749 net.cpp:137] Memory required for data: 19569720
I1211 15:05:31.584826 15749 layer_factory.hpp:77] Creating layer relu0_0/x1
I1211 15:05:31.584832 15749 net.cpp:84] Creating Layer relu0_0/x1
I1211 15:05:31.584836 15749 net.cpp:406] relu0_0/x1 <- conv0_0/x1/bn
I1211 15:05:31.584838 15749 net.cpp:367] relu0_0/x1 -> conv0_0/x1/bn (in-place)
I1211 15:05:31.585168 15749 net.cpp:122] Setting up relu0_0/x1
I1211 15:05:31.585178 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.585181 15749 net.cpp:137] Memory required for data: 23458872
I1211 15:05:31.585184 15749 layer_factory.hpp:77] Creating layer conv0_0/x1
I1211 15:05:31.585194 15749 net.cpp:84] Creating Layer conv0_0/x1
I1211 15:05:31.585197 15749 net.cpp:406] conv0_0/x1 <- conv0_0/x1/bn
I1211 15:05:31.585201 15749 net.cpp:380] conv0_0/x1 -> conv0_0/x1
I1211 15:05:31.587101 15749 net.cpp:122] Setting up conv0_0/x1
I1211 15:05:31.587116 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.587118 15749 net.cpp:137] Memory required for data: 39015480
I1211 15:05:31.587123 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/bn
I1211 15:05:31.587131 15749 net.cpp:84] Creating Layer conv0_0/x2/bn
I1211 15:05:31.587133 15749 net.cpp:406] conv0_0/x2/bn <- conv0_0/x1
I1211 15:05:31.587138 15749 net.cpp:380] conv0_0/x2/bn -> conv0_0/x2/bn
I1211 15:05:31.587435 15749 net.cpp:122] Setting up conv0_0/x2/bn
I1211 15:05:31.587441 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.587443 15749 net.cpp:137] Memory required for data: 54572088
I1211 15:05:31.587451 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/scale
I1211 15:05:31.587460 15749 net.cpp:84] Creating Layer conv0_0/x2/scale
I1211 15:05:31.587463 15749 net.cpp:406] conv0_0/x2/scale <- conv0_0/x2/bn
I1211 15:05:31.587468 15749 net.cpp:367] conv0_0/x2/scale -> conv0_0/x2/bn (in-place)
I1211 15:05:31.587519 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/scale
I1211 15:05:31.588244 15749 net.cpp:122] Setting up conv0_0/x2/scale
I1211 15:05:31.588258 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.588260 15749 net.cpp:137] Memory required for data: 70128696
I1211 15:05:31.588266 15749 layer_factory.hpp:77] Creating layer relu0_0/x2
I1211 15:05:31.588273 15749 net.cpp:84] Creating Layer relu0_0/x2
I1211 15:05:31.588275 15749 net.cpp:406] relu0_0/x2 <- conv0_0/x2/bn
I1211 15:05:31.588279 15749 net.cpp:367] relu0_0/x2 -> conv0_0/x2/bn (in-place)
I1211 15:05:31.588462 15749 net.cpp:122] Setting up relu0_0/x2
I1211 15:05:31.588470 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.588472 15749 net.cpp:137] Memory required for data: 85685304
I1211 15:05:31.588475 15749 layer_factory.hpp:77] Creating layer conv0_0/x2
I1211 15:05:31.588485 15749 net.cpp:84] Creating Layer conv0_0/x2
I1211 15:05:31.588488 15749 net.cpp:406] conv0_0/x2 <- conv0_0/x2/bn
I1211 15:05:31.588495 15749 net.cpp:380] conv0_0/x2 -> conv0_0/x2
I1211 15:05:31.590730 15749 net.cpp:122] Setting up conv0_0/x2
I1211 15:05:31.590754 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.590756 15749 net.cpp:137] Memory required for data: 89574456
I1211 15:05:31.590764 15749 layer_factory.hpp:77] Creating layer concat0_0
I1211 15:05:31.590770 15749 net.cpp:84] Creating Layer concat0_0
I1211 15:05:31.590773 15749 net.cpp:406] concat0_0 <- conv_init_conv_init_0_split_1
I1211 15:05:31.590778 15749 net.cpp:406] concat0_0 <- conv0_0/x2
I1211 15:05:31.590783 15749 net.cpp:380] concat0_0 -> concat0_0
I1211 15:05:31.590823 15749 net.cpp:122] Setting up concat0_0
I1211 15:05:31.590829 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.590831 15749 net.cpp:137] Memory required for data: 97352760
I1211 15:05:31.590833 15749 layer_factory.hpp:77] Creating layer concat0_0_concat0_0_0_split
I1211 15:05:31.590839 15749 net.cpp:84] Creating Layer concat0_0_concat0_0_0_split
I1211 15:05:31.590842 15749 net.cpp:406] concat0_0_concat0_0_0_split <- concat0_0
I1211 15:05:31.590845 15749 net.cpp:380] concat0_0_concat0_0_0_split -> concat0_0_concat0_0_0_split_0
I1211 15:05:31.590850 15749 net.cpp:380] concat0_0_concat0_0_0_split -> concat0_0_concat0_0_0_split_1
I1211 15:05:31.590898 15749 net.cpp:122] Setting up concat0_0_concat0_0_0_split
I1211 15:05:31.590901 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.590904 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.590908 15749 net.cpp:137] Memory required for data: 112909368
I1211 15:05:31.590909 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/bn
I1211 15:05:31.590915 15749 net.cpp:84] Creating Layer conv0_1/x1/bn
I1211 15:05:31.590917 15749 net.cpp:406] conv0_1/x1/bn <- concat0_0_concat0_0_0_split_0
I1211 15:05:31.590921 15749 net.cpp:380] conv0_1/x1/bn -> conv0_1/x1/bn
I1211 15:05:31.591215 15749 net.cpp:122] Setting up conv0_1/x1/bn
I1211 15:05:31.591223 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.591225 15749 net.cpp:137] Memory required for data: 120687672
I1211 15:05:31.591233 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/scale
I1211 15:05:31.591238 15749 net.cpp:84] Creating Layer conv0_1/x1/scale
I1211 15:05:31.591241 15749 net.cpp:406] conv0_1/x1/scale <- conv0_1/x1/bn
I1211 15:05:31.591245 15749 net.cpp:367] conv0_1/x1/scale -> conv0_1/x1/bn (in-place)
I1211 15:05:31.591300 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/scale
I1211 15:05:31.591500 15749 net.cpp:122] Setting up conv0_1/x1/scale
I1211 15:05:31.591506 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.591508 15749 net.cpp:137] Memory required for data: 128465976
I1211 15:05:31.591517 15749 layer_factory.hpp:77] Creating layer relu0_1/x1
I1211 15:05:31.591524 15749 net.cpp:84] Creating Layer relu0_1/x1
I1211 15:05:31.591531 15749 net.cpp:406] relu0_1/x1 <- conv0_1/x1/bn
I1211 15:05:31.591536 15749 net.cpp:367] relu0_1/x1 -> conv0_1/x1/bn (in-place)
I1211 15:05:31.591953 15749 net.cpp:122] Setting up relu0_1/x1
I1211 15:05:31.591964 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.591966 15749 net.cpp:137] Memory required for data: 136244280
I1211 15:05:31.591969 15749 layer_factory.hpp:77] Creating layer conv0_1/x1
I1211 15:05:31.591979 15749 net.cpp:84] Creating Layer conv0_1/x1
I1211 15:05:31.591982 15749 net.cpp:406] conv0_1/x1 <- conv0_1/x1/bn
I1211 15:05:31.591987 15749 net.cpp:380] conv0_1/x1 -> conv0_1/x1
I1211 15:05:31.594220 15749 net.cpp:122] Setting up conv0_1/x1
I1211 15:05:31.594249 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.594252 15749 net.cpp:137] Memory required for data: 151800888
I1211 15:05:31.594260 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/bn
I1211 15:05:31.594271 15749 net.cpp:84] Creating Layer conv0_1/x2/bn
I1211 15:05:31.594275 15749 net.cpp:406] conv0_1/x2/bn <- conv0_1/x1
I1211 15:05:31.594280 15749 net.cpp:380] conv0_1/x2/bn -> conv0_1/x2/bn
I1211 15:05:31.594596 15749 net.cpp:122] Setting up conv0_1/x2/bn
I1211 15:05:31.594604 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.594606 15749 net.cpp:137] Memory required for data: 167357496
I1211 15:05:31.594612 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/scale
I1211 15:05:31.594620 15749 net.cpp:84] Creating Layer conv0_1/x2/scale
I1211 15:05:31.594624 15749 net.cpp:406] conv0_1/x2/scale <- conv0_1/x2/bn
I1211 15:05:31.594626 15749 net.cpp:367] conv0_1/x2/scale -> conv0_1/x2/bn (in-place)
I1211 15:05:31.594678 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/scale
I1211 15:05:31.594861 15749 net.cpp:122] Setting up conv0_1/x2/scale
I1211 15:05:31.594868 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.594871 15749 net.cpp:137] Memory required for data: 182914104
I1211 15:05:31.594875 15749 layer_factory.hpp:77] Creating layer relu0_1/x2
I1211 15:05:31.594882 15749 net.cpp:84] Creating Layer relu0_1/x2
I1211 15:05:31.594883 15749 net.cpp:406] relu0_1/x2 <- conv0_1/x2/bn
I1211 15:05:31.594888 15749 net.cpp:367] relu0_1/x2 -> conv0_1/x2/bn (in-place)
I1211 15:05:31.595062 15749 net.cpp:122] Setting up relu0_1/x2
I1211 15:05:31.595068 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.595072 15749 net.cpp:137] Memory required for data: 198470712
I1211 15:05:31.595073 15749 layer_factory.hpp:77] Creating layer conv0_1/x2
I1211 15:05:31.595082 15749 net.cpp:84] Creating Layer conv0_1/x2
I1211 15:05:31.595085 15749 net.cpp:406] conv0_1/x2 <- conv0_1/x2/bn
I1211 15:05:31.595090 15749 net.cpp:380] conv0_1/x2 -> conv0_1/x2
I1211 15:05:31.597971 15749 net.cpp:122] Setting up conv0_1/x2
I1211 15:05:31.597995 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.597997 15749 net.cpp:137] Memory required for data: 202359864
I1211 15:05:31.598004 15749 layer_factory.hpp:77] Creating layer concat0_1
I1211 15:05:31.598013 15749 net.cpp:84] Creating Layer concat0_1
I1211 15:05:31.598017 15749 net.cpp:406] concat0_1 <- concat0_0_concat0_0_0_split_1
I1211 15:05:31.598022 15749 net.cpp:406] concat0_1 <- conv0_1/x2
I1211 15:05:31.598026 15749 net.cpp:380] concat0_1 -> concat0_1
I1211 15:05:31.598067 15749 net.cpp:122] Setting up concat0_1
I1211 15:05:31.598073 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.598076 15749 net.cpp:137] Memory required for data: 214027320
I1211 15:05:31.598078 15749 layer_factory.hpp:77] Creating layer concat0_1_concat0_1_0_split
I1211 15:05:31.598084 15749 net.cpp:84] Creating Layer concat0_1_concat0_1_0_split
I1211 15:05:31.598086 15749 net.cpp:406] concat0_1_concat0_1_0_split <- concat0_1
I1211 15:05:31.598090 15749 net.cpp:380] concat0_1_concat0_1_0_split -> concat0_1_concat0_1_0_split_0
I1211 15:05:31.598095 15749 net.cpp:380] concat0_1_concat0_1_0_split -> concat0_1_concat0_1_0_split_1
I1211 15:05:31.598142 15749 net.cpp:122] Setting up concat0_1_concat0_1_0_split
I1211 15:05:31.598152 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.598155 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.598157 15749 net.cpp:137] Memory required for data: 237362232
I1211 15:05:31.598160 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/bn
I1211 15:05:31.598165 15749 net.cpp:84] Creating Layer conv0_2/x1/bn
I1211 15:05:31.598168 15749 net.cpp:406] conv0_2/x1/bn <- concat0_1_concat0_1_0_split_0
I1211 15:05:31.598172 15749 net.cpp:380] conv0_2/x1/bn -> conv0_2/x1/bn
I1211 15:05:31.598476 15749 net.cpp:122] Setting up conv0_2/x1/bn
I1211 15:05:31.598482 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.598485 15749 net.cpp:137] Memory required for data: 249029688
I1211 15:05:31.598491 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/scale
I1211 15:05:31.598498 15749 net.cpp:84] Creating Layer conv0_2/x1/scale
I1211 15:05:31.598501 15749 net.cpp:406] conv0_2/x1/scale <- conv0_2/x1/bn
I1211 15:05:31.598505 15749 net.cpp:367] conv0_2/x1/scale -> conv0_2/x1/bn (in-place)
I1211 15:05:31.598556 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/scale
I1211 15:05:31.598747 15749 net.cpp:122] Setting up conv0_2/x1/scale
I1211 15:05:31.598752 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.598755 15749 net.cpp:137] Memory required for data: 260697144
I1211 15:05:31.598759 15749 layer_factory.hpp:77] Creating layer relu0_2/x1
I1211 15:05:31.598765 15749 net.cpp:84] Creating Layer relu0_2/x1
I1211 15:05:31.598767 15749 net.cpp:406] relu0_2/x1 <- conv0_2/x1/bn
I1211 15:05:31.598772 15749 net.cpp:367] relu0_2/x1 -> conv0_2/x1/bn (in-place)
I1211 15:05:31.599112 15749 net.cpp:122] Setting up relu0_2/x1
I1211 15:05:31.599123 15749 net.cpp:129] Top shape: 1 96 72 422 (2916864)
I1211 15:05:31.599125 15749 net.cpp:137] Memory required for data: 272364600
I1211 15:05:31.599128 15749 layer_factory.hpp:77] Creating layer conv0_2/x1
I1211 15:05:31.599138 15749 net.cpp:84] Creating Layer conv0_2/x1
I1211 15:05:31.599140 15749 net.cpp:406] conv0_2/x1 <- conv0_2/x1/bn
I1211 15:05:31.599145 15749 net.cpp:380] conv0_2/x1 -> conv0_2/x1
I1211 15:05:31.600713 15749 net.cpp:122] Setting up conv0_2/x1
I1211 15:05:31.600726 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.600729 15749 net.cpp:137] Memory required for data: 287921208
I1211 15:05:31.600734 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/bn
I1211 15:05:31.600740 15749 net.cpp:84] Creating Layer conv0_2/x2/bn
I1211 15:05:31.600744 15749 net.cpp:406] conv0_2/x2/bn <- conv0_2/x1
I1211 15:05:31.600749 15749 net.cpp:380] conv0_2/x2/bn -> conv0_2/x2/bn
I1211 15:05:31.601053 15749 net.cpp:122] Setting up conv0_2/x2/bn
I1211 15:05:31.601060 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.601063 15749 net.cpp:137] Memory required for data: 303477816
I1211 15:05:31.601073 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/scale
I1211 15:05:31.601079 15749 net.cpp:84] Creating Layer conv0_2/x2/scale
I1211 15:05:31.601083 15749 net.cpp:406] conv0_2/x2/scale <- conv0_2/x2/bn
I1211 15:05:31.601086 15749 net.cpp:367] conv0_2/x2/scale -> conv0_2/x2/bn (in-place)
I1211 15:05:31.601137 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/scale
I1211 15:05:31.601318 15749 net.cpp:122] Setting up conv0_2/x2/scale
I1211 15:05:31.601325 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.601327 15749 net.cpp:137] Memory required for data: 319034424
I1211 15:05:31.601331 15749 layer_factory.hpp:77] Creating layer relu0_2/x2
I1211 15:05:31.601338 15749 net.cpp:84] Creating Layer relu0_2/x2
I1211 15:05:31.601341 15749 net.cpp:406] relu0_2/x2 <- conv0_2/x2/bn
I1211 15:05:31.601344 15749 net.cpp:367] relu0_2/x2 -> conv0_2/x2/bn (in-place)
I1211 15:05:31.601689 15749 net.cpp:122] Setting up relu0_2/x2
I1211 15:05:31.601699 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.601702 15749 net.cpp:137] Memory required for data: 334591032
I1211 15:05:31.601706 15749 layer_factory.hpp:77] Creating layer conv0_2/x2
I1211 15:05:31.601719 15749 net.cpp:84] Creating Layer conv0_2/x2
I1211 15:05:31.601723 15749 net.cpp:406] conv0_2/x2 <- conv0_2/x2/bn
I1211 15:05:31.601727 15749 net.cpp:380] conv0_2/x2 -> conv0_2/x2
I1211 15:05:31.612390 15749 net.cpp:122] Setting up conv0_2/x2
I1211 15:05:31.612426 15749 net.cpp:129] Top shape: 1 32 72 422 (972288)
I1211 15:05:31.612431 15749 net.cpp:137] Memory required for data: 338480184
I1211 15:05:31.612442 15749 layer_factory.hpp:77] Creating layer concat0_2
I1211 15:05:31.612457 15749 net.cpp:84] Creating Layer concat0_2
I1211 15:05:31.612463 15749 net.cpp:406] concat0_2 <- concat0_1_concat0_1_0_split_1
I1211 15:05:31.612470 15749 net.cpp:406] concat0_2 <- conv0_2/x2
I1211 15:05:31.612478 15749 net.cpp:380] concat0_2 -> concat0_2
I1211 15:05:31.612534 15749 net.cpp:122] Setting up concat0_2
I1211 15:05:31.612541 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.612545 15749 net.cpp:137] Memory required for data: 354036792
I1211 15:05:31.612550 15749 layer_factory.hpp:77] Creating layer BatchNorm1
I1211 15:05:31.612557 15749 net.cpp:84] Creating Layer BatchNorm1
I1211 15:05:31.612562 15749 net.cpp:406] BatchNorm1 <- concat0_2
I1211 15:05:31.612570 15749 net.cpp:380] BatchNorm1 -> BatchNorm1
I1211 15:05:31.632721 15749 net.cpp:122] Setting up BatchNorm1
I1211 15:05:31.632757 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.632761 15749 net.cpp:137] Memory required for data: 369593400
I1211 15:05:31.632776 15749 layer_factory.hpp:77] Creating layer Scale1
I1211 15:05:31.632789 15749 net.cpp:84] Creating Layer Scale1
I1211 15:05:31.632796 15749 net.cpp:406] Scale1 <- BatchNorm1
I1211 15:05:31.632804 15749 net.cpp:367] Scale1 -> BatchNorm1 (in-place)
I1211 15:05:31.632884 15749 layer_factory.hpp:77] Creating layer Scale1
I1211 15:05:31.633147 15749 net.cpp:122] Setting up Scale1
I1211 15:05:31.633155 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.633159 15749 net.cpp:137] Memory required for data: 385150008
I1211 15:05:31.633167 15749 layer_factory.hpp:77] Creating layer ReLU1
I1211 15:05:31.633174 15749 net.cpp:84] Creating Layer ReLU1
I1211 15:05:31.633178 15749 net.cpp:406] ReLU1 <- BatchNorm1
I1211 15:05:31.633184 15749 net.cpp:367] ReLU1 -> BatchNorm1 (in-place)
I1211 15:05:31.633476 15749 net.cpp:122] Setting up ReLU1
I1211 15:05:31.633487 15749 net.cpp:129] Top shape: 1 128 72 422 (3889152)
I1211 15:05:31.633491 15749 net.cpp:137] Memory required for data: 400706616
I1211 15:05:31.633496 15749 layer_factory.hpp:77] Creating layer conv0_blk
I1211 15:05:31.633509 15749 net.cpp:84] Creating Layer conv0_blk
I1211 15:05:31.633513 15749 net.cpp:406] conv0_blk <- BatchNorm1
I1211 15:05:31.633522 15749 net.cpp:380] conv0_blk -> conv0_blk
I1211 15:05:31.635732 15749 net.cpp:122] Setting up conv0_blk
I1211 15:05:31.694567 15749 net.cpp:129] Top shape: 1 64 72 422 (1944576)
I1211 15:05:31.694594 15749 net.cpp:137] Memory required for data: 408484920
I1211 15:05:31.694607 15749 layer_factory.hpp:77] Creating layer pool0
I1211 15:05:31.694620 15749 net.cpp:84] Creating Layer pool0
I1211 15:05:31.694627 15749 net.cpp:406] pool0 <- conv0_blk
I1211 15:05:31.694635 15749 net.cpp:380] pool0 -> pool0
I1211 15:05:31.695312 15749 net.cpp:122] Setting up pool0
I1211 15:05:31.695327 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.695333 15749 net.cpp:137] Memory required for data: 410429496
I1211 15:05:31.695336 15749 layer_factory.hpp:77] Creating layer pool0_pool0_0_split
I1211 15:05:31.695343 15749 net.cpp:84] Creating Layer pool0_pool0_0_split
I1211 15:05:31.695348 15749 net.cpp:406] pool0_pool0_0_split <- pool0
I1211 15:05:31.695354 15749 net.cpp:380] pool0_pool0_0_split -> pool0_pool0_0_split_0
I1211 15:05:31.695361 15749 net.cpp:380] pool0_pool0_0_split -> pool0_pool0_0_split_1
I1211 15:05:31.695436 15749 net.cpp:122] Setting up pool0_pool0_0_split
I1211 15:05:31.695444 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.695451 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.695453 15749 net.cpp:137] Memory required for data: 414318648
I1211 15:05:31.695461 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/bn
I1211 15:05:31.695469 15749 net.cpp:84] Creating Layer conv1_0/x1/bn
I1211 15:05:31.695473 15749 net.cpp:406] conv1_0/x1/bn <- pool0_pool0_0_split_0
I1211 15:05:31.695482 15749 net.cpp:380] conv1_0/x1/bn -> conv1_0/x1/bn
I1211 15:05:31.695917 15749 net.cpp:122] Setting up conv1_0/x1/bn
I1211 15:05:31.695927 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.695931 15749 net.cpp:137] Memory required for data: 416263224
I1211 15:05:31.695942 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/scale
I1211 15:05:31.695952 15749 net.cpp:84] Creating Layer conv1_0/x1/scale
I1211 15:05:31.695957 15749 net.cpp:406] conv1_0/x1/scale <- conv1_0/x1/bn
I1211 15:05:31.695962 15749 net.cpp:367] conv1_0/x1/scale -> conv1_0/x1/bn (in-place)
I1211 15:05:31.696038 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/scale
I1211 15:05:31.696270 15749 net.cpp:122] Setting up conv1_0/x1/scale
I1211 15:05:31.696280 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.696283 15749 net.cpp:137] Memory required for data: 418207800
I1211 15:05:31.696291 15749 layer_factory.hpp:77] Creating layer relu1_0/x1
I1211 15:05:31.696300 15749 net.cpp:84] Creating Layer relu1_0/x1
I1211 15:05:31.696303 15749 net.cpp:406] relu1_0/x1 <- conv1_0/x1/bn
I1211 15:05:31.696308 15749 net.cpp:367] relu1_0/x1 -> conv1_0/x1/bn (in-place)
I1211 15:05:31.696528 15749 net.cpp:122] Setting up relu1_0/x1
I1211 15:05:31.696539 15749 net.cpp:129] Top shape: 1 64 36 211 (486144)
I1211 15:05:31.696543 15749 net.cpp:137] Memory required for data: 420152376
I1211 15:05:31.696547 15749 layer_factory.hpp:77] Creating layer conv1_0/x1
I1211 15:05:31.696560 15749 net.cpp:84] Creating Layer conv1_0/x1
I1211 15:05:31.696564 15749 net.cpp:406] conv1_0/x1 <- conv1_0/x1/bn
I1211 15:05:31.696571 15749 net.cpp:380] conv1_0/x1 -> conv1_0/x1
I1211 15:05:31.698333 15749 net.cpp:122] Setting up conv1_0/x1
I1211 15:05:31.698348 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.698351 15749 net.cpp:137] Memory required for data: 424041528
I1211 15:05:31.698359 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/bn
I1211 15:05:31.698367 15749 net.cpp:84] Creating Layer conv1_0/x2/bn
I1211 15:05:31.698371 15749 net.cpp:406] conv1_0/x2/bn <- conv1_0/x1
I1211 15:05:31.698379 15749 net.cpp:380] conv1_0/x2/bn -> conv1_0/x2/bn
I1211 15:05:31.698770 15749 net.cpp:122] Setting up conv1_0/x2/bn
I1211 15:05:31.698777 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.698781 15749 net.cpp:137] Memory required for data: 427930680
I1211 15:05:31.698791 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/scale
I1211 15:05:31.698797 15749 net.cpp:84] Creating Layer conv1_0/x2/scale
I1211 15:05:31.698802 15749 net.cpp:406] conv1_0/x2/scale <- conv1_0/x2/bn
I1211 15:05:31.698810 15749 net.cpp:367] conv1_0/x2/scale -> conv1_0/x2/bn (in-place)
I1211 15:05:31.698881 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/scale
I1211 15:05:31.699098 15749 net.cpp:122] Setting up conv1_0/x2/scale
I1211 15:05:31.699107 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.699111 15749 net.cpp:137] Memory required for data: 431819832
I1211 15:05:31.699118 15749 layer_factory.hpp:77] Creating layer relu1_0/x2
I1211 15:05:31.699124 15749 net.cpp:84] Creating Layer relu1_0/x2
I1211 15:05:31.699129 15749 net.cpp:406] relu1_0/x2 <- conv1_0/x2/bn
I1211 15:05:31.699134 15749 net.cpp:367] relu1_0/x2 -> conv1_0/x2/bn (in-place)
I1211 15:05:31.699545 15749 net.cpp:122] Setting up relu1_0/x2
I1211 15:05:31.699559 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.699563 15749 net.cpp:137] Memory required for data: 435708984
I1211 15:05:31.699568 15749 layer_factory.hpp:77] Creating layer conv1_0/x2
I1211 15:05:31.699579 15749 net.cpp:84] Creating Layer conv1_0/x2
I1211 15:05:31.699584 15749 net.cpp:406] conv1_0/x2 <- conv1_0/x2/bn
I1211 15:05:31.699590 15749 net.cpp:380] conv1_0/x2 -> conv1_0/x2
I1211 15:05:31.728193 15749 net.cpp:122] Setting up conv1_0/x2
I1211 15:05:31.728233 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.728238 15749 net.cpp:137] Memory required for data: 436681272
I1211 15:05:31.728250 15749 layer_factory.hpp:77] Creating layer concat1_0
I1211 15:05:31.728265 15749 net.cpp:84] Creating Layer concat1_0
I1211 15:05:31.728271 15749 net.cpp:406] concat1_0 <- pool0_pool0_0_split_1
I1211 15:05:31.728278 15749 net.cpp:406] concat1_0 <- conv1_0/x2
I1211 15:05:31.728286 15749 net.cpp:380] concat1_0 -> concat1_0
I1211 15:05:31.728350 15749 net.cpp:122] Setting up concat1_0
I1211 15:05:31.728358 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.728363 15749 net.cpp:137] Memory required for data: 439598136
I1211 15:05:31.728366 15749 layer_factory.hpp:77] Creating layer concat1_0_concat1_0_0_split
I1211 15:05:31.728374 15749 net.cpp:84] Creating Layer concat1_0_concat1_0_0_split
I1211 15:05:31.728379 15749 net.cpp:406] concat1_0_concat1_0_0_split <- concat1_0
I1211 15:05:31.728384 15749 net.cpp:380] concat1_0_concat1_0_0_split -> concat1_0_concat1_0_0_split_0
I1211 15:05:31.728392 15749 net.cpp:380] concat1_0_concat1_0_0_split -> concat1_0_concat1_0_0_split_1
I1211 15:05:31.728461 15749 net.cpp:122] Setting up concat1_0_concat1_0_0_split
I1211 15:05:31.728468 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.728473 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.728477 15749 net.cpp:137] Memory required for data: 445431864
I1211 15:05:31.728482 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/bn
I1211 15:05:31.728489 15749 net.cpp:84] Creating Layer conv1_1/x1/bn
I1211 15:05:31.728493 15749 net.cpp:406] conv1_1/x1/bn <- concat1_0_concat1_0_0_split_0
I1211 15:05:31.728500 15749 net.cpp:380] conv1_1/x1/bn -> conv1_1/x1/bn
I1211 15:05:31.728941 15749 net.cpp:122] Setting up conv1_1/x1/bn
I1211 15:05:31.728950 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.728955 15749 net.cpp:137] Memory required for data: 448348728
I1211 15:05:31.728966 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/scale
I1211 15:05:31.728976 15749 net.cpp:84] Creating Layer conv1_1/x1/scale
I1211 15:05:31.728981 15749 net.cpp:406] conv1_1/x1/scale <- conv1_1/x1/bn
I1211 15:05:31.728986 15749 net.cpp:367] conv1_1/x1/scale -> conv1_1/x1/bn (in-place)
I1211 15:05:31.729061 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/scale
I1211 15:05:31.729301 15749 net.cpp:122] Setting up conv1_1/x1/scale
I1211 15:05:31.729310 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.729315 15749 net.cpp:137] Memory required for data: 451265592
I1211 15:05:31.729321 15749 layer_factory.hpp:77] Creating layer relu1_1/x1
I1211 15:05:31.729329 15749 net.cpp:84] Creating Layer relu1_1/x1
I1211 15:05:31.729333 15749 net.cpp:406] relu1_1/x1 <- conv1_1/x1/bn
I1211 15:05:31.729341 15749 net.cpp:367] relu1_1/x1 -> conv1_1/x1/bn (in-place)
I1211 15:05:31.729907 15749 net.cpp:122] Setting up relu1_1/x1
I1211 15:05:31.729925 15749 net.cpp:129] Top shape: 1 96 36 211 (729216)
I1211 15:05:31.729930 15749 net.cpp:137] Memory required for data: 454182456
I1211 15:05:31.729935 15749 layer_factory.hpp:77] Creating layer conv1_1/x1
I1211 15:05:31.729950 15749 net.cpp:84] Creating Layer conv1_1/x1
I1211 15:05:31.729955 15749 net.cpp:406] conv1_1/x1 <- conv1_1/x1/bn
I1211 15:05:31.729964 15749 net.cpp:380] conv1_1/x1 -> conv1_1/x1
I1211 15:05:31.801384 15749 net.cpp:122] Setting up conv1_1/x1
I1211 15:05:31.801421 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.801425 15749 net.cpp:137] Memory required for data: 458071608
I1211 15:05:31.801436 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/bn
I1211 15:05:31.801450 15749 net.cpp:84] Creating Layer conv1_1/x2/bn
I1211 15:05:31.801455 15749 net.cpp:406] conv1_1/x2/bn <- conv1_1/x1
I1211 15:05:31.801465 15749 net.cpp:380] conv1_1/x2/bn -> conv1_1/x2/bn
I1211 15:05:31.801877 15749 net.cpp:122] Setting up conv1_1/x2/bn
I1211 15:05:31.801887 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.801895 15749 net.cpp:137] Memory required for data: 461960760
I1211 15:05:31.801905 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/scale
I1211 15:05:31.801915 15749 net.cpp:84] Creating Layer conv1_1/x2/scale
I1211 15:05:31.801919 15749 net.cpp:406] conv1_1/x2/scale <- conv1_1/x2/bn
I1211 15:05:31.801928 15749 net.cpp:367] conv1_1/x2/scale -> conv1_1/x2/bn (in-place)
I1211 15:05:31.802006 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/scale
I1211 15:05:31.802245 15749 net.cpp:122] Setting up conv1_1/x2/scale
I1211 15:05:31.802254 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.802258 15749 net.cpp:137] Memory required for data: 465849912
I1211 15:05:31.802273 15749 layer_factory.hpp:77] Creating layer relu1_1/x2
I1211 15:05:31.802281 15749 net.cpp:84] Creating Layer relu1_1/x2
I1211 15:05:31.802285 15749 net.cpp:406] relu1_1/x2 <- conv1_1/x2/bn
I1211 15:05:31.802291 15749 net.cpp:367] relu1_1/x2 -> conv1_1/x2/bn (in-place)
I1211 15:05:31.802530 15749 net.cpp:122] Setting up relu1_1/x2
I1211 15:05:31.802541 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.802544 15749 net.cpp:137] Memory required for data: 469739064
I1211 15:05:31.802548 15749 layer_factory.hpp:77] Creating layer conv1_1/x2
I1211 15:05:31.802562 15749 net.cpp:84] Creating Layer conv1_1/x2
I1211 15:05:31.802567 15749 net.cpp:406] conv1_1/x2 <- conv1_1/x2/bn
I1211 15:05:31.802574 15749 net.cpp:380] conv1_1/x2 -> conv1_1/x2
I1211 15:05:31.805896 15749 net.cpp:122] Setting up conv1_1/x2
I1211 15:05:31.805932 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.805936 15749 net.cpp:137] Memory required for data: 470711352
I1211 15:05:31.805946 15749 layer_factory.hpp:77] Creating layer concat1_1
I1211 15:05:31.805960 15749 net.cpp:84] Creating Layer concat1_1
I1211 15:05:31.805968 15749 net.cpp:406] concat1_1 <- concat1_0_concat1_0_0_split_1
I1211 15:05:31.805975 15749 net.cpp:406] concat1_1 <- conv1_1/x2
I1211 15:05:31.805982 15749 net.cpp:380] concat1_1 -> concat1_1
I1211 15:05:31.806041 15749 net.cpp:122] Setting up concat1_1
I1211 15:05:31.806049 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.806053 15749 net.cpp:137] Memory required for data: 474600504
I1211 15:05:31.806057 15749 layer_factory.hpp:77] Creating layer concat1_1_concat1_1_0_split
I1211 15:05:31.806064 15749 net.cpp:84] Creating Layer concat1_1_concat1_1_0_split
I1211 15:05:31.806068 15749 net.cpp:406] concat1_1_concat1_1_0_split <- concat1_1
I1211 15:05:31.806076 15749 net.cpp:380] concat1_1_concat1_1_0_split -> concat1_1_concat1_1_0_split_0
I1211 15:05:31.806082 15749 net.cpp:380] concat1_1_concat1_1_0_split -> concat1_1_concat1_1_0_split_1
I1211 15:05:31.806151 15749 net.cpp:122] Setting up concat1_1_concat1_1_0_split
I1211 15:05:31.806159 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.806164 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.806169 15749 net.cpp:137] Memory required for data: 482378808
I1211 15:05:31.806171 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/bn
I1211 15:05:31.806180 15749 net.cpp:84] Creating Layer conv1_2/x1/bn
I1211 15:05:31.806185 15749 net.cpp:406] conv1_2/x1/bn <- concat1_1_concat1_1_0_split_0
I1211 15:05:31.806191 15749 net.cpp:380] conv1_2/x1/bn -> conv1_2/x1/bn
I1211 15:05:31.806607 15749 net.cpp:122] Setting up conv1_2/x1/bn
I1211 15:05:31.806615 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.806619 15749 net.cpp:137] Memory required for data: 486267960
I1211 15:05:31.806629 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/scale
I1211 15:05:31.806639 15749 net.cpp:84] Creating Layer conv1_2/x1/scale
I1211 15:05:31.806644 15749 net.cpp:406] conv1_2/x1/scale <- conv1_2/x1/bn
I1211 15:05:31.806650 15749 net.cpp:367] conv1_2/x1/scale -> conv1_2/x1/bn (in-place)
I1211 15:05:31.806727 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/scale
I1211 15:05:31.806951 15749 net.cpp:122] Setting up conv1_2/x1/scale
I1211 15:05:31.806960 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.806964 15749 net.cpp:137] Memory required for data: 490157112
I1211 15:05:31.806977 15749 layer_factory.hpp:77] Creating layer relu1_2/x1
I1211 15:05:31.806985 15749 net.cpp:84] Creating Layer relu1_2/x1
I1211 15:05:31.806989 15749 net.cpp:406] relu1_2/x1 <- conv1_2/x1/bn
I1211 15:05:31.806995 15749 net.cpp:367] relu1_2/x1 -> conv1_2/x1/bn (in-place)
I1211 15:05:31.807435 15749 net.cpp:122] Setting up relu1_2/x1
I1211 15:05:31.807448 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.807452 15749 net.cpp:137] Memory required for data: 494046264
I1211 15:05:31.807457 15749 layer_factory.hpp:77] Creating layer conv1_2/x1
I1211 15:05:31.807471 15749 net.cpp:84] Creating Layer conv1_2/x1
I1211 15:05:31.807476 15749 net.cpp:406] conv1_2/x1 <- conv1_2/x1/bn
I1211 15:05:31.807482 15749 net.cpp:380] conv1_2/x1 -> conv1_2/x1
I1211 15:05:31.809598 15749 net.cpp:122] Setting up conv1_2/x1
I1211 15:05:31.809613 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.809617 15749 net.cpp:137] Memory required for data: 497935416
I1211 15:05:31.809624 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/bn
I1211 15:05:31.809635 15749 net.cpp:84] Creating Layer conv1_2/x2/bn
I1211 15:05:31.809640 15749 net.cpp:406] conv1_2/x2/bn <- conv1_2/x1
I1211 15:05:31.809648 15749 net.cpp:380] conv1_2/x2/bn -> conv1_2/x2/bn
I1211 15:05:31.810052 15749 net.cpp:122] Setting up conv1_2/x2/bn
I1211 15:05:31.810061 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.810065 15749 net.cpp:137] Memory required for data: 501824568
I1211 15:05:31.810075 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/scale
I1211 15:05:31.810088 15749 net.cpp:84] Creating Layer conv1_2/x2/scale
I1211 15:05:31.810093 15749 net.cpp:406] conv1_2/x2/scale <- conv1_2/x2/bn
I1211 15:05:31.810099 15749 net.cpp:367] conv1_2/x2/scale -> conv1_2/x2/bn (in-place)
I1211 15:05:31.810173 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/scale
I1211 15:05:31.810397 15749 net.cpp:122] Setting up conv1_2/x2/scale
I1211 15:05:31.810406 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.810410 15749 net.cpp:137] Memory required for data: 505713720
I1211 15:05:31.810418 15749 layer_factory.hpp:77] Creating layer relu1_2/x2
I1211 15:05:31.810425 15749 net.cpp:84] Creating Layer relu1_2/x2
I1211 15:05:31.810430 15749 net.cpp:406] relu1_2/x2 <- conv1_2/x2/bn
I1211 15:05:31.810436 15749 net.cpp:367] relu1_2/x2 -> conv1_2/x2/bn (in-place)
I1211 15:05:31.810657 15749 net.cpp:122] Setting up relu1_2/x2
I1211 15:05:31.810667 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.810672 15749 net.cpp:137] Memory required for data: 509602872
I1211 15:05:31.810676 15749 layer_factory.hpp:77] Creating layer conv1_2/x2
I1211 15:05:31.810688 15749 net.cpp:84] Creating Layer conv1_2/x2
I1211 15:05:31.810693 15749 net.cpp:406] conv1_2/x2 <- conv1_2/x2/bn
I1211 15:05:31.810698 15749 net.cpp:380] conv1_2/x2 -> conv1_2/x2
I1211 15:05:31.813691 15749 net.cpp:122] Setting up conv1_2/x2
I1211 15:05:31.813707 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.813711 15749 net.cpp:137] Memory required for data: 510575160
I1211 15:05:31.813719 15749 layer_factory.hpp:77] Creating layer concat1_2
I1211 15:05:31.813726 15749 net.cpp:84] Creating Layer concat1_2
I1211 15:05:31.813732 15749 net.cpp:406] concat1_2 <- concat1_1_concat1_1_0_split_1
I1211 15:05:31.813738 15749 net.cpp:406] concat1_2 <- conv1_2/x2
I1211 15:05:31.813745 15749 net.cpp:380] concat1_2 -> concat1_2
I1211 15:05:31.813797 15749 net.cpp:122] Setting up concat1_2
I1211 15:05:31.813805 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.813809 15749 net.cpp:137] Memory required for data: 515436600
I1211 15:05:31.813813 15749 layer_factory.hpp:77] Creating layer concat1_2_concat1_2_0_split
I1211 15:05:31.813820 15749 net.cpp:84] Creating Layer concat1_2_concat1_2_0_split
I1211 15:05:31.813824 15749 net.cpp:406] concat1_2_concat1_2_0_split <- concat1_2
I1211 15:05:31.813833 15749 net.cpp:380] concat1_2_concat1_2_0_split -> concat1_2_concat1_2_0_split_0
I1211 15:05:31.813844 15749 net.cpp:380] concat1_2_concat1_2_0_split -> concat1_2_concat1_2_0_split_1
I1211 15:05:31.813917 15749 net.cpp:122] Setting up concat1_2_concat1_2_0_split
I1211 15:05:31.813925 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.813930 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.813935 15749 net.cpp:137] Memory required for data: 525159480
I1211 15:05:31.813938 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/bn
I1211 15:05:31.813944 15749 net.cpp:84] Creating Layer conv1_3/x1/bn
I1211 15:05:31.813949 15749 net.cpp:406] conv1_3/x1/bn <- concat1_2_concat1_2_0_split_0
I1211 15:05:31.813956 15749 net.cpp:380] conv1_3/x1/bn -> conv1_3/x1/bn
I1211 15:05:31.814386 15749 net.cpp:122] Setting up conv1_3/x1/bn
I1211 15:05:31.814394 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.814399 15749 net.cpp:137] Memory required for data: 530020920
I1211 15:05:31.814407 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/scale
I1211 15:05:31.814417 15749 net.cpp:84] Creating Layer conv1_3/x1/scale
I1211 15:05:31.814421 15749 net.cpp:406] conv1_3/x1/scale <- conv1_3/x1/bn
I1211 15:05:31.814427 15749 net.cpp:367] conv1_3/x1/scale -> conv1_3/x1/bn (in-place)
I1211 15:05:31.814502 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/scale
I1211 15:05:31.814744 15749 net.cpp:122] Setting up conv1_3/x1/scale
I1211 15:05:31.814754 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.814757 15749 net.cpp:137] Memory required for data: 534882360
I1211 15:05:31.814764 15749 layer_factory.hpp:77] Creating layer relu1_3/x1
I1211 15:05:31.814771 15749 net.cpp:84] Creating Layer relu1_3/x1
I1211 15:05:31.814775 15749 net.cpp:406] relu1_3/x1 <- conv1_3/x1/bn
I1211 15:05:31.814781 15749 net.cpp:367] relu1_3/x1 -> conv1_3/x1/bn (in-place)
I1211 15:05:31.815210 15749 net.cpp:122] Setting up relu1_3/x1
I1211 15:05:31.815223 15749 net.cpp:129] Top shape: 1 160 36 211 (1215360)
I1211 15:05:31.815227 15749 net.cpp:137] Memory required for data: 539743800
I1211 15:05:31.815232 15749 layer_factory.hpp:77] Creating layer conv1_3/x1
I1211 15:05:31.815243 15749 net.cpp:84] Creating Layer conv1_3/x1
I1211 15:05:31.815248 15749 net.cpp:406] conv1_3/x1 <- conv1_3/x1/bn
I1211 15:05:31.815255 15749 net.cpp:380] conv1_3/x1 -> conv1_3/x1
I1211 15:05:31.826031 15749 net.cpp:122] Setting up conv1_3/x1
I1211 15:05:31.826066 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.826071 15749 net.cpp:137] Memory required for data: 543632952
I1211 15:05:31.826081 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/bn
I1211 15:05:31.826094 15749 net.cpp:84] Creating Layer conv1_3/x2/bn
I1211 15:05:31.826100 15749 net.cpp:406] conv1_3/x2/bn <- conv1_3/x1
I1211 15:05:31.826110 15749 net.cpp:380] conv1_3/x2/bn -> conv1_3/x2/bn
I1211 15:05:31.826562 15749 net.cpp:122] Setting up conv1_3/x2/bn
I1211 15:05:31.826571 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.826575 15749 net.cpp:137] Memory required for data: 547522104
I1211 15:05:31.826586 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/scale
I1211 15:05:31.826596 15749 net.cpp:84] Creating Layer conv1_3/x2/scale
I1211 15:05:31.826601 15749 net.cpp:406] conv1_3/x2/scale <- conv1_3/x2/bn
I1211 15:05:31.826606 15749 net.cpp:367] conv1_3/x2/scale -> conv1_3/x2/bn (in-place)
I1211 15:05:31.826684 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/scale
I1211 15:05:31.826920 15749 net.cpp:122] Setting up conv1_3/x2/scale
I1211 15:05:31.826928 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.826932 15749 net.cpp:137] Memory required for data: 551411256
I1211 15:05:31.826939 15749 layer_factory.hpp:77] Creating layer relu1_3/x2
I1211 15:05:31.826947 15749 net.cpp:84] Creating Layer relu1_3/x2
I1211 15:05:31.826951 15749 net.cpp:406] relu1_3/x2 <- conv1_3/x2/bn
I1211 15:05:31.826956 15749 net.cpp:367] relu1_3/x2 -> conv1_3/x2/bn (in-place)
I1211 15:05:31.827385 15749 net.cpp:122] Setting up relu1_3/x2
I1211 15:05:31.827399 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.827409 15749 net.cpp:137] Memory required for data: 555300408
I1211 15:05:31.827412 15749 layer_factory.hpp:77] Creating layer conv1_3/x2
I1211 15:05:31.827425 15749 net.cpp:84] Creating Layer conv1_3/x2
I1211 15:05:31.827430 15749 net.cpp:406] conv1_3/x2 <- conv1_3/x2/bn
I1211 15:05:31.827438 15749 net.cpp:380] conv1_3/x2 -> conv1_3/x2
I1211 15:05:31.876170 15749 net.cpp:122] Setting up conv1_3/x2
I1211 15:05:31.876205 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.876210 15749 net.cpp:137] Memory required for data: 556272696
I1211 15:05:31.876221 15749 layer_factory.hpp:77] Creating layer concat1_3
I1211 15:05:31.876235 15749 net.cpp:84] Creating Layer concat1_3
I1211 15:05:31.876241 15749 net.cpp:406] concat1_3 <- concat1_2_concat1_2_0_split_1
I1211 15:05:31.876250 15749 net.cpp:406] concat1_3 <- conv1_3/x2
I1211 15:05:31.876260 15749 net.cpp:380] concat1_3 -> concat1_3
I1211 15:05:31.876317 15749 net.cpp:122] Setting up concat1_3
I1211 15:05:31.876325 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.876329 15749 net.cpp:137] Memory required for data: 562106424
I1211 15:05:31.876333 15749 layer_factory.hpp:77] Creating layer concat1_3_concat1_3_0_split
I1211 15:05:31.876341 15749 net.cpp:84] Creating Layer concat1_3_concat1_3_0_split
I1211 15:05:31.876345 15749 net.cpp:406] concat1_3_concat1_3_0_split <- concat1_3
I1211 15:05:31.876351 15749 net.cpp:380] concat1_3_concat1_3_0_split -> concat1_3_concat1_3_0_split_0
I1211 15:05:31.876358 15749 net.cpp:380] concat1_3_concat1_3_0_split -> concat1_3_concat1_3_0_split_1
I1211 15:05:31.876430 15749 net.cpp:122] Setting up concat1_3_concat1_3_0_split
I1211 15:05:31.876437 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.876442 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.876446 15749 net.cpp:137] Memory required for data: 573773880
I1211 15:05:31.876451 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/bn
I1211 15:05:31.876459 15749 net.cpp:84] Creating Layer conv1_4/x1/bn
I1211 15:05:31.876463 15749 net.cpp:406] conv1_4/x1/bn <- concat1_3_concat1_3_0_split_0
I1211 15:05:31.876469 15749 net.cpp:380] conv1_4/x1/bn -> conv1_4/x1/bn
I1211 15:05:31.876929 15749 net.cpp:122] Setting up conv1_4/x1/bn
I1211 15:05:31.876938 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.876942 15749 net.cpp:137] Memory required for data: 579607608
I1211 15:05:31.876953 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/scale
I1211 15:05:31.876963 15749 net.cpp:84] Creating Layer conv1_4/x1/scale
I1211 15:05:31.876967 15749 net.cpp:406] conv1_4/x1/scale <- conv1_4/x1/bn
I1211 15:05:31.876973 15749 net.cpp:367] conv1_4/x1/scale -> conv1_4/x1/bn (in-place)
I1211 15:05:31.877053 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/scale
I1211 15:05:31.898492 15749 net.cpp:122] Setting up conv1_4/x1/scale
I1211 15:05:31.898528 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.898533 15749 net.cpp:137] Memory required for data: 585441336
I1211 15:05:31.898545 15749 layer_factory.hpp:77] Creating layer relu1_4/x1
I1211 15:05:31.898560 15749 net.cpp:84] Creating Layer relu1_4/x1
I1211 15:05:31.898566 15749 net.cpp:406] relu1_4/x1 <- conv1_4/x1/bn
I1211 15:05:31.898578 15749 net.cpp:367] relu1_4/x1 -> conv1_4/x1/bn (in-place)
I1211 15:05:31.898895 15749 net.cpp:122] Setting up relu1_4/x1
I1211 15:05:31.898910 15749 net.cpp:129] Top shape: 1 192 36 211 (1458432)
I1211 15:05:31.898913 15749 net.cpp:137] Memory required for data: 591275064
I1211 15:05:31.898918 15749 layer_factory.hpp:77] Creating layer conv1_4/x1
I1211 15:05:31.898934 15749 net.cpp:84] Creating Layer conv1_4/x1
I1211 15:05:31.898939 15749 net.cpp:406] conv1_4/x1 <- conv1_4/x1/bn
I1211 15:05:31.898948 15749 net.cpp:380] conv1_4/x1 -> conv1_4/x1
I1211 15:05:31.902669 15749 net.cpp:122] Setting up conv1_4/x1
I1211 15:05:31.902709 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.902714 15749 net.cpp:137] Memory required for data: 595164216
I1211 15:05:31.902725 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/bn
I1211 15:05:31.902748 15749 net.cpp:84] Creating Layer conv1_4/x2/bn
I1211 15:05:31.902756 15749 net.cpp:406] conv1_4/x2/bn <- conv1_4/x1
I1211 15:05:31.902766 15749 net.cpp:380] conv1_4/x2/bn -> conv1_4/x2/bn
I1211 15:05:31.903264 15749 net.cpp:122] Setting up conv1_4/x2/bn
I1211 15:05:31.903282 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.903287 15749 net.cpp:137] Memory required for data: 599053368
I1211 15:05:31.903300 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/scale
I1211 15:05:31.903313 15749 net.cpp:84] Creating Layer conv1_4/x2/scale
I1211 15:05:31.903318 15749 net.cpp:406] conv1_4/x2/scale <- conv1_4/x2/bn
I1211 15:05:31.903326 15749 net.cpp:367] conv1_4/x2/scale -> conv1_4/x2/bn (in-place)
I1211 15:05:31.903415 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/scale
I1211 15:05:31.903666 15749 net.cpp:122] Setting up conv1_4/x2/scale
I1211 15:05:31.903677 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.903681 15749 net.cpp:137] Memory required for data: 602942520
I1211 15:05:31.903689 15749 layer_factory.hpp:77] Creating layer relu1_4/x2
I1211 15:05:31.903698 15749 net.cpp:84] Creating Layer relu1_4/x2
I1211 15:05:31.903703 15749 net.cpp:406] relu1_4/x2 <- conv1_4/x2/bn
I1211 15:05:31.903709 15749 net.cpp:367] relu1_4/x2 -> conv1_4/x2/bn (in-place)
I1211 15:05:31.904337 15749 net.cpp:122] Setting up relu1_4/x2
I1211 15:05:31.904358 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.904363 15749 net.cpp:137] Memory required for data: 606831672
I1211 15:05:31.904368 15749 layer_factory.hpp:77] Creating layer conv1_4/x2
I1211 15:05:31.904388 15749 net.cpp:84] Creating Layer conv1_4/x2
I1211 15:05:31.904395 15749 net.cpp:406] conv1_4/x2 <- conv1_4/x2/bn
I1211 15:05:31.904404 15749 net.cpp:380] conv1_4/x2 -> conv1_4/x2
I1211 15:05:31.907809 15749 net.cpp:122] Setting up conv1_4/x2
I1211 15:05:31.907845 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.907850 15749 net.cpp:137] Memory required for data: 607803960
I1211 15:05:31.907861 15749 layer_factory.hpp:77] Creating layer concat1_4
I1211 15:05:31.907876 15749 net.cpp:84] Creating Layer concat1_4
I1211 15:05:31.907882 15749 net.cpp:406] concat1_4 <- concat1_3_concat1_3_0_split_1
I1211 15:05:31.907891 15749 net.cpp:406] concat1_4 <- conv1_4/x2
I1211 15:05:31.907898 15749 net.cpp:380] concat1_4 -> concat1_4
I1211 15:05:31.907958 15749 net.cpp:122] Setting up concat1_4
I1211 15:05:31.907966 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.907970 15749 net.cpp:137] Memory required for data: 614609976
I1211 15:05:31.907974 15749 layer_factory.hpp:77] Creating layer concat1_4_concat1_4_0_split
I1211 15:05:31.907980 15749 net.cpp:84] Creating Layer concat1_4_concat1_4_0_split
I1211 15:05:31.907984 15749 net.cpp:406] concat1_4_concat1_4_0_split <- concat1_4
I1211 15:05:31.907992 15749 net.cpp:380] concat1_4_concat1_4_0_split -> concat1_4_concat1_4_0_split_0
I1211 15:05:31.908004 15749 net.cpp:380] concat1_4_concat1_4_0_split -> concat1_4_concat1_4_0_split_1
I1211 15:05:31.908077 15749 net.cpp:122] Setting up concat1_4_concat1_4_0_split
I1211 15:05:31.908087 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.908092 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.908097 15749 net.cpp:137] Memory required for data: 628222008
I1211 15:05:31.908100 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/bn
I1211 15:05:31.908107 15749 net.cpp:84] Creating Layer conv1_5/x1/bn
I1211 15:05:31.908112 15749 net.cpp:406] conv1_5/x1/bn <- concat1_4_concat1_4_0_split_0
I1211 15:05:31.908118 15749 net.cpp:380] conv1_5/x1/bn -> conv1_5/x1/bn
I1211 15:05:31.908592 15749 net.cpp:122] Setting up conv1_5/x1/bn
I1211 15:05:31.908602 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.908607 15749 net.cpp:137] Memory required for data: 635028024
I1211 15:05:31.908617 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/scale
I1211 15:05:31.908627 15749 net.cpp:84] Creating Layer conv1_5/x1/scale
I1211 15:05:31.908637 15749 net.cpp:406] conv1_5/x1/scale <- conv1_5/x1/bn
I1211 15:05:31.908643 15749 net.cpp:367] conv1_5/x1/scale -> conv1_5/x1/bn (in-place)
I1211 15:05:31.908725 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/scale
I1211 15:05:31.908979 15749 net.cpp:122] Setting up conv1_5/x1/scale
I1211 15:05:31.908988 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.908993 15749 net.cpp:137] Memory required for data: 641834040
I1211 15:05:31.908999 15749 layer_factory.hpp:77] Creating layer relu1_5/x1
I1211 15:05:31.909008 15749 net.cpp:84] Creating Layer relu1_5/x1
I1211 15:05:31.909013 15749 net.cpp:406] relu1_5/x1 <- conv1_5/x1/bn
I1211 15:05:31.909018 15749 net.cpp:367] relu1_5/x1 -> conv1_5/x1/bn (in-place)
I1211 15:05:31.909263 15749 net.cpp:122] Setting up relu1_5/x1
I1211 15:05:31.909274 15749 net.cpp:129] Top shape: 1 224 36 211 (1701504)
I1211 15:05:31.909278 15749 net.cpp:137] Memory required for data: 648640056
I1211 15:05:31.909282 15749 layer_factory.hpp:77] Creating layer conv1_5/x1
I1211 15:05:31.909296 15749 net.cpp:84] Creating Layer conv1_5/x1
I1211 15:05:31.909301 15749 net.cpp:406] conv1_5/x1 <- conv1_5/x1/bn
I1211 15:05:31.909308 15749 net.cpp:380] conv1_5/x1 -> conv1_5/x1
I1211 15:05:31.911998 15749 net.cpp:122] Setting up conv1_5/x1
I1211 15:05:31.912022 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.912027 15749 net.cpp:137] Memory required for data: 652529208
I1211 15:05:31.912036 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/bn
I1211 15:05:31.912047 15749 net.cpp:84] Creating Layer conv1_5/x2/bn
I1211 15:05:31.912052 15749 net.cpp:406] conv1_5/x2/bn <- conv1_5/x1
I1211 15:05:31.912060 15749 net.cpp:380] conv1_5/x2/bn -> conv1_5/x2/bn
I1211 15:05:31.912520 15749 net.cpp:122] Setting up conv1_5/x2/bn
I1211 15:05:31.912530 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.912534 15749 net.cpp:137] Memory required for data: 656418360
I1211 15:05:31.912544 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/scale
I1211 15:05:31.912554 15749 net.cpp:84] Creating Layer conv1_5/x2/scale
I1211 15:05:31.912559 15749 net.cpp:406] conv1_5/x2/scale <- conv1_5/x2/bn
I1211 15:05:31.912564 15749 net.cpp:367] conv1_5/x2/scale -> conv1_5/x2/bn (in-place)
I1211 15:05:31.912643 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/scale
I1211 15:05:31.912880 15749 net.cpp:122] Setting up conv1_5/x2/scale
I1211 15:05:31.912889 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.912892 15749 net.cpp:137] Memory required for data: 660307512
I1211 15:05:31.912900 15749 layer_factory.hpp:77] Creating layer relu1_5/x2
I1211 15:05:31.912907 15749 net.cpp:84] Creating Layer relu1_5/x2
I1211 15:05:31.912912 15749 net.cpp:406] relu1_5/x2 <- conv1_5/x2/bn
I1211 15:05:31.912917 15749 net.cpp:367] relu1_5/x2 -> conv1_5/x2/bn (in-place)
I1211 15:05:31.913375 15749 net.cpp:122] Setting up relu1_5/x2
I1211 15:05:31.913388 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.913393 15749 net.cpp:137] Memory required for data: 664196664
I1211 15:05:31.913398 15749 layer_factory.hpp:77] Creating layer conv1_5/x2
I1211 15:05:31.913410 15749 net.cpp:84] Creating Layer conv1_5/x2
I1211 15:05:31.913414 15749 net.cpp:406] conv1_5/x2 <- conv1_5/x2/bn
I1211 15:05:31.913424 15749 net.cpp:380] conv1_5/x2 -> conv1_5/x2
I1211 15:05:31.924914 15749 net.cpp:122] Setting up conv1_5/x2
I1211 15:05:31.924947 15749 net.cpp:129] Top shape: 1 32 36 211 (243072)
I1211 15:05:31.924952 15749 net.cpp:137] Memory required for data: 665168952
I1211 15:05:31.924962 15749 layer_factory.hpp:77] Creating layer concat1_5
I1211 15:05:31.924975 15749 net.cpp:84] Creating Layer concat1_5
I1211 15:05:31.924983 15749 net.cpp:406] concat1_5 <- concat1_4_concat1_4_0_split_1
I1211 15:05:31.924990 15749 net.cpp:406] concat1_5 <- conv1_5/x2
I1211 15:05:31.924998 15749 net.cpp:380] concat1_5 -> concat1_5
I1211 15:05:31.925057 15749 net.cpp:122] Setting up concat1_5
I1211 15:05:31.925066 15749 net.cpp:129] Top shape: 1 256 36 211 (1944576)
I1211 15:05:31.925071 15749 net.cpp:137] Memory required for data: 672947256
I1211 15:05:31.925078 15749 layer_factory.hpp:77] Creating layer BatchNorm2
I1211 15:05:31.925086 15749 net.cpp:84] Creating Layer BatchNorm2
I1211 15:05:31.925091 15749 net.cpp:406] BatchNorm2 <- concat1_5
I1211 15:05:31.925098 15749 net.cpp:380] BatchNorm2 -> BatchNorm2
I1211 15:05:31.925556 15749 net.cpp:122] Setting up BatchNorm2
I1211 15:05:31.941845 15749 net.cpp:129] Top shape: 1 256 36 211 (1944576)
I1211 15:05:31.941859 15749 net.cpp:137] Memory required for data: 680725560
I1211 15:05:31.941874 15749 layer_factory.hpp:77] Creating layer Scale2
I1211 15:05:31.941891 15749 net.cpp:84] Creating Layer Scale2
I1211 15:05:31.941897 15749 net.cpp:406] Scale2 <- BatchNorm2
I1211 15:05:31.941906 15749 net.cpp:367] Scale2 -> BatchNorm2 (in-place)
I1211 15:05:31.942085 15749 layer_factory.hpp:77] Creating layer Scale2
I1211 15:05:31.942363 15749 net.cpp:122] Setting up Scale2
I1211 15:05:31.942373 15749 net.cpp:129] Top shape: 1 256 36 211 (1944576)
I1211 15:05:31.942376 15749 net.cpp:137] Memory required for data: 688503864
I1211 15:05:31.942384 15749 layer_factory.hpp:77] Creating layer ReLU2
I1211 15:05:31.942391 15749 net.cpp:84] Creating Layer ReLU2
I1211 15:05:31.942395 15749 net.cpp:406] ReLU2 <- BatchNorm2
I1211 15:05:31.942401 15749 net.cpp:367] ReLU2 -> BatchNorm2 (in-place)
I1211 15:05:31.943007 15749 net.cpp:122] Setting up ReLU2
I1211 15:05:31.943022 15749 net.cpp:129] Top shape: 1 256 36 211 (1944576)
I1211 15:05:31.943027 15749 net.cpp:137] Memory required for data: 696282168
I1211 15:05:31.943030 15749 layer_factory.hpp:77] Creating layer conv1_blk
I1211 15:05:31.943043 15749 net.cpp:84] Creating Layer conv1_blk
I1211 15:05:31.943048 15749 net.cpp:406] conv1_blk <- BatchNorm2
I1211 15:05:31.943058 15749 net.cpp:380] conv1_blk -> conv1_blk
I1211 15:05:31.945852 15749 net.cpp:122] Setting up conv1_blk
I1211 15:05:31.945873 15749 net.cpp:129] Top shape: 1 128 36 211 (972288)
I1211 15:05:31.945876 15749 net.cpp:137] Memory required for data: 700171320
I1211 15:05:31.945884 15749 layer_factory.hpp:77] Creating layer pool1
I1211 15:05:31.945894 15749 net.cpp:84] Creating Layer pool1
I1211 15:05:31.945899 15749 net.cpp:406] pool1 <- conv1_blk
I1211 15:05:31.945905 15749 net.cpp:380] pool1 -> pool1
I1211 15:05:31.946174 15749 net.cpp:122] Setting up pool1
I1211 15:05:31.946185 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.946189 15749 net.cpp:137] Memory required for data: 701148216
I1211 15:05:31.946193 15749 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1211 15:05:31.946202 15749 net.cpp:84] Creating Layer pool1_pool1_0_split
I1211 15:05:31.946207 15749 net.cpp:406] pool1_pool1_0_split <- pool1
I1211 15:05:31.946215 15749 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1211 15:05:31.946223 15749 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1211 15:05:31.946300 15749 net.cpp:122] Setting up pool1_pool1_0_split
I1211 15:05:31.946307 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.946312 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.946316 15749 net.cpp:137] Memory required for data: 703102008
I1211 15:05:31.946319 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/bn
I1211 15:05:31.946328 15749 net.cpp:84] Creating Layer conv2_0/x1/bn
I1211 15:05:31.946332 15749 net.cpp:406] conv2_0/x1/bn <- pool1_pool1_0_split_0
I1211 15:05:31.946339 15749 net.cpp:380] conv2_0/x1/bn -> conv2_0/x1/bn
I1211 15:05:31.946772 15749 net.cpp:122] Setting up conv2_0/x1/bn
I1211 15:05:31.946780 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.946784 15749 net.cpp:137] Memory required for data: 704078904
I1211 15:05:31.946794 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/scale
I1211 15:05:31.946802 15749 net.cpp:84] Creating Layer conv2_0/x1/scale
I1211 15:05:31.946806 15749 net.cpp:406] conv2_0/x1/scale <- conv2_0/x1/bn
I1211 15:05:31.946812 15749 net.cpp:367] conv2_0/x1/scale -> conv2_0/x1/bn (in-place)
I1211 15:05:31.946893 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/scale
I1211 15:05:31.947139 15749 net.cpp:122] Setting up conv2_0/x1/scale
I1211 15:05:31.947147 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.947151 15749 net.cpp:137] Memory required for data: 705055800
I1211 15:05:31.947158 15749 layer_factory.hpp:77] Creating layer relu2_0/x1
I1211 15:05:31.947165 15749 net.cpp:84] Creating Layer relu2_0/x1
I1211 15:05:31.947170 15749 net.cpp:406] relu2_0/x1 <- conv2_0/x1/bn
I1211 15:05:31.947175 15749 net.cpp:367] relu2_0/x1 -> conv2_0/x1/bn (in-place)
I1211 15:05:31.997691 15749 net.cpp:122] Setting up relu2_0/x1
I1211 15:05:31.997721 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.997725 15749 net.cpp:137] Memory required for data: 706032696
I1211 15:05:31.997730 15749 layer_factory.hpp:77] Creating layer conv2_0/x1
I1211 15:05:31.997745 15749 net.cpp:84] Creating Layer conv2_0/x1
I1211 15:05:31.997750 15749 net.cpp:406] conv2_0/x1 <- conv2_0/x1/bn
I1211 15:05:31.997759 15749 net.cpp:380] conv2_0/x1 -> conv2_0/x1
I1211 15:05:31.999554 15749 net.cpp:122] Setting up conv2_0/x1
I1211 15:05:31.999583 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.999585 15749 net.cpp:137] Memory required for data: 707009592
I1211 15:05:31.999593 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/bn
I1211 15:05:31.999601 15749 net.cpp:84] Creating Layer conv2_0/x2/bn
I1211 15:05:31.999605 15749 net.cpp:406] conv2_0/x2/bn <- conv2_0/x1
I1211 15:05:31.999613 15749 net.cpp:380] conv2_0/x2/bn -> conv2_0/x2/bn
I1211 15:05:31.999981 15749 net.cpp:122] Setting up conv2_0/x2/bn
I1211 15:05:31.999989 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:31.999991 15749 net.cpp:137] Memory required for data: 707986488
I1211 15:05:32.000006 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/scale
I1211 15:05:32.000013 15749 net.cpp:84] Creating Layer conv2_0/x2/scale
I1211 15:05:32.000017 15749 net.cpp:406] conv2_0/x2/scale <- conv2_0/x2/bn
I1211 15:05:32.000022 15749 net.cpp:367] conv2_0/x2/scale -> conv2_0/x2/bn (in-place)
I1211 15:05:32.000087 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/scale
I1211 15:05:32.000267 15749 net.cpp:122] Setting up conv2_0/x2/scale
I1211 15:05:32.000273 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.000275 15749 net.cpp:137] Memory required for data: 708963384
I1211 15:05:32.000280 15749 layer_factory.hpp:77] Creating layer relu2_0/x2
I1211 15:05:32.000285 15749 net.cpp:84] Creating Layer relu2_0/x2
I1211 15:05:32.000288 15749 net.cpp:406] relu2_0/x2 <- conv2_0/x2/bn
I1211 15:05:32.000291 15749 net.cpp:367] relu2_0/x2 -> conv2_0/x2/bn (in-place)
I1211 15:05:32.000478 15749 net.cpp:122] Setting up relu2_0/x2
I1211 15:05:32.000485 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.000488 15749 net.cpp:137] Memory required for data: 709940280
I1211 15:05:32.000490 15749 layer_factory.hpp:77] Creating layer conv2_0/x2
I1211 15:05:32.000500 15749 net.cpp:84] Creating Layer conv2_0/x2
I1211 15:05:32.000504 15749 net.cpp:406] conv2_0/x2 <- conv2_0/x2/bn
I1211 15:05:32.000509 15749 net.cpp:380] conv2_0/x2 -> conv2_0/x2
I1211 15:05:32.002971 15749 net.cpp:122] Setting up conv2_0/x2
I1211 15:05:32.002984 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.002986 15749 net.cpp:137] Memory required for data: 710184504
I1211 15:05:32.002991 15749 layer_factory.hpp:77] Creating layer concat2_0
I1211 15:05:32.002998 15749 net.cpp:84] Creating Layer concat2_0
I1211 15:05:32.003001 15749 net.cpp:406] concat2_0 <- pool1_pool1_0_split_1
I1211 15:05:32.003005 15749 net.cpp:406] concat2_0 <- conv2_0/x2
I1211 15:05:32.003010 15749 net.cpp:380] concat2_0 -> concat2_0
I1211 15:05:32.003057 15749 net.cpp:122] Setting up concat2_0
I1211 15:05:32.003063 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.003065 15749 net.cpp:137] Memory required for data: 711405624
I1211 15:05:32.003067 15749 layer_factory.hpp:77] Creating layer concat2_0_concat2_0_0_split
I1211 15:05:32.003072 15749 net.cpp:84] Creating Layer concat2_0_concat2_0_0_split
I1211 15:05:32.003075 15749 net.cpp:406] concat2_0_concat2_0_0_split <- concat2_0
I1211 15:05:32.003082 15749 net.cpp:380] concat2_0_concat2_0_0_split -> concat2_0_concat2_0_0_split_0
I1211 15:05:32.003088 15749 net.cpp:380] concat2_0_concat2_0_0_split -> concat2_0_concat2_0_0_split_1
I1211 15:05:32.003149 15749 net.cpp:122] Setting up concat2_0_concat2_0_0_split
I1211 15:05:32.003154 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.003157 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.003160 15749 net.cpp:137] Memory required for data: 713847864
I1211 15:05:32.003162 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/bn
I1211 15:05:32.003167 15749 net.cpp:84] Creating Layer conv2_1/x1/bn
I1211 15:05:32.003170 15749 net.cpp:406] conv2_1/x1/bn <- concat2_0_concat2_0_0_split_0
I1211 15:05:32.003176 15749 net.cpp:380] conv2_1/x1/bn -> conv2_1/x1/bn
I1211 15:05:32.003523 15749 net.cpp:122] Setting up conv2_1/x1/bn
I1211 15:05:32.003530 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.003532 15749 net.cpp:137] Memory required for data: 715068984
I1211 15:05:32.003538 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/scale
I1211 15:05:32.003545 15749 net.cpp:84] Creating Layer conv2_1/x1/scale
I1211 15:05:32.003548 15749 net.cpp:406] conv2_1/x1/scale <- conv2_1/x1/bn
I1211 15:05:32.003553 15749 net.cpp:367] conv2_1/x1/scale -> conv2_1/x1/bn (in-place)
I1211 15:05:32.003613 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/scale
I1211 15:05:32.003813 15749 net.cpp:122] Setting up conv2_1/x1/scale
I1211 15:05:32.003820 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.003823 15749 net.cpp:137] Memory required for data: 716290104
I1211 15:05:32.003828 15749 layer_factory.hpp:77] Creating layer relu2_1/x1
I1211 15:05:32.003832 15749 net.cpp:84] Creating Layer relu2_1/x1
I1211 15:05:32.003835 15749 net.cpp:406] relu2_1/x1 <- conv2_1/x1/bn
I1211 15:05:32.003839 15749 net.cpp:367] relu2_1/x1 -> conv2_1/x1/bn (in-place)
I1211 15:05:32.004204 15749 net.cpp:122] Setting up relu2_1/x1
I1211 15:05:32.004215 15749 net.cpp:129] Top shape: 1 160 18 106 (305280)
I1211 15:05:32.004216 15749 net.cpp:137] Memory required for data: 717511224
I1211 15:05:32.004220 15749 layer_factory.hpp:77] Creating layer conv2_1/x1
I1211 15:05:32.004228 15749 net.cpp:84] Creating Layer conv2_1/x1
I1211 15:05:32.004231 15749 net.cpp:406] conv2_1/x1 <- conv2_1/x1/bn
I1211 15:05:32.004236 15749 net.cpp:380] conv2_1/x1 -> conv2_1/x1
I1211 15:05:32.005946 15749 net.cpp:122] Setting up conv2_1/x1
I1211 15:05:32.005960 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.005964 15749 net.cpp:137] Memory required for data: 718488120
I1211 15:05:32.005969 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/bn
I1211 15:05:32.005975 15749 net.cpp:84] Creating Layer conv2_1/x2/bn
I1211 15:05:32.005978 15749 net.cpp:406] conv2_1/x2/bn <- conv2_1/x1
I1211 15:05:32.005985 15749 net.cpp:380] conv2_1/x2/bn -> conv2_1/x2/bn
I1211 15:05:32.006325 15749 net.cpp:122] Setting up conv2_1/x2/bn
I1211 15:05:32.006333 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.006335 15749 net.cpp:137] Memory required for data: 719465016
I1211 15:05:32.006342 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/scale
I1211 15:05:32.006350 15749 net.cpp:84] Creating Layer conv2_1/x2/scale
I1211 15:05:32.006352 15749 net.cpp:406] conv2_1/x2/scale <- conv2_1/x2/bn
I1211 15:05:32.006357 15749 net.cpp:367] conv2_1/x2/scale -> conv2_1/x2/bn (in-place)
I1211 15:05:32.006418 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/scale
I1211 15:05:32.006598 15749 net.cpp:122] Setting up conv2_1/x2/scale
I1211 15:05:32.006604 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.006608 15749 net.cpp:137] Memory required for data: 720441912
I1211 15:05:32.006613 15749 layer_factory.hpp:77] Creating layer relu2_1/x2
I1211 15:05:32.006618 15749 net.cpp:84] Creating Layer relu2_1/x2
I1211 15:05:32.006621 15749 net.cpp:406] relu2_1/x2 <- conv2_1/x2/bn
I1211 15:05:32.006624 15749 net.cpp:367] relu2_1/x2 -> conv2_1/x2/bn (in-place)
I1211 15:05:32.007040 15749 net.cpp:122] Setting up relu2_1/x2
I1211 15:05:32.007050 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.007052 15749 net.cpp:137] Memory required for data: 721418808
I1211 15:05:32.007055 15749 layer_factory.hpp:77] Creating layer conv2_1/x2
I1211 15:05:32.007066 15749 net.cpp:84] Creating Layer conv2_1/x2
I1211 15:05:32.007071 15749 net.cpp:406] conv2_1/x2 <- conv2_1/x2/bn
I1211 15:05:32.007076 15749 net.cpp:380] conv2_1/x2 -> conv2_1/x2
I1211 15:05:32.009635 15749 net.cpp:122] Setting up conv2_1/x2
I1211 15:05:32.009665 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.009668 15749 net.cpp:137] Memory required for data: 721663032
I1211 15:05:32.009676 15749 layer_factory.hpp:77] Creating layer concat2_1
I1211 15:05:32.009687 15749 net.cpp:84] Creating Layer concat2_1
I1211 15:05:32.009692 15749 net.cpp:406] concat2_1 <- concat2_0_concat2_0_0_split_1
I1211 15:05:32.009697 15749 net.cpp:406] concat2_1 <- conv2_1/x2
I1211 15:05:32.009702 15749 net.cpp:380] concat2_1 -> concat2_1
I1211 15:05:32.009752 15749 net.cpp:122] Setting up concat2_1
I1211 15:05:32.009759 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.009763 15749 net.cpp:137] Memory required for data: 723128376
I1211 15:05:32.009764 15749 layer_factory.hpp:77] Creating layer concat2_1_concat2_1_0_split
I1211 15:05:32.009769 15749 net.cpp:84] Creating Layer concat2_1_concat2_1_0_split
I1211 15:05:32.009773 15749 net.cpp:406] concat2_1_concat2_1_0_split <- concat2_1
I1211 15:05:32.009776 15749 net.cpp:380] concat2_1_concat2_1_0_split -> concat2_1_concat2_1_0_split_0
I1211 15:05:32.009780 15749 net.cpp:380] concat2_1_concat2_1_0_split -> concat2_1_concat2_1_0_split_1
I1211 15:05:32.009840 15749 net.cpp:122] Setting up concat2_1_concat2_1_0_split
I1211 15:05:32.009845 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.009848 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.009850 15749 net.cpp:137] Memory required for data: 726059064
I1211 15:05:32.009852 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/bn
I1211 15:05:32.009858 15749 net.cpp:84] Creating Layer conv2_2/x1/bn
I1211 15:05:32.009861 15749 net.cpp:406] conv2_2/x1/bn <- concat2_1_concat2_1_0_split_0
I1211 15:05:32.009865 15749 net.cpp:380] conv2_2/x1/bn -> conv2_2/x1/bn
I1211 15:05:32.010231 15749 net.cpp:122] Setting up conv2_2/x1/bn
I1211 15:05:32.010237 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.010241 15749 net.cpp:137] Memory required for data: 727524408
I1211 15:05:32.010247 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/scale
I1211 15:05:32.010255 15749 net.cpp:84] Creating Layer conv2_2/x1/scale
I1211 15:05:32.010258 15749 net.cpp:406] conv2_2/x1/scale <- conv2_2/x1/bn
I1211 15:05:32.010263 15749 net.cpp:367] conv2_2/x1/scale -> conv2_2/x1/bn (in-place)
I1211 15:05:32.010327 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/scale
I1211 15:05:32.010531 15749 net.cpp:122] Setting up conv2_2/x1/scale
I1211 15:05:32.010540 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.010542 15749 net.cpp:137] Memory required for data: 728989752
I1211 15:05:32.010547 15749 layer_factory.hpp:77] Creating layer relu2_2/x1
I1211 15:05:32.010552 15749 net.cpp:84] Creating Layer relu2_2/x1
I1211 15:05:32.010555 15749 net.cpp:406] relu2_2/x1 <- conv2_2/x1/bn
I1211 15:05:32.010558 15749 net.cpp:367] relu2_2/x1 -> conv2_2/x1/bn (in-place)
I1211 15:05:32.010771 15749 net.cpp:122] Setting up relu2_2/x1
I1211 15:05:32.010779 15749 net.cpp:129] Top shape: 1 192 18 106 (366336)
I1211 15:05:32.010782 15749 net.cpp:137] Memory required for data: 730455096
I1211 15:05:32.010784 15749 layer_factory.hpp:77] Creating layer conv2_2/x1
I1211 15:05:32.010793 15749 net.cpp:84] Creating Layer conv2_2/x1
I1211 15:05:32.010797 15749 net.cpp:406] conv2_2/x1 <- conv2_2/x1/bn
I1211 15:05:32.010802 15749 net.cpp:380] conv2_2/x1 -> conv2_2/x1
I1211 15:05:32.013609 15749 net.cpp:122] Setting up conv2_2/x1
I1211 15:05:32.013643 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.013650 15749 net.cpp:137] Memory required for data: 731431992
I1211 15:05:32.013659 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/bn
I1211 15:05:32.013674 15749 net.cpp:84] Creating Layer conv2_2/x2/bn
I1211 15:05:32.013680 15749 net.cpp:406] conv2_2/x2/bn <- conv2_2/x1
I1211 15:05:32.013686 15749 net.cpp:380] conv2_2/x2/bn -> conv2_2/x2/bn
I1211 15:05:32.014051 15749 net.cpp:122] Setting up conv2_2/x2/bn
I1211 15:05:32.014061 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.014063 15749 net.cpp:137] Memory required for data: 732408888
I1211 15:05:32.014071 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/scale
I1211 15:05:32.014080 15749 net.cpp:84] Creating Layer conv2_2/x2/scale
I1211 15:05:32.014082 15749 net.cpp:406] conv2_2/x2/scale <- conv2_2/x2/bn
I1211 15:05:32.014086 15749 net.cpp:367] conv2_2/x2/scale -> conv2_2/x2/bn (in-place)
I1211 15:05:32.014156 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/scale
I1211 15:05:32.014341 15749 net.cpp:122] Setting up conv2_2/x2/scale
I1211 15:05:32.014348 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.014350 15749 net.cpp:137] Memory required for data: 733385784
I1211 15:05:32.014355 15749 layer_factory.hpp:77] Creating layer relu2_2/x2
I1211 15:05:32.014363 15749 net.cpp:84] Creating Layer relu2_2/x2
I1211 15:05:32.014365 15749 net.cpp:406] relu2_2/x2 <- conv2_2/x2/bn
I1211 15:05:32.014369 15749 net.cpp:367] relu2_2/x2 -> conv2_2/x2/bn (in-place)
I1211 15:05:32.014828 15749 net.cpp:122] Setting up relu2_2/x2
I1211 15:05:32.014839 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.014842 15749 net.cpp:137] Memory required for data: 734362680
I1211 15:05:32.014844 15749 layer_factory.hpp:77] Creating layer conv2_2/x2
I1211 15:05:32.014854 15749 net.cpp:84] Creating Layer conv2_2/x2
I1211 15:05:32.014858 15749 net.cpp:406] conv2_2/x2 <- conv2_2/x2/bn
I1211 15:05:32.014863 15749 net.cpp:380] conv2_2/x2 -> conv2_2/x2
I1211 15:05:32.017230 15749 net.cpp:122] Setting up conv2_2/x2
I1211 15:05:32.017248 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.017251 15749 net.cpp:137] Memory required for data: 734606904
I1211 15:05:32.017257 15749 layer_factory.hpp:77] Creating layer concat2_2
I1211 15:05:32.017263 15749 net.cpp:84] Creating Layer concat2_2
I1211 15:05:32.017268 15749 net.cpp:406] concat2_2 <- concat2_1_concat2_1_0_split_1
I1211 15:05:32.017274 15749 net.cpp:406] concat2_2 <- conv2_2/x2
I1211 15:05:32.017278 15749 net.cpp:380] concat2_2 -> concat2_2
I1211 15:05:32.017325 15749 net.cpp:122] Setting up concat2_2
I1211 15:05:32.017331 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.017334 15749 net.cpp:137] Memory required for data: 736316472
I1211 15:05:32.017336 15749 layer_factory.hpp:77] Creating layer concat2_2_concat2_2_0_split
I1211 15:05:32.017343 15749 net.cpp:84] Creating Layer concat2_2_concat2_2_0_split
I1211 15:05:32.017345 15749 net.cpp:406] concat2_2_concat2_2_0_split <- concat2_2
I1211 15:05:32.017349 15749 net.cpp:380] concat2_2_concat2_2_0_split -> concat2_2_concat2_2_0_split_0
I1211 15:05:32.017354 15749 net.cpp:380] concat2_2_concat2_2_0_split -> concat2_2_concat2_2_0_split_1
I1211 15:05:32.017413 15749 net.cpp:122] Setting up concat2_2_concat2_2_0_split
I1211 15:05:32.017419 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.017422 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.017424 15749 net.cpp:137] Memory required for data: 739735608
I1211 15:05:32.017426 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/bn
I1211 15:05:32.017432 15749 net.cpp:84] Creating Layer conv2_3/x1/bn
I1211 15:05:32.017436 15749 net.cpp:406] conv2_3/x1/bn <- concat2_2_concat2_2_0_split_0
I1211 15:05:32.017439 15749 net.cpp:380] conv2_3/x1/bn -> conv2_3/x1/bn
I1211 15:05:32.017808 15749 net.cpp:122] Setting up conv2_3/x1/bn
I1211 15:05:32.017814 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.017817 15749 net.cpp:137] Memory required for data: 741445176
I1211 15:05:32.017827 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/scale
I1211 15:05:32.017835 15749 net.cpp:84] Creating Layer conv2_3/x1/scale
I1211 15:05:32.017838 15749 net.cpp:406] conv2_3/x1/scale <- conv2_3/x1/bn
I1211 15:05:32.017841 15749 net.cpp:367] conv2_3/x1/scale -> conv2_3/x1/bn (in-place)
I1211 15:05:32.017906 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/scale
I1211 15:05:32.018105 15749 net.cpp:122] Setting up conv2_3/x1/scale
I1211 15:05:32.018110 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.018113 15749 net.cpp:137] Memory required for data: 743154744
I1211 15:05:32.018118 15749 layer_factory.hpp:77] Creating layer relu2_3/x1
I1211 15:05:32.018123 15749 net.cpp:84] Creating Layer relu2_3/x1
I1211 15:05:32.018126 15749 net.cpp:406] relu2_3/x1 <- conv2_3/x1/bn
I1211 15:05:32.018129 15749 net.cpp:367] relu2_3/x1 -> conv2_3/x1/bn (in-place)
I1211 15:05:32.018318 15749 net.cpp:122] Setting up relu2_3/x1
I1211 15:05:32.018326 15749 net.cpp:129] Top shape: 1 224 18 106 (427392)
I1211 15:05:32.018329 15749 net.cpp:137] Memory required for data: 744864312
I1211 15:05:32.018332 15749 layer_factory.hpp:77] Creating layer conv2_3/x1
I1211 15:05:32.018342 15749 net.cpp:84] Creating Layer conv2_3/x1
I1211 15:05:32.018344 15749 net.cpp:406] conv2_3/x1 <- conv2_3/x1/bn
I1211 15:05:32.018350 15749 net.cpp:380] conv2_3/x1 -> conv2_3/x1
I1211 15:05:32.020997 15749 net.cpp:122] Setting up conv2_3/x1
I1211 15:05:32.021013 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.021018 15749 net.cpp:137] Memory required for data: 745841208
I1211 15:05:32.021024 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/bn
I1211 15:05:32.021034 15749 net.cpp:84] Creating Layer conv2_3/x2/bn
I1211 15:05:32.021039 15749 net.cpp:406] conv2_3/x2/bn <- conv2_3/x1
I1211 15:05:32.021045 15749 net.cpp:380] conv2_3/x2/bn -> conv2_3/x2/bn
I1211 15:05:32.021505 15749 net.cpp:122] Setting up conv2_3/x2/bn
I1211 15:05:32.021514 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.021518 15749 net.cpp:137] Memory required for data: 746818104
I1211 15:05:32.021528 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/scale
I1211 15:05:32.021536 15749 net.cpp:84] Creating Layer conv2_3/x2/scale
I1211 15:05:32.021541 15749 net.cpp:406] conv2_3/x2/scale <- conv2_3/x2/bn
I1211 15:05:32.021546 15749 net.cpp:367] conv2_3/x2/scale -> conv2_3/x2/bn (in-place)
I1211 15:05:32.021627 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/scale
I1211 15:05:32.021875 15749 net.cpp:122] Setting up conv2_3/x2/scale
I1211 15:05:32.021884 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.021888 15749 net.cpp:137] Memory required for data: 747795000
I1211 15:05:32.021895 15749 layer_factory.hpp:77] Creating layer relu2_3/x2
I1211 15:05:32.021903 15749 net.cpp:84] Creating Layer relu2_3/x2
I1211 15:05:32.021906 15749 net.cpp:406] relu2_3/x2 <- conv2_3/x2/bn
I1211 15:05:32.021914 15749 net.cpp:367] relu2_3/x2 -> conv2_3/x2/bn (in-place)
I1211 15:05:32.022356 15749 net.cpp:122] Setting up relu2_3/x2
I1211 15:05:32.022369 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.022373 15749 net.cpp:137] Memory required for data: 748771896
I1211 15:05:32.022377 15749 layer_factory.hpp:77] Creating layer conv2_3/x2
I1211 15:05:32.022390 15749 net.cpp:84] Creating Layer conv2_3/x2
I1211 15:05:32.022395 15749 net.cpp:406] conv2_3/x2 <- conv2_3/x2/bn
I1211 15:05:32.022403 15749 net.cpp:380] conv2_3/x2 -> conv2_3/x2
I1211 15:05:32.033792 15749 net.cpp:122] Setting up conv2_3/x2
I1211 15:05:32.033830 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.033835 15749 net.cpp:137] Memory required for data: 749016120
I1211 15:05:32.033848 15749 layer_factory.hpp:77] Creating layer concat2_3
I1211 15:05:32.033860 15749 net.cpp:84] Creating Layer concat2_3
I1211 15:05:32.033869 15749 net.cpp:406] concat2_3 <- concat2_2_concat2_2_0_split_1
I1211 15:05:32.033876 15749 net.cpp:406] concat2_3 <- conv2_3/x2
I1211 15:05:32.033884 15749 net.cpp:380] concat2_3 -> concat2_3
I1211 15:05:32.033960 15749 net.cpp:122] Setting up concat2_3
I1211 15:05:32.033973 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.033978 15749 net.cpp:137] Memory required for data: 750969912
I1211 15:05:32.033982 15749 layer_factory.hpp:77] Creating layer concat2_3_concat2_3_0_split
I1211 15:05:32.033989 15749 net.cpp:84] Creating Layer concat2_3_concat2_3_0_split
I1211 15:05:32.033993 15749 net.cpp:406] concat2_3_concat2_3_0_split <- concat2_3
I1211 15:05:32.033999 15749 net.cpp:380] concat2_3_concat2_3_0_split -> concat2_3_concat2_3_0_split_0
I1211 15:05:32.034009 15749 net.cpp:380] concat2_3_concat2_3_0_split -> concat2_3_concat2_3_0_split_1
I1211 15:05:32.034093 15749 net.cpp:122] Setting up concat2_3_concat2_3_0_split
I1211 15:05:32.034102 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.034107 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.034111 15749 net.cpp:137] Memory required for data: 754877496
I1211 15:05:32.034116 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/bn
I1211 15:05:32.034122 15749 net.cpp:84] Creating Layer conv2_4/x1/bn
I1211 15:05:32.034126 15749 net.cpp:406] conv2_4/x1/bn <- concat2_3_concat2_3_0_split_0
I1211 15:05:32.034137 15749 net.cpp:380] conv2_4/x1/bn -> conv2_4/x1/bn
I1211 15:05:32.034621 15749 net.cpp:122] Setting up conv2_4/x1/bn
I1211 15:05:32.034631 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.034636 15749 net.cpp:137] Memory required for data: 756831288
I1211 15:05:32.034646 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/scale
I1211 15:05:32.034654 15749 net.cpp:84] Creating Layer conv2_4/x1/scale
I1211 15:05:32.034659 15749 net.cpp:406] conv2_4/x1/scale <- conv2_4/x1/bn
I1211 15:05:32.034667 15749 net.cpp:367] conv2_4/x1/scale -> conv2_4/x1/bn (in-place)
I1211 15:05:32.034752 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/scale
I1211 15:05:32.035006 15749 net.cpp:122] Setting up conv2_4/x1/scale
I1211 15:05:32.035014 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.035018 15749 net.cpp:137] Memory required for data: 758785080
I1211 15:05:32.035027 15749 layer_factory.hpp:77] Creating layer relu2_4/x1
I1211 15:05:32.035033 15749 net.cpp:84] Creating Layer relu2_4/x1
I1211 15:05:32.035038 15749 net.cpp:406] relu2_4/x1 <- conv2_4/x1/bn
I1211 15:05:32.035043 15749 net.cpp:367] relu2_4/x1 -> conv2_4/x1/bn (in-place)
I1211 15:05:32.035651 15749 net.cpp:122] Setting up relu2_4/x1
I1211 15:05:32.035667 15749 net.cpp:129] Top shape: 1 256 18 106 (488448)
I1211 15:05:32.035672 15749 net.cpp:137] Memory required for data: 760738872
I1211 15:05:32.035676 15749 layer_factory.hpp:77] Creating layer conv2_4/x1
I1211 15:05:32.035689 15749 net.cpp:84] Creating Layer conv2_4/x1
I1211 15:05:32.035693 15749 net.cpp:406] conv2_4/x1 <- conv2_4/x1/bn
I1211 15:05:32.035704 15749 net.cpp:380] conv2_4/x1 -> conv2_4/x1
I1211 15:05:32.077806 15749 net.cpp:122] Setting up conv2_4/x1
I1211 15:05:32.077839 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.077844 15749 net.cpp:137] Memory required for data: 761715768
I1211 15:05:32.077853 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/bn
I1211 15:05:32.077865 15749 net.cpp:84] Creating Layer conv2_4/x2/bn
I1211 15:05:32.077872 15749 net.cpp:406] conv2_4/x2/bn <- conv2_4/x1
I1211 15:05:32.077883 15749 net.cpp:380] conv2_4/x2/bn -> conv2_4/x2/bn
I1211 15:05:32.099911 15749 net.cpp:122] Setting up conv2_4/x2/bn
I1211 15:05:32.099944 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.099949 15749 net.cpp:137] Memory required for data: 762692664
I1211 15:05:32.099964 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/scale
I1211 15:05:32.099978 15749 net.cpp:84] Creating Layer conv2_4/x2/scale
I1211 15:05:32.099984 15749 net.cpp:406] conv2_4/x2/scale <- conv2_4/x2/bn
I1211 15:05:32.099993 15749 net.cpp:367] conv2_4/x2/scale -> conv2_4/x2/bn (in-place)
I1211 15:05:32.100112 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/scale
I1211 15:05:32.100400 15749 net.cpp:122] Setting up conv2_4/x2/scale
I1211 15:05:32.100409 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.100419 15749 net.cpp:137] Memory required for data: 763669560
I1211 15:05:32.100426 15749 layer_factory.hpp:77] Creating layer relu2_4/x2
I1211 15:05:32.100433 15749 net.cpp:84] Creating Layer relu2_4/x2
I1211 15:05:32.100437 15749 net.cpp:406] relu2_4/x2 <- conv2_4/x2/bn
I1211 15:05:32.100443 15749 net.cpp:367] relu2_4/x2 -> conv2_4/x2/bn (in-place)
I1211 15:05:32.100745 15749 net.cpp:122] Setting up relu2_4/x2
I1211 15:05:32.100756 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.100760 15749 net.cpp:137] Memory required for data: 764646456
I1211 15:05:32.100764 15749 layer_factory.hpp:77] Creating layer conv2_4/x2
I1211 15:05:32.100777 15749 net.cpp:84] Creating Layer conv2_4/x2
I1211 15:05:32.100782 15749 net.cpp:406] conv2_4/x2 <- conv2_4/x2/bn
I1211 15:05:32.100790 15749 net.cpp:380] conv2_4/x2 -> conv2_4/x2
I1211 15:05:32.107067 15749 net.cpp:122] Setting up conv2_4/x2
I1211 15:05:32.107101 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.107106 15749 net.cpp:137] Memory required for data: 764890680
I1211 15:05:32.107116 15749 layer_factory.hpp:77] Creating layer concat2_4
I1211 15:05:32.107130 15749 net.cpp:84] Creating Layer concat2_4
I1211 15:05:32.107137 15749 net.cpp:406] concat2_4 <- concat2_3_concat2_3_0_split_1
I1211 15:05:32.107146 15749 net.cpp:406] concat2_4 <- conv2_4/x2
I1211 15:05:32.107153 15749 net.cpp:380] concat2_4 -> concat2_4
I1211 15:05:32.107225 15749 net.cpp:122] Setting up concat2_4
I1211 15:05:32.107234 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.107239 15749 net.cpp:137] Memory required for data: 767088696
I1211 15:05:32.107242 15749 layer_factory.hpp:77] Creating layer concat2_4_concat2_4_0_split
I1211 15:05:32.107250 15749 net.cpp:84] Creating Layer concat2_4_concat2_4_0_split
I1211 15:05:32.107254 15749 net.cpp:406] concat2_4_concat2_4_0_split <- concat2_4
I1211 15:05:32.107260 15749 net.cpp:380] concat2_4_concat2_4_0_split -> concat2_4_concat2_4_0_split_0
I1211 15:05:32.107267 15749 net.cpp:380] concat2_4_concat2_4_0_split -> concat2_4_concat2_4_0_split_1
I1211 15:05:32.107355 15749 net.cpp:122] Setting up concat2_4_concat2_4_0_split
I1211 15:05:32.107363 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.107368 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.107372 15749 net.cpp:137] Memory required for data: 771484728
I1211 15:05:32.107376 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/bn
I1211 15:05:32.107384 15749 net.cpp:84] Creating Layer conv2_5/x1/bn
I1211 15:05:32.107389 15749 net.cpp:406] conv2_5/x1/bn <- concat2_4_concat2_4_0_split_0
I1211 15:05:32.107395 15749 net.cpp:380] conv2_5/x1/bn -> conv2_5/x1/bn
I1211 15:05:32.107918 15749 net.cpp:122] Setting up conv2_5/x1/bn
I1211 15:05:32.107926 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.107928 15749 net.cpp:137] Memory required for data: 773682744
I1211 15:05:32.107936 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/scale
I1211 15:05:32.107944 15749 net.cpp:84] Creating Layer conv2_5/x1/scale
I1211 15:05:32.107946 15749 net.cpp:406] conv2_5/x1/scale <- conv2_5/x1/bn
I1211 15:05:32.107950 15749 net.cpp:367] conv2_5/x1/scale -> conv2_5/x1/bn (in-place)
I1211 15:05:32.108022 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/scale
I1211 15:05:32.108240 15749 net.cpp:122] Setting up conv2_5/x1/scale
I1211 15:05:32.108247 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.108249 15749 net.cpp:137] Memory required for data: 775880760
I1211 15:05:32.108254 15749 layer_factory.hpp:77] Creating layer relu2_5/x1
I1211 15:05:32.108260 15749 net.cpp:84] Creating Layer relu2_5/x1
I1211 15:05:32.108263 15749 net.cpp:406] relu2_5/x1 <- conv2_5/x1/bn
I1211 15:05:32.108268 15749 net.cpp:367] relu2_5/x1 -> conv2_5/x1/bn (in-place)
I1211 15:05:32.108837 15749 net.cpp:122] Setting up relu2_5/x1
I1211 15:05:32.108850 15749 net.cpp:129] Top shape: 1 288 18 106 (549504)
I1211 15:05:32.108852 15749 net.cpp:137] Memory required for data: 778078776
I1211 15:05:32.108860 15749 layer_factory.hpp:77] Creating layer conv2_5/x1
I1211 15:05:32.108870 15749 net.cpp:84] Creating Layer conv2_5/x1
I1211 15:05:32.108875 15749 net.cpp:406] conv2_5/x1 <- conv2_5/x1/bn
I1211 15:05:32.108880 15749 net.cpp:380] conv2_5/x1 -> conv2_5/x1
I1211 15:05:32.111399 15749 net.cpp:122] Setting up conv2_5/x1
I1211 15:05:32.111429 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.111433 15749 net.cpp:137] Memory required for data: 779055672
I1211 15:05:32.111440 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/bn
I1211 15:05:32.111451 15749 net.cpp:84] Creating Layer conv2_5/x2/bn
I1211 15:05:32.111456 15749 net.cpp:406] conv2_5/x2/bn <- conv2_5/x1
I1211 15:05:32.111462 15749 net.cpp:380] conv2_5/x2/bn -> conv2_5/x2/bn
I1211 15:05:32.111850 15749 net.cpp:122] Setting up conv2_5/x2/bn
I1211 15:05:32.111858 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.111860 15749 net.cpp:137] Memory required for data: 780032568
I1211 15:05:32.111867 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/scale
I1211 15:05:32.111881 15749 net.cpp:84] Creating Layer conv2_5/x2/scale
I1211 15:05:32.111884 15749 net.cpp:406] conv2_5/x2/scale <- conv2_5/x2/bn
I1211 15:05:32.111888 15749 net.cpp:367] conv2_5/x2/scale -> conv2_5/x2/bn (in-place)
I1211 15:05:32.111955 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/scale
I1211 15:05:32.112148 15749 net.cpp:122] Setting up conv2_5/x2/scale
I1211 15:05:32.112154 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.112157 15749 net.cpp:137] Memory required for data: 781009464
I1211 15:05:32.112161 15749 layer_factory.hpp:77] Creating layer relu2_5/x2
I1211 15:05:32.112167 15749 net.cpp:84] Creating Layer relu2_5/x2
I1211 15:05:32.112170 15749 net.cpp:406] relu2_5/x2 <- conv2_5/x2/bn
I1211 15:05:32.112174 15749 net.cpp:367] relu2_5/x2 -> conv2_5/x2/bn (in-place)
I1211 15:05:32.112372 15749 net.cpp:122] Setting up relu2_5/x2
I1211 15:05:32.112380 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.112383 15749 net.cpp:137] Memory required for data: 781986360
I1211 15:05:32.112386 15749 layer_factory.hpp:77] Creating layer conv2_5/x2
I1211 15:05:32.112396 15749 net.cpp:84] Creating Layer conv2_5/x2
I1211 15:05:32.112399 15749 net.cpp:406] conv2_5/x2 <- conv2_5/x2/bn
I1211 15:05:32.112406 15749 net.cpp:380] conv2_5/x2 -> conv2_5/x2
I1211 15:05:32.115546 15749 net.cpp:122] Setting up conv2_5/x2
I1211 15:05:32.115574 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.115576 15749 net.cpp:137] Memory required for data: 782230584
I1211 15:05:32.115584 15749 layer_factory.hpp:77] Creating layer concat2_5
I1211 15:05:32.115592 15749 net.cpp:84] Creating Layer concat2_5
I1211 15:05:32.115598 15749 net.cpp:406] concat2_5 <- concat2_4_concat2_4_0_split_1
I1211 15:05:32.115604 15749 net.cpp:406] concat2_5 <- conv2_5/x2
I1211 15:05:32.115609 15749 net.cpp:380] concat2_5 -> concat2_5
I1211 15:05:32.115659 15749 net.cpp:122] Setting up concat2_5
I1211 15:05:32.115666 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.115669 15749 net.cpp:137] Memory required for data: 784672824
I1211 15:05:32.115670 15749 layer_factory.hpp:77] Creating layer concat2_5_concat2_5_0_split
I1211 15:05:32.115675 15749 net.cpp:84] Creating Layer concat2_5_concat2_5_0_split
I1211 15:05:32.115679 15749 net.cpp:406] concat2_5_concat2_5_0_split <- concat2_5
I1211 15:05:32.115684 15749 net.cpp:380] concat2_5_concat2_5_0_split -> concat2_5_concat2_5_0_split_0
I1211 15:05:32.115689 15749 net.cpp:380] concat2_5_concat2_5_0_split -> concat2_5_concat2_5_0_split_1
I1211 15:05:32.115762 15749 net.cpp:122] Setting up concat2_5_concat2_5_0_split
I1211 15:05:32.115768 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.115772 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.115774 15749 net.cpp:137] Memory required for data: 789557304
I1211 15:05:32.115777 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/bn
I1211 15:05:32.115782 15749 net.cpp:84] Creating Layer conv2_6/x1/bn
I1211 15:05:32.115788 15749 net.cpp:406] conv2_6/x1/bn <- concat2_5_concat2_5_0_split_0
I1211 15:05:32.115793 15749 net.cpp:380] conv2_6/x1/bn -> conv2_6/x1/bn
I1211 15:05:32.116206 15749 net.cpp:122] Setting up conv2_6/x1/bn
I1211 15:05:32.116212 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.116215 15749 net.cpp:137] Memory required for data: 791999544
I1211 15:05:32.116221 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/scale
I1211 15:05:32.116228 15749 net.cpp:84] Creating Layer conv2_6/x1/scale
I1211 15:05:32.116232 15749 net.cpp:406] conv2_6/x1/scale <- conv2_6/x1/bn
I1211 15:05:32.116235 15749 net.cpp:367] conv2_6/x1/scale -> conv2_6/x1/bn (in-place)
I1211 15:05:32.116307 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/scale
I1211 15:05:32.116518 15749 net.cpp:122] Setting up conv2_6/x1/scale
I1211 15:05:32.116523 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.116526 15749 net.cpp:137] Memory required for data: 794441784
I1211 15:05:32.116530 15749 layer_factory.hpp:77] Creating layer relu2_6/x1
I1211 15:05:32.116536 15749 net.cpp:84] Creating Layer relu2_6/x1
I1211 15:05:32.116539 15749 net.cpp:406] relu2_6/x1 <- conv2_6/x1/bn
I1211 15:05:32.116542 15749 net.cpp:367] relu2_6/x1 -> conv2_6/x1/bn (in-place)
I1211 15:05:32.116906 15749 net.cpp:122] Setting up relu2_6/x1
I1211 15:05:32.116916 15749 net.cpp:129] Top shape: 1 320 18 106 (610560)
I1211 15:05:32.116919 15749 net.cpp:137] Memory required for data: 796884024
I1211 15:05:32.116921 15749 layer_factory.hpp:77] Creating layer conv2_6/x1
I1211 15:05:32.116933 15749 net.cpp:84] Creating Layer conv2_6/x1
I1211 15:05:32.116936 15749 net.cpp:406] conv2_6/x1 <- conv2_6/x1/bn
I1211 15:05:32.116942 15749 net.cpp:380] conv2_6/x1 -> conv2_6/x1
I1211 15:05:32.119148 15749 net.cpp:122] Setting up conv2_6/x1
I1211 15:05:32.119158 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.119161 15749 net.cpp:137] Memory required for data: 797860920
I1211 15:05:32.119165 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/bn
I1211 15:05:32.119173 15749 net.cpp:84] Creating Layer conv2_6/x2/bn
I1211 15:05:32.119175 15749 net.cpp:406] conv2_6/x2/bn <- conv2_6/x1
I1211 15:05:32.119179 15749 net.cpp:380] conv2_6/x2/bn -> conv2_6/x2/bn
I1211 15:05:32.119537 15749 net.cpp:122] Setting up conv2_6/x2/bn
I1211 15:05:32.119544 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.119546 15749 net.cpp:137] Memory required for data: 798837816
I1211 15:05:32.119552 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/scale
I1211 15:05:32.119559 15749 net.cpp:84] Creating Layer conv2_6/x2/scale
I1211 15:05:32.119561 15749 net.cpp:406] conv2_6/x2/scale <- conv2_6/x2/bn
I1211 15:05:32.119565 15749 net.cpp:367] conv2_6/x2/scale -> conv2_6/x2/bn (in-place)
I1211 15:05:32.119627 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/scale
I1211 15:05:32.119827 15749 net.cpp:122] Setting up conv2_6/x2/scale
I1211 15:05:32.119833 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.119835 15749 net.cpp:137] Memory required for data: 799814712
I1211 15:05:32.119840 15749 layer_factory.hpp:77] Creating layer relu2_6/x2
I1211 15:05:32.119846 15749 net.cpp:84] Creating Layer relu2_6/x2
I1211 15:05:32.119849 15749 net.cpp:406] relu2_6/x2 <- conv2_6/x2/bn
I1211 15:05:32.119853 15749 net.cpp:367] relu2_6/x2 -> conv2_6/x2/bn (in-place)
I1211 15:05:32.120213 15749 net.cpp:122] Setting up relu2_6/x2
I1211 15:05:32.120223 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.120225 15749 net.cpp:137] Memory required for data: 800791608
I1211 15:05:32.120229 15749 layer_factory.hpp:77] Creating layer conv2_6/x2
I1211 15:05:32.120236 15749 net.cpp:84] Creating Layer conv2_6/x2
I1211 15:05:32.120240 15749 net.cpp:406] conv2_6/x2 <- conv2_6/x2/bn
I1211 15:05:32.120244 15749 net.cpp:380] conv2_6/x2 -> conv2_6/x2
I1211 15:05:32.122514 15749 net.cpp:122] Setting up conv2_6/x2
I1211 15:05:32.122526 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.122529 15749 net.cpp:137] Memory required for data: 801035832
I1211 15:05:32.122537 15749 layer_factory.hpp:77] Creating layer concat2_6
I1211 15:05:32.122544 15749 net.cpp:84] Creating Layer concat2_6
I1211 15:05:32.122547 15749 net.cpp:406] concat2_6 <- concat2_5_concat2_5_0_split_1
I1211 15:05:32.122552 15749 net.cpp:406] concat2_6 <- conv2_6/x2
I1211 15:05:32.122556 15749 net.cpp:380] concat2_6 -> concat2_6
I1211 15:05:32.122603 15749 net.cpp:122] Setting up concat2_6
I1211 15:05:32.122611 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.122612 15749 net.cpp:137] Memory required for data: 803722296
I1211 15:05:32.122614 15749 layer_factory.hpp:77] Creating layer concat2_6_concat2_6_0_split
I1211 15:05:32.122620 15749 net.cpp:84] Creating Layer concat2_6_concat2_6_0_split
I1211 15:05:32.122622 15749 net.cpp:406] concat2_6_concat2_6_0_split <- concat2_6
I1211 15:05:32.122627 15749 net.cpp:380] concat2_6_concat2_6_0_split -> concat2_6_concat2_6_0_split_0
I1211 15:05:32.122632 15749 net.cpp:380] concat2_6_concat2_6_0_split -> concat2_6_concat2_6_0_split_1
I1211 15:05:32.122694 15749 net.cpp:122] Setting up concat2_6_concat2_6_0_split
I1211 15:05:32.122699 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.122702 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.122704 15749 net.cpp:137] Memory required for data: 809095224
I1211 15:05:32.122706 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/bn
I1211 15:05:32.122714 15749 net.cpp:84] Creating Layer conv2_7/x1/bn
I1211 15:05:32.122716 15749 net.cpp:406] conv2_7/x1/bn <- concat2_6_concat2_6_0_split_0
I1211 15:05:32.122720 15749 net.cpp:380] conv2_7/x1/bn -> conv2_7/x1/bn
I1211 15:05:32.123111 15749 net.cpp:122] Setting up conv2_7/x1/bn
I1211 15:05:32.123118 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.123121 15749 net.cpp:137] Memory required for data: 811781688
I1211 15:05:32.123126 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/scale
I1211 15:05:32.123133 15749 net.cpp:84] Creating Layer conv2_7/x1/scale
I1211 15:05:32.123136 15749 net.cpp:406] conv2_7/x1/scale <- conv2_7/x1/bn
I1211 15:05:32.123139 15749 net.cpp:367] conv2_7/x1/scale -> conv2_7/x1/bn (in-place)
I1211 15:05:32.123212 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/scale
I1211 15:05:32.123426 15749 net.cpp:122] Setting up conv2_7/x1/scale
I1211 15:05:32.123432 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.123435 15749 net.cpp:137] Memory required for data: 814468152
I1211 15:05:32.123440 15749 layer_factory.hpp:77] Creating layer relu2_7/x1
I1211 15:05:32.123445 15749 net.cpp:84] Creating Layer relu2_7/x1
I1211 15:05:32.123447 15749 net.cpp:406] relu2_7/x1 <- conv2_7/x1/bn
I1211 15:05:32.123450 15749 net.cpp:367] relu2_7/x1 -> conv2_7/x1/bn (in-place)
I1211 15:05:32.123646 15749 net.cpp:122] Setting up relu2_7/x1
I1211 15:05:32.123653 15749 net.cpp:129] Top shape: 1 352 18 106 (671616)
I1211 15:05:32.123656 15749 net.cpp:137] Memory required for data: 817154616
I1211 15:05:32.123659 15749 layer_factory.hpp:77] Creating layer conv2_7/x1
I1211 15:05:32.123667 15749 net.cpp:84] Creating Layer conv2_7/x1
I1211 15:05:32.123670 15749 net.cpp:406] conv2_7/x1 <- conv2_7/x1/bn
I1211 15:05:32.123675 15749 net.cpp:380] conv2_7/x1 -> conv2_7/x1
I1211 15:05:32.126230 15749 net.cpp:122] Setting up conv2_7/x1
I1211 15:05:32.126261 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.126265 15749 net.cpp:137] Memory required for data: 818131512
I1211 15:05:32.126272 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/bn
I1211 15:05:32.126283 15749 net.cpp:84] Creating Layer conv2_7/x2/bn
I1211 15:05:32.126289 15749 net.cpp:406] conv2_7/x2/bn <- conv2_7/x1
I1211 15:05:32.126296 15749 net.cpp:380] conv2_7/x2/bn -> conv2_7/x2/bn
I1211 15:05:32.126699 15749 net.cpp:122] Setting up conv2_7/x2/bn
I1211 15:05:32.126711 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.126714 15749 net.cpp:137] Memory required for data: 819108408
I1211 15:05:32.126721 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/scale
I1211 15:05:32.126731 15749 net.cpp:84] Creating Layer conv2_7/x2/scale
I1211 15:05:32.126740 15749 net.cpp:406] conv2_7/x2/scale <- conv2_7/x2/bn
I1211 15:05:32.126745 15749 net.cpp:367] conv2_7/x2/scale -> conv2_7/x2/bn (in-place)
I1211 15:05:32.126819 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/scale
I1211 15:05:32.127041 15749 net.cpp:122] Setting up conv2_7/x2/scale
I1211 15:05:32.127049 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.127053 15749 net.cpp:137] Memory required for data: 820085304
I1211 15:05:32.127058 15749 layer_factory.hpp:77] Creating layer relu2_7/x2
I1211 15:05:32.127063 15749 net.cpp:84] Creating Layer relu2_7/x2
I1211 15:05:32.127066 15749 net.cpp:406] relu2_7/x2 <- conv2_7/x2/bn
I1211 15:05:32.127071 15749 net.cpp:367] relu2_7/x2 -> conv2_7/x2/bn (in-place)
I1211 15:05:32.127646 15749 net.cpp:122] Setting up relu2_7/x2
I1211 15:05:32.127666 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.127670 15749 net.cpp:137] Memory required for data: 821062200
I1211 15:05:32.127672 15749 layer_factory.hpp:77] Creating layer conv2_7/x2
I1211 15:05:32.127684 15749 net.cpp:84] Creating Layer conv2_7/x2
I1211 15:05:32.127689 15749 net.cpp:406] conv2_7/x2 <- conv2_7/x2/bn
I1211 15:05:32.127696 15749 net.cpp:380] conv2_7/x2 -> conv2_7/x2
I1211 15:05:32.130581 15749 net.cpp:122] Setting up conv2_7/x2
I1211 15:05:32.130614 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.130617 15749 net.cpp:137] Memory required for data: 821306424
I1211 15:05:32.130625 15749 layer_factory.hpp:77] Creating layer concat2_7
I1211 15:05:32.130636 15749 net.cpp:84] Creating Layer concat2_7
I1211 15:05:32.130641 15749 net.cpp:406] concat2_7 <- concat2_6_concat2_6_0_split_1
I1211 15:05:32.130647 15749 net.cpp:406] concat2_7 <- conv2_7/x2
I1211 15:05:32.130653 15749 net.cpp:380] concat2_7 -> concat2_7
I1211 15:05:32.130713 15749 net.cpp:122] Setting up concat2_7
I1211 15:05:32.130719 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.130722 15749 net.cpp:137] Memory required for data: 824237112
I1211 15:05:32.130723 15749 layer_factory.hpp:77] Creating layer concat2_7_concat2_7_0_split
I1211 15:05:32.130728 15749 net.cpp:84] Creating Layer concat2_7_concat2_7_0_split
I1211 15:05:32.130731 15749 net.cpp:406] concat2_7_concat2_7_0_split <- concat2_7
I1211 15:05:32.130736 15749 net.cpp:380] concat2_7_concat2_7_0_split -> concat2_7_concat2_7_0_split_0
I1211 15:05:32.130741 15749 net.cpp:380] concat2_7_concat2_7_0_split -> concat2_7_concat2_7_0_split_1
I1211 15:05:32.130807 15749 net.cpp:122] Setting up concat2_7_concat2_7_0_split
I1211 15:05:32.130813 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.130816 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.130818 15749 net.cpp:137] Memory required for data: 830098488
I1211 15:05:32.130821 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/bn
I1211 15:05:32.130827 15749 net.cpp:84] Creating Layer conv2_8/x1/bn
I1211 15:05:32.130831 15749 net.cpp:406] conv2_8/x1/bn <- concat2_7_concat2_7_0_split_0
I1211 15:05:32.130834 15749 net.cpp:380] conv2_8/x1/bn -> conv2_8/x1/bn
I1211 15:05:32.131255 15749 net.cpp:122] Setting up conv2_8/x1/bn
I1211 15:05:32.131263 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.131265 15749 net.cpp:137] Memory required for data: 833029176
I1211 15:05:32.131273 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/scale
I1211 15:05:32.131280 15749 net.cpp:84] Creating Layer conv2_8/x1/scale
I1211 15:05:32.131283 15749 net.cpp:406] conv2_8/x1/scale <- conv2_8/x1/bn
I1211 15:05:32.131289 15749 net.cpp:367] conv2_8/x1/scale -> conv2_8/x1/bn (in-place)
I1211 15:05:32.131356 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/scale
I1211 15:05:32.131567 15749 net.cpp:122] Setting up conv2_8/x1/scale
I1211 15:05:32.131573 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.131575 15749 net.cpp:137] Memory required for data: 835959864
I1211 15:05:32.131580 15749 layer_factory.hpp:77] Creating layer relu2_8/x1
I1211 15:05:32.131587 15749 net.cpp:84] Creating Layer relu2_8/x1
I1211 15:05:32.131593 15749 net.cpp:406] relu2_8/x1 <- conv2_8/x1/bn
I1211 15:05:32.131597 15749 net.cpp:367] relu2_8/x1 -> conv2_8/x1/bn (in-place)
I1211 15:05:32.131832 15749 net.cpp:122] Setting up relu2_8/x1
I1211 15:05:32.131841 15749 net.cpp:129] Top shape: 1 384 18 106 (732672)
I1211 15:05:32.131844 15749 net.cpp:137] Memory required for data: 838890552
I1211 15:05:32.131847 15749 layer_factory.hpp:77] Creating layer conv2_8/x1
I1211 15:05:32.131856 15749 net.cpp:84] Creating Layer conv2_8/x1
I1211 15:05:32.131860 15749 net.cpp:406] conv2_8/x1 <- conv2_8/x1/bn
I1211 15:05:32.131865 15749 net.cpp:380] conv2_8/x1 -> conv2_8/x1
I1211 15:05:32.134464 15749 net.cpp:122] Setting up conv2_8/x1
I1211 15:05:32.134483 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.134485 15749 net.cpp:137] Memory required for data: 839867448
I1211 15:05:32.134491 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/bn
I1211 15:05:32.134500 15749 net.cpp:84] Creating Layer conv2_8/x2/bn
I1211 15:05:32.134505 15749 net.cpp:406] conv2_8/x2/bn <- conv2_8/x1
I1211 15:05:32.134510 15749 net.cpp:380] conv2_8/x2/bn -> conv2_8/x2/bn
I1211 15:05:32.134897 15749 net.cpp:122] Setting up conv2_8/x2/bn
I1211 15:05:32.134903 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.134907 15749 net.cpp:137] Memory required for data: 840844344
I1211 15:05:32.134912 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/scale
I1211 15:05:32.134919 15749 net.cpp:84] Creating Layer conv2_8/x2/scale
I1211 15:05:32.134922 15749 net.cpp:406] conv2_8/x2/scale <- conv2_8/x2/bn
I1211 15:05:32.134927 15749 net.cpp:367] conv2_8/x2/scale -> conv2_8/x2/bn (in-place)
I1211 15:05:32.134994 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/scale
I1211 15:05:32.135193 15749 net.cpp:122] Setting up conv2_8/x2/scale
I1211 15:05:32.135200 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.135202 15749 net.cpp:137] Memory required for data: 841821240
I1211 15:05:32.135206 15749 layer_factory.hpp:77] Creating layer relu2_8/x2
I1211 15:05:32.135213 15749 net.cpp:84] Creating Layer relu2_8/x2
I1211 15:05:32.135216 15749 net.cpp:406] relu2_8/x2 <- conv2_8/x2/bn
I1211 15:05:32.135219 15749 net.cpp:367] relu2_8/x2 -> conv2_8/x2/bn (in-place)
I1211 15:05:32.135604 15749 net.cpp:122] Setting up relu2_8/x2
I1211 15:05:32.135614 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.135617 15749 net.cpp:137] Memory required for data: 842798136
I1211 15:05:32.135620 15749 layer_factory.hpp:77] Creating layer conv2_8/x2
I1211 15:05:32.135629 15749 net.cpp:84] Creating Layer conv2_8/x2
I1211 15:05:32.135633 15749 net.cpp:406] conv2_8/x2 <- conv2_8/x2/bn
I1211 15:05:32.135638 15749 net.cpp:380] conv2_8/x2 -> conv2_8/x2
I1211 15:05:32.138911 15749 net.cpp:122] Setting up conv2_8/x2
I1211 15:05:32.138947 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.138952 15749 net.cpp:137] Memory required for data: 843042360
I1211 15:05:32.138963 15749 layer_factory.hpp:77] Creating layer concat2_8
I1211 15:05:32.138976 15749 net.cpp:84] Creating Layer concat2_8
I1211 15:05:32.138983 15749 net.cpp:406] concat2_8 <- concat2_7_concat2_7_0_split_1
I1211 15:05:32.138991 15749 net.cpp:406] concat2_8 <- conv2_8/x2
I1211 15:05:32.139003 15749 net.cpp:380] concat2_8 -> concat2_8
I1211 15:05:32.139071 15749 net.cpp:122] Setting up concat2_8
I1211 15:05:32.139081 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.139084 15749 net.cpp:137] Memory required for data: 846217272
I1211 15:05:32.139088 15749 layer_factory.hpp:77] Creating layer concat2_8_concat2_8_0_split
I1211 15:05:32.139096 15749 net.cpp:84] Creating Layer concat2_8_concat2_8_0_split
I1211 15:05:32.139101 15749 net.cpp:406] concat2_8_concat2_8_0_split <- concat2_8
I1211 15:05:32.139107 15749 net.cpp:380] concat2_8_concat2_8_0_split -> concat2_8_concat2_8_0_split_0
I1211 15:05:32.139114 15749 net.cpp:380] concat2_8_concat2_8_0_split -> concat2_8_concat2_8_0_split_1
I1211 15:05:32.139206 15749 net.cpp:122] Setting up concat2_8_concat2_8_0_split
I1211 15:05:32.139219 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.139225 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.139227 15749 net.cpp:137] Memory required for data: 852567096
I1211 15:05:32.139231 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/bn
I1211 15:05:32.139240 15749 net.cpp:84] Creating Layer conv2_9/x1/bn
I1211 15:05:32.139245 15749 net.cpp:406] conv2_9/x1/bn <- concat2_8_concat2_8_0_split_0
I1211 15:05:32.139250 15749 net.cpp:380] conv2_9/x1/bn -> conv2_9/x1/bn
I1211 15:05:32.139823 15749 net.cpp:122] Setting up conv2_9/x1/bn
I1211 15:05:32.139835 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.139839 15749 net.cpp:137] Memory required for data: 855742008
I1211 15:05:32.139850 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/scale
I1211 15:05:32.139859 15749 net.cpp:84] Creating Layer conv2_9/x1/scale
I1211 15:05:32.139863 15749 net.cpp:406] conv2_9/x1/scale <- conv2_9/x1/bn
I1211 15:05:32.139871 15749 net.cpp:367] conv2_9/x1/scale -> conv2_9/x1/bn (in-place)
I1211 15:05:32.139971 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/scale
I1211 15:05:32.140276 15749 net.cpp:122] Setting up conv2_9/x1/scale
I1211 15:05:32.140285 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.140290 15749 net.cpp:137] Memory required for data: 858916920
I1211 15:05:32.140296 15749 layer_factory.hpp:77] Creating layer relu2_9/x1
I1211 15:05:32.140305 15749 net.cpp:84] Creating Layer relu2_9/x1
I1211 15:05:32.140308 15749 net.cpp:406] relu2_9/x1 <- conv2_9/x1/bn
I1211 15:05:32.140316 15749 net.cpp:367] relu2_9/x1 -> conv2_9/x1/bn (in-place)
I1211 15:05:32.140897 15749 net.cpp:122] Setting up relu2_9/x1
I1211 15:05:32.140913 15749 net.cpp:129] Top shape: 1 416 18 106 (793728)
I1211 15:05:32.140918 15749 net.cpp:137] Memory required for data: 862091832
I1211 15:05:32.140921 15749 layer_factory.hpp:77] Creating layer conv2_9/x1
I1211 15:05:32.140938 15749 net.cpp:84] Creating Layer conv2_9/x1
I1211 15:05:32.140943 15749 net.cpp:406] conv2_9/x1 <- conv2_9/x1/bn
I1211 15:05:32.140950 15749 net.cpp:380] conv2_9/x1 -> conv2_9/x1
I1211 15:05:32.144945 15749 net.cpp:122] Setting up conv2_9/x1
I1211 15:05:32.144984 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.144989 15749 net.cpp:137] Memory required for data: 863068728
I1211 15:05:32.144999 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/bn
I1211 15:05:32.145012 15749 net.cpp:84] Creating Layer conv2_9/x2/bn
I1211 15:05:32.145020 15749 net.cpp:406] conv2_9/x2/bn <- conv2_9/x1
I1211 15:05:32.145030 15749 net.cpp:380] conv2_9/x2/bn -> conv2_9/x2/bn
I1211 15:05:32.145586 15749 net.cpp:122] Setting up conv2_9/x2/bn
I1211 15:05:32.145597 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.145601 15749 net.cpp:137] Memory required for data: 864045624
I1211 15:05:32.145612 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/scale
I1211 15:05:32.145620 15749 net.cpp:84] Creating Layer conv2_9/x2/scale
I1211 15:05:32.145625 15749 net.cpp:406] conv2_9/x2/scale <- conv2_9/x2/bn
I1211 15:05:32.145632 15749 net.cpp:367] conv2_9/x2/scale -> conv2_9/x2/bn (in-place)
I1211 15:05:32.145727 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/scale
I1211 15:05:32.146008 15749 net.cpp:122] Setting up conv2_9/x2/scale
I1211 15:05:32.146018 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.146021 15749 net.cpp:137] Memory required for data: 865022520
I1211 15:05:32.146028 15749 layer_factory.hpp:77] Creating layer relu2_9/x2
I1211 15:05:32.146035 15749 net.cpp:84] Creating Layer relu2_9/x2
I1211 15:05:32.146039 15749 net.cpp:406] relu2_9/x2 <- conv2_9/x2/bn
I1211 15:05:32.146044 15749 net.cpp:367] relu2_9/x2 -> conv2_9/x2/bn (in-place)
I1211 15:05:32.146301 15749 net.cpp:122] Setting up relu2_9/x2
I1211 15:05:32.146313 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.146317 15749 net.cpp:137] Memory required for data: 865999416
I1211 15:05:32.146322 15749 layer_factory.hpp:77] Creating layer conv2_9/x2
I1211 15:05:32.146334 15749 net.cpp:84] Creating Layer conv2_9/x2
I1211 15:05:32.146343 15749 net.cpp:406] conv2_9/x2 <- conv2_9/x2/bn
I1211 15:05:32.146350 15749 net.cpp:380] conv2_9/x2 -> conv2_9/x2
I1211 15:05:32.149633 15749 net.cpp:122] Setting up conv2_9/x2
I1211 15:05:32.149652 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.149657 15749 net.cpp:137] Memory required for data: 866243640
I1211 15:05:32.149664 15749 layer_factory.hpp:77] Creating layer concat2_9
I1211 15:05:32.149674 15749 net.cpp:84] Creating Layer concat2_9
I1211 15:05:32.149682 15749 net.cpp:406] concat2_9 <- concat2_8_concat2_8_0_split_1
I1211 15:05:32.149688 15749 net.cpp:406] concat2_9 <- conv2_9/x2
I1211 15:05:32.149694 15749 net.cpp:380] concat2_9 -> concat2_9
I1211 15:05:32.149756 15749 net.cpp:122] Setting up concat2_9
I1211 15:05:32.149766 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.149770 15749 net.cpp:137] Memory required for data: 869662776
I1211 15:05:32.149773 15749 layer_factory.hpp:77] Creating layer concat2_9_concat2_9_0_split
I1211 15:05:32.149780 15749 net.cpp:84] Creating Layer concat2_9_concat2_9_0_split
I1211 15:05:32.149785 15749 net.cpp:406] concat2_9_concat2_9_0_split <- concat2_9
I1211 15:05:32.149791 15749 net.cpp:380] concat2_9_concat2_9_0_split -> concat2_9_concat2_9_0_split_0
I1211 15:05:32.149797 15749 net.cpp:380] concat2_9_concat2_9_0_split -> concat2_9_concat2_9_0_split_1
I1211 15:05:32.149889 15749 net.cpp:122] Setting up concat2_9_concat2_9_0_split
I1211 15:05:32.149897 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.149902 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.149905 15749 net.cpp:137] Memory required for data: 876501048
I1211 15:05:32.149909 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/bn
I1211 15:05:32.149919 15749 net.cpp:84] Creating Layer conv2_10/x1/bn
I1211 15:05:32.149924 15749 net.cpp:406] conv2_10/x1/bn <- concat2_9_concat2_9_0_split_0
I1211 15:05:32.149930 15749 net.cpp:380] conv2_10/x1/bn -> conv2_10/x1/bn
I1211 15:05:32.150511 15749 net.cpp:122] Setting up conv2_10/x1/bn
I1211 15:05:32.150521 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.150524 15749 net.cpp:137] Memory required for data: 879920184
I1211 15:05:32.150533 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/scale
I1211 15:05:32.150543 15749 net.cpp:84] Creating Layer conv2_10/x1/scale
I1211 15:05:32.150547 15749 net.cpp:406] conv2_10/x1/scale <- conv2_10/x1/bn
I1211 15:05:32.150554 15749 net.cpp:367] conv2_10/x1/scale -> conv2_10/x1/bn (in-place)
I1211 15:05:32.150650 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/scale
I1211 15:05:32.150956 15749 net.cpp:122] Setting up conv2_10/x1/scale
I1211 15:05:32.150964 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.150969 15749 net.cpp:137] Memory required for data: 883339320
I1211 15:05:32.150975 15749 layer_factory.hpp:77] Creating layer relu2_10/x1
I1211 15:05:32.150984 15749 net.cpp:84] Creating Layer relu2_10/x1
I1211 15:05:32.150988 15749 net.cpp:406] relu2_10/x1 <- conv2_10/x1/bn
I1211 15:05:32.150993 15749 net.cpp:367] relu2_10/x1 -> conv2_10/x1/bn (in-place)
I1211 15:05:32.151473 15749 net.cpp:122] Setting up relu2_10/x1
I1211 15:05:32.151486 15749 net.cpp:129] Top shape: 1 448 18 106 (854784)
I1211 15:05:32.151490 15749 net.cpp:137] Memory required for data: 886758456
I1211 15:05:32.151494 15749 layer_factory.hpp:77] Creating layer conv2_10/x1
I1211 15:05:32.151507 15749 net.cpp:84] Creating Layer conv2_10/x1
I1211 15:05:32.151512 15749 net.cpp:406] conv2_10/x1 <- conv2_10/x1/bn
I1211 15:05:32.151520 15749 net.cpp:380] conv2_10/x1 -> conv2_10/x1
I1211 15:05:32.155299 15749 net.cpp:122] Setting up conv2_10/x1
I1211 15:05:32.155320 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.155325 15749 net.cpp:137] Memory required for data: 887735352
I1211 15:05:32.155333 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/bn
I1211 15:05:32.155342 15749 net.cpp:84] Creating Layer conv2_10/x2/bn
I1211 15:05:32.155347 15749 net.cpp:406] conv2_10/x2/bn <- conv2_10/x1
I1211 15:05:32.155360 15749 net.cpp:380] conv2_10/x2/bn -> conv2_10/x2/bn
I1211 15:05:32.155915 15749 net.cpp:122] Setting up conv2_10/x2/bn
I1211 15:05:32.155925 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.155928 15749 net.cpp:137] Memory required for data: 888712248
I1211 15:05:32.155936 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/scale
I1211 15:05:32.155946 15749 net.cpp:84] Creating Layer conv2_10/x2/scale
I1211 15:05:32.155951 15749 net.cpp:406] conv2_10/x2/scale <- conv2_10/x2/bn
I1211 15:05:32.155958 15749 net.cpp:367] conv2_10/x2/scale -> conv2_10/x2/bn (in-place)
I1211 15:05:32.156049 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/scale
I1211 15:05:32.156330 15749 net.cpp:122] Setting up conv2_10/x2/scale
I1211 15:05:32.156339 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.156343 15749 net.cpp:137] Memory required for data: 889689144
I1211 15:05:32.156350 15749 layer_factory.hpp:77] Creating layer relu2_10/x2
I1211 15:05:32.156358 15749 net.cpp:84] Creating Layer relu2_10/x2
I1211 15:05:32.156361 15749 net.cpp:406] relu2_10/x2 <- conv2_10/x2/bn
I1211 15:05:32.156368 15749 net.cpp:367] relu2_10/x2 -> conv2_10/x2/bn (in-place)
I1211 15:05:32.156776 15749 net.cpp:122] Setting up relu2_10/x2
I1211 15:05:32.156790 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.156795 15749 net.cpp:137] Memory required for data: 890666040
I1211 15:05:32.156798 15749 layer_factory.hpp:77] Creating layer conv2_10/x2
I1211 15:05:32.156811 15749 net.cpp:84] Creating Layer conv2_10/x2
I1211 15:05:32.156816 15749 net.cpp:406] conv2_10/x2 <- conv2_10/x2/bn
I1211 15:05:32.156823 15749 net.cpp:380] conv2_10/x2 -> conv2_10/x2
I1211 15:05:32.160037 15749 net.cpp:122] Setting up conv2_10/x2
I1211 15:05:32.160058 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.160061 15749 net.cpp:137] Memory required for data: 890910264
I1211 15:05:32.160069 15749 layer_factory.hpp:77] Creating layer concat2_10
I1211 15:05:32.160079 15749 net.cpp:84] Creating Layer concat2_10
I1211 15:05:32.160084 15749 net.cpp:406] concat2_10 <- concat2_9_concat2_9_0_split_1
I1211 15:05:32.160091 15749 net.cpp:406] concat2_10 <- conv2_10/x2
I1211 15:05:32.160099 15749 net.cpp:380] concat2_10 -> concat2_10
I1211 15:05:32.160161 15749 net.cpp:122] Setting up concat2_10
I1211 15:05:32.160171 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.160174 15749 net.cpp:137] Memory required for data: 894573624
I1211 15:05:32.160178 15749 layer_factory.hpp:77] Creating layer concat2_10_concat2_10_0_split
I1211 15:05:32.160184 15749 net.cpp:84] Creating Layer concat2_10_concat2_10_0_split
I1211 15:05:32.160188 15749 net.cpp:406] concat2_10_concat2_10_0_split <- concat2_10
I1211 15:05:32.160195 15749 net.cpp:380] concat2_10_concat2_10_0_split -> concat2_10_concat2_10_0_split_0
I1211 15:05:32.160203 15749 net.cpp:380] concat2_10_concat2_10_0_split -> concat2_10_concat2_10_0_split_1
I1211 15:05:32.160295 15749 net.cpp:122] Setting up concat2_10_concat2_10_0_split
I1211 15:05:32.160303 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.160308 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.160312 15749 net.cpp:137] Memory required for data: 901900344
I1211 15:05:32.160316 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/bn
I1211 15:05:32.160323 15749 net.cpp:84] Creating Layer conv2_11/x1/bn
I1211 15:05:32.160327 15749 net.cpp:406] conv2_11/x1/bn <- concat2_10_concat2_10_0_split_0
I1211 15:05:32.160334 15749 net.cpp:380] conv2_11/x1/bn -> conv2_11/x1/bn
I1211 15:05:32.160938 15749 net.cpp:122] Setting up conv2_11/x1/bn
I1211 15:05:32.160948 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.160951 15749 net.cpp:137] Memory required for data: 905563704
I1211 15:05:32.160961 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/scale
I1211 15:05:32.160970 15749 net.cpp:84] Creating Layer conv2_11/x1/scale
I1211 15:05:32.160975 15749 net.cpp:406] conv2_11/x1/scale <- conv2_11/x1/bn
I1211 15:05:32.160981 15749 net.cpp:367] conv2_11/x1/scale -> conv2_11/x1/bn (in-place)
I1211 15:05:32.161087 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/scale
I1211 15:05:32.161406 15749 net.cpp:122] Setting up conv2_11/x1/scale
I1211 15:05:32.161415 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.161419 15749 net.cpp:137] Memory required for data: 909227064
I1211 15:05:32.161442 15749 layer_factory.hpp:77] Creating layer relu2_11/x1
I1211 15:05:32.161450 15749 net.cpp:84] Creating Layer relu2_11/x1
I1211 15:05:32.161454 15749 net.cpp:406] relu2_11/x1 <- conv2_11/x1/bn
I1211 15:05:32.161460 15749 net.cpp:367] relu2_11/x1 -> conv2_11/x1/bn (in-place)
I1211 15:05:32.161945 15749 net.cpp:122] Setting up relu2_11/x1
I1211 15:05:32.161957 15749 net.cpp:129] Top shape: 1 480 18 106 (915840)
I1211 15:05:32.161962 15749 net.cpp:137] Memory required for data: 912890424
I1211 15:05:32.161967 15749 layer_factory.hpp:77] Creating layer conv2_11/x1
I1211 15:05:32.161983 15749 net.cpp:84] Creating Layer conv2_11/x1
I1211 15:05:32.161988 15749 net.cpp:406] conv2_11/x1 <- conv2_11/x1/bn
I1211 15:05:32.161995 15749 net.cpp:380] conv2_11/x1 -> conv2_11/x1
I1211 15:05:32.167327 15749 net.cpp:122] Setting up conv2_11/x1
I1211 15:05:32.167363 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.167368 15749 net.cpp:137] Memory required for data: 913867320
I1211 15:05:32.167379 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/bn
I1211 15:05:32.167393 15749 net.cpp:84] Creating Layer conv2_11/x2/bn
I1211 15:05:32.167400 15749 net.cpp:406] conv2_11/x2/bn <- conv2_11/x1
I1211 15:05:32.167409 15749 net.cpp:380] conv2_11/x2/bn -> conv2_11/x2/bn
I1211 15:05:32.168002 15749 net.cpp:122] Setting up conv2_11/x2/bn
I1211 15:05:32.168012 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.168016 15749 net.cpp:137] Memory required for data: 914844216
I1211 15:05:32.168026 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/scale
I1211 15:05:32.168037 15749 net.cpp:84] Creating Layer conv2_11/x2/scale
I1211 15:05:32.168042 15749 net.cpp:406] conv2_11/x2/scale <- conv2_11/x2/bn
I1211 15:05:32.168048 15749 net.cpp:367] conv2_11/x2/scale -> conv2_11/x2/bn (in-place)
I1211 15:05:32.168146 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/scale
I1211 15:05:32.168439 15749 net.cpp:122] Setting up conv2_11/x2/scale
I1211 15:05:32.168448 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.168452 15749 net.cpp:137] Memory required for data: 915821112
I1211 15:05:32.168459 15749 layer_factory.hpp:77] Creating layer relu2_11/x2
I1211 15:05:32.168468 15749 net.cpp:84] Creating Layer relu2_11/x2
I1211 15:05:32.168473 15749 net.cpp:406] relu2_11/x2 <- conv2_11/x2/bn
I1211 15:05:32.168478 15749 net.cpp:367] relu2_11/x2 -> conv2_11/x2/bn (in-place)
I1211 15:05:32.168953 15749 net.cpp:122] Setting up relu2_11/x2
I1211 15:05:32.168965 15749 net.cpp:129] Top shape: 1 128 18 106 (244224)
I1211 15:05:32.168970 15749 net.cpp:137] Memory required for data: 916798008
I1211 15:05:32.168974 15749 layer_factory.hpp:77] Creating layer conv2_11/x2
I1211 15:05:32.168988 15749 net.cpp:84] Creating Layer conv2_11/x2
I1211 15:05:32.168993 15749 net.cpp:406] conv2_11/x2 <- conv2_11/x2/bn
I1211 15:05:32.169000 15749 net.cpp:380] conv2_11/x2 -> conv2_11/x2
I1211 15:05:32.172261 15749 net.cpp:122] Setting up conv2_11/x2
I1211 15:05:32.172282 15749 net.cpp:129] Top shape: 1 32 18 106 (61056)
I1211 15:05:32.172287 15749 net.cpp:137] Memory required for data: 917042232
I1211 15:05:32.172294 15749 layer_factory.hpp:77] Creating layer concat2_11
I1211 15:05:32.172304 15749 net.cpp:84] Creating Layer concat2_11
I1211 15:05:32.172312 15749 net.cpp:406] concat2_11 <- concat2_10_concat2_10_0_split_1
I1211 15:05:32.172320 15749 net.cpp:406] concat2_11 <- conv2_11/x2
I1211 15:05:32.172327 15749 net.cpp:380] concat2_11 -> concat2_11
I1211 15:05:32.172390 15749 net.cpp:122] Setting up concat2_11
I1211 15:05:32.172399 15749 net.cpp:129] Top shape: 1 512 18 106 (976896)
I1211 15:05:32.172403 15749 net.cpp:137] Memory required for data: 920949816
I1211 15:05:32.172413 15749 layer_factory.hpp:77] Creating layer tpp5
I1211 15:05:32.172421 15749 net.cpp:84] Creating Layer tpp5
I1211 15:05:32.172426 15749 net.cpp:406] tpp5 <- concat2_11
I1211 15:05:32.172432 15749 net.cpp:380] tpp5 -> tpp5
I1211 15:05:32.173615 15749 net.cpp:122] Setting up tpp5
I1211 15:05:32.173629 15749 net.cpp:129] Top shape: 1 7680 (7680)
I1211 15:05:32.173633 15749 net.cpp:137] Memory required for data: 920980536
I1211 15:05:32.173637 15749 layer_factory.hpp:77] Creating layer fc6_d
I1211 15:05:32.173647 15749 net.cpp:84] Creating Layer fc6_d
I1211 15:05:32.173652 15749 net.cpp:406] fc6_d <- tpp5
I1211 15:05:32.173658 15749 net.cpp:380] fc6_d -> fc6_d
I1211 15:05:34.637118 15749 net.cpp:122] Setting up fc6_d
I1211 15:05:34.637154 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:34.637158 15749 net.cpp:137] Memory required for data: 920996920
I1211 15:05:34.637166 15749 layer_factory.hpp:77] Creating layer relu6
I1211 15:05:34.637176 15749 net.cpp:84] Creating Layer relu6
I1211 15:05:34.637181 15749 net.cpp:406] relu6 <- fc6_d
I1211 15:05:34.637187 15749 net.cpp:367] relu6 -> fc6_d (in-place)
I1211 15:05:34.637444 15749 net.cpp:122] Setting up relu6
I1211 15:05:34.637454 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:34.637455 15749 net.cpp:137] Memory required for data: 921013304
I1211 15:05:34.637459 15749 layer_factory.hpp:77] Creating layer drop6
I1211 15:05:34.637472 15749 net.cpp:84] Creating Layer drop6
I1211 15:05:34.637476 15749 net.cpp:406] drop6 <- fc6_d
I1211 15:05:34.637482 15749 net.cpp:367] drop6 -> fc6_d (in-place)
I1211 15:05:34.637531 15749 net.cpp:122] Setting up drop6
I1211 15:05:34.637537 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:34.637539 15749 net.cpp:137] Memory required for data: 921029688
I1211 15:05:34.637542 15749 layer_factory.hpp:77] Creating layer fc7_d
I1211 15:05:34.637548 15749 net.cpp:84] Creating Layer fc7_d
I1211 15:05:34.637552 15749 net.cpp:406] fc7_d <- fc6_d
I1211 15:05:34.637555 15749 net.cpp:380] fc7_d -> fc7_d
I1211 15:05:36.802460 15749 net.cpp:122] Setting up fc7_d
I1211 15:05:36.802494 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:36.802496 15749 net.cpp:137] Memory required for data: 921046072
I1211 15:05:36.802505 15749 layer_factory.hpp:77] Creating layer relu7
I1211 15:05:36.802515 15749 net.cpp:84] Creating Layer relu7
I1211 15:05:36.802520 15749 net.cpp:406] relu7 <- fc7_d
I1211 15:05:36.802525 15749 net.cpp:367] relu7 -> fc7_d (in-place)
I1211 15:05:36.803093 15749 net.cpp:122] Setting up relu7
I1211 15:05:36.803105 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:36.803108 15749 net.cpp:137] Memory required for data: 921062456
I1211 15:05:36.803112 15749 layer_factory.hpp:77] Creating layer drop7
I1211 15:05:36.803122 15749 net.cpp:84] Creating Layer drop7
I1211 15:05:36.803125 15749 net.cpp:406] drop7 <- fc7_d
I1211 15:05:36.803130 15749 net.cpp:367] drop7 -> fc7_d (in-place)
I1211 15:05:36.803184 15749 net.cpp:122] Setting up drop7
I1211 15:05:36.803189 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:36.803191 15749 net.cpp:137] Memory required for data: 921078840
I1211 15:05:36.803194 15749 layer_factory.hpp:77] Creating layer fc8_d
I1211 15:05:36.803201 15749 net.cpp:84] Creating Layer fc8_d
I1211 15:05:36.803205 15749 net.cpp:406] fc8_d <- fc7_d
I1211 15:05:36.803208 15749 net.cpp:380] fc8_d -> fc8_d
I1211 15:05:37.192860 15749 net.cpp:122] Setting up fc8_d
I1211 15:05:37.192898 15749 net.cpp:129] Top shape: 1 604 (604)
I1211 15:05:37.192903 15749 net.cpp:137] Memory required for data: 921081256
I1211 15:05:37.192914 15749 layer_factory.hpp:77] Creating layer loss
I1211 15:05:37.192926 15749 net.cpp:84] Creating Layer loss
I1211 15:05:37.192934 15749 net.cpp:406] loss <- fc8_d
I1211 15:05:37.192940 15749 net.cpp:406] loss <- phocs
I1211 15:05:37.192946 15749 net.cpp:380] loss -> loss
I1211 15:05:37.193044 15749 net.cpp:122] Setting up loss
I1211 15:05:37.193054 15749 net.cpp:129] Top shape: (1)
I1211 15:05:37.193058 15749 net.cpp:132]     with loss weight 1
I1211 15:05:37.193071 15749 net.cpp:137] Memory required for data: 921081260
I1211 15:05:37.193084 15749 net.cpp:198] loss needs backward computation.
I1211 15:05:37.193089 15749 net.cpp:198] fc8_d needs backward computation.
I1211 15:05:37.193092 15749 net.cpp:198] drop7 needs backward computation.
I1211 15:05:37.193096 15749 net.cpp:198] relu7 needs backward computation.
I1211 15:05:37.193100 15749 net.cpp:198] fc7_d needs backward computation.
I1211 15:05:37.193104 15749 net.cpp:198] drop6 needs backward computation.
I1211 15:05:37.193109 15749 net.cpp:198] relu6 needs backward computation.
I1211 15:05:37.193112 15749 net.cpp:198] fc6_d needs backward computation.
I1211 15:05:37.193116 15749 net.cpp:198] tpp5 needs backward computation.
I1211 15:05:37.193121 15749 net.cpp:198] concat2_11 needs backward computation.
I1211 15:05:37.193126 15749 net.cpp:198] conv2_11/x2 needs backward computation.
I1211 15:05:37.193130 15749 net.cpp:198] relu2_11/x2 needs backward computation.
I1211 15:05:37.193135 15749 net.cpp:198] conv2_11/x2/scale needs backward computation.
I1211 15:05:37.193138 15749 net.cpp:198] conv2_11/x2/bn needs backward computation.
I1211 15:05:37.193143 15749 net.cpp:198] conv2_11/x1 needs backward computation.
I1211 15:05:37.193147 15749 net.cpp:198] relu2_11/x1 needs backward computation.
I1211 15:05:37.193151 15749 net.cpp:198] conv2_11/x1/scale needs backward computation.
I1211 15:05:37.193156 15749 net.cpp:198] conv2_11/x1/bn needs backward computation.
I1211 15:05:37.193159 15749 net.cpp:198] concat2_10_concat2_10_0_split needs backward computation.
I1211 15:05:37.193164 15749 net.cpp:198] concat2_10 needs backward computation.
I1211 15:05:37.193169 15749 net.cpp:198] conv2_10/x2 needs backward computation.
I1211 15:05:37.193173 15749 net.cpp:198] relu2_10/x2 needs backward computation.
I1211 15:05:37.193177 15749 net.cpp:198] conv2_10/x2/scale needs backward computation.
I1211 15:05:37.193181 15749 net.cpp:198] conv2_10/x2/bn needs backward computation.
I1211 15:05:37.193186 15749 net.cpp:198] conv2_10/x1 needs backward computation.
I1211 15:05:37.193190 15749 net.cpp:198] relu2_10/x1 needs backward computation.
I1211 15:05:37.193194 15749 net.cpp:198] conv2_10/x1/scale needs backward computation.
I1211 15:05:37.193198 15749 net.cpp:198] conv2_10/x1/bn needs backward computation.
I1211 15:05:37.193202 15749 net.cpp:198] concat2_9_concat2_9_0_split needs backward computation.
I1211 15:05:37.193207 15749 net.cpp:198] concat2_9 needs backward computation.
I1211 15:05:37.193212 15749 net.cpp:198] conv2_9/x2 needs backward computation.
I1211 15:05:37.193217 15749 net.cpp:198] relu2_9/x2 needs backward computation.
I1211 15:05:37.193220 15749 net.cpp:198] conv2_9/x2/scale needs backward computation.
I1211 15:05:37.193224 15749 net.cpp:198] conv2_9/x2/bn needs backward computation.
I1211 15:05:37.193229 15749 net.cpp:198] conv2_9/x1 needs backward computation.
I1211 15:05:37.193233 15749 net.cpp:198] relu2_9/x1 needs backward computation.
I1211 15:05:37.193238 15749 net.cpp:198] conv2_9/x1/scale needs backward computation.
I1211 15:05:37.193241 15749 net.cpp:198] conv2_9/x1/bn needs backward computation.
I1211 15:05:37.193245 15749 net.cpp:198] concat2_8_concat2_8_0_split needs backward computation.
I1211 15:05:37.193249 15749 net.cpp:198] concat2_8 needs backward computation.
I1211 15:05:37.193254 15749 net.cpp:198] conv2_8/x2 needs backward computation.
I1211 15:05:37.193259 15749 net.cpp:198] relu2_8/x2 needs backward computation.
I1211 15:05:37.193264 15749 net.cpp:198] conv2_8/x2/scale needs backward computation.
I1211 15:05:37.193267 15749 net.cpp:198] conv2_8/x2/bn needs backward computation.
I1211 15:05:37.193271 15749 net.cpp:198] conv2_8/x1 needs backward computation.
I1211 15:05:37.193275 15749 net.cpp:198] relu2_8/x1 needs backward computation.
I1211 15:05:37.193279 15749 net.cpp:198] conv2_8/x1/scale needs backward computation.
I1211 15:05:37.193284 15749 net.cpp:198] conv2_8/x1/bn needs backward computation.
I1211 15:05:37.193289 15749 net.cpp:198] concat2_7_concat2_7_0_split needs backward computation.
I1211 15:05:37.193292 15749 net.cpp:198] concat2_7 needs backward computation.
I1211 15:05:37.193300 15749 net.cpp:198] conv2_7/x2 needs backward computation.
I1211 15:05:37.193303 15749 net.cpp:198] relu2_7/x2 needs backward computation.
I1211 15:05:37.193307 15749 net.cpp:198] conv2_7/x2/scale needs backward computation.
I1211 15:05:37.193311 15749 net.cpp:198] conv2_7/x2/bn needs backward computation.
I1211 15:05:37.193316 15749 net.cpp:198] conv2_7/x1 needs backward computation.
I1211 15:05:37.193320 15749 net.cpp:198] relu2_7/x1 needs backward computation.
I1211 15:05:37.193325 15749 net.cpp:198] conv2_7/x1/scale needs backward computation.
I1211 15:05:37.193328 15749 net.cpp:198] conv2_7/x1/bn needs backward computation.
I1211 15:05:37.193333 15749 net.cpp:198] concat2_6_concat2_6_0_split needs backward computation.
I1211 15:05:37.193337 15749 net.cpp:198] concat2_6 needs backward computation.
I1211 15:05:37.193342 15749 net.cpp:198] conv2_6/x2 needs backward computation.
I1211 15:05:37.193346 15749 net.cpp:198] relu2_6/x2 needs backward computation.
I1211 15:05:37.193351 15749 net.cpp:198] conv2_6/x2/scale needs backward computation.
I1211 15:05:37.193354 15749 net.cpp:198] conv2_6/x2/bn needs backward computation.
I1211 15:05:37.193359 15749 net.cpp:198] conv2_6/x1 needs backward computation.
I1211 15:05:37.193363 15749 net.cpp:198] relu2_6/x1 needs backward computation.
I1211 15:05:37.193367 15749 net.cpp:198] conv2_6/x1/scale needs backward computation.
I1211 15:05:37.193372 15749 net.cpp:198] conv2_6/x1/bn needs backward computation.
I1211 15:05:37.193375 15749 net.cpp:198] concat2_5_concat2_5_0_split needs backward computation.
I1211 15:05:37.193380 15749 net.cpp:198] concat2_5 needs backward computation.
I1211 15:05:37.193385 15749 net.cpp:198] conv2_5/x2 needs backward computation.
I1211 15:05:37.193389 15749 net.cpp:198] relu2_5/x2 needs backward computation.
I1211 15:05:37.193393 15749 net.cpp:198] conv2_5/x2/scale needs backward computation.
I1211 15:05:37.193397 15749 net.cpp:198] conv2_5/x2/bn needs backward computation.
I1211 15:05:37.193401 15749 net.cpp:198] conv2_5/x1 needs backward computation.
I1211 15:05:37.193406 15749 net.cpp:198] relu2_5/x1 needs backward computation.
I1211 15:05:37.193410 15749 net.cpp:198] conv2_5/x1/scale needs backward computation.
I1211 15:05:37.193414 15749 net.cpp:198] conv2_5/x1/bn needs backward computation.
I1211 15:05:37.193418 15749 net.cpp:198] concat2_4_concat2_4_0_split needs backward computation.
I1211 15:05:37.193424 15749 net.cpp:198] concat2_4 needs backward computation.
I1211 15:05:37.193429 15749 net.cpp:198] conv2_4/x2 needs backward computation.
I1211 15:05:37.193434 15749 net.cpp:198] relu2_4/x2 needs backward computation.
I1211 15:05:37.193437 15749 net.cpp:198] conv2_4/x2/scale needs backward computation.
I1211 15:05:37.193441 15749 net.cpp:198] conv2_4/x2/bn needs backward computation.
I1211 15:05:37.193446 15749 net.cpp:198] conv2_4/x1 needs backward computation.
I1211 15:05:37.193450 15749 net.cpp:198] relu2_4/x1 needs backward computation.
I1211 15:05:37.193454 15749 net.cpp:198] conv2_4/x1/scale needs backward computation.
I1211 15:05:37.193459 15749 net.cpp:198] conv2_4/x1/bn needs backward computation.
I1211 15:05:37.193462 15749 net.cpp:198] concat2_3_concat2_3_0_split needs backward computation.
I1211 15:05:37.193466 15749 net.cpp:198] concat2_3 needs backward computation.
I1211 15:05:37.193471 15749 net.cpp:198] conv2_3/x2 needs backward computation.
I1211 15:05:37.193476 15749 net.cpp:198] relu2_3/x2 needs backward computation.
I1211 15:05:37.193480 15749 net.cpp:198] conv2_3/x2/scale needs backward computation.
I1211 15:05:37.193485 15749 net.cpp:198] conv2_3/x2/bn needs backward computation.
I1211 15:05:37.193488 15749 net.cpp:198] conv2_3/x1 needs backward computation.
I1211 15:05:37.193492 15749 net.cpp:198] relu2_3/x1 needs backward computation.
I1211 15:05:37.193496 15749 net.cpp:198] conv2_3/x1/scale needs backward computation.
I1211 15:05:37.193500 15749 net.cpp:198] conv2_3/x1/bn needs backward computation.
I1211 15:05:37.193506 15749 net.cpp:198] concat2_2_concat2_2_0_split needs backward computation.
I1211 15:05:37.193511 15749 net.cpp:198] concat2_2 needs backward computation.
I1211 15:05:37.193516 15749 net.cpp:198] conv2_2/x2 needs backward computation.
I1211 15:05:37.193521 15749 net.cpp:198] relu2_2/x2 needs backward computation.
I1211 15:05:37.193524 15749 net.cpp:198] conv2_2/x2/scale needs backward computation.
I1211 15:05:37.193528 15749 net.cpp:198] conv2_2/x2/bn needs backward computation.
I1211 15:05:37.193533 15749 net.cpp:198] conv2_2/x1 needs backward computation.
I1211 15:05:37.193537 15749 net.cpp:198] relu2_2/x1 needs backward computation.
I1211 15:05:37.193542 15749 net.cpp:198] conv2_2/x1/scale needs backward computation.
I1211 15:05:37.193545 15749 net.cpp:198] conv2_2/x1/bn needs backward computation.
I1211 15:05:37.193549 15749 net.cpp:198] concat2_1_concat2_1_0_split needs backward computation.
I1211 15:05:37.193554 15749 net.cpp:198] concat2_1 needs backward computation.
I1211 15:05:37.193558 15749 net.cpp:198] conv2_1/x2 needs backward computation.
I1211 15:05:37.193563 15749 net.cpp:198] relu2_1/x2 needs backward computation.
I1211 15:05:37.193567 15749 net.cpp:198] conv2_1/x2/scale needs backward computation.
I1211 15:05:37.193572 15749 net.cpp:198] conv2_1/x2/bn needs backward computation.
I1211 15:05:37.193575 15749 net.cpp:198] conv2_1/x1 needs backward computation.
I1211 15:05:37.193579 15749 net.cpp:198] relu2_1/x1 needs backward computation.
I1211 15:05:37.193583 15749 net.cpp:198] conv2_1/x1/scale needs backward computation.
I1211 15:05:37.193588 15749 net.cpp:198] conv2_1/x1/bn needs backward computation.
I1211 15:05:37.193593 15749 net.cpp:198] concat2_0_concat2_0_0_split needs backward computation.
I1211 15:05:37.193596 15749 net.cpp:198] concat2_0 needs backward computation.
I1211 15:05:37.193601 15749 net.cpp:198] conv2_0/x2 needs backward computation.
I1211 15:05:37.193605 15749 net.cpp:198] relu2_0/x2 needs backward computation.
I1211 15:05:37.193609 15749 net.cpp:198] conv2_0/x2/scale needs backward computation.
I1211 15:05:37.193614 15749 net.cpp:198] conv2_0/x2/bn needs backward computation.
I1211 15:05:37.193619 15749 net.cpp:198] conv2_0/x1 needs backward computation.
I1211 15:05:37.193622 15749 net.cpp:198] relu2_0/x1 needs backward computation.
I1211 15:05:37.193626 15749 net.cpp:198] conv2_0/x1/scale needs backward computation.
I1211 15:05:37.193630 15749 net.cpp:198] conv2_0/x1/bn needs backward computation.
I1211 15:05:37.193635 15749 net.cpp:198] pool1_pool1_0_split needs backward computation.
I1211 15:05:37.193641 15749 net.cpp:198] pool1 needs backward computation.
I1211 15:05:37.193645 15749 net.cpp:198] conv1_blk needs backward computation.
I1211 15:05:37.193650 15749 net.cpp:198] ReLU2 needs backward computation.
I1211 15:05:37.193655 15749 net.cpp:198] Scale2 needs backward computation.
I1211 15:05:37.193658 15749 net.cpp:198] BatchNorm2 needs backward computation.
I1211 15:05:37.193663 15749 net.cpp:198] concat1_5 needs backward computation.
I1211 15:05:37.193668 15749 net.cpp:198] conv1_5/x2 needs backward computation.
I1211 15:05:37.193672 15749 net.cpp:198] relu1_5/x2 needs backward computation.
I1211 15:05:37.193677 15749 net.cpp:198] conv1_5/x2/scale needs backward computation.
I1211 15:05:37.193681 15749 net.cpp:198] conv1_5/x2/bn needs backward computation.
I1211 15:05:37.193686 15749 net.cpp:198] conv1_5/x1 needs backward computation.
I1211 15:05:37.193691 15749 net.cpp:198] relu1_5/x1 needs backward computation.
I1211 15:05:37.193694 15749 net.cpp:198] conv1_5/x1/scale needs backward computation.
I1211 15:05:37.193698 15749 net.cpp:198] conv1_5/x1/bn needs backward computation.
I1211 15:05:37.193702 15749 net.cpp:198] concat1_4_concat1_4_0_split needs backward computation.
I1211 15:05:37.193707 15749 net.cpp:198] concat1_4 needs backward computation.
I1211 15:05:37.193712 15749 net.cpp:198] conv1_4/x2 needs backward computation.
I1211 15:05:37.193717 15749 net.cpp:198] relu1_4/x2 needs backward computation.
I1211 15:05:37.193720 15749 net.cpp:198] conv1_4/x2/scale needs backward computation.
I1211 15:05:37.193727 15749 net.cpp:198] conv1_4/x2/bn needs backward computation.
I1211 15:05:37.193732 15749 net.cpp:198] conv1_4/x1 needs backward computation.
I1211 15:05:37.193735 15749 net.cpp:198] relu1_4/x1 needs backward computation.
I1211 15:05:37.193739 15749 net.cpp:198] conv1_4/x1/scale needs backward computation.
I1211 15:05:37.193743 15749 net.cpp:198] conv1_4/x1/bn needs backward computation.
I1211 15:05:37.193748 15749 net.cpp:198] concat1_3_concat1_3_0_split needs backward computation.
I1211 15:05:37.193753 15749 net.cpp:198] concat1_3 needs backward computation.
I1211 15:05:37.193758 15749 net.cpp:198] conv1_3/x2 needs backward computation.
I1211 15:05:37.193763 15749 net.cpp:198] relu1_3/x2 needs backward computation.
I1211 15:05:37.193766 15749 net.cpp:198] conv1_3/x2/scale needs backward computation.
I1211 15:05:37.193770 15749 net.cpp:198] conv1_3/x2/bn needs backward computation.
I1211 15:05:37.193774 15749 net.cpp:198] conv1_3/x1 needs backward computation.
I1211 15:05:37.193779 15749 net.cpp:198] relu1_3/x1 needs backward computation.
I1211 15:05:37.193783 15749 net.cpp:198] conv1_3/x1/scale needs backward computation.
I1211 15:05:37.193787 15749 net.cpp:198] conv1_3/x1/bn needs backward computation.
I1211 15:05:37.193791 15749 net.cpp:198] concat1_2_concat1_2_0_split needs backward computation.
I1211 15:05:37.193796 15749 net.cpp:198] concat1_2 needs backward computation.
I1211 15:05:37.193801 15749 net.cpp:198] conv1_2/x2 needs backward computation.
I1211 15:05:37.193805 15749 net.cpp:198] relu1_2/x2 needs backward computation.
I1211 15:05:37.193809 15749 net.cpp:198] conv1_2/x2/scale needs backward computation.
I1211 15:05:37.193814 15749 net.cpp:198] conv1_2/x2/bn needs backward computation.
I1211 15:05:37.193819 15749 net.cpp:198] conv1_2/x1 needs backward computation.
I1211 15:05:37.193822 15749 net.cpp:198] relu1_2/x1 needs backward computation.
I1211 15:05:37.193826 15749 net.cpp:198] conv1_2/x1/scale needs backward computation.
I1211 15:05:37.193830 15749 net.cpp:198] conv1_2/x1/bn needs backward computation.
I1211 15:05:37.193835 15749 net.cpp:198] concat1_1_concat1_1_0_split needs backward computation.
I1211 15:05:37.193840 15749 net.cpp:198] concat1_1 needs backward computation.
I1211 15:05:37.193843 15749 net.cpp:198] conv1_1/x2 needs backward computation.
I1211 15:05:37.193848 15749 net.cpp:198] relu1_1/x2 needs backward computation.
I1211 15:05:37.193852 15749 net.cpp:198] conv1_1/x2/scale needs backward computation.
I1211 15:05:37.193856 15749 net.cpp:198] conv1_1/x2/bn needs backward computation.
I1211 15:05:37.193861 15749 net.cpp:198] conv1_1/x1 needs backward computation.
I1211 15:05:37.193864 15749 net.cpp:198] relu1_1/x1 needs backward computation.
I1211 15:05:37.193868 15749 net.cpp:198] conv1_1/x1/scale needs backward computation.
I1211 15:05:37.193872 15749 net.cpp:198] conv1_1/x1/bn needs backward computation.
I1211 15:05:37.193876 15749 net.cpp:198] concat1_0_concat1_0_0_split needs backward computation.
I1211 15:05:37.193881 15749 net.cpp:198] concat1_0 needs backward computation.
I1211 15:05:37.193886 15749 net.cpp:198] conv1_0/x2 needs backward computation.
I1211 15:05:37.193891 15749 net.cpp:198] relu1_0/x2 needs backward computation.
I1211 15:05:37.193894 15749 net.cpp:198] conv1_0/x2/scale needs backward computation.
I1211 15:05:37.193898 15749 net.cpp:198] conv1_0/x2/bn needs backward computation.
I1211 15:05:37.193902 15749 net.cpp:198] conv1_0/x1 needs backward computation.
I1211 15:05:37.193907 15749 net.cpp:198] relu1_0/x1 needs backward computation.
I1211 15:05:37.193912 15749 net.cpp:198] conv1_0/x1/scale needs backward computation.
I1211 15:05:37.193915 15749 net.cpp:198] conv1_0/x1/bn needs backward computation.
I1211 15:05:37.193920 15749 net.cpp:198] pool0_pool0_0_split needs backward computation.
I1211 15:05:37.193924 15749 net.cpp:198] pool0 needs backward computation.
I1211 15:05:37.193929 15749 net.cpp:198] conv0_blk needs backward computation.
I1211 15:05:37.193933 15749 net.cpp:198] ReLU1 needs backward computation.
I1211 15:05:37.193938 15749 net.cpp:198] Scale1 needs backward computation.
I1211 15:05:37.193944 15749 net.cpp:198] BatchNorm1 needs backward computation.
I1211 15:05:37.193948 15749 net.cpp:198] concat0_2 needs backward computation.
I1211 15:05:37.193953 15749 net.cpp:198] conv0_2/x2 needs backward computation.
I1211 15:05:37.193959 15749 net.cpp:198] relu0_2/x2 needs backward computation.
I1211 15:05:37.193964 15749 net.cpp:198] conv0_2/x2/scale needs backward computation.
I1211 15:05:37.193969 15749 net.cpp:198] conv0_2/x2/bn needs backward computation.
I1211 15:05:37.193972 15749 net.cpp:198] conv0_2/x1 needs backward computation.
I1211 15:05:37.193976 15749 net.cpp:198] relu0_2/x1 needs backward computation.
I1211 15:05:37.193980 15749 net.cpp:198] conv0_2/x1/scale needs backward computation.
I1211 15:05:37.193984 15749 net.cpp:198] conv0_2/x1/bn needs backward computation.
I1211 15:05:37.193989 15749 net.cpp:198] concat0_1_concat0_1_0_split needs backward computation.
I1211 15:05:37.193994 15749 net.cpp:198] concat0_1 needs backward computation.
I1211 15:05:37.193998 15749 net.cpp:198] conv0_1/x2 needs backward computation.
I1211 15:05:37.194003 15749 net.cpp:198] relu0_1/x2 needs backward computation.
I1211 15:05:37.194007 15749 net.cpp:198] conv0_1/x2/scale needs backward computation.
I1211 15:05:37.194011 15749 net.cpp:198] conv0_1/x2/bn needs backward computation.
I1211 15:05:37.194015 15749 net.cpp:198] conv0_1/x1 needs backward computation.
I1211 15:05:37.194020 15749 net.cpp:198] relu0_1/x1 needs backward computation.
I1211 15:05:37.194023 15749 net.cpp:198] conv0_1/x1/scale needs backward computation.
I1211 15:05:37.194027 15749 net.cpp:198] conv0_1/x1/bn needs backward computation.
I1211 15:05:37.194032 15749 net.cpp:198] concat0_0_concat0_0_0_split needs backward computation.
I1211 15:05:37.194036 15749 net.cpp:198] concat0_0 needs backward computation.
I1211 15:05:37.194042 15749 net.cpp:198] conv0_0/x2 needs backward computation.
I1211 15:05:37.194046 15749 net.cpp:198] relu0_0/x2 needs backward computation.
I1211 15:05:37.194051 15749 net.cpp:198] conv0_0/x2/scale needs backward computation.
I1211 15:05:37.194054 15749 net.cpp:198] conv0_0/x2/bn needs backward computation.
I1211 15:05:37.194058 15749 net.cpp:198] conv0_0/x1 needs backward computation.
I1211 15:05:37.194063 15749 net.cpp:198] relu0_0/x1 needs backward computation.
I1211 15:05:37.194067 15749 net.cpp:198] conv0_0/x1/scale needs backward computation.
I1211 15:05:37.194072 15749 net.cpp:198] conv0_0/x1/bn needs backward computation.
I1211 15:05:37.194075 15749 net.cpp:198] conv_init_conv_init_0_split needs backward computation.
I1211 15:05:37.194080 15749 net.cpp:198] conv_init needs backward computation.
I1211 15:05:37.194085 15749 net.cpp:200] phocs does not need backward computation.
I1211 15:05:37.194089 15749 net.cpp:200] word_images does not need backward computation.
I1211 15:05:37.194093 15749 net.cpp:242] This network produces output label
I1211 15:05:37.194097 15749 net.cpp:242] This network produces output label_phocs
I1211 15:05:37.194103 15749 net.cpp:242] This network produces output loss
I1211 15:05:37.194244 15749 net.cpp:255] Network initialization done.
I1211 15:05:37.214588 15749 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/fwolf/Workspace/DensePHOCNet/data/models/exp/test_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt
I1211 15:05:37.214644 15749 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 15:05:37.214658 15749 solver.cpp:172] Creating test net (#0) specified by test_net file: /home/fwolf/Workspace/DensePHOCNet/data/models/exp/test_dense_L48b3k32_BCtpp_phocnet_gw_cv1.prototxt
I1211 15:05:37.215180 15749 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer drop6
I1211 15:05:37.215198 15749 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer drop7
I1211 15:05:37.217469 15749 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "word_images"
  type: "Data"
  top: "word_images"
  top: "label"
  transform_param {
    scale: -0.0039215689
    mean_value: 255
  }
  data_param {
    source: "/data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_test_word_images_lmdb"
    batch_size: 1
    backend: LMDB
    prefetch: 20
  }
}
layer {
  name: "phocs"
  type: "Data"
  top: "phocs"
  top: "label_phocs"
  data_param {
    source: "/data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_test_phocs_lmdb"
    batch_size: 1
    backend: LMDB
    prefetch: 20
  }
}
layer {
  name: "conv_init"
  type: "Convolution"
  bottom: "word_images"
  top: "conv_init"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_0/x1/bn"
  type: "BatchNorm"
  bottom: "conv_init"
  top: "conv0_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_0/x1/scale"
  type: "Scale"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_0/x1"
  type: "ReLU"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1/bn"
}
layer {
  name: "conv0_0/x1"
  type: "Convolution"
  bottom: "conv0_0/x1/bn"
  top: "conv0_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_0/x1"
  top: "conv0_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_0/x2/scale"
  type: "Scale"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_0/x2"
  type: "ReLU"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2/bn"
}
layer {
  name: "conv0_0/x2"
  type: "Convolution"
  bottom: "conv0_0/x2/bn"
  top: "conv0_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_0"
  type: "Concat"
  bottom: "conv_init"
  bottom: "conv0_0/x2"
  top: "concat0_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv0_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat0_0"
  top: "conv0_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_1/x1/scale"
  type: "Scale"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_1/x1"
  type: "ReLU"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1/bn"
}
layer {
  name: "conv0_1/x1"
  type: "Convolution"
  bottom: "conv0_1/x1/bn"
  top: "conv0_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_1/x1"
  top: "conv0_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_1/x2/scale"
  type: "Scale"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_1/x2"
  type: "ReLU"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2/bn"
}
layer {
  name: "conv0_1/x2"
  type: "Convolution"
  bottom: "conv0_1/x2/bn"
  top: "conv0_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_1"
  type: "Concat"
  bottom: "concat0_0"
  bottom: "conv0_1/x2"
  top: "concat0_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv0_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat0_1"
  top: "conv0_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_2/x1/scale"
  type: "Scale"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_2/x1"
  type: "ReLU"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1/bn"
}
layer {
  name: "conv0_2/x1"
  type: "Convolution"
  bottom: "conv0_2/x1/bn"
  top: "conv0_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv0_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv0_2/x1"
  top: "conv0_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv0_2/x2/scale"
  type: "Scale"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu0_2/x2"
  type: "ReLU"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2/bn"
}
layer {
  name: "conv0_2/x2"
  type: "Convolution"
  bottom: "conv0_2/x2/bn"
  top: "conv0_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat0_2"
  type: "Concat"
  bottom: "concat0_1"
  bottom: "conv0_2/x2"
  top: "concat0_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "concat0_2"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "conv0_blk"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "conv0_blk"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0_blk"
  top: "pool0"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_0/x1/bn"
  type: "BatchNorm"
  bottom: "pool0"
  top: "conv1_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_0/x1/scale"
  type: "Scale"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_0/x1"
  type: "ReLU"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1/bn"
}
layer {
  name: "conv1_0/x1"
  type: "Convolution"
  bottom: "conv1_0/x1/bn"
  top: "conv1_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_0/x1"
  top: "conv1_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_0/x2/scale"
  type: "Scale"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_0/x2"
  type: "ReLU"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2/bn"
}
layer {
  name: "conv1_0/x2"
  type: "Convolution"
  bottom: "conv1_0/x2/bn"
  top: "conv1_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_0"
  type: "Concat"
  bottom: "pool0"
  bottom: "conv1_0/x2"
  top: "concat1_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_0"
  top: "conv1_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/x1/scale"
  type: "Scale"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/x1"
  type: "ReLU"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1/bn"
}
layer {
  name: "conv1_1/x1"
  type: "Convolution"
  bottom: "conv1_1/x1/bn"
  top: "conv1_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_1/x1"
  top: "conv1_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/x2/scale"
  type: "Scale"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/x2"
  type: "ReLU"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2/bn"
}
layer {
  name: "conv1_1/x2"
  type: "Convolution"
  bottom: "conv1_1/x2/bn"
  top: "conv1_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_1"
  type: "Concat"
  bottom: "concat1_0"
  bottom: "conv1_1/x2"
  top: "concat1_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_1"
  top: "conv1_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/x1/scale"
  type: "Scale"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/x1"
  type: "ReLU"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1/bn"
}
layer {
  name: "conv1_2/x1"
  type: "Convolution"
  bottom: "conv1_2/x1/bn"
  top: "conv1_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_2/x1"
  top: "conv1_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/x2/scale"
  type: "Scale"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/x2"
  type: "ReLU"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2/bn"
}
layer {
  name: "conv1_2/x2"
  type: "Convolution"
  bottom: "conv1_2/x2/bn"
  top: "conv1_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_2"
  type: "Concat"
  bottom: "concat1_1"
  bottom: "conv1_2/x2"
  top: "concat1_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_2"
  top: "conv1_3/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_3/x1/scale"
  type: "Scale"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_3/x1"
  type: "ReLU"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1/bn"
}
layer {
  name: "conv1_3/x1"
  type: "Convolution"
  bottom: "conv1_3/x1/bn"
  top: "conv1_3/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_3/x1"
  top: "conv1_3/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_3/x2/scale"
  type: "Scale"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_3/x2"
  type: "ReLU"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2/bn"
}
layer {
  name: "conv1_3/x2"
  type: "Convolution"
  bottom: "conv1_3/x2/bn"
  top: "conv1_3/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_3"
  type: "Concat"
  bottom: "concat1_2"
  bottom: "conv1_3/x2"
  top: "concat1_3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_3"
  top: "conv1_4/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_4/x1/scale"
  type: "Scale"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_4/x1"
  type: "ReLU"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1/bn"
}
layer {
  name: "conv1_4/x1"
  type: "Convolution"
  bottom: "conv1_4/x1/bn"
  top: "conv1_4/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_4/x1"
  top: "conv1_4/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_4/x2/scale"
  type: "Scale"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_4/x2"
  type: "ReLU"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2/bn"
}
layer {
  name: "conv1_4/x2"
  type: "Convolution"
  bottom: "conv1_4/x2/bn"
  top: "conv1_4/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_4"
  type: "Concat"
  bottom: "concat1_3"
  bottom: "conv1_4/x2"
  top: "concat1_4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat1_4"
  top: "conv1_5/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_5/x1/scale"
  type: "Scale"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_5/x1"
  type: "ReLU"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1/bn"
}
layer {
  name: "conv1_5/x1"
  type: "Convolution"
  bottom: "conv1_5/x1/bn"
  top: "conv1_5/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv1_5/x2/bn"
  type: "BatchNorm"
  bottom: "conv1_5/x1"
  top: "conv1_5/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_5/x2/scale"
  type: "Scale"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_5/x2"
  type: "ReLU"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2/bn"
}
layer {
  name: "conv1_5/x2"
  type: "Convolution"
  bottom: "conv1_5/x2/bn"
  top: "conv1_5/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat1_5"
  type: "Concat"
  bottom: "concat1_4"
  bottom: "conv1_5/x2"
  top: "concat1_5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "concat1_5"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "conv1_blk"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "conv1_blk"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_blk"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_0/x1/bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv2_0/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_0/x1/scale"
  type: "Scale"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_0/x1"
  type: "ReLU"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1/bn"
}
layer {
  name: "conv2_0/x1"
  type: "Convolution"
  bottom: "conv2_0/x1/bn"
  top: "conv2_0/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_0/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_0/x1"
  top: "conv2_0/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_0/x2/scale"
  type: "Scale"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_0/x2"
  type: "ReLU"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2/bn"
}
layer {
  name: "conv2_0/x2"
  type: "Convolution"
  bottom: "conv2_0/x2/bn"
  top: "conv2_0/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_0"
  type: "Concat"
  bottom: "pool1"
  bottom: "conv2_0/x2"
  top: "concat2_0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_1/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_0"
  top: "conv2_1/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/x1/scale"
  type: "Scale"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/x1"
  type: "ReLU"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
}
layer {
  name: "conv2_1/x1"
  type: "Convolution"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_1/x1"
  top: "conv2_1/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/x2/scale"
  type: "Scale"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/x2"
  type: "ReLU"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
}
layer {
  name: "conv2_1/x2"
  type: "Convolution"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_1"
  type: "Concat"
  bottom: "concat2_0"
  bottom: "conv2_1/x2"
  top: "concat2_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_1"
  top: "conv2_2/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/x1/scale"
  type: "Scale"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/x1"
  type: "ReLU"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
}
layer {
  name: "conv2_2/x1"
  type: "Convolution"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_2/x1"
  top: "conv2_2/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/x2/scale"
  type: "Scale"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/x2"
  type: "ReLU"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
}
layer {
  name: "conv2_2/x2"
  type: "Convolution"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_2"
  type: "Concat"
  bottom: "concat2_1"
  bottom: "conv2_2/x2"
  top: "concat2_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_2"
  top: "conv2_3/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3/x1/scale"
  type: "Scale"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_3/x1"
  type: "ReLU"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
}
layer {
  name: "conv2_3/x1"
  type: "Convolution"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_3/x1"
  top: "conv2_3/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3/x2/scale"
  type: "Scale"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_3/x2"
  type: "ReLU"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
}
layer {
  name: "conv2_3/x2"
  type: "Convolution"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_3"
  type: "Concat"
  bottom: "concat2_2"
  bottom: "conv2_3/x2"
  top: "concat2_3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_3"
  top: "conv2_4/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4/x1/scale"
  type: "Scale"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_4/x1"
  type: "ReLU"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
}
layer {
  name: "conv2_4/x1"
  type: "Convolution"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "conv2_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_4/x1"
  top: "conv2_4/x2/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4/x2/scale"
  type: "Scale"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_4/x2"
  type: "ReLU"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
}
layer {
  name: "conv2_4/x2"
  type: "Convolution"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "concat2_4"
  type: "Concat"
  bottom: "concat2_3"
  bottom: "conv2_4/x2"
  top: "concat2_4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv2_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat2_4"
  top: "conv2_5/x1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_5/x1/scale"
  type: "Scale"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_5/x1"
  type: "ReLU"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
}
layer {
  name: "conv2_5/x1"
  type: "Convolution"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kerne
I1211 15:05:37.218683 15749 layer_factory.hpp:77] Creating layer word_images
I1211 15:05:37.218799 15749 db_lmdb.cpp:35] Opened lmdb /data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_test_word_images_lmdb
I1211 15:05:37.218835 15749 net.cpp:84] Creating Layer word_images
I1211 15:05:37.218845 15749 net.cpp:380] word_images -> word_images
I1211 15:05:37.218863 15749 net.cpp:380] word_images -> label
I1211 15:05:37.220144 15749 data_layer.cpp:44] output data size: 1,1,66,139
I1211 15:05:37.224980 15749 net.cpp:122] Setting up word_images
I1211 15:05:37.225018 15749 net.cpp:129] Top shape: 1 1 66 139 (9174)
I1211 15:05:37.225023 15749 net.cpp:129] Top shape: 1 (1)
I1211 15:05:37.225028 15749 net.cpp:137] Memory required for data: 36700
I1211 15:05:37.225034 15749 layer_factory.hpp:77] Creating layer phocs
I1211 15:05:37.225113 15749 db_lmdb.cpp:35] Opened lmdb /data/fwolf/min26/gw_cv1_nti500000_pul2-3-4-5_test_phocs_lmdb
I1211 15:05:37.225142 15749 net.cpp:84] Creating Layer phocs
I1211 15:05:37.225149 15749 net.cpp:380] phocs -> phocs
I1211 15:05:37.225162 15749 net.cpp:380] phocs -> label_phocs
I1211 15:05:37.226120 15749 data_layer.cpp:44] output data size: 1,1,1,604
I1211 15:05:37.231925 15749 net.cpp:122] Setting up phocs
I1211 15:05:37.231956 15749 net.cpp:129] Top shape: 1 1 1 604 (604)
I1211 15:05:37.231961 15749 net.cpp:129] Top shape: 1 (1)
I1211 15:05:37.231964 15749 net.cpp:137] Memory required for data: 39120
I1211 15:05:37.231971 15749 layer_factory.hpp:77] Creating layer conv_init
I1211 15:05:37.231992 15749 net.cpp:84] Creating Layer conv_init
I1211 15:05:37.231997 15749 net.cpp:406] conv_init <- word_images
I1211 15:05:37.232007 15749 net.cpp:380] conv_init -> conv_init
I1211 15:05:37.234592 15749 net.cpp:122] Setting up conv_init
I1211 15:05:37.234614 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.234618 15749 net.cpp:137] Memory required for data: 1213392
I1211 15:05:37.234629 15749 layer_factory.hpp:77] Creating layer conv_init_conv_init_0_split
I1211 15:05:37.234639 15749 net.cpp:84] Creating Layer conv_init_conv_init_0_split
I1211 15:05:37.234644 15749 net.cpp:406] conv_init_conv_init_0_split <- conv_init
I1211 15:05:37.234650 15749 net.cpp:380] conv_init_conv_init_0_split -> conv_init_conv_init_0_split_0
I1211 15:05:37.234660 15749 net.cpp:380] conv_init_conv_init_0_split -> conv_init_conv_init_0_split_1
I1211 15:05:37.234786 15749 net.cpp:122] Setting up conv_init_conv_init_0_split
I1211 15:05:37.234796 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.234800 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.234804 15749 net.cpp:137] Memory required for data: 3561936
I1211 15:05:37.234807 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/bn
I1211 15:05:37.234818 15749 net.cpp:84] Creating Layer conv0_0/x1/bn
I1211 15:05:37.234822 15749 net.cpp:406] conv0_0/x1/bn <- conv_init_conv_init_0_split_0
I1211 15:05:37.234833 15749 net.cpp:380] conv0_0/x1/bn -> conv0_0/x1/bn
I1211 15:05:37.243813 15749 net.cpp:122] Setting up conv0_0/x1/bn
I1211 15:05:37.243850 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.243855 15749 net.cpp:137] Memory required for data: 4736208
I1211 15:05:37.243875 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/scale
I1211 15:05:37.243888 15749 net.cpp:84] Creating Layer conv0_0/x1/scale
I1211 15:05:37.243893 15749 net.cpp:406] conv0_0/x1/scale <- conv0_0/x1/bn
I1211 15:05:37.243903 15749 net.cpp:367] conv0_0/x1/scale -> conv0_0/x1/bn (in-place)
I1211 15:05:37.244025 15749 layer_factory.hpp:77] Creating layer conv0_0/x1/scale
I1211 15:05:37.244365 15749 net.cpp:122] Setting up conv0_0/x1/scale
I1211 15:05:37.244376 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.244380 15749 net.cpp:137] Memory required for data: 5910480
I1211 15:05:37.244390 15749 layer_factory.hpp:77] Creating layer relu0_0/x1
I1211 15:05:37.244400 15749 net.cpp:84] Creating Layer relu0_0/x1
I1211 15:05:37.244405 15749 net.cpp:406] relu0_0/x1 <- conv0_0/x1/bn
I1211 15:05:37.244410 15749 net.cpp:367] relu0_0/x1 -> conv0_0/x1/bn (in-place)
I1211 15:05:37.244741 15749 net.cpp:122] Setting up relu0_0/x1
I1211 15:05:37.244752 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.244756 15749 net.cpp:137] Memory required for data: 7084752
I1211 15:05:37.244761 15749 layer_factory.hpp:77] Creating layer conv0_0/x1
I1211 15:05:37.244774 15749 net.cpp:84] Creating Layer conv0_0/x1
I1211 15:05:37.244779 15749 net.cpp:406] conv0_0/x1 <- conv0_0/x1/bn
I1211 15:05:37.244786 15749 net.cpp:380] conv0_0/x1 -> conv0_0/x1
I1211 15:05:37.246781 15749 net.cpp:122] Setting up conv0_0/x1
I1211 15:05:37.246798 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.246803 15749 net.cpp:137] Memory required for data: 11781840
I1211 15:05:37.246809 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/bn
I1211 15:05:37.246820 15749 net.cpp:84] Creating Layer conv0_0/x2/bn
I1211 15:05:37.246825 15749 net.cpp:406] conv0_0/x2/bn <- conv0_0/x1
I1211 15:05:37.246832 15749 net.cpp:380] conv0_0/x2/bn -> conv0_0/x2/bn
I1211 15:05:37.247391 15749 net.cpp:122] Setting up conv0_0/x2/bn
I1211 15:05:37.247401 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.247404 15749 net.cpp:137] Memory required for data: 16478928
I1211 15:05:37.247421 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/scale
I1211 15:05:37.247428 15749 net.cpp:84] Creating Layer conv0_0/x2/scale
I1211 15:05:37.247433 15749 net.cpp:406] conv0_0/x2/scale <- conv0_0/x2/bn
I1211 15:05:37.247438 15749 net.cpp:367] conv0_0/x2/scale -> conv0_0/x2/bn (in-place)
I1211 15:05:37.247534 15749 layer_factory.hpp:77] Creating layer conv0_0/x2/scale
I1211 15:05:37.317039 15749 net.cpp:122] Setting up conv0_0/x2/scale
I1211 15:05:37.317075 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.317078 15749 net.cpp:137] Memory required for data: 21176016
I1211 15:05:37.317091 15749 layer_factory.hpp:77] Creating layer relu0_0/x2
I1211 15:05:37.317103 15749 net.cpp:84] Creating Layer relu0_0/x2
I1211 15:05:37.317109 15749 net.cpp:406] relu0_0/x2 <- conv0_0/x2/bn
I1211 15:05:37.317118 15749 net.cpp:367] relu0_0/x2 -> conv0_0/x2/bn (in-place)
I1211 15:05:37.317744 15749 net.cpp:122] Setting up relu0_0/x2
I1211 15:05:37.317757 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.317761 15749 net.cpp:137] Memory required for data: 25873104
I1211 15:05:37.317765 15749 layer_factory.hpp:77] Creating layer conv0_0/x2
I1211 15:05:37.317780 15749 net.cpp:84] Creating Layer conv0_0/x2
I1211 15:05:37.317785 15749 net.cpp:406] conv0_0/x2 <- conv0_0/x2/bn
I1211 15:05:37.317793 15749 net.cpp:380] conv0_0/x2 -> conv0_0/x2
I1211 15:05:37.321143 15749 net.cpp:122] Setting up conv0_0/x2
I1211 15:05:37.321158 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.321162 15749 net.cpp:137] Memory required for data: 27047376
I1211 15:05:37.321169 15749 layer_factory.hpp:77] Creating layer concat0_0
I1211 15:05:37.321182 15749 net.cpp:84] Creating Layer concat0_0
I1211 15:05:37.321187 15749 net.cpp:406] concat0_0 <- conv_init_conv_init_0_split_1
I1211 15:05:37.321192 15749 net.cpp:406] concat0_0 <- conv0_0/x2
I1211 15:05:37.321199 15749 net.cpp:380] concat0_0 -> concat0_0
I1211 15:05:37.321269 15749 net.cpp:122] Setting up concat0_0
I1211 15:05:37.321277 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.321281 15749 net.cpp:137] Memory required for data: 29395920
I1211 15:05:37.321285 15749 layer_factory.hpp:77] Creating layer concat0_0_concat0_0_0_split
I1211 15:05:37.321292 15749 net.cpp:84] Creating Layer concat0_0_concat0_0_0_split
I1211 15:05:37.321296 15749 net.cpp:406] concat0_0_concat0_0_0_split <- concat0_0
I1211 15:05:37.321303 15749 net.cpp:380] concat0_0_concat0_0_0_split -> concat0_0_concat0_0_0_split_0
I1211 15:05:37.321310 15749 net.cpp:380] concat0_0_concat0_0_0_split -> concat0_0_concat0_0_0_split_1
I1211 15:05:37.321408 15749 net.cpp:122] Setting up concat0_0_concat0_0_0_split
I1211 15:05:37.321416 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.321421 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.321425 15749 net.cpp:137] Memory required for data: 34093008
I1211 15:05:37.321429 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/bn
I1211 15:05:37.321435 15749 net.cpp:84] Creating Layer conv0_1/x1/bn
I1211 15:05:37.321439 15749 net.cpp:406] conv0_1/x1/bn <- concat0_0_concat0_0_0_split_0
I1211 15:05:37.321446 15749 net.cpp:380] conv0_1/x1/bn -> conv0_1/x1/bn
I1211 15:05:37.322880 15749 net.cpp:122] Setting up conv0_1/x1/bn
I1211 15:05:37.322896 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.322899 15749 net.cpp:137] Memory required for data: 36441552
I1211 15:05:37.322909 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/scale
I1211 15:05:37.322921 15749 net.cpp:84] Creating Layer conv0_1/x1/scale
I1211 15:05:37.322926 15749 net.cpp:406] conv0_1/x1/scale <- conv0_1/x1/bn
I1211 15:05:37.322932 15749 net.cpp:367] conv0_1/x1/scale -> conv0_1/x1/bn (in-place)
I1211 15:05:37.323005 15749 layer_factory.hpp:77] Creating layer conv0_1/x1/scale
I1211 15:05:37.323233 15749 net.cpp:122] Setting up conv0_1/x1/scale
I1211 15:05:37.323242 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.323246 15749 net.cpp:137] Memory required for data: 38790096
I1211 15:05:37.323257 15749 layer_factory.hpp:77] Creating layer relu0_1/x1
I1211 15:05:37.323266 15749 net.cpp:84] Creating Layer relu0_1/x1
I1211 15:05:37.323269 15749 net.cpp:406] relu0_1/x1 <- conv0_1/x1/bn
I1211 15:05:37.323276 15749 net.cpp:367] relu0_1/x1 -> conv0_1/x1/bn (in-place)
I1211 15:05:37.323879 15749 net.cpp:122] Setting up relu0_1/x1
I1211 15:05:37.323891 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.323896 15749 net.cpp:137] Memory required for data: 41138640
I1211 15:05:37.323900 15749 layer_factory.hpp:77] Creating layer conv0_1/x1
I1211 15:05:37.323913 15749 net.cpp:84] Creating Layer conv0_1/x1
I1211 15:05:37.323917 15749 net.cpp:406] conv0_1/x1 <- conv0_1/x1/bn
I1211 15:05:37.323925 15749 net.cpp:380] conv0_1/x1 -> conv0_1/x1
I1211 15:05:37.325902 15749 net.cpp:122] Setting up conv0_1/x1
I1211 15:05:37.325919 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.325925 15749 net.cpp:137] Memory required for data: 45835728
I1211 15:05:37.325932 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/bn
I1211 15:05:37.325942 15749 net.cpp:84] Creating Layer conv0_1/x2/bn
I1211 15:05:37.325947 15749 net.cpp:406] conv0_1/x2/bn <- conv0_1/x1
I1211 15:05:37.325953 15749 net.cpp:380] conv0_1/x2/bn -> conv0_1/x2/bn
I1211 15:05:37.326331 15749 net.cpp:122] Setting up conv0_1/x2/bn
I1211 15:05:37.326341 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.326345 15749 net.cpp:137] Memory required for data: 50532816
I1211 15:05:37.326354 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/scale
I1211 15:05:37.326364 15749 net.cpp:84] Creating Layer conv0_1/x2/scale
I1211 15:05:37.326369 15749 net.cpp:406] conv0_1/x2/scale <- conv0_1/x2/bn
I1211 15:05:37.326380 15749 net.cpp:367] conv0_1/x2/scale -> conv0_1/x2/bn (in-place)
I1211 15:05:37.326447 15749 layer_factory.hpp:77] Creating layer conv0_1/x2/scale
I1211 15:05:37.326666 15749 net.cpp:122] Setting up conv0_1/x2/scale
I1211 15:05:37.326675 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.326679 15749 net.cpp:137] Memory required for data: 55229904
I1211 15:05:37.326686 15749 layer_factory.hpp:77] Creating layer relu0_1/x2
I1211 15:05:37.326694 15749 net.cpp:84] Creating Layer relu0_1/x2
I1211 15:05:37.326699 15749 net.cpp:406] relu0_1/x2 <- conv0_1/x2/bn
I1211 15:05:37.326704 15749 net.cpp:367] relu0_1/x2 -> conv0_1/x2/bn (in-place)
I1211 15:05:37.326995 15749 net.cpp:122] Setting up relu0_1/x2
I1211 15:05:37.327006 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.327011 15749 net.cpp:137] Memory required for data: 59926992
I1211 15:05:37.327015 15749 layer_factory.hpp:77] Creating layer conv0_1/x2
I1211 15:05:37.327028 15749 net.cpp:84] Creating Layer conv0_1/x2
I1211 15:05:37.327033 15749 net.cpp:406] conv0_1/x2 <- conv0_1/x2/bn
I1211 15:05:37.327040 15749 net.cpp:380] conv0_1/x2 -> conv0_1/x2
I1211 15:05:37.331190 15749 net.cpp:122] Setting up conv0_1/x2
I1211 15:05:37.331223 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.331228 15749 net.cpp:137] Memory required for data: 61101264
I1211 15:05:37.331238 15749 layer_factory.hpp:77] Creating layer concat0_1
I1211 15:05:37.331248 15749 net.cpp:84] Creating Layer concat0_1
I1211 15:05:37.331254 15749 net.cpp:406] concat0_1 <- concat0_0_concat0_0_0_split_1
I1211 15:05:37.331262 15749 net.cpp:406] concat0_1 <- conv0_1/x2
I1211 15:05:37.331269 15749 net.cpp:380] concat0_1 -> concat0_1
I1211 15:05:37.331317 15749 net.cpp:122] Setting up concat0_1
I1211 15:05:37.331326 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.331329 15749 net.cpp:137] Memory required for data: 64624080
I1211 15:05:37.331333 15749 layer_factory.hpp:77] Creating layer concat0_1_concat0_1_0_split
I1211 15:05:37.331341 15749 net.cpp:84] Creating Layer concat0_1_concat0_1_0_split
I1211 15:05:37.331346 15749 net.cpp:406] concat0_1_concat0_1_0_split <- concat0_1
I1211 15:05:37.331351 15749 net.cpp:380] concat0_1_concat0_1_0_split -> concat0_1_concat0_1_0_split_0
I1211 15:05:37.331358 15749 net.cpp:380] concat0_1_concat0_1_0_split -> concat0_1_concat0_1_0_split_1
I1211 15:05:37.331418 15749 net.cpp:122] Setting up concat0_1_concat0_1_0_split
I1211 15:05:37.331426 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.331431 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.331435 15749 net.cpp:137] Memory required for data: 71669712
I1211 15:05:37.331439 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/bn
I1211 15:05:37.331447 15749 net.cpp:84] Creating Layer conv0_2/x1/bn
I1211 15:05:37.331451 15749 net.cpp:406] conv0_2/x1/bn <- concat0_1_concat0_1_0_split_0
I1211 15:05:37.331459 15749 net.cpp:380] conv0_2/x1/bn -> conv0_2/x1/bn
I1211 15:05:37.331892 15749 net.cpp:122] Setting up conv0_2/x1/bn
I1211 15:05:37.331902 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.331905 15749 net.cpp:137] Memory required for data: 75192528
I1211 15:05:37.331918 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/scale
I1211 15:05:37.331926 15749 net.cpp:84] Creating Layer conv0_2/x1/scale
I1211 15:05:37.331930 15749 net.cpp:406] conv0_2/x1/scale <- conv0_2/x1/bn
I1211 15:05:37.331936 15749 net.cpp:367] conv0_2/x1/scale -> conv0_2/x1/bn (in-place)
I1211 15:05:37.332005 15749 layer_factory.hpp:77] Creating layer conv0_2/x1/scale
I1211 15:05:37.332234 15749 net.cpp:122] Setting up conv0_2/x1/scale
I1211 15:05:37.332243 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.332247 15749 net.cpp:137] Memory required for data: 78715344
I1211 15:05:37.332254 15749 layer_factory.hpp:77] Creating layer relu0_2/x1
I1211 15:05:37.332262 15749 net.cpp:84] Creating Layer relu0_2/x1
I1211 15:05:37.332265 15749 net.cpp:406] relu0_2/x1 <- conv0_2/x1/bn
I1211 15:05:37.332273 15749 net.cpp:367] relu0_2/x1 -> conv0_2/x1/bn (in-place)
I1211 15:05:37.332784 15749 net.cpp:122] Setting up relu0_2/x1
I1211 15:05:37.332798 15749 net.cpp:129] Top shape: 1 96 66 139 (880704)
I1211 15:05:37.332803 15749 net.cpp:137] Memory required for data: 82238160
I1211 15:05:37.332808 15749 layer_factory.hpp:77] Creating layer conv0_2/x1
I1211 15:05:37.332820 15749 net.cpp:84] Creating Layer conv0_2/x1
I1211 15:05:37.332824 15749 net.cpp:406] conv0_2/x1 <- conv0_2/x1/bn
I1211 15:05:37.332832 15749 net.cpp:380] conv0_2/x1 -> conv0_2/x1
I1211 15:05:37.334929 15749 net.cpp:122] Setting up conv0_2/x1
I1211 15:05:37.334949 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.334954 15749 net.cpp:137] Memory required for data: 86935248
I1211 15:05:37.334961 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/bn
I1211 15:05:37.334971 15749 net.cpp:84] Creating Layer conv0_2/x2/bn
I1211 15:05:37.334976 15749 net.cpp:406] conv0_2/x2/bn <- conv0_2/x1
I1211 15:05:37.334983 15749 net.cpp:380] conv0_2/x2/bn -> conv0_2/x2/bn
I1211 15:05:37.335346 15749 net.cpp:122] Setting up conv0_2/x2/bn
I1211 15:05:37.335356 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.335361 15749 net.cpp:137] Memory required for data: 91632336
I1211 15:05:37.335373 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/scale
I1211 15:05:37.335383 15749 net.cpp:84] Creating Layer conv0_2/x2/scale
I1211 15:05:37.335388 15749 net.cpp:406] conv0_2/x2/scale <- conv0_2/x2/bn
I1211 15:05:37.335395 15749 net.cpp:367] conv0_2/x2/scale -> conv0_2/x2/bn (in-place)
I1211 15:05:37.335459 15749 layer_factory.hpp:77] Creating layer conv0_2/x2/scale
I1211 15:05:37.335671 15749 net.cpp:122] Setting up conv0_2/x2/scale
I1211 15:05:37.335681 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.335685 15749 net.cpp:137] Memory required for data: 96329424
I1211 15:05:37.335692 15749 layer_factory.hpp:77] Creating layer relu0_2/x2
I1211 15:05:37.335700 15749 net.cpp:84] Creating Layer relu0_2/x2
I1211 15:05:37.335705 15749 net.cpp:406] relu0_2/x2 <- conv0_2/x2/bn
I1211 15:05:37.335712 15749 net.cpp:367] relu0_2/x2 -> conv0_2/x2/bn (in-place)
I1211 15:05:37.335974 15749 net.cpp:122] Setting up relu0_2/x2
I1211 15:05:37.335985 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.335990 15749 net.cpp:137] Memory required for data: 101026512
I1211 15:05:37.335994 15749 layer_factory.hpp:77] Creating layer conv0_2/x2
I1211 15:05:37.336005 15749 net.cpp:84] Creating Layer conv0_2/x2
I1211 15:05:37.336009 15749 net.cpp:406] conv0_2/x2 <- conv0_2/x2/bn
I1211 15:05:37.336017 15749 net.cpp:380] conv0_2/x2 -> conv0_2/x2
I1211 15:05:37.338886 15749 net.cpp:122] Setting up conv0_2/x2
I1211 15:05:37.338901 15749 net.cpp:129] Top shape: 1 32 66 139 (293568)
I1211 15:05:37.338903 15749 net.cpp:137] Memory required for data: 102200784
I1211 15:05:37.338909 15749 layer_factory.hpp:77] Creating layer concat0_2
I1211 15:05:37.338918 15749 net.cpp:84] Creating Layer concat0_2
I1211 15:05:37.338922 15749 net.cpp:406] concat0_2 <- concat0_1_concat0_1_0_split_1
I1211 15:05:37.338927 15749 net.cpp:406] concat0_2 <- conv0_2/x2
I1211 15:05:37.338932 15749 net.cpp:380] concat0_2 -> concat0_2
I1211 15:05:37.338968 15749 net.cpp:122] Setting up concat0_2
I1211 15:05:37.338974 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.338976 15749 net.cpp:137] Memory required for data: 106897872
I1211 15:05:37.338979 15749 layer_factory.hpp:77] Creating layer BatchNorm1
I1211 15:05:37.338984 15749 net.cpp:84] Creating Layer BatchNorm1
I1211 15:05:37.338989 15749 net.cpp:406] BatchNorm1 <- concat0_2
I1211 15:05:37.338994 15749 net.cpp:380] BatchNorm1 -> BatchNorm1
I1211 15:05:37.339279 15749 net.cpp:122] Setting up BatchNorm1
I1211 15:05:37.339285 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.339287 15749 net.cpp:137] Memory required for data: 111594960
I1211 15:05:37.339293 15749 layer_factory.hpp:77] Creating layer Scale1
I1211 15:05:37.339300 15749 net.cpp:84] Creating Layer Scale1
I1211 15:05:37.339303 15749 net.cpp:406] Scale1 <- BatchNorm1
I1211 15:05:37.339310 15749 net.cpp:367] Scale1 -> BatchNorm1 (in-place)
I1211 15:05:37.339361 15749 layer_factory.hpp:77] Creating layer Scale1
I1211 15:05:37.339525 15749 net.cpp:122] Setting up Scale1
I1211 15:05:37.339532 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.339534 15749 net.cpp:137] Memory required for data: 116292048
I1211 15:05:37.339540 15749 layer_factory.hpp:77] Creating layer ReLU1
I1211 15:05:37.339545 15749 net.cpp:84] Creating Layer ReLU1
I1211 15:05:37.339548 15749 net.cpp:406] ReLU1 <- BatchNorm1
I1211 15:05:37.339552 15749 net.cpp:367] ReLU1 -> BatchNorm1 (in-place)
I1211 15:05:37.339951 15749 net.cpp:122] Setting up ReLU1
I1211 15:05:37.339962 15749 net.cpp:129] Top shape: 1 128 66 139 (1174272)
I1211 15:05:37.339964 15749 net.cpp:137] Memory required for data: 120989136
I1211 15:05:37.339967 15749 layer_factory.hpp:77] Creating layer conv0_blk
I1211 15:05:37.339977 15749 net.cpp:84] Creating Layer conv0_blk
I1211 15:05:37.339980 15749 net.cpp:406] conv0_blk <- BatchNorm1
I1211 15:05:37.339985 15749 net.cpp:380] conv0_blk -> conv0_blk
I1211 15:05:37.341446 15749 net.cpp:122] Setting up conv0_blk
I1211 15:05:37.341457 15749 net.cpp:129] Top shape: 1 64 66 139 (587136)
I1211 15:05:37.341460 15749 net.cpp:137] Memory required for data: 123337680
I1211 15:05:37.341464 15749 layer_factory.hpp:77] Creating layer pool0
I1211 15:05:37.341470 15749 net.cpp:84] Creating Layer pool0
I1211 15:05:37.341473 15749 net.cpp:406] pool0 <- conv0_blk
I1211 15:05:37.341480 15749 net.cpp:380] pool0 -> pool0
I1211 15:05:37.341986 15749 net.cpp:122] Setting up pool0
I1211 15:05:37.341997 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342000 15749 net.cpp:137] Memory required for data: 123929040
I1211 15:05:37.342003 15749 layer_factory.hpp:77] Creating layer pool0_pool0_0_split
I1211 15:05:37.342008 15749 net.cpp:84] Creating Layer pool0_pool0_0_split
I1211 15:05:37.342011 15749 net.cpp:406] pool0_pool0_0_split <- pool0
I1211 15:05:37.342017 15749 net.cpp:380] pool0_pool0_0_split -> pool0_pool0_0_split_0
I1211 15:05:37.342022 15749 net.cpp:380] pool0_pool0_0_split -> pool0_pool0_0_split_1
I1211 15:05:37.342073 15749 net.cpp:122] Setting up pool0_pool0_0_split
I1211 15:05:37.342078 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342082 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342084 15749 net.cpp:137] Memory required for data: 125111760
I1211 15:05:37.342087 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/bn
I1211 15:05:37.342092 15749 net.cpp:84] Creating Layer conv1_0/x1/bn
I1211 15:05:37.342095 15749 net.cpp:406] conv1_0/x1/bn <- pool0_pool0_0_split_0
I1211 15:05:37.342099 15749 net.cpp:380] conv1_0/x1/bn -> conv1_0/x1/bn
I1211 15:05:37.342423 15749 net.cpp:122] Setting up conv1_0/x1/bn
I1211 15:05:37.342430 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342432 15749 net.cpp:137] Memory required for data: 125703120
I1211 15:05:37.342439 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/scale
I1211 15:05:37.342447 15749 net.cpp:84] Creating Layer conv1_0/x1/scale
I1211 15:05:37.342448 15749 net.cpp:406] conv1_0/x1/scale <- conv1_0/x1/bn
I1211 15:05:37.342453 15749 net.cpp:367] conv1_0/x1/scale -> conv1_0/x1/bn (in-place)
I1211 15:05:37.342504 15749 layer_factory.hpp:77] Creating layer conv1_0/x1/scale
I1211 15:05:37.342701 15749 net.cpp:122] Setting up conv1_0/x1/scale
I1211 15:05:37.342708 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342711 15749 net.cpp:137] Memory required for data: 126294480
I1211 15:05:37.342715 15749 layer_factory.hpp:77] Creating layer relu1_0/x1
I1211 15:05:37.342721 15749 net.cpp:84] Creating Layer relu1_0/x1
I1211 15:05:37.342723 15749 net.cpp:406] relu1_0/x1 <- conv1_0/x1/bn
I1211 15:05:37.342727 15749 net.cpp:367] relu1_0/x1 -> conv1_0/x1/bn (in-place)
I1211 15:05:37.342958 15749 net.cpp:122] Setting up relu1_0/x1
I1211 15:05:37.342967 15749 net.cpp:129] Top shape: 1 64 33 70 (147840)
I1211 15:05:37.342969 15749 net.cpp:137] Memory required for data: 126885840
I1211 15:05:37.342978 15749 layer_factory.hpp:77] Creating layer conv1_0/x1
I1211 15:05:37.342986 15749 net.cpp:84] Creating Layer conv1_0/x1
I1211 15:05:37.342989 15749 net.cpp:406] conv1_0/x1 <- conv1_0/x1/bn
I1211 15:05:37.342994 15749 net.cpp:380] conv1_0/x1 -> conv1_0/x1
I1211 15:05:37.344591 15749 net.cpp:122] Setting up conv1_0/x1
I1211 15:05:37.344610 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.344614 15749 net.cpp:137] Memory required for data: 128068560
I1211 15:05:37.344619 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/bn
I1211 15:05:37.344627 15749 net.cpp:84] Creating Layer conv1_0/x2/bn
I1211 15:05:37.344630 15749 net.cpp:406] conv1_0/x2/bn <- conv1_0/x1
I1211 15:05:37.344635 15749 net.cpp:380] conv1_0/x2/bn -> conv1_0/x2/bn
I1211 15:05:37.344947 15749 net.cpp:122] Setting up conv1_0/x2/bn
I1211 15:05:37.344954 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.344956 15749 net.cpp:137] Memory required for data: 129251280
I1211 15:05:37.344961 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/scale
I1211 15:05:37.344969 15749 net.cpp:84] Creating Layer conv1_0/x2/scale
I1211 15:05:37.344972 15749 net.cpp:406] conv1_0/x2/scale <- conv1_0/x2/bn
I1211 15:05:37.344975 15749 net.cpp:367] conv1_0/x2/scale -> conv1_0/x2/bn (in-place)
I1211 15:05:37.345024 15749 layer_factory.hpp:77] Creating layer conv1_0/x2/scale
I1211 15:05:37.345202 15749 net.cpp:122] Setting up conv1_0/x2/scale
I1211 15:05:37.345208 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.345211 15749 net.cpp:137] Memory required for data: 130434000
I1211 15:05:37.345216 15749 layer_factory.hpp:77] Creating layer relu1_0/x2
I1211 15:05:37.345221 15749 net.cpp:84] Creating Layer relu1_0/x2
I1211 15:05:37.345223 15749 net.cpp:406] relu1_0/x2 <- conv1_0/x2/bn
I1211 15:05:37.345228 15749 net.cpp:367] relu1_0/x2 -> conv1_0/x2/bn (in-place)
I1211 15:05:37.345638 15749 net.cpp:122] Setting up relu1_0/x2
I1211 15:05:37.345649 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.345651 15749 net.cpp:137] Memory required for data: 131616720
I1211 15:05:37.345654 15749 layer_factory.hpp:77] Creating layer conv1_0/x2
I1211 15:05:37.345664 15749 net.cpp:84] Creating Layer conv1_0/x2
I1211 15:05:37.345666 15749 net.cpp:406] conv1_0/x2 <- conv1_0/x2/bn
I1211 15:05:37.345672 15749 net.cpp:380] conv1_0/x2 -> conv1_0/x2
I1211 15:05:37.348592 15749 net.cpp:122] Setting up conv1_0/x2
I1211 15:05:37.348621 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.348624 15749 net.cpp:137] Memory required for data: 131912400
I1211 15:05:37.348632 15749 layer_factory.hpp:77] Creating layer concat1_0
I1211 15:05:37.348644 15749 net.cpp:84] Creating Layer concat1_0
I1211 15:05:37.348649 15749 net.cpp:406] concat1_0 <- pool0_pool0_0_split_1
I1211 15:05:37.348654 15749 net.cpp:406] concat1_0 <- conv1_0/x2
I1211 15:05:37.348659 15749 net.cpp:380] concat1_0 -> concat1_0
I1211 15:05:37.348701 15749 net.cpp:122] Setting up concat1_0
I1211 15:05:37.348706 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.348707 15749 net.cpp:137] Memory required for data: 132799440
I1211 15:05:37.348711 15749 layer_factory.hpp:77] Creating layer concat1_0_concat1_0_0_split
I1211 15:05:37.348716 15749 net.cpp:84] Creating Layer concat1_0_concat1_0_0_split
I1211 15:05:37.348719 15749 net.cpp:406] concat1_0_concat1_0_0_split <- concat1_0
I1211 15:05:37.348722 15749 net.cpp:380] concat1_0_concat1_0_0_split -> concat1_0_concat1_0_0_split_0
I1211 15:05:37.348727 15749 net.cpp:380] concat1_0_concat1_0_0_split -> concat1_0_concat1_0_0_split_1
I1211 15:05:37.348776 15749 net.cpp:122] Setting up concat1_0_concat1_0_0_split
I1211 15:05:37.348781 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.348784 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.348786 15749 net.cpp:137] Memory required for data: 134573520
I1211 15:05:37.348789 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/bn
I1211 15:05:37.348795 15749 net.cpp:84] Creating Layer conv1_1/x1/bn
I1211 15:05:37.348803 15749 net.cpp:406] conv1_1/x1/bn <- concat1_0_concat1_0_0_split_0
I1211 15:05:37.348809 15749 net.cpp:380] conv1_1/x1/bn -> conv1_1/x1/bn
I1211 15:05:37.349151 15749 net.cpp:122] Setting up conv1_1/x1/bn
I1211 15:05:37.349159 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.349160 15749 net.cpp:137] Memory required for data: 135460560
I1211 15:05:37.349169 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/scale
I1211 15:05:37.349175 15749 net.cpp:84] Creating Layer conv1_1/x1/scale
I1211 15:05:37.349177 15749 net.cpp:406] conv1_1/x1/scale <- conv1_1/x1/bn
I1211 15:05:37.349181 15749 net.cpp:367] conv1_1/x1/scale -> conv1_1/x1/bn (in-place)
I1211 15:05:37.349236 15749 layer_factory.hpp:77] Creating layer conv1_1/x1/scale
I1211 15:05:37.349431 15749 net.cpp:122] Setting up conv1_1/x1/scale
I1211 15:05:37.349438 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.349440 15749 net.cpp:137] Memory required for data: 136347600
I1211 15:05:37.349445 15749 layer_factory.hpp:77] Creating layer relu1_1/x1
I1211 15:05:37.349452 15749 net.cpp:84] Creating Layer relu1_1/x1
I1211 15:05:37.349454 15749 net.cpp:406] relu1_1/x1 <- conv1_1/x1/bn
I1211 15:05:37.349462 15749 net.cpp:367] relu1_1/x1 -> conv1_1/x1/bn (in-place)
I1211 15:05:37.349704 15749 net.cpp:122] Setting up relu1_1/x1
I1211 15:05:37.349712 15749 net.cpp:129] Top shape: 1 96 33 70 (221760)
I1211 15:05:37.349715 15749 net.cpp:137] Memory required for data: 137234640
I1211 15:05:37.349719 15749 layer_factory.hpp:77] Creating layer conv1_1/x1
I1211 15:05:37.349727 15749 net.cpp:84] Creating Layer conv1_1/x1
I1211 15:05:37.349730 15749 net.cpp:406] conv1_1/x1 <- conv1_1/x1/bn
I1211 15:05:37.349736 15749 net.cpp:380] conv1_1/x1 -> conv1_1/x1
I1211 15:05:37.351471 15749 net.cpp:122] Setting up conv1_1/x1
I1211 15:05:37.351487 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.351490 15749 net.cpp:137] Memory required for data: 138417360
I1211 15:05:37.351495 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/bn
I1211 15:05:37.351503 15749 net.cpp:84] Creating Layer conv1_1/x2/bn
I1211 15:05:37.351507 15749 net.cpp:406] conv1_1/x2/bn <- conv1_1/x1
I1211 15:05:37.351512 15749 net.cpp:380] conv1_1/x2/bn -> conv1_1/x2/bn
I1211 15:05:37.351840 15749 net.cpp:122] Setting up conv1_1/x2/bn
I1211 15:05:37.351846 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.351848 15749 net.cpp:137] Memory required for data: 139600080
I1211 15:05:37.351855 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/scale
I1211 15:05:37.351862 15749 net.cpp:84] Creating Layer conv1_1/x2/scale
I1211 15:05:37.351866 15749 net.cpp:406] conv1_1/x2/scale <- conv1_1/x2/bn
I1211 15:05:37.351869 15749 net.cpp:367] conv1_1/x2/scale -> conv1_1/x2/bn (in-place)
I1211 15:05:37.351922 15749 layer_factory.hpp:77] Creating layer conv1_1/x2/scale
I1211 15:05:37.352102 15749 net.cpp:122] Setting up conv1_1/x2/scale
I1211 15:05:37.352108 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.352110 15749 net.cpp:137] Memory required for data: 140782800
I1211 15:05:37.352121 15749 layer_factory.hpp:77] Creating layer relu1_1/x2
I1211 15:05:37.352128 15749 net.cpp:84] Creating Layer relu1_1/x2
I1211 15:05:37.352130 15749 net.cpp:406] relu1_1/x2 <- conv1_1/x2/bn
I1211 15:05:37.352133 15749 net.cpp:367] relu1_1/x2 -> conv1_1/x2/bn (in-place)
I1211 15:05:37.352516 15749 net.cpp:122] Setting up relu1_1/x2
I1211 15:05:37.352526 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.352530 15749 net.cpp:137] Memory required for data: 141965520
I1211 15:05:37.352532 15749 layer_factory.hpp:77] Creating layer conv1_1/x2
I1211 15:05:37.352541 15749 net.cpp:84] Creating Layer conv1_1/x2
I1211 15:05:37.352545 15749 net.cpp:406] conv1_1/x2 <- conv1_1/x2/bn
I1211 15:05:37.352550 15749 net.cpp:380] conv1_1/x2 -> conv1_1/x2
I1211 15:05:37.354836 15749 net.cpp:122] Setting up conv1_1/x2
I1211 15:05:37.354848 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.354851 15749 net.cpp:137] Memory required for data: 142261200
I1211 15:05:37.354859 15749 layer_factory.hpp:77] Creating layer concat1_1
I1211 15:05:37.354866 15749 net.cpp:84] Creating Layer concat1_1
I1211 15:05:37.354869 15749 net.cpp:406] concat1_1 <- concat1_0_concat1_0_0_split_1
I1211 15:05:37.354874 15749 net.cpp:406] concat1_1 <- conv1_1/x2
I1211 15:05:37.354878 15749 net.cpp:380] concat1_1 -> concat1_1
I1211 15:05:37.354918 15749 net.cpp:122] Setting up concat1_1
I1211 15:05:37.354923 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.354925 15749 net.cpp:137] Memory required for data: 143443920
I1211 15:05:37.354928 15749 layer_factory.hpp:77] Creating layer concat1_1_concat1_1_0_split
I1211 15:05:37.354933 15749 net.cpp:84] Creating Layer concat1_1_concat1_1_0_split
I1211 15:05:37.354936 15749 net.cpp:406] concat1_1_concat1_1_0_split <- concat1_1
I1211 15:05:37.354939 15749 net.cpp:380] concat1_1_concat1_1_0_split -> concat1_1_concat1_1_0_split_0
I1211 15:05:37.354944 15749 net.cpp:380] concat1_1_concat1_1_0_split -> concat1_1_concat1_1_0_split_1
I1211 15:05:37.354991 15749 net.cpp:122] Setting up concat1_1_concat1_1_0_split
I1211 15:05:37.354996 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.355000 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.355002 15749 net.cpp:137] Memory required for data: 145809360
I1211 15:05:37.355005 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/bn
I1211 15:05:37.355010 15749 net.cpp:84] Creating Layer conv1_2/x1/bn
I1211 15:05:37.355012 15749 net.cpp:406] conv1_2/x1/bn <- concat1_1_concat1_1_0_split_0
I1211 15:05:37.355016 15749 net.cpp:380] conv1_2/x1/bn -> conv1_2/x1/bn
I1211 15:05:37.355319 15749 net.cpp:122] Setting up conv1_2/x1/bn
I1211 15:05:37.355325 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.355327 15749 net.cpp:137] Memory required for data: 146992080
I1211 15:05:37.355334 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/scale
I1211 15:05:37.355340 15749 net.cpp:84] Creating Layer conv1_2/x1/scale
I1211 15:05:37.355343 15749 net.cpp:406] conv1_2/x1/scale <- conv1_2/x1/bn
I1211 15:05:37.355347 15749 net.cpp:367] conv1_2/x1/scale -> conv1_2/x1/bn (in-place)
I1211 15:05:37.355397 15749 layer_factory.hpp:77] Creating layer conv1_2/x1/scale
I1211 15:05:37.355578 15749 net.cpp:122] Setting up conv1_2/x1/scale
I1211 15:05:37.355585 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.355587 15749 net.cpp:137] Memory required for data: 148174800
I1211 15:05:37.355592 15749 layer_factory.hpp:77] Creating layer relu1_2/x1
I1211 15:05:37.355597 15749 net.cpp:84] Creating Layer relu1_2/x1
I1211 15:05:37.355599 15749 net.cpp:406] relu1_2/x1 <- conv1_2/x1/bn
I1211 15:05:37.355604 15749 net.cpp:367] relu1_2/x1 -> conv1_2/x1/bn (in-place)
I1211 15:05:37.356004 15749 net.cpp:122] Setting up relu1_2/x1
I1211 15:05:37.356015 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.356017 15749 net.cpp:137] Memory required for data: 149357520
I1211 15:05:37.356020 15749 layer_factory.hpp:77] Creating layer conv1_2/x1
I1211 15:05:37.356030 15749 net.cpp:84] Creating Layer conv1_2/x1
I1211 15:05:37.356034 15749 net.cpp:406] conv1_2/x1 <- conv1_2/x1/bn
I1211 15:05:37.356037 15749 net.cpp:380] conv1_2/x1 -> conv1_2/x1
I1211 15:05:37.357812 15749 net.cpp:122] Setting up conv1_2/x1
I1211 15:05:37.357834 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.357837 15749 net.cpp:137] Memory required for data: 150540240
I1211 15:05:37.357844 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/bn
I1211 15:05:37.357852 15749 net.cpp:84] Creating Layer conv1_2/x2/bn
I1211 15:05:37.357856 15749 net.cpp:406] conv1_2/x2/bn <- conv1_2/x1
I1211 15:05:37.357863 15749 net.cpp:380] conv1_2/x2/bn -> conv1_2/x2/bn
I1211 15:05:37.358188 15749 net.cpp:122] Setting up conv1_2/x2/bn
I1211 15:05:37.358197 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.358199 15749 net.cpp:137] Memory required for data: 151722960
I1211 15:05:37.358206 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/scale
I1211 15:05:37.358217 15749 net.cpp:84] Creating Layer conv1_2/x2/scale
I1211 15:05:37.358224 15749 net.cpp:406] conv1_2/x2/scale <- conv1_2/x2/bn
I1211 15:05:37.358229 15749 net.cpp:367] conv1_2/x2/scale -> conv1_2/x2/bn (in-place)
I1211 15:05:37.358284 15749 layer_factory.hpp:77] Creating layer conv1_2/x2/scale
I1211 15:05:37.358469 15749 net.cpp:122] Setting up conv1_2/x2/scale
I1211 15:05:37.358476 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.358479 15749 net.cpp:137] Memory required for data: 152905680
I1211 15:05:37.358484 15749 layer_factory.hpp:77] Creating layer relu1_2/x2
I1211 15:05:37.358490 15749 net.cpp:84] Creating Layer relu1_2/x2
I1211 15:05:37.358494 15749 net.cpp:406] relu1_2/x2 <- conv1_2/x2/bn
I1211 15:05:37.358496 15749 net.cpp:367] relu1_2/x2 -> conv1_2/x2/bn (in-place)
I1211 15:05:37.358731 15749 net.cpp:122] Setting up relu1_2/x2
I1211 15:05:37.358739 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.358741 15749 net.cpp:137] Memory required for data: 154088400
I1211 15:05:37.358745 15749 layer_factory.hpp:77] Creating layer conv1_2/x2
I1211 15:05:37.358757 15749 net.cpp:84] Creating Layer conv1_2/x2
I1211 15:05:37.358759 15749 net.cpp:406] conv1_2/x2 <- conv1_2/x2/bn
I1211 15:05:37.358763 15749 net.cpp:380] conv1_2/x2 -> conv1_2/x2
I1211 15:05:37.361521 15749 net.cpp:122] Setting up conv1_2/x2
I1211 15:05:37.361552 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.361554 15749 net.cpp:137] Memory required for data: 154384080
I1211 15:05:37.361563 15749 layer_factory.hpp:77] Creating layer concat1_2
I1211 15:05:37.361574 15749 net.cpp:84] Creating Layer concat1_2
I1211 15:05:37.361579 15749 net.cpp:406] concat1_2 <- concat1_1_concat1_1_0_split_1
I1211 15:05:37.361584 15749 net.cpp:406] concat1_2 <- conv1_2/x2
I1211 15:05:37.361590 15749 net.cpp:380] concat1_2 -> concat1_2
I1211 15:05:37.361632 15749 net.cpp:122] Setting up concat1_2
I1211 15:05:37.361639 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.361640 15749 net.cpp:137] Memory required for data: 155862480
I1211 15:05:37.361642 15749 layer_factory.hpp:77] Creating layer concat1_2_concat1_2_0_split
I1211 15:05:37.361647 15749 net.cpp:84] Creating Layer concat1_2_concat1_2_0_split
I1211 15:05:37.361650 15749 net.cpp:406] concat1_2_concat1_2_0_split <- concat1_2
I1211 15:05:37.361655 15749 net.cpp:380] concat1_2_concat1_2_0_split -> concat1_2_concat1_2_0_split_0
I1211 15:05:37.361660 15749 net.cpp:380] concat1_2_concat1_2_0_split -> concat1_2_concat1_2_0_split_1
I1211 15:05:37.361709 15749 net.cpp:122] Setting up concat1_2_concat1_2_0_split
I1211 15:05:37.361714 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.361717 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.361719 15749 net.cpp:137] Memory required for data: 158819280
I1211 15:05:37.361722 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/bn
I1211 15:05:37.361728 15749 net.cpp:84] Creating Layer conv1_3/x1/bn
I1211 15:05:37.361732 15749 net.cpp:406] conv1_3/x1/bn <- concat1_2_concat1_2_0_split_0
I1211 15:05:37.361735 15749 net.cpp:380] conv1_3/x1/bn -> conv1_3/x1/bn
I1211 15:05:37.362169 15749 net.cpp:122] Setting up conv1_3/x1/bn
I1211 15:05:37.362179 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.362182 15749 net.cpp:137] Memory required for data: 160297680
I1211 15:05:37.362192 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/scale
I1211 15:05:37.362200 15749 net.cpp:84] Creating Layer conv1_3/x1/scale
I1211 15:05:37.362205 15749 net.cpp:406] conv1_3/x1/scale <- conv1_3/x1/bn
I1211 15:05:37.362215 15749 net.cpp:367] conv1_3/x1/scale -> conv1_3/x1/bn (in-place)
I1211 15:05:37.362283 15749 layer_factory.hpp:77] Creating layer conv1_3/x1/scale
I1211 15:05:37.362534 15749 net.cpp:122] Setting up conv1_3/x1/scale
I1211 15:05:37.362543 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.362547 15749 net.cpp:137] Memory required for data: 161776080
I1211 15:05:37.362555 15749 layer_factory.hpp:77] Creating layer relu1_3/x1
I1211 15:05:37.362565 15749 net.cpp:84] Creating Layer relu1_3/x1
I1211 15:05:37.362573 15749 net.cpp:406] relu1_3/x1 <- conv1_3/x1/bn
I1211 15:05:37.362579 15749 net.cpp:367] relu1_3/x1 -> conv1_3/x1/bn (in-place)
I1211 15:05:37.363116 15749 net.cpp:122] Setting up relu1_3/x1
I1211 15:05:37.363129 15749 net.cpp:129] Top shape: 1 160 33 70 (369600)
I1211 15:05:37.363133 15749 net.cpp:137] Memory required for data: 163254480
I1211 15:05:37.363137 15749 layer_factory.hpp:77] Creating layer conv1_3/x1
I1211 15:05:37.363152 15749 net.cpp:84] Creating Layer conv1_3/x1
I1211 15:05:37.363157 15749 net.cpp:406] conv1_3/x1 <- conv1_3/x1/bn
I1211 15:05:37.363163 15749 net.cpp:380] conv1_3/x1 -> conv1_3/x1
I1211 15:05:37.365540 15749 net.cpp:122] Setting up conv1_3/x1
I1211 15:05:37.365556 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.365561 15749 net.cpp:137] Memory required for data: 164437200
I1211 15:05:37.365567 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/bn
I1211 15:05:37.365576 15749 net.cpp:84] Creating Layer conv1_3/x2/bn
I1211 15:05:37.365581 15749 net.cpp:406] conv1_3/x2/bn <- conv1_3/x1
I1211 15:05:37.365591 15749 net.cpp:380] conv1_3/x2/bn -> conv1_3/x2/bn
I1211 15:05:37.365993 15749 net.cpp:122] Setting up conv1_3/x2/bn
I1211 15:05:37.366003 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.366006 15749 net.cpp:137] Memory required for data: 165619920
I1211 15:05:37.366014 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/scale
I1211 15:05:37.366022 15749 net.cpp:84] Creating Layer conv1_3/x2/scale
I1211 15:05:37.366027 15749 net.cpp:406] conv1_3/x2/scale <- conv1_3/x2/bn
I1211 15:05:37.366034 15749 net.cpp:367] conv1_3/x2/scale -> conv1_3/x2/bn (in-place)
I1211 15:05:37.366101 15749 layer_factory.hpp:77] Creating layer conv1_3/x2/scale
I1211 15:05:37.366340 15749 net.cpp:122] Setting up conv1_3/x2/scale
I1211 15:05:37.366350 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.366354 15749 net.cpp:137] Memory required for data: 166802640
I1211 15:05:37.366361 15749 layer_factory.hpp:77] Creating layer relu1_3/x2
I1211 15:05:37.366369 15749 net.cpp:84] Creating Layer relu1_3/x2
I1211 15:05:37.366372 15749 net.cpp:406] relu1_3/x2 <- conv1_3/x2/bn
I1211 15:05:37.366377 15749 net.cpp:367] relu1_3/x2 -> conv1_3/x2/bn (in-place)
I1211 15:05:37.366770 15749 net.cpp:122] Setting up relu1_3/x2
I1211 15:05:37.366783 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.366787 15749 net.cpp:137] Memory required for data: 167985360
I1211 15:05:37.366792 15749 layer_factory.hpp:77] Creating layer conv1_3/x2
I1211 15:05:37.366804 15749 net.cpp:84] Creating Layer conv1_3/x2
I1211 15:05:37.366808 15749 net.cpp:406] conv1_3/x2 <- conv1_3/x2/bn
I1211 15:05:37.366817 15749 net.cpp:380] conv1_3/x2 -> conv1_3/x2
I1211 15:05:37.369964 15749 net.cpp:122] Setting up conv1_3/x2
I1211 15:05:37.369982 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.369987 15749 net.cpp:137] Memory required for data: 168281040
I1211 15:05:37.369994 15749 layer_factory.hpp:77] Creating layer concat1_3
I1211 15:05:37.370002 15749 net.cpp:84] Creating Layer concat1_3
I1211 15:05:37.370007 15749 net.cpp:406] concat1_3 <- concat1_2_concat1_2_0_split_1
I1211 15:05:37.370013 15749 net.cpp:406] concat1_3 <- conv1_3/x2
I1211 15:05:37.370020 15749 net.cpp:380] concat1_3 -> concat1_3
I1211 15:05:37.370071 15749 net.cpp:122] Setting up concat1_3
I1211 15:05:37.370079 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.370084 15749 net.cpp:137] Memory required for data: 170055120
I1211 15:05:37.370087 15749 layer_factory.hpp:77] Creating layer concat1_3_concat1_3_0_split
I1211 15:05:37.370095 15749 net.cpp:84] Creating Layer concat1_3_concat1_3_0_split
I1211 15:05:37.370098 15749 net.cpp:406] concat1_3_concat1_3_0_split <- concat1_3
I1211 15:05:37.370103 15749 net.cpp:380] concat1_3_concat1_3_0_split -> concat1_3_concat1_3_0_split_0
I1211 15:05:37.370112 15749 net.cpp:380] concat1_3_concat1_3_0_split -> concat1_3_concat1_3_0_split_1
I1211 15:05:37.370177 15749 net.cpp:122] Setting up concat1_3_concat1_3_0_split
I1211 15:05:37.370183 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.370193 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.370198 15749 net.cpp:137] Memory required for data: 173603280
I1211 15:05:37.370201 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/bn
I1211 15:05:37.370208 15749 net.cpp:84] Creating Layer conv1_4/x1/bn
I1211 15:05:37.370213 15749 net.cpp:406] conv1_4/x1/bn <- concat1_3_concat1_3_0_split_0
I1211 15:05:37.370220 15749 net.cpp:380] conv1_4/x1/bn -> conv1_4/x1/bn
I1211 15:05:37.370656 15749 net.cpp:122] Setting up conv1_4/x1/bn
I1211 15:05:37.370666 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.370669 15749 net.cpp:137] Memory required for data: 175377360
I1211 15:05:37.370678 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/scale
I1211 15:05:37.370688 15749 net.cpp:84] Creating Layer conv1_4/x1/scale
I1211 15:05:37.370693 15749 net.cpp:406] conv1_4/x1/scale <- conv1_4/x1/bn
I1211 15:05:37.370700 15749 net.cpp:367] conv1_4/x1/scale -> conv1_4/x1/bn (in-place)
I1211 15:05:37.370769 15749 layer_factory.hpp:77] Creating layer conv1_4/x1/scale
I1211 15:05:37.371026 15749 net.cpp:122] Setting up conv1_4/x1/scale
I1211 15:05:37.371037 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.371040 15749 net.cpp:137] Memory required for data: 177151440
I1211 15:05:37.371047 15749 layer_factory.hpp:77] Creating layer relu1_4/x1
I1211 15:05:37.371055 15749 net.cpp:84] Creating Layer relu1_4/x1
I1211 15:05:37.371059 15749 net.cpp:406] relu1_4/x1 <- conv1_4/x1/bn
I1211 15:05:37.371064 15749 net.cpp:367] relu1_4/x1 -> conv1_4/x1/bn (in-place)
I1211 15:05:37.371773 15749 net.cpp:122] Setting up relu1_4/x1
I1211 15:05:37.371786 15749 net.cpp:129] Top shape: 1 192 33 70 (443520)
I1211 15:05:37.371790 15749 net.cpp:137] Memory required for data: 178925520
I1211 15:05:37.371795 15749 layer_factory.hpp:77] Creating layer conv1_4/x1
I1211 15:05:37.371809 15749 net.cpp:84] Creating Layer conv1_4/x1
I1211 15:05:37.371814 15749 net.cpp:406] conv1_4/x1 <- conv1_4/x1/bn
I1211 15:05:37.371821 15749 net.cpp:380] conv1_4/x1 -> conv1_4/x1
I1211 15:05:37.374685 15749 net.cpp:122] Setting up conv1_4/x1
I1211 15:05:37.374719 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.374724 15749 net.cpp:137] Memory required for data: 180108240
I1211 15:05:37.374735 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/bn
I1211 15:05:37.374748 15749 net.cpp:84] Creating Layer conv1_4/x2/bn
I1211 15:05:37.374754 15749 net.cpp:406] conv1_4/x2/bn <- conv1_4/x1
I1211 15:05:37.374765 15749 net.cpp:380] conv1_4/x2/bn -> conv1_4/x2/bn
I1211 15:05:37.375211 15749 net.cpp:122] Setting up conv1_4/x2/bn
I1211 15:05:37.375221 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.375226 15749 net.cpp:137] Memory required for data: 181290960
I1211 15:05:37.375236 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/scale
I1211 15:05:37.375246 15749 net.cpp:84] Creating Layer conv1_4/x2/scale
I1211 15:05:37.375249 15749 net.cpp:406] conv1_4/x2/scale <- conv1_4/x2/bn
I1211 15:05:37.375257 15749 net.cpp:367] conv1_4/x2/scale -> conv1_4/x2/bn (in-place)
I1211 15:05:37.375329 15749 layer_factory.hpp:77] Creating layer conv1_4/x2/scale
I1211 15:05:37.375568 15749 net.cpp:122] Setting up conv1_4/x2/scale
I1211 15:05:37.375578 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.375582 15749 net.cpp:137] Memory required for data: 182473680
I1211 15:05:37.375589 15749 layer_factory.hpp:77] Creating layer relu1_4/x2
I1211 15:05:37.375597 15749 net.cpp:84] Creating Layer relu1_4/x2
I1211 15:05:37.375602 15749 net.cpp:406] relu1_4/x2 <- conv1_4/x2/bn
I1211 15:05:37.375607 15749 net.cpp:367] relu1_4/x2 -> conv1_4/x2/bn (in-place)
I1211 15:05:37.376210 15749 net.cpp:122] Setting up relu1_4/x2
I1211 15:05:37.376225 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.376230 15749 net.cpp:137] Memory required for data: 183656400
I1211 15:05:37.376235 15749 layer_factory.hpp:77] Creating layer conv1_4/x2
I1211 15:05:37.376247 15749 net.cpp:84] Creating Layer conv1_4/x2
I1211 15:05:37.376257 15749 net.cpp:406] conv1_4/x2 <- conv1_4/x2/bn
I1211 15:05:37.376266 15749 net.cpp:380] conv1_4/x2 -> conv1_4/x2
I1211 15:05:37.380396 15749 net.cpp:122] Setting up conv1_4/x2
I1211 15:05:37.380430 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.380435 15749 net.cpp:137] Memory required for data: 183952080
I1211 15:05:37.380445 15749 layer_factory.hpp:77] Creating layer concat1_4
I1211 15:05:37.380457 15749 net.cpp:84] Creating Layer concat1_4
I1211 15:05:37.380465 15749 net.cpp:406] concat1_4 <- concat1_3_concat1_3_0_split_1
I1211 15:05:37.380472 15749 net.cpp:406] concat1_4 <- conv1_4/x2
I1211 15:05:37.380481 15749 net.cpp:380] concat1_4 -> concat1_4
I1211 15:05:37.380533 15749 net.cpp:122] Setting up concat1_4
I1211 15:05:37.380542 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.380547 15749 net.cpp:137] Memory required for data: 186021840
I1211 15:05:37.380550 15749 layer_factory.hpp:77] Creating layer concat1_4_concat1_4_0_split
I1211 15:05:37.380558 15749 net.cpp:84] Creating Layer concat1_4_concat1_4_0_split
I1211 15:05:37.380561 15749 net.cpp:406] concat1_4_concat1_4_0_split <- concat1_4
I1211 15:05:37.380568 15749 net.cpp:380] concat1_4_concat1_4_0_split -> concat1_4_concat1_4_0_split_0
I1211 15:05:37.380580 15749 net.cpp:380] concat1_4_concat1_4_0_split -> concat1_4_concat1_4_0_split_1
I1211 15:05:37.380645 15749 net.cpp:122] Setting up concat1_4_concat1_4_0_split
I1211 15:05:37.380653 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.380658 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.380662 15749 net.cpp:137] Memory required for data: 190161360
I1211 15:05:37.380666 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/bn
I1211 15:05:37.380674 15749 net.cpp:84] Creating Layer conv1_5/x1/bn
I1211 15:05:37.380681 15749 net.cpp:406] conv1_5/x1/bn <- concat1_4_concat1_4_0_split_0
I1211 15:05:37.380686 15749 net.cpp:380] conv1_5/x1/bn -> conv1_5/x1/bn
I1211 15:05:37.381139 15749 net.cpp:122] Setting up conv1_5/x1/bn
I1211 15:05:37.381148 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.381152 15749 net.cpp:137] Memory required for data: 192231120
I1211 15:05:37.381161 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/scale
I1211 15:05:37.381171 15749 net.cpp:84] Creating Layer conv1_5/x1/scale
I1211 15:05:37.381175 15749 net.cpp:406] conv1_5/x1/scale <- conv1_5/x1/bn
I1211 15:05:37.381182 15749 net.cpp:367] conv1_5/x1/scale -> conv1_5/x1/bn (in-place)
I1211 15:05:37.381255 15749 layer_factory.hpp:77] Creating layer conv1_5/x1/scale
I1211 15:05:37.381520 15749 net.cpp:122] Setting up conv1_5/x1/scale
I1211 15:05:37.381528 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.381532 15749 net.cpp:137] Memory required for data: 194300880
I1211 15:05:37.381539 15749 layer_factory.hpp:77] Creating layer relu1_5/x1
I1211 15:05:37.381548 15749 net.cpp:84] Creating Layer relu1_5/x1
I1211 15:05:37.381552 15749 net.cpp:406] relu1_5/x1 <- conv1_5/x1/bn
I1211 15:05:37.381558 15749 net.cpp:367] relu1_5/x1 -> conv1_5/x1/bn (in-place)
I1211 15:05:37.381829 15749 net.cpp:122] Setting up relu1_5/x1
I1211 15:05:37.381839 15749 net.cpp:129] Top shape: 1 224 33 70 (517440)
I1211 15:05:37.381844 15749 net.cpp:137] Memory required for data: 196370640
I1211 15:05:37.381847 15749 layer_factory.hpp:77] Creating layer conv1_5/x1
I1211 15:05:37.381860 15749 net.cpp:84] Creating Layer conv1_5/x1
I1211 15:05:37.381865 15749 net.cpp:406] conv1_5/x1 <- conv1_5/x1/bn
I1211 15:05:37.381871 15749 net.cpp:380] conv1_5/x1 -> conv1_5/x1
I1211 15:05:37.392932 15749 net.cpp:122] Setting up conv1_5/x1
I1211 15:05:37.392966 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.392971 15749 net.cpp:137] Memory required for data: 197553360
I1211 15:05:37.392979 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/bn
I1211 15:05:37.392992 15749 net.cpp:84] Creating Layer conv1_5/x2/bn
I1211 15:05:37.392999 15749 net.cpp:406] conv1_5/x2/bn <- conv1_5/x1
I1211 15:05:37.393007 15749 net.cpp:380] conv1_5/x2/bn -> conv1_5/x2/bn
I1211 15:05:37.393442 15749 net.cpp:122] Setting up conv1_5/x2/bn
I1211 15:05:37.393452 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.393456 15749 net.cpp:137] Memory required for data: 198736080
I1211 15:05:37.393465 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/scale
I1211 15:05:37.393476 15749 net.cpp:84] Creating Layer conv1_5/x2/scale
I1211 15:05:37.393479 15749 net.cpp:406] conv1_5/x2/scale <- conv1_5/x2/bn
I1211 15:05:37.393486 15749 net.cpp:367] conv1_5/x2/scale -> conv1_5/x2/bn (in-place)
I1211 15:05:37.393555 15749 layer_factory.hpp:77] Creating layer conv1_5/x2/scale
I1211 15:05:37.393800 15749 net.cpp:122] Setting up conv1_5/x2/scale
I1211 15:05:37.393810 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.393815 15749 net.cpp:137] Memory required for data: 199918800
I1211 15:05:37.393821 15749 layer_factory.hpp:77] Creating layer relu1_5/x2
I1211 15:05:37.393829 15749 net.cpp:84] Creating Layer relu1_5/x2
I1211 15:05:37.393834 15749 net.cpp:406] relu1_5/x2 <- conv1_5/x2/bn
I1211 15:05:37.393839 15749 net.cpp:367] relu1_5/x2 -> conv1_5/x2/bn (in-place)
I1211 15:05:37.394320 15749 net.cpp:122] Setting up relu1_5/x2
I1211 15:05:37.394332 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.394336 15749 net.cpp:137] Memory required for data: 201101520
I1211 15:05:37.394341 15749 layer_factory.hpp:77] Creating layer conv1_5/x2
I1211 15:05:37.394354 15749 net.cpp:84] Creating Layer conv1_5/x2
I1211 15:05:37.394359 15749 net.cpp:406] conv1_5/x2 <- conv1_5/x2/bn
I1211 15:05:37.394367 15749 net.cpp:380] conv1_5/x2 -> conv1_5/x2
I1211 15:05:37.451314 15749 net.cpp:122] Setting up conv1_5/x2
I1211 15:05:37.451351 15749 net.cpp:129] Top shape: 1 32 33 70 (73920)
I1211 15:05:37.451355 15749 net.cpp:137] Memory required for data: 201397200
I1211 15:05:37.451366 15749 layer_factory.hpp:77] Creating layer concat1_5
I1211 15:05:37.451380 15749 net.cpp:84] Creating Layer concat1_5
I1211 15:05:37.451388 15749 net.cpp:406] concat1_5 <- concat1_4_concat1_4_0_split_1
I1211 15:05:37.451396 15749 net.cpp:406] concat1_5 <- conv1_5/x2
I1211 15:05:37.451403 15749 net.cpp:380] concat1_5 -> concat1_5
I1211 15:05:37.451457 15749 net.cpp:122] Setting up concat1_5
I1211 15:05:37.451465 15749 net.cpp:129] Top shape: 1 256 33 70 (591360)
I1211 15:05:37.451469 15749 net.cpp:137] Memory required for data: 203762640
I1211 15:05:37.451473 15749 layer_factory.hpp:77] Creating layer BatchNorm2
I1211 15:05:37.451481 15749 net.cpp:84] Creating Layer BatchNorm2
I1211 15:05:37.451486 15749 net.cpp:406] BatchNorm2 <- concat1_5
I1211 15:05:37.451493 15749 net.cpp:380] BatchNorm2 -> BatchNorm2
I1211 15:05:37.463735 15749 net.cpp:122] Setting up BatchNorm2
I1211 15:05:37.463775 15749 net.cpp:129] Top shape: 1 256 33 70 (591360)
I1211 15:05:37.463780 15749 net.cpp:137] Memory required for data: 206128080
I1211 15:05:37.463796 15749 layer_factory.hpp:77] Creating layer Scale2
I1211 15:05:37.463810 15749 net.cpp:84] Creating Layer Scale2
I1211 15:05:37.463817 15749 net.cpp:406] Scale2 <- BatchNorm2
I1211 15:05:37.463826 15749 net.cpp:367] Scale2 -> BatchNorm2 (in-place)
I1211 15:05:37.463913 15749 layer_factory.hpp:77] Creating layer Scale2
I1211 15:05:37.464191 15749 net.cpp:122] Setting up Scale2
I1211 15:05:37.464203 15749 net.cpp:129] Top shape: 1 256 33 70 (591360)
I1211 15:05:37.464208 15749 net.cpp:137] Memory required for data: 208493520
I1211 15:05:37.464216 15749 layer_factory.hpp:77] Creating layer ReLU2
I1211 15:05:37.464224 15749 net.cpp:84] Creating Layer ReLU2
I1211 15:05:37.464229 15749 net.cpp:406] ReLU2 <- BatchNorm2
I1211 15:05:37.464236 15749 net.cpp:367] ReLU2 -> BatchNorm2 (in-place)
I1211 15:05:37.464613 15749 net.cpp:122] Setting up ReLU2
I1211 15:05:37.464627 15749 net.cpp:129] Top shape: 1 256 33 70 (591360)
I1211 15:05:37.464630 15749 net.cpp:137] Memory required for data: 210858960
I1211 15:05:37.464634 15749 layer_factory.hpp:77] Creating layer conv1_blk
I1211 15:05:37.464649 15749 net.cpp:84] Creating Layer conv1_blk
I1211 15:05:37.464654 15749 net.cpp:406] conv1_blk <- BatchNorm2
I1211 15:05:37.464669 15749 net.cpp:380] conv1_blk -> conv1_blk
I1211 15:05:37.467954 15749 net.cpp:122] Setting up conv1_blk
I1211 15:05:37.467990 15749 net.cpp:129] Top shape: 1 128 33 70 (295680)
I1211 15:05:37.467995 15749 net.cpp:137] Memory required for data: 212041680
I1211 15:05:37.468005 15749 layer_factory.hpp:77] Creating layer pool1
I1211 15:05:37.468019 15749 net.cpp:84] Creating Layer pool1
I1211 15:05:37.468025 15749 net.cpp:406] pool1 <- conv1_blk
I1211 15:05:37.468034 15749 net.cpp:380] pool1 -> pool1
I1211 15:05:37.468595 15749 net.cpp:122] Setting up pool1
I1211 15:05:37.468610 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.468613 15749 net.cpp:137] Memory required for data: 212346320
I1211 15:05:37.468618 15749 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1211 15:05:37.468626 15749 net.cpp:84] Creating Layer pool1_pool1_0_split
I1211 15:05:37.468629 15749 net.cpp:406] pool1_pool1_0_split <- pool1
I1211 15:05:37.468636 15749 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1211 15:05:37.468646 15749 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1211 15:05:37.468713 15749 net.cpp:122] Setting up pool1_pool1_0_split
I1211 15:05:37.468724 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.468729 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.468732 15749 net.cpp:137] Memory required for data: 212955600
I1211 15:05:37.468736 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/bn
I1211 15:05:37.468744 15749 net.cpp:84] Creating Layer conv2_0/x1/bn
I1211 15:05:37.468747 15749 net.cpp:406] conv2_0/x1/bn <- pool1_pool1_0_split_0
I1211 15:05:37.468755 15749 net.cpp:380] conv2_0/x1/bn -> conv2_0/x1/bn
I1211 15:05:37.469202 15749 net.cpp:122] Setting up conv2_0/x1/bn
I1211 15:05:37.469211 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.469215 15749 net.cpp:137] Memory required for data: 213260240
I1211 15:05:37.469226 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/scale
I1211 15:05:37.469235 15749 net.cpp:84] Creating Layer conv2_0/x1/scale
I1211 15:05:37.469239 15749 net.cpp:406] conv2_0/x1/scale <- conv2_0/x1/bn
I1211 15:05:37.469247 15749 net.cpp:367] conv2_0/x1/scale -> conv2_0/x1/bn (in-place)
I1211 15:05:37.469321 15749 layer_factory.hpp:77] Creating layer conv2_0/x1/scale
I1211 15:05:37.469588 15749 net.cpp:122] Setting up conv2_0/x1/scale
I1211 15:05:37.469599 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.469602 15749 net.cpp:137] Memory required for data: 213564880
I1211 15:05:37.469609 15749 layer_factory.hpp:77] Creating layer relu2_0/x1
I1211 15:05:37.469617 15749 net.cpp:84] Creating Layer relu2_0/x1
I1211 15:05:37.469621 15749 net.cpp:406] relu2_0/x1 <- conv2_0/x1/bn
I1211 15:05:37.469627 15749 net.cpp:367] relu2_0/x1 -> conv2_0/x1/bn (in-place)
I1211 15:05:37.470206 15749 net.cpp:122] Setting up relu2_0/x1
I1211 15:05:37.470222 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.470227 15749 net.cpp:137] Memory required for data: 213869520
I1211 15:05:37.470232 15749 layer_factory.hpp:77] Creating layer conv2_0/x1
I1211 15:05:37.470244 15749 net.cpp:84] Creating Layer conv2_0/x1
I1211 15:05:37.470248 15749 net.cpp:406] conv2_0/x1 <- conv2_0/x1/bn
I1211 15:05:37.470257 15749 net.cpp:380] conv2_0/x1 -> conv2_0/x1
I1211 15:05:37.472905 15749 net.cpp:122] Setting up conv2_0/x1
I1211 15:05:37.472934 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.472939 15749 net.cpp:137] Memory required for data: 214174160
I1211 15:05:37.472947 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/bn
I1211 15:05:37.472959 15749 net.cpp:84] Creating Layer conv2_0/x2/bn
I1211 15:05:37.472965 15749 net.cpp:406] conv2_0/x2/bn <- conv2_0/x1
I1211 15:05:37.472975 15749 net.cpp:380] conv2_0/x2/bn -> conv2_0/x2/bn
I1211 15:05:37.473425 15749 net.cpp:122] Setting up conv2_0/x2/bn
I1211 15:05:37.473436 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.473439 15749 net.cpp:137] Memory required for data: 214478800
I1211 15:05:37.473462 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/scale
I1211 15:05:37.473476 15749 net.cpp:84] Creating Layer conv2_0/x2/scale
I1211 15:05:37.473481 15749 net.cpp:406] conv2_0/x2/scale <- conv2_0/x2/bn
I1211 15:05:37.473487 15749 net.cpp:367] conv2_0/x2/scale -> conv2_0/x2/bn (in-place)
I1211 15:05:37.473562 15749 layer_factory.hpp:77] Creating layer conv2_0/x2/scale
I1211 15:05:37.473873 15749 net.cpp:122] Setting up conv2_0/x2/scale
I1211 15:05:37.473886 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.473888 15749 net.cpp:137] Memory required for data: 214783440
I1211 15:05:37.473896 15749 layer_factory.hpp:77] Creating layer relu2_0/x2
I1211 15:05:37.473904 15749 net.cpp:84] Creating Layer relu2_0/x2
I1211 15:05:37.473908 15749 net.cpp:406] relu2_0/x2 <- conv2_0/x2/bn
I1211 15:05:37.473914 15749 net.cpp:367] relu2_0/x2 -> conv2_0/x2/bn (in-place)
I1211 15:05:37.474190 15749 net.cpp:122] Setting up relu2_0/x2
I1211 15:05:37.474201 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.474205 15749 net.cpp:137] Memory required for data: 215088080
I1211 15:05:37.474210 15749 layer_factory.hpp:77] Creating layer conv2_0/x2
I1211 15:05:37.474222 15749 net.cpp:84] Creating Layer conv2_0/x2
I1211 15:05:37.474226 15749 net.cpp:406] conv2_0/x2 <- conv2_0/x2/bn
I1211 15:05:37.474238 15749 net.cpp:380] conv2_0/x2 -> conv2_0/x2
I1211 15:05:37.477658 15749 net.cpp:122] Setting up conv2_0/x2
I1211 15:05:37.477674 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.477677 15749 net.cpp:137] Memory required for data: 215164240
I1211 15:05:37.477684 15749 layer_factory.hpp:77] Creating layer concat2_0
I1211 15:05:37.477694 15749 net.cpp:84] Creating Layer concat2_0
I1211 15:05:37.477699 15749 net.cpp:406] concat2_0 <- pool1_pool1_0_split_1
I1211 15:05:37.477705 15749 net.cpp:406] concat2_0 <- conv2_0/x2
I1211 15:05:37.477712 15749 net.cpp:380] concat2_0 -> concat2_0
I1211 15:05:37.477764 15749 net.cpp:122] Setting up concat2_0
I1211 15:05:37.477772 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.477777 15749 net.cpp:137] Memory required for data: 215545040
I1211 15:05:37.477780 15749 layer_factory.hpp:77] Creating layer concat2_0_concat2_0_0_split
I1211 15:05:37.477787 15749 net.cpp:84] Creating Layer concat2_0_concat2_0_0_split
I1211 15:05:37.477792 15749 net.cpp:406] concat2_0_concat2_0_0_split <- concat2_0
I1211 15:05:37.477798 15749 net.cpp:380] concat2_0_concat2_0_0_split -> concat2_0_concat2_0_0_split_0
I1211 15:05:37.477805 15749 net.cpp:380] concat2_0_concat2_0_0_split -> concat2_0_concat2_0_0_split_1
I1211 15:05:37.477870 15749 net.cpp:122] Setting up concat2_0_concat2_0_0_split
I1211 15:05:37.477879 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.477885 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.477887 15749 net.cpp:137] Memory required for data: 216306640
I1211 15:05:37.477891 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/bn
I1211 15:05:37.477900 15749 net.cpp:84] Creating Layer conv2_1/x1/bn
I1211 15:05:37.477903 15749 net.cpp:406] conv2_1/x1/bn <- concat2_0_concat2_0_0_split_0
I1211 15:05:37.477911 15749 net.cpp:380] conv2_1/x1/bn -> conv2_1/x1/bn
I1211 15:05:37.478353 15749 net.cpp:122] Setting up conv2_1/x1/bn
I1211 15:05:37.478363 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.478366 15749 net.cpp:137] Memory required for data: 216687440
I1211 15:05:37.478375 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/scale
I1211 15:05:37.478384 15749 net.cpp:84] Creating Layer conv2_1/x1/scale
I1211 15:05:37.478387 15749 net.cpp:406] conv2_1/x1/scale <- conv2_1/x1/bn
I1211 15:05:37.478394 15749 net.cpp:367] conv2_1/x1/scale -> conv2_1/x1/bn (in-place)
I1211 15:05:37.478466 15749 layer_factory.hpp:77] Creating layer conv2_1/x1/scale
I1211 15:05:37.478739 15749 net.cpp:122] Setting up conv2_1/x1/scale
I1211 15:05:37.478749 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.478752 15749 net.cpp:137] Memory required for data: 217068240
I1211 15:05:37.478760 15749 layer_factory.hpp:77] Creating layer relu2_1/x1
I1211 15:05:37.478771 15749 net.cpp:84] Creating Layer relu2_1/x1
I1211 15:05:37.478776 15749 net.cpp:406] relu2_1/x1 <- conv2_1/x1/bn
I1211 15:05:37.478781 15749 net.cpp:367] relu2_1/x1 -> conv2_1/x1/bn (in-place)
I1211 15:05:37.479264 15749 net.cpp:122] Setting up relu2_1/x1
I1211 15:05:37.479277 15749 net.cpp:129] Top shape: 1 160 17 35 (95200)
I1211 15:05:37.479281 15749 net.cpp:137] Memory required for data: 217449040
I1211 15:05:37.479286 15749 layer_factory.hpp:77] Creating layer conv2_1/x1
I1211 15:05:37.479300 15749 net.cpp:84] Creating Layer conv2_1/x1
I1211 15:05:37.479305 15749 net.cpp:406] conv2_1/x1 <- conv2_1/x1/bn
I1211 15:05:37.479311 15749 net.cpp:380] conv2_1/x1 -> conv2_1/x1
I1211 15:05:37.481775 15749 net.cpp:122] Setting up conv2_1/x1
I1211 15:05:37.481792 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.481797 15749 net.cpp:137] Memory required for data: 217753680
I1211 15:05:37.481804 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/bn
I1211 15:05:37.481813 15749 net.cpp:84] Creating Layer conv2_1/x2/bn
I1211 15:05:37.481818 15749 net.cpp:406] conv2_1/x2/bn <- conv2_1/x1
I1211 15:05:37.481827 15749 net.cpp:380] conv2_1/x2/bn -> conv2_1/x2/bn
I1211 15:05:37.482255 15749 net.cpp:122] Setting up conv2_1/x2/bn
I1211 15:05:37.482265 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.482270 15749 net.cpp:137] Memory required for data: 218058320
I1211 15:05:37.482278 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/scale
I1211 15:05:37.482286 15749 net.cpp:84] Creating Layer conv2_1/x2/scale
I1211 15:05:37.482291 15749 net.cpp:406] conv2_1/x2/scale <- conv2_1/x2/bn
I1211 15:05:37.482303 15749 net.cpp:367] conv2_1/x2/scale -> conv2_1/x2/bn (in-place)
I1211 15:05:37.482378 15749 layer_factory.hpp:77] Creating layer conv2_1/x2/scale
I1211 15:05:37.482630 15749 net.cpp:122] Setting up conv2_1/x2/scale
I1211 15:05:37.482640 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.482645 15749 net.cpp:137] Memory required for data: 218362960
I1211 15:05:37.482651 15749 layer_factory.hpp:77] Creating layer relu2_1/x2
I1211 15:05:37.482658 15749 net.cpp:84] Creating Layer relu2_1/x2
I1211 15:05:37.482663 15749 net.cpp:406] relu2_1/x2 <- conv2_1/x2/bn
I1211 15:05:37.482668 15749 net.cpp:367] relu2_1/x2 -> conv2_1/x2/bn (in-place)
I1211 15:05:37.482944 15749 net.cpp:122] Setting up relu2_1/x2
I1211 15:05:37.482954 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.482959 15749 net.cpp:137] Memory required for data: 218667600
I1211 15:05:37.482962 15749 layer_factory.hpp:77] Creating layer conv2_1/x2
I1211 15:05:37.482975 15749 net.cpp:84] Creating Layer conv2_1/x2
I1211 15:05:37.482978 15749 net.cpp:406] conv2_1/x2 <- conv2_1/x2/bn
I1211 15:05:37.482985 15749 net.cpp:380] conv2_1/x2 -> conv2_1/x2
I1211 15:05:37.486199 15749 net.cpp:122] Setting up conv2_1/x2
I1211 15:05:37.486215 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.486219 15749 net.cpp:137] Memory required for data: 218743760
I1211 15:05:37.486227 15749 layer_factory.hpp:77] Creating layer concat2_1
I1211 15:05:37.486237 15749 net.cpp:84] Creating Layer concat2_1
I1211 15:05:37.486243 15749 net.cpp:406] concat2_1 <- concat2_0_concat2_0_0_split_1
I1211 15:05:37.486248 15749 net.cpp:406] concat2_1 <- conv2_1/x2
I1211 15:05:37.486254 15749 net.cpp:380] concat2_1 -> concat2_1
I1211 15:05:37.486307 15749 net.cpp:122] Setting up concat2_1
I1211 15:05:37.486316 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.486320 15749 net.cpp:137] Memory required for data: 219200720
I1211 15:05:37.486323 15749 layer_factory.hpp:77] Creating layer concat2_1_concat2_1_0_split
I1211 15:05:37.486330 15749 net.cpp:84] Creating Layer concat2_1_concat2_1_0_split
I1211 15:05:37.486335 15749 net.cpp:406] concat2_1_concat2_1_0_split <- concat2_1
I1211 15:05:37.486340 15749 net.cpp:380] concat2_1_concat2_1_0_split -> concat2_1_concat2_1_0_split_0
I1211 15:05:37.486347 15749 net.cpp:380] concat2_1_concat2_1_0_split -> concat2_1_concat2_1_0_split_1
I1211 15:05:37.486418 15749 net.cpp:122] Setting up concat2_1_concat2_1_0_split
I1211 15:05:37.486431 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.486436 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.486440 15749 net.cpp:137] Memory required for data: 220114640
I1211 15:05:37.486444 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/bn
I1211 15:05:37.486451 15749 net.cpp:84] Creating Layer conv2_2/x1/bn
I1211 15:05:37.486455 15749 net.cpp:406] conv2_2/x1/bn <- concat2_1_concat2_1_0_split_0
I1211 15:05:37.486462 15749 net.cpp:380] conv2_2/x1/bn -> conv2_2/x1/bn
I1211 15:05:37.486948 15749 net.cpp:122] Setting up conv2_2/x1/bn
I1211 15:05:37.486958 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.486963 15749 net.cpp:137] Memory required for data: 220571600
I1211 15:05:37.486971 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/scale
I1211 15:05:37.486982 15749 net.cpp:84] Creating Layer conv2_2/x1/scale
I1211 15:05:37.486987 15749 net.cpp:406] conv2_2/x1/scale <- conv2_2/x1/bn
I1211 15:05:37.486994 15749 net.cpp:367] conv2_2/x1/scale -> conv2_2/x1/bn (in-place)
I1211 15:05:37.487068 15749 layer_factory.hpp:77] Creating layer conv2_2/x1/scale
I1211 15:05:37.487350 15749 net.cpp:122] Setting up conv2_2/x1/scale
I1211 15:05:37.487360 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.487363 15749 net.cpp:137] Memory required for data: 221028560
I1211 15:05:37.487370 15749 layer_factory.hpp:77] Creating layer relu2_2/x1
I1211 15:05:37.487377 15749 net.cpp:84] Creating Layer relu2_2/x1
I1211 15:05:37.487382 15749 net.cpp:406] relu2_2/x1 <- conv2_2/x1/bn
I1211 15:05:37.487387 15749 net.cpp:367] relu2_2/x1 -> conv2_2/x1/bn (in-place)
I1211 15:05:37.488021 15749 net.cpp:122] Setting up relu2_2/x1
I1211 15:05:37.488035 15749 net.cpp:129] Top shape: 1 192 17 35 (114240)
I1211 15:05:37.488039 15749 net.cpp:137] Memory required for data: 221485520
I1211 15:05:37.488044 15749 layer_factory.hpp:77] Creating layer conv2_2/x1
I1211 15:05:37.488057 15749 net.cpp:84] Creating Layer conv2_2/x1
I1211 15:05:37.488062 15749 net.cpp:406] conv2_2/x1 <- conv2_2/x1/bn
I1211 15:05:37.488070 15749 net.cpp:380] conv2_2/x1 -> conv2_2/x1
I1211 15:05:37.490774 15749 net.cpp:122] Setting up conv2_2/x1
I1211 15:05:37.490792 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.490795 15749 net.cpp:137] Memory required for data: 221790160
I1211 15:05:37.490803 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/bn
I1211 15:05:37.490818 15749 net.cpp:84] Creating Layer conv2_2/x2/bn
I1211 15:05:37.490823 15749 net.cpp:406] conv2_2/x2/bn <- conv2_2/x1
I1211 15:05:37.490829 15749 net.cpp:380] conv2_2/x2/bn -> conv2_2/x2/bn
I1211 15:05:37.491274 15749 net.cpp:122] Setting up conv2_2/x2/bn
I1211 15:05:37.491286 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.491289 15749 net.cpp:137] Memory required for data: 222094800
I1211 15:05:37.491300 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/scale
I1211 15:05:37.491310 15749 net.cpp:84] Creating Layer conv2_2/x2/scale
I1211 15:05:37.491315 15749 net.cpp:406] conv2_2/x2/scale <- conv2_2/x2/bn
I1211 15:05:37.491322 15749 net.cpp:367] conv2_2/x2/scale -> conv2_2/x2/bn (in-place)
I1211 15:05:37.491395 15749 layer_factory.hpp:77] Creating layer conv2_2/x2/scale
I1211 15:05:37.491657 15749 net.cpp:122] Setting up conv2_2/x2/scale
I1211 15:05:37.491667 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.491670 15749 net.cpp:137] Memory required for data: 222399440
I1211 15:05:37.491677 15749 layer_factory.hpp:77] Creating layer relu2_2/x2
I1211 15:05:37.491685 15749 net.cpp:84] Creating Layer relu2_2/x2
I1211 15:05:37.491689 15749 net.cpp:406] relu2_2/x2 <- conv2_2/x2/bn
I1211 15:05:37.491695 15749 net.cpp:367] relu2_2/x2 -> conv2_2/x2/bn (in-place)
I1211 15:05:37.492270 15749 net.cpp:122] Setting up relu2_2/x2
I1211 15:05:37.492285 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.492288 15749 net.cpp:137] Memory required for data: 222704080
I1211 15:05:37.492292 15749 layer_factory.hpp:77] Creating layer conv2_2/x2
I1211 15:05:37.492312 15749 net.cpp:84] Creating Layer conv2_2/x2
I1211 15:05:37.492318 15749 net.cpp:406] conv2_2/x2 <- conv2_2/x2/bn
I1211 15:05:37.492326 15749 net.cpp:380] conv2_2/x2 -> conv2_2/x2
I1211 15:05:37.496372 15749 net.cpp:122] Setting up conv2_2/x2
I1211 15:05:37.496395 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.496400 15749 net.cpp:137] Memory required for data: 222780240
I1211 15:05:37.496408 15749 layer_factory.hpp:77] Creating layer concat2_2
I1211 15:05:37.496417 15749 net.cpp:84] Creating Layer concat2_2
I1211 15:05:37.496424 15749 net.cpp:406] concat2_2 <- concat2_1_concat2_1_0_split_1
I1211 15:05:37.496430 15749 net.cpp:406] concat2_2 <- conv2_2/x2
I1211 15:05:37.496438 15749 net.cpp:380] concat2_2 -> concat2_2
I1211 15:05:37.496492 15749 net.cpp:122] Setting up concat2_2
I1211 15:05:37.496500 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.496505 15749 net.cpp:137] Memory required for data: 223313360
I1211 15:05:37.496508 15749 layer_factory.hpp:77] Creating layer concat2_2_concat2_2_0_split
I1211 15:05:37.496516 15749 net.cpp:84] Creating Layer concat2_2_concat2_2_0_split
I1211 15:05:37.496520 15749 net.cpp:406] concat2_2_concat2_2_0_split <- concat2_2
I1211 15:05:37.496526 15749 net.cpp:380] concat2_2_concat2_2_0_split -> concat2_2_concat2_2_0_split_0
I1211 15:05:37.496533 15749 net.cpp:380] concat2_2_concat2_2_0_split -> concat2_2_concat2_2_0_split_1
I1211 15:05:37.496603 15749 net.cpp:122] Setting up concat2_2_concat2_2_0_split
I1211 15:05:37.496611 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.496616 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.496620 15749 net.cpp:137] Memory required for data: 224379600
I1211 15:05:37.496623 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/bn
I1211 15:05:37.496632 15749 net.cpp:84] Creating Layer conv2_3/x1/bn
I1211 15:05:37.496636 15749 net.cpp:406] conv2_3/x1/bn <- concat2_2_concat2_2_0_split_0
I1211 15:05:37.496642 15749 net.cpp:380] conv2_3/x1/bn -> conv2_3/x1/bn
I1211 15:05:37.497104 15749 net.cpp:122] Setting up conv2_3/x1/bn
I1211 15:05:37.497113 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.497117 15749 net.cpp:137] Memory required for data: 224912720
I1211 15:05:37.497126 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/scale
I1211 15:05:37.497136 15749 net.cpp:84] Creating Layer conv2_3/x1/scale
I1211 15:05:37.497141 15749 net.cpp:406] conv2_3/x1/scale <- conv2_3/x1/bn
I1211 15:05:37.497148 15749 net.cpp:367] conv2_3/x1/scale -> conv2_3/x1/bn (in-place)
I1211 15:05:37.497220 15749 layer_factory.hpp:77] Creating layer conv2_3/x1/scale
I1211 15:05:37.497500 15749 net.cpp:122] Setting up conv2_3/x1/scale
I1211 15:05:37.497510 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.497514 15749 net.cpp:137] Memory required for data: 225445840
I1211 15:05:37.497521 15749 layer_factory.hpp:77] Creating layer relu2_3/x1
I1211 15:05:37.497529 15749 net.cpp:84] Creating Layer relu2_3/x1
I1211 15:05:37.497534 15749 net.cpp:406] relu2_3/x1 <- conv2_3/x1/bn
I1211 15:05:37.497539 15749 net.cpp:367] relu2_3/x1 -> conv2_3/x1/bn (in-place)
I1211 15:05:37.497813 15749 net.cpp:122] Setting up relu2_3/x1
I1211 15:05:37.497823 15749 net.cpp:129] Top shape: 1 224 17 35 (133280)
I1211 15:05:37.497828 15749 net.cpp:137] Memory required for data: 225978960
I1211 15:05:37.497833 15749 layer_factory.hpp:77] Creating layer conv2_3/x1
I1211 15:05:37.497843 15749 net.cpp:84] Creating Layer conv2_3/x1
I1211 15:05:37.497848 15749 net.cpp:406] conv2_3/x1 <- conv2_3/x1/bn
I1211 15:05:37.497856 15749 net.cpp:380] conv2_3/x1 -> conv2_3/x1
I1211 15:05:37.500536 15749 net.cpp:122] Setting up conv2_3/x1
I1211 15:05:37.500551 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.500555 15749 net.cpp:137] Memory required for data: 226283600
I1211 15:05:37.500562 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/bn
I1211 15:05:37.500571 15749 net.cpp:84] Creating Layer conv2_3/x2/bn
I1211 15:05:37.500576 15749 net.cpp:406] conv2_3/x2/bn <- conv2_3/x1
I1211 15:05:37.500588 15749 net.cpp:380] conv2_3/x2/bn -> conv2_3/x2/bn
I1211 15:05:37.501018 15749 net.cpp:122] Setting up conv2_3/x2/bn
I1211 15:05:37.501026 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.501030 15749 net.cpp:137] Memory required for data: 226588240
I1211 15:05:37.501039 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/scale
I1211 15:05:37.501049 15749 net.cpp:84] Creating Layer conv2_3/x2/scale
I1211 15:05:37.501055 15749 net.cpp:406] conv2_3/x2/scale <- conv2_3/x2/bn
I1211 15:05:37.501061 15749 net.cpp:367] conv2_3/x2/scale -> conv2_3/x2/bn (in-place)
I1211 15:05:37.501134 15749 layer_factory.hpp:77] Creating layer conv2_3/x2/scale
I1211 15:05:37.501392 15749 net.cpp:122] Setting up conv2_3/x2/scale
I1211 15:05:37.501401 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.501405 15749 net.cpp:137] Memory required for data: 226892880
I1211 15:05:37.501412 15749 layer_factory.hpp:77] Creating layer relu2_3/x2
I1211 15:05:37.501420 15749 net.cpp:84] Creating Layer relu2_3/x2
I1211 15:05:37.501423 15749 net.cpp:406] relu2_3/x2 <- conv2_3/x2/bn
I1211 15:05:37.501430 15749 net.cpp:367] relu2_3/x2 -> conv2_3/x2/bn (in-place)
I1211 15:05:37.501919 15749 net.cpp:122] Setting up relu2_3/x2
I1211 15:05:37.501932 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.501936 15749 net.cpp:137] Memory required for data: 227197520
I1211 15:05:37.501940 15749 layer_factory.hpp:77] Creating layer conv2_3/x2
I1211 15:05:37.501953 15749 net.cpp:84] Creating Layer conv2_3/x2
I1211 15:05:37.501957 15749 net.cpp:406] conv2_3/x2 <- conv2_3/x2/bn
I1211 15:05:37.501965 15749 net.cpp:380] conv2_3/x2 -> conv2_3/x2
I1211 15:05:37.505115 15749 net.cpp:122] Setting up conv2_3/x2
I1211 15:05:37.505127 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.505131 15749 net.cpp:137] Memory required for data: 227273680
I1211 15:05:37.505138 15749 layer_factory.hpp:77] Creating layer concat2_3
I1211 15:05:37.505147 15749 net.cpp:84] Creating Layer concat2_3
I1211 15:05:37.505152 15749 net.cpp:406] concat2_3 <- concat2_2_concat2_2_0_split_1
I1211 15:05:37.505158 15749 net.cpp:406] concat2_3 <- conv2_3/x2
I1211 15:05:37.505164 15749 net.cpp:380] concat2_3 -> concat2_3
I1211 15:05:37.505218 15749 net.cpp:122] Setting up concat2_3
I1211 15:05:37.505226 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.505229 15749 net.cpp:137] Memory required for data: 227882960
I1211 15:05:37.505234 15749 layer_factory.hpp:77] Creating layer concat2_3_concat2_3_0_split
I1211 15:05:37.505240 15749 net.cpp:84] Creating Layer concat2_3_concat2_3_0_split
I1211 15:05:37.505244 15749 net.cpp:406] concat2_3_concat2_3_0_split <- concat2_3
I1211 15:05:37.505251 15749 net.cpp:380] concat2_3_concat2_3_0_split -> concat2_3_concat2_3_0_split_0
I1211 15:05:37.505259 15749 net.cpp:380] concat2_3_concat2_3_0_split -> concat2_3_concat2_3_0_split_1
I1211 15:05:37.505327 15749 net.cpp:122] Setting up concat2_3_concat2_3_0_split
I1211 15:05:37.505336 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.505340 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.505344 15749 net.cpp:137] Memory required for data: 229101520
I1211 15:05:37.505347 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/bn
I1211 15:05:37.505355 15749 net.cpp:84] Creating Layer conv2_4/x1/bn
I1211 15:05:37.505359 15749 net.cpp:406] conv2_4/x1/bn <- concat2_3_concat2_3_0_split_0
I1211 15:05:37.505367 15749 net.cpp:380] conv2_4/x1/bn -> conv2_4/x1/bn
I1211 15:05:37.505796 15749 net.cpp:122] Setting up conv2_4/x1/bn
I1211 15:05:37.505805 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.505810 15749 net.cpp:137] Memory required for data: 229710800
I1211 15:05:37.505820 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/scale
I1211 15:05:37.505828 15749 net.cpp:84] Creating Layer conv2_4/x1/scale
I1211 15:05:37.505832 15749 net.cpp:406] conv2_4/x1/scale <- conv2_4/x1/bn
I1211 15:05:37.505839 15749 net.cpp:367] conv2_4/x1/scale -> conv2_4/x1/bn (in-place)
I1211 15:05:37.505913 15749 layer_factory.hpp:77] Creating layer conv2_4/x1/scale
I1211 15:05:37.506176 15749 net.cpp:122] Setting up conv2_4/x1/scale
I1211 15:05:37.506186 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.506191 15749 net.cpp:137] Memory required for data: 230320080
I1211 15:05:37.506197 15749 layer_factory.hpp:77] Creating layer relu2_4/x1
I1211 15:05:37.506206 15749 net.cpp:84] Creating Layer relu2_4/x1
I1211 15:05:37.506209 15749 net.cpp:406] relu2_4/x1 <- conv2_4/x1/bn
I1211 15:05:37.506216 15749 net.cpp:367] relu2_4/x1 -> conv2_4/x1/bn (in-place)
I1211 15:05:37.506494 15749 net.cpp:122] Setting up relu2_4/x1
I1211 15:05:37.506505 15749 net.cpp:129] Top shape: 1 256 17 35 (152320)
I1211 15:05:37.506508 15749 net.cpp:137] Memory required for data: 230929360
I1211 15:05:37.506512 15749 layer_factory.hpp:77] Creating layer conv2_4/x1
I1211 15:05:37.506525 15749 net.cpp:84] Creating Layer conv2_4/x1
I1211 15:05:37.506530 15749 net.cpp:406] conv2_4/x1 <- conv2_4/x1/bn
I1211 15:05:37.506536 15749 net.cpp:380] conv2_4/x1 -> conv2_4/x1
I1211 15:05:37.509663 15749 net.cpp:122] Setting up conv2_4/x1
I1211 15:05:37.509697 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.509702 15749 net.cpp:137] Memory required for data: 231234000
I1211 15:05:37.509712 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/bn
I1211 15:05:37.509726 15749 net.cpp:84] Creating Layer conv2_4/x2/bn
I1211 15:05:37.509732 15749 net.cpp:406] conv2_4/x2/bn <- conv2_4/x1
I1211 15:05:37.509740 15749 net.cpp:380] conv2_4/x2/bn -> conv2_4/x2/bn
I1211 15:05:37.510212 15749 net.cpp:122] Setting up conv2_4/x2/bn
I1211 15:05:37.510223 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.510226 15749 net.cpp:137] Memory required for data: 231538640
I1211 15:05:37.510236 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/scale
I1211 15:05:37.510248 15749 net.cpp:84] Creating Layer conv2_4/x2/scale
I1211 15:05:37.510252 15749 net.cpp:406] conv2_4/x2/scale <- conv2_4/x2/bn
I1211 15:05:37.510258 15749 net.cpp:367] conv2_4/x2/scale -> conv2_4/x2/bn (in-place)
I1211 15:05:37.510334 15749 layer_factory.hpp:77] Creating layer conv2_4/x2/scale
I1211 15:05:37.510596 15749 net.cpp:122] Setting up conv2_4/x2/scale
I1211 15:05:37.510604 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.510608 15749 net.cpp:137] Memory required for data: 231843280
I1211 15:05:37.510617 15749 layer_factory.hpp:77] Creating layer relu2_4/x2
I1211 15:05:37.510624 15749 net.cpp:84] Creating Layer relu2_4/x2
I1211 15:05:37.510629 15749 net.cpp:406] relu2_4/x2 <- conv2_4/x2/bn
I1211 15:05:37.510634 15749 net.cpp:367] relu2_4/x2 -> conv2_4/x2/bn (in-place)
I1211 15:05:37.511510 15749 net.cpp:122] Setting up relu2_4/x2
I1211 15:05:37.511536 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.511540 15749 net.cpp:137] Memory required for data: 232147920
I1211 15:05:37.511548 15749 layer_factory.hpp:77] Creating layer conv2_4/x2
I1211 15:05:37.511564 15749 net.cpp:84] Creating Layer conv2_4/x2
I1211 15:05:37.511569 15749 net.cpp:406] conv2_4/x2 <- conv2_4/x2/bn
I1211 15:05:37.511577 15749 net.cpp:380] conv2_4/x2 -> conv2_4/x2
I1211 15:05:37.515305 15749 net.cpp:122] Setting up conv2_4/x2
I1211 15:05:37.515339 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.515344 15749 net.cpp:137] Memory required for data: 232224080
I1211 15:05:37.515354 15749 layer_factory.hpp:77] Creating layer concat2_4
I1211 15:05:37.515367 15749 net.cpp:84] Creating Layer concat2_4
I1211 15:05:37.515373 15749 net.cpp:406] concat2_4 <- concat2_3_concat2_3_0_split_1
I1211 15:05:37.515381 15749 net.cpp:406] concat2_4 <- conv2_4/x2
I1211 15:05:37.515389 15749 net.cpp:380] concat2_4 -> concat2_4
I1211 15:05:37.515445 15749 net.cpp:122] Setting up concat2_4
I1211 15:05:37.515453 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.515457 15749 net.cpp:137] Memory required for data: 232909520
I1211 15:05:37.515461 15749 layer_factory.hpp:77] Creating layer concat2_4_concat2_4_0_split
I1211 15:05:37.515468 15749 net.cpp:84] Creating Layer concat2_4_concat2_4_0_split
I1211 15:05:37.515477 15749 net.cpp:406] concat2_4_concat2_4_0_split <- concat2_4
I1211 15:05:37.515485 15749 net.cpp:380] concat2_4_concat2_4_0_split -> concat2_4_concat2_4_0_split_0
I1211 15:05:37.515492 15749 net.cpp:380] concat2_4_concat2_4_0_split -> concat2_4_concat2_4_0_split_1
I1211 15:05:37.515566 15749 net.cpp:122] Setting up concat2_4_concat2_4_0_split
I1211 15:05:37.515574 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.515579 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.515583 15749 net.cpp:137] Memory required for data: 234280400
I1211 15:05:37.515588 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/bn
I1211 15:05:37.515595 15749 net.cpp:84] Creating Layer conv2_5/x1/bn
I1211 15:05:37.515599 15749 net.cpp:406] conv2_5/x1/bn <- concat2_4_concat2_4_0_split_0
I1211 15:05:37.515605 15749 net.cpp:380] conv2_5/x1/bn -> conv2_5/x1/bn
I1211 15:05:37.516152 15749 net.cpp:122] Setting up conv2_5/x1/bn
I1211 15:05:37.516161 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.516165 15749 net.cpp:137] Memory required for data: 234965840
I1211 15:05:37.516175 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/scale
I1211 15:05:37.516185 15749 net.cpp:84] Creating Layer conv2_5/x1/scale
I1211 15:05:37.516191 15749 net.cpp:406] conv2_5/x1/scale <- conv2_5/x1/bn
I1211 15:05:37.516196 15749 net.cpp:367] conv2_5/x1/scale -> conv2_5/x1/bn (in-place)
I1211 15:05:37.516296 15749 layer_factory.hpp:77] Creating layer conv2_5/x1/scale
I1211 15:05:37.516608 15749 net.cpp:122] Setting up conv2_5/x1/scale
I1211 15:05:37.516618 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.516623 15749 net.cpp:137] Memory required for data: 235651280
I1211 15:05:37.516629 15749 layer_factory.hpp:77] Creating layer relu2_5/x1
I1211 15:05:37.516638 15749 net.cpp:84] Creating Layer relu2_5/x1
I1211 15:05:37.516641 15749 net.cpp:406] relu2_5/x1 <- conv2_5/x1/bn
I1211 15:05:37.516647 15749 net.cpp:367] relu2_5/x1 -> conv2_5/x1/bn (in-place)
I1211 15:05:37.517165 15749 net.cpp:122] Setting up relu2_5/x1
I1211 15:05:37.517179 15749 net.cpp:129] Top shape: 1 288 17 35 (171360)
I1211 15:05:37.517182 15749 net.cpp:137] Memory required for data: 236336720
I1211 15:05:37.517187 15749 layer_factory.hpp:77] Creating layer conv2_5/x1
I1211 15:05:37.517200 15749 net.cpp:84] Creating Layer conv2_5/x1
I1211 15:05:37.517205 15749 net.cpp:406] conv2_5/x1 <- conv2_5/x1/bn
I1211 15:05:37.517213 15749 net.cpp:380] conv2_5/x1 -> conv2_5/x1
I1211 15:05:37.520246 15749 net.cpp:122] Setting up conv2_5/x1
I1211 15:05:37.520262 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.520267 15749 net.cpp:137] Memory required for data: 236641360
I1211 15:05:37.520273 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/bn
I1211 15:05:37.520283 15749 net.cpp:84] Creating Layer conv2_5/x2/bn
I1211 15:05:37.520288 15749 net.cpp:406] conv2_5/x2/bn <- conv2_5/x1
I1211 15:05:37.520295 15749 net.cpp:380] conv2_5/x2/bn -> conv2_5/x2/bn
I1211 15:05:37.520762 15749 net.cpp:122] Setting up conv2_5/x2/bn
I1211 15:05:37.520774 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.520778 15749 net.cpp:137] Memory required for data: 236946000
I1211 15:05:37.520787 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/scale
I1211 15:05:37.520797 15749 net.cpp:84] Creating Layer conv2_5/x2/scale
I1211 15:05:37.520802 15749 net.cpp:406] conv2_5/x2/scale <- conv2_5/x2/bn
I1211 15:05:37.520808 15749 net.cpp:367] conv2_5/x2/scale -> conv2_5/x2/bn (in-place)
I1211 15:05:37.520889 15749 layer_factory.hpp:77] Creating layer conv2_5/x2/scale
I1211 15:05:37.521165 15749 net.cpp:122] Setting up conv2_5/x2/scale
I1211 15:05:37.521174 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.521178 15749 net.cpp:137] Memory required for data: 237250640
I1211 15:05:37.521185 15749 layer_factory.hpp:77] Creating layer relu2_5/x2
I1211 15:05:37.521193 15749 net.cpp:84] Creating Layer relu2_5/x2
I1211 15:05:37.521198 15749 net.cpp:406] relu2_5/x2 <- conv2_5/x2/bn
I1211 15:05:37.521203 15749 net.cpp:367] relu2_5/x2 -> conv2_5/x2/bn (in-place)
I1211 15:05:37.521494 15749 net.cpp:122] Setting up relu2_5/x2
I1211 15:05:37.521505 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.521510 15749 net.cpp:137] Memory required for data: 237555280
I1211 15:05:37.521514 15749 layer_factory.hpp:77] Creating layer conv2_5/x2
I1211 15:05:37.521526 15749 net.cpp:84] Creating Layer conv2_5/x2
I1211 15:05:37.521531 15749 net.cpp:406] conv2_5/x2 <- conv2_5/x2/bn
I1211 15:05:37.521539 15749 net.cpp:380] conv2_5/x2 -> conv2_5/x2
I1211 15:05:37.524966 15749 net.cpp:122] Setting up conv2_5/x2
I1211 15:05:37.524993 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.524998 15749 net.cpp:137] Memory required for data: 237631440
I1211 15:05:37.525008 15749 layer_factory.hpp:77] Creating layer concat2_5
I1211 15:05:37.525019 15749 net.cpp:84] Creating Layer concat2_5
I1211 15:05:37.525027 15749 net.cpp:406] concat2_5 <- concat2_4_concat2_4_0_split_1
I1211 15:05:37.525033 15749 net.cpp:406] concat2_5 <- conv2_5/x2
I1211 15:05:37.525043 15749 net.cpp:380] concat2_5 -> concat2_5
I1211 15:05:37.525099 15749 net.cpp:122] Setting up concat2_5
I1211 15:05:37.525108 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.525112 15749 net.cpp:137] Memory required for data: 238393040
I1211 15:05:37.525116 15749 layer_factory.hpp:77] Creating layer concat2_5_concat2_5_0_split
I1211 15:05:37.525123 15749 net.cpp:84] Creating Layer concat2_5_concat2_5_0_split
I1211 15:05:37.525127 15749 net.cpp:406] concat2_5_concat2_5_0_split <- concat2_5
I1211 15:05:37.525135 15749 net.cpp:380] concat2_5_concat2_5_0_split -> concat2_5_concat2_5_0_split_0
I1211 15:05:37.525142 15749 net.cpp:380] concat2_5_concat2_5_0_split -> concat2_5_concat2_5_0_split_1
I1211 15:05:37.525215 15749 net.cpp:122] Setting up concat2_5_concat2_5_0_split
I1211 15:05:37.525223 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.525228 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.525233 15749 net.cpp:137] Memory required for data: 239916240
I1211 15:05:37.525236 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/bn
I1211 15:05:37.525245 15749 net.cpp:84] Creating Layer conv2_6/x1/bn
I1211 15:05:37.525250 15749 net.cpp:406] conv2_6/x1/bn <- concat2_5_concat2_5_0_split_0
I1211 15:05:37.525256 15749 net.cpp:380] conv2_6/x1/bn -> conv2_6/x1/bn
I1211 15:05:37.525806 15749 net.cpp:122] Setting up conv2_6/x1/bn
I1211 15:05:37.525818 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.525821 15749 net.cpp:137] Memory required for data: 240677840
I1211 15:05:37.525832 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/scale
I1211 15:05:37.525842 15749 net.cpp:84] Creating Layer conv2_6/x1/scale
I1211 15:05:37.525847 15749 net.cpp:406] conv2_6/x1/scale <- conv2_6/x1/bn
I1211 15:05:37.525854 15749 net.cpp:367] conv2_6/x1/scale -> conv2_6/x1/bn (in-place)
I1211 15:05:37.525964 15749 layer_factory.hpp:77] Creating layer conv2_6/x1/scale
I1211 15:05:37.526283 15749 net.cpp:122] Setting up conv2_6/x1/scale
I1211 15:05:37.526293 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.526298 15749 net.cpp:137] Memory required for data: 241439440
I1211 15:05:37.526304 15749 layer_factory.hpp:77] Creating layer relu2_6/x1
I1211 15:05:37.526314 15749 net.cpp:84] Creating Layer relu2_6/x1
I1211 15:05:37.526319 15749 net.cpp:406] relu2_6/x1 <- conv2_6/x1/bn
I1211 15:05:37.526324 15749 net.cpp:367] relu2_6/x1 -> conv2_6/x1/bn (in-place)
I1211 15:05:37.526973 15749 net.cpp:122] Setting up relu2_6/x1
I1211 15:05:37.526988 15749 net.cpp:129] Top shape: 1 320 17 35 (190400)
I1211 15:05:37.526991 15749 net.cpp:137] Memory required for data: 242201040
I1211 15:05:37.526996 15749 layer_factory.hpp:77] Creating layer conv2_6/x1
I1211 15:05:37.527009 15749 net.cpp:84] Creating Layer conv2_6/x1
I1211 15:05:37.527014 15749 net.cpp:406] conv2_6/x1 <- conv2_6/x1/bn
I1211 15:05:37.527024 15749 net.cpp:380] conv2_6/x1 -> conv2_6/x1
I1211 15:05:37.530966 15749 net.cpp:122] Setting up conv2_6/x1
I1211 15:05:37.530992 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.531000 15749 net.cpp:137] Memory required for data: 242505680
I1211 15:05:37.531009 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/bn
I1211 15:05:37.531019 15749 net.cpp:84] Creating Layer conv2_6/x2/bn
I1211 15:05:37.531024 15749 net.cpp:406] conv2_6/x2/bn <- conv2_6/x1
I1211 15:05:37.531033 15749 net.cpp:380] conv2_6/x2/bn -> conv2_6/x2/bn
I1211 15:05:37.531507 15749 net.cpp:122] Setting up conv2_6/x2/bn
I1211 15:05:37.531517 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.531522 15749 net.cpp:137] Memory required for data: 242810320
I1211 15:05:37.531532 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/scale
I1211 15:05:37.531541 15749 net.cpp:84] Creating Layer conv2_6/x2/scale
I1211 15:05:37.531545 15749 net.cpp:406] conv2_6/x2/scale <- conv2_6/x2/bn
I1211 15:05:37.531553 15749 net.cpp:367] conv2_6/x2/scale -> conv2_6/x2/bn (in-place)
I1211 15:05:37.531632 15749 layer_factory.hpp:77] Creating layer conv2_6/x2/scale
I1211 15:05:37.531919 15749 net.cpp:122] Setting up conv2_6/x2/scale
I1211 15:05:37.531930 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.531934 15749 net.cpp:137] Memory required for data: 243114960
I1211 15:05:37.531942 15749 layer_factory.hpp:77] Creating layer relu2_6/x2
I1211 15:05:37.531949 15749 net.cpp:84] Creating Layer relu2_6/x2
I1211 15:05:37.531955 15749 net.cpp:406] relu2_6/x2 <- conv2_6/x2/bn
I1211 15:05:37.531960 15749 net.cpp:367] relu2_6/x2 -> conv2_6/x2/bn (in-place)
I1211 15:05:37.532259 15749 net.cpp:122] Setting up relu2_6/x2
I1211 15:05:37.532270 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.532274 15749 net.cpp:137] Memory required for data: 243419600
I1211 15:05:37.532279 15749 layer_factory.hpp:77] Creating layer conv2_6/x2
I1211 15:05:37.532291 15749 net.cpp:84] Creating Layer conv2_6/x2
I1211 15:05:37.532295 15749 net.cpp:406] conv2_6/x2 <- conv2_6/x2/bn
I1211 15:05:37.532302 15749 net.cpp:380] conv2_6/x2 -> conv2_6/x2
I1211 15:05:37.544297 15749 net.cpp:122] Setting up conv2_6/x2
I1211 15:05:37.544335 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.544340 15749 net.cpp:137] Memory required for data: 243495760
I1211 15:05:37.544351 15749 layer_factory.hpp:77] Creating layer concat2_6
I1211 15:05:37.544366 15749 net.cpp:84] Creating Layer concat2_6
I1211 15:05:37.544374 15749 net.cpp:406] concat2_6 <- concat2_5_concat2_5_0_split_1
I1211 15:05:37.544384 15749 net.cpp:406] concat2_6 <- conv2_6/x2
I1211 15:05:37.544390 15749 net.cpp:380] concat2_6 -> concat2_6
I1211 15:05:37.544472 15749 net.cpp:122] Setting up concat2_6
I1211 15:05:37.544481 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.544486 15749 net.cpp:137] Memory required for data: 244333520
I1211 15:05:37.544489 15749 layer_factory.hpp:77] Creating layer concat2_6_concat2_6_0_split
I1211 15:05:37.544497 15749 net.cpp:84] Creating Layer concat2_6_concat2_6_0_split
I1211 15:05:37.544502 15749 net.cpp:406] concat2_6_concat2_6_0_split <- concat2_6
I1211 15:05:37.544507 15749 net.cpp:380] concat2_6_concat2_6_0_split -> concat2_6_concat2_6_0_split_0
I1211 15:05:37.544514 15749 net.cpp:380] concat2_6_concat2_6_0_split -> concat2_6_concat2_6_0_split_1
I1211 15:05:37.544596 15749 net.cpp:122] Setting up concat2_6_concat2_6_0_split
I1211 15:05:37.544605 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.544610 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.544613 15749 net.cpp:137] Memory required for data: 246009040
I1211 15:05:37.544616 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/bn
I1211 15:05:37.544625 15749 net.cpp:84] Creating Layer conv2_7/x1/bn
I1211 15:05:37.544631 15749 net.cpp:406] conv2_7/x1/bn <- concat2_6_concat2_6_0_split_0
I1211 15:05:37.544636 15749 net.cpp:380] conv2_7/x1/bn -> conv2_7/x1/bn
I1211 15:05:37.545265 15749 net.cpp:122] Setting up conv2_7/x1/bn
I1211 15:05:37.545286 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.545290 15749 net.cpp:137] Memory required for data: 246846800
I1211 15:05:37.545310 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/scale
I1211 15:05:37.545322 15749 net.cpp:84] Creating Layer conv2_7/x1/scale
I1211 15:05:37.545328 15749 net.cpp:406] conv2_7/x1/scale <- conv2_7/x1/bn
I1211 15:05:37.545336 15749 net.cpp:367] conv2_7/x1/scale -> conv2_7/x1/bn (in-place)
I1211 15:05:37.545464 15749 layer_factory.hpp:77] Creating layer conv2_7/x1/scale
I1211 15:05:37.545821 15749 net.cpp:122] Setting up conv2_7/x1/scale
I1211 15:05:37.545835 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.545838 15749 net.cpp:137] Memory required for data: 247684560
I1211 15:05:37.545847 15749 layer_factory.hpp:77] Creating layer relu2_7/x1
I1211 15:05:37.545856 15749 net.cpp:84] Creating Layer relu2_7/x1
I1211 15:05:37.545862 15749 net.cpp:406] relu2_7/x1 <- conv2_7/x1/bn
I1211 15:05:37.545867 15749 net.cpp:367] relu2_7/x1 -> conv2_7/x1/bn (in-place)
I1211 15:05:37.546674 15749 net.cpp:122] Setting up relu2_7/x1
I1211 15:05:37.546710 15749 net.cpp:129] Top shape: 1 352 17 35 (209440)
I1211 15:05:37.546713 15749 net.cpp:137] Memory required for data: 248522320
I1211 15:05:37.546720 15749 layer_factory.hpp:77] Creating layer conv2_7/x1
I1211 15:05:37.546741 15749 net.cpp:84] Creating Layer conv2_7/x1
I1211 15:05:37.546747 15749 net.cpp:406] conv2_7/x1 <- conv2_7/x1/bn
I1211 15:05:37.546758 15749 net.cpp:380] conv2_7/x1 -> conv2_7/x1
I1211 15:05:37.609400 15749 net.cpp:122] Setting up conv2_7/x1
I1211 15:05:37.609433 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.609437 15749 net.cpp:137] Memory required for data: 248826960
I1211 15:05:37.609447 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/bn
I1211 15:05:37.609459 15749 net.cpp:84] Creating Layer conv2_7/x2/bn
I1211 15:05:37.609467 15749 net.cpp:406] conv2_7/x2/bn <- conv2_7/x1
I1211 15:05:37.609474 15749 net.cpp:380] conv2_7/x2/bn -> conv2_7/x2/bn
I1211 15:05:37.609971 15749 net.cpp:122] Setting up conv2_7/x2/bn
I1211 15:05:37.609979 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.609983 15749 net.cpp:137] Memory required for data: 249131600
I1211 15:05:37.609993 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/scale
I1211 15:05:37.610003 15749 net.cpp:84] Creating Layer conv2_7/x2/scale
I1211 15:05:37.610008 15749 net.cpp:406] conv2_7/x2/scale <- conv2_7/x2/bn
I1211 15:05:37.610013 15749 net.cpp:367] conv2_7/x2/scale -> conv2_7/x2/bn (in-place)
I1211 15:05:37.610095 15749 layer_factory.hpp:77] Creating layer conv2_7/x2/scale
I1211 15:05:37.610376 15749 net.cpp:122] Setting up conv2_7/x2/scale
I1211 15:05:37.610386 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.610390 15749 net.cpp:137] Memory required for data: 249436240
I1211 15:05:37.610397 15749 layer_factory.hpp:77] Creating layer relu2_7/x2
I1211 15:05:37.610404 15749 net.cpp:84] Creating Layer relu2_7/x2
I1211 15:05:37.610409 15749 net.cpp:406] relu2_7/x2 <- conv2_7/x2/bn
I1211 15:05:37.610415 15749 net.cpp:367] relu2_7/x2 -> conv2_7/x2/bn (in-place)
I1211 15:05:37.610918 15749 net.cpp:122] Setting up relu2_7/x2
I1211 15:05:37.610931 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.610935 15749 net.cpp:137] Memory required for data: 249740880
I1211 15:05:37.610940 15749 layer_factory.hpp:77] Creating layer conv2_7/x2
I1211 15:05:37.610952 15749 net.cpp:84] Creating Layer conv2_7/x2
I1211 15:05:37.610958 15749 net.cpp:406] conv2_7/x2 <- conv2_7/x2/bn
I1211 15:05:37.610966 15749 net.cpp:380] conv2_7/x2 -> conv2_7/x2
I1211 15:05:37.617755 15749 net.cpp:122] Setting up conv2_7/x2
I1211 15:05:37.617790 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.617795 15749 net.cpp:137] Memory required for data: 249817040
I1211 15:05:37.617805 15749 layer_factory.hpp:77] Creating layer concat2_7
I1211 15:05:37.617818 15749 net.cpp:84] Creating Layer concat2_7
I1211 15:05:37.617825 15749 net.cpp:406] concat2_7 <- concat2_6_concat2_6_0_split_1
I1211 15:05:37.617832 15749 net.cpp:406] concat2_7 <- conv2_7/x2
I1211 15:05:37.617841 15749 net.cpp:380] concat2_7 -> concat2_7
I1211 15:05:37.617900 15749 net.cpp:122] Setting up concat2_7
I1211 15:05:37.617913 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.617918 15749 net.cpp:137] Memory required for data: 250730960
I1211 15:05:37.617921 15749 layer_factory.hpp:77] Creating layer concat2_7_concat2_7_0_split
I1211 15:05:37.617929 15749 net.cpp:84] Creating Layer concat2_7_concat2_7_0_split
I1211 15:05:37.617934 15749 net.cpp:406] concat2_7_concat2_7_0_split <- concat2_7
I1211 15:05:37.617940 15749 net.cpp:380] concat2_7_concat2_7_0_split -> concat2_7_concat2_7_0_split_0
I1211 15:05:37.617947 15749 net.cpp:380] concat2_7_concat2_7_0_split -> concat2_7_concat2_7_0_split_1
I1211 15:05:37.618023 15749 net.cpp:122] Setting up concat2_7_concat2_7_0_split
I1211 15:05:37.618031 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.618036 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.618039 15749 net.cpp:137] Memory required for data: 252558800
I1211 15:05:37.618043 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/bn
I1211 15:05:37.618052 15749 net.cpp:84] Creating Layer conv2_8/x1/bn
I1211 15:05:37.618057 15749 net.cpp:406] conv2_8/x1/bn <- concat2_7_concat2_7_0_split_0
I1211 15:05:37.618063 15749 net.cpp:380] conv2_8/x1/bn -> conv2_8/x1/bn
I1211 15:05:37.618589 15749 net.cpp:122] Setting up conv2_8/x1/bn
I1211 15:05:37.618598 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.618602 15749 net.cpp:137] Memory required for data: 253472720
I1211 15:05:37.618611 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/scale
I1211 15:05:37.618621 15749 net.cpp:84] Creating Layer conv2_8/x1/scale
I1211 15:05:37.618625 15749 net.cpp:406] conv2_8/x1/scale <- conv2_8/x1/bn
I1211 15:05:37.618633 15749 net.cpp:367] conv2_8/x1/scale -> conv2_8/x1/bn (in-place)
I1211 15:05:37.618737 15749 layer_factory.hpp:77] Creating layer conv2_8/x1/scale
I1211 15:05:37.619132 15749 net.cpp:122] Setting up conv2_8/x1/scale
I1211 15:05:37.619143 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.619148 15749 net.cpp:137] Memory required for data: 254386640
I1211 15:05:37.619154 15749 layer_factory.hpp:77] Creating layer relu2_8/x1
I1211 15:05:37.619163 15749 net.cpp:84] Creating Layer relu2_8/x1
I1211 15:05:37.619166 15749 net.cpp:406] relu2_8/x1 <- conv2_8/x1/bn
I1211 15:05:37.619174 15749 net.cpp:367] relu2_8/x1 -> conv2_8/x1/bn (in-place)
I1211 15:05:37.619451 15749 net.cpp:122] Setting up relu2_8/x1
I1211 15:05:37.619462 15749 net.cpp:129] Top shape: 1 384 17 35 (228480)
I1211 15:05:37.619465 15749 net.cpp:137] Memory required for data: 255300560
I1211 15:05:37.619469 15749 layer_factory.hpp:77] Creating layer conv2_8/x1
I1211 15:05:37.619482 15749 net.cpp:84] Creating Layer conv2_8/x1
I1211 15:05:37.619487 15749 net.cpp:406] conv2_8/x1 <- conv2_8/x1/bn
I1211 15:05:37.619494 15749 net.cpp:380] conv2_8/x1 -> conv2_8/x1
I1211 15:05:37.623396 15749 net.cpp:122] Setting up conv2_8/x1
I1211 15:05:37.623435 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.623440 15749 net.cpp:137] Memory required for data: 255605200
I1211 15:05:37.623451 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/bn
I1211 15:05:37.623464 15749 net.cpp:84] Creating Layer conv2_8/x2/bn
I1211 15:05:37.623471 15749 net.cpp:406] conv2_8/x2/bn <- conv2_8/x1
I1211 15:05:37.623482 15749 net.cpp:380] conv2_8/x2/bn -> conv2_8/x2/bn
I1211 15:05:37.624017 15749 net.cpp:122] Setting up conv2_8/x2/bn
I1211 15:05:37.624033 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.624037 15749 net.cpp:137] Memory required for data: 255909840
I1211 15:05:37.624049 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/scale
I1211 15:05:37.624060 15749 net.cpp:84] Creating Layer conv2_8/x2/scale
I1211 15:05:37.624065 15749 net.cpp:406] conv2_8/x2/scale <- conv2_8/x2/bn
I1211 15:05:37.624079 15749 net.cpp:367] conv2_8/x2/scale -> conv2_8/x2/bn (in-place)
I1211 15:05:37.624163 15749 layer_factory.hpp:77] Creating layer conv2_8/x2/scale
I1211 15:05:37.624442 15749 net.cpp:122] Setting up conv2_8/x2/scale
I1211 15:05:37.624452 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.624460 15749 net.cpp:137] Memory required for data: 256214480
I1211 15:05:37.624469 15749 layer_factory.hpp:77] Creating layer relu2_8/x2
I1211 15:05:37.624476 15749 net.cpp:84] Creating Layer relu2_8/x2
I1211 15:05:37.624480 15749 net.cpp:406] relu2_8/x2 <- conv2_8/x2/bn
I1211 15:05:37.624486 15749 net.cpp:367] relu2_8/x2 -> conv2_8/x2/bn (in-place)
I1211 15:05:37.625161 15749 net.cpp:122] Setting up relu2_8/x2
I1211 15:05:37.625176 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.625180 15749 net.cpp:137] Memory required for data: 256519120
I1211 15:05:37.625185 15749 layer_factory.hpp:77] Creating layer conv2_8/x2
I1211 15:05:37.625198 15749 net.cpp:84] Creating Layer conv2_8/x2
I1211 15:05:37.625203 15749 net.cpp:406] conv2_8/x2 <- conv2_8/x2/bn
I1211 15:05:37.625211 15749 net.cpp:380] conv2_8/x2 -> conv2_8/x2
I1211 15:05:37.628547 15749 net.cpp:122] Setting up conv2_8/x2
I1211 15:05:37.628567 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.628571 15749 net.cpp:137] Memory required for data: 256595280
I1211 15:05:37.628581 15749 layer_factory.hpp:77] Creating layer concat2_8
I1211 15:05:37.628590 15749 net.cpp:84] Creating Layer concat2_8
I1211 15:05:37.628597 15749 net.cpp:406] concat2_8 <- concat2_7_concat2_7_0_split_1
I1211 15:05:37.628603 15749 net.cpp:406] concat2_8 <- conv2_8/x2
I1211 15:05:37.628609 15749 net.cpp:380] concat2_8 -> concat2_8
I1211 15:05:37.628666 15749 net.cpp:122] Setting up concat2_8
I1211 15:05:37.628674 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.628679 15749 net.cpp:137] Memory required for data: 257585360
I1211 15:05:37.628682 15749 layer_factory.hpp:77] Creating layer concat2_8_concat2_8_0_split
I1211 15:05:37.628690 15749 net.cpp:84] Creating Layer concat2_8_concat2_8_0_split
I1211 15:05:37.628693 15749 net.cpp:406] concat2_8_concat2_8_0_split <- concat2_8
I1211 15:05:37.628701 15749 net.cpp:380] concat2_8_concat2_8_0_split -> concat2_8_concat2_8_0_split_0
I1211 15:05:37.628708 15749 net.cpp:380] concat2_8_concat2_8_0_split -> concat2_8_concat2_8_0_split_1
I1211 15:05:37.628784 15749 net.cpp:122] Setting up concat2_8_concat2_8_0_split
I1211 15:05:37.628793 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.628798 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.628801 15749 net.cpp:137] Memory required for data: 259565520
I1211 15:05:37.628804 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/bn
I1211 15:05:37.628811 15749 net.cpp:84] Creating Layer conv2_9/x1/bn
I1211 15:05:37.628816 15749 net.cpp:406] conv2_9/x1/bn <- concat2_8_concat2_8_0_split_0
I1211 15:05:37.628823 15749 net.cpp:380] conv2_9/x1/bn -> conv2_9/x1/bn
I1211 15:05:37.629374 15749 net.cpp:122] Setting up conv2_9/x1/bn
I1211 15:05:37.629384 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.629389 15749 net.cpp:137] Memory required for data: 260555600
I1211 15:05:37.629397 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/scale
I1211 15:05:37.629406 15749 net.cpp:84] Creating Layer conv2_9/x1/scale
I1211 15:05:37.629411 15749 net.cpp:406] conv2_9/x1/scale <- conv2_9/x1/bn
I1211 15:05:37.629417 15749 net.cpp:367] conv2_9/x1/scale -> conv2_9/x1/bn (in-place)
I1211 15:05:37.629519 15749 layer_factory.hpp:77] Creating layer conv2_9/x1/scale
I1211 15:05:37.629842 15749 net.cpp:122] Setting up conv2_9/x1/scale
I1211 15:05:37.629853 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.629858 15749 net.cpp:137] Memory required for data: 261545680
I1211 15:05:37.629864 15749 layer_factory.hpp:77] Creating layer relu2_9/x1
I1211 15:05:37.629871 15749 net.cpp:84] Creating Layer relu2_9/x1
I1211 15:05:37.629876 15749 net.cpp:406] relu2_9/x1 <- conv2_9/x1/bn
I1211 15:05:37.629881 15749 net.cpp:367] relu2_9/x1 -> conv2_9/x1/bn (in-place)
I1211 15:05:37.630161 15749 net.cpp:122] Setting up relu2_9/x1
I1211 15:05:37.630172 15749 net.cpp:129] Top shape: 1 416 17 35 (247520)
I1211 15:05:37.630175 15749 net.cpp:137] Memory required for data: 262535760
I1211 15:05:37.630179 15749 layer_factory.hpp:77] Creating layer conv2_9/x1
I1211 15:05:37.630195 15749 net.cpp:84] Creating Layer conv2_9/x1
I1211 15:05:37.630201 15749 net.cpp:406] conv2_9/x1 <- conv2_9/x1/bn
I1211 15:05:37.630208 15749 net.cpp:380] conv2_9/x1 -> conv2_9/x1
I1211 15:05:37.634517 15749 net.cpp:122] Setting up conv2_9/x1
I1211 15:05:37.634531 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.634536 15749 net.cpp:137] Memory required for data: 262840400
I1211 15:05:37.634542 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/bn
I1211 15:05:37.634551 15749 net.cpp:84] Creating Layer conv2_9/x2/bn
I1211 15:05:37.634555 15749 net.cpp:406] conv2_9/x2/bn <- conv2_9/x1
I1211 15:05:37.634563 15749 net.cpp:380] conv2_9/x2/bn -> conv2_9/x2/bn
I1211 15:05:37.635025 15749 net.cpp:122] Setting up conv2_9/x2/bn
I1211 15:05:37.635035 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.635040 15749 net.cpp:137] Memory required for data: 263145040
I1211 15:05:37.635048 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/scale
I1211 15:05:37.635056 15749 net.cpp:84] Creating Layer conv2_9/x2/scale
I1211 15:05:37.635061 15749 net.cpp:406] conv2_9/x2/scale <- conv2_9/x2/bn
I1211 15:05:37.635068 15749 net.cpp:367] conv2_9/x2/scale -> conv2_9/x2/bn (in-place)
I1211 15:05:37.635148 15749 layer_factory.hpp:77] Creating layer conv2_9/x2/scale
I1211 15:05:37.635426 15749 net.cpp:122] Setting up conv2_9/x2/scale
I1211 15:05:37.635435 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.635439 15749 net.cpp:137] Memory required for data: 263449680
I1211 15:05:37.635447 15749 layer_factory.hpp:77] Creating layer relu2_9/x2
I1211 15:05:37.635453 15749 net.cpp:84] Creating Layer relu2_9/x2
I1211 15:05:37.635458 15749 net.cpp:406] relu2_9/x2 <- conv2_9/x2/bn
I1211 15:05:37.635463 15749 net.cpp:367] relu2_9/x2 -> conv2_9/x2/bn (in-place)
I1211 15:05:37.635979 15749 net.cpp:122] Setting up relu2_9/x2
I1211 15:05:37.635993 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.635996 15749 net.cpp:137] Memory required for data: 263754320
I1211 15:05:37.636001 15749 layer_factory.hpp:77] Creating layer conv2_9/x2
I1211 15:05:37.636013 15749 net.cpp:84] Creating Layer conv2_9/x2
I1211 15:05:37.636018 15749 net.cpp:406] conv2_9/x2 <- conv2_9/x2/bn
I1211 15:05:37.636026 15749 net.cpp:380] conv2_9/x2 -> conv2_9/x2
I1211 15:05:37.639549 15749 net.cpp:122] Setting up conv2_9/x2
I1211 15:05:37.639585 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.639588 15749 net.cpp:137] Memory required for data: 263830480
I1211 15:05:37.639597 15749 layer_factory.hpp:77] Creating layer concat2_9
I1211 15:05:37.639609 15749 net.cpp:84] Creating Layer concat2_9
I1211 15:05:37.639616 15749 net.cpp:406] concat2_9 <- concat2_8_concat2_8_0_split_1
I1211 15:05:37.639621 15749 net.cpp:406] concat2_9 <- conv2_9/x2
I1211 15:05:37.639626 15749 net.cpp:380] concat2_9 -> concat2_9
I1211 15:05:37.639680 15749 net.cpp:122] Setting up concat2_9
I1211 15:05:37.639686 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.639689 15749 net.cpp:137] Memory required for data: 264896720
I1211 15:05:37.639691 15749 layer_factory.hpp:77] Creating layer concat2_9_concat2_9_0_split
I1211 15:05:37.639698 15749 net.cpp:84] Creating Layer concat2_9_concat2_9_0_split
I1211 15:05:37.639700 15749 net.cpp:406] concat2_9_concat2_9_0_split <- concat2_9
I1211 15:05:37.639704 15749 net.cpp:380] concat2_9_concat2_9_0_split -> concat2_9_concat2_9_0_split_0
I1211 15:05:37.639710 15749 net.cpp:380] concat2_9_concat2_9_0_split -> concat2_9_concat2_9_0_split_1
I1211 15:05:37.639780 15749 net.cpp:122] Setting up concat2_9_concat2_9_0_split
I1211 15:05:37.639786 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.639789 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.639791 15749 net.cpp:137] Memory required for data: 267029200
I1211 15:05:37.639793 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/bn
I1211 15:05:37.639801 15749 net.cpp:84] Creating Layer conv2_10/x1/bn
I1211 15:05:37.639803 15749 net.cpp:406] conv2_10/x1/bn <- concat2_9_concat2_9_0_split_0
I1211 15:05:37.639813 15749 net.cpp:380] conv2_10/x1/bn -> conv2_10/x1/bn
I1211 15:05:37.640271 15749 net.cpp:122] Setting up conv2_10/x1/bn
I1211 15:05:37.640283 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.640286 15749 net.cpp:137] Memory required for data: 268095440
I1211 15:05:37.640293 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/scale
I1211 15:05:37.640301 15749 net.cpp:84] Creating Layer conv2_10/x1/scale
I1211 15:05:37.640305 15749 net.cpp:406] conv2_10/x1/scale <- conv2_10/x1/bn
I1211 15:05:37.640310 15749 net.cpp:367] conv2_10/x1/scale -> conv2_10/x1/bn (in-place)
I1211 15:05:37.640396 15749 layer_factory.hpp:77] Creating layer conv2_10/x1/scale
I1211 15:05:37.640650 15749 net.cpp:122] Setting up conv2_10/x1/scale
I1211 15:05:37.640658 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.640661 15749 net.cpp:137] Memory required for data: 269161680
I1211 15:05:37.640666 15749 layer_factory.hpp:77] Creating layer relu2_10/x1
I1211 15:05:37.640671 15749 net.cpp:84] Creating Layer relu2_10/x1
I1211 15:05:37.640674 15749 net.cpp:406] relu2_10/x1 <- conv2_10/x1/bn
I1211 15:05:37.640679 15749 net.cpp:367] relu2_10/x1 -> conv2_10/x1/bn (in-place)
I1211 15:05:37.641296 15749 net.cpp:122] Setting up relu2_10/x1
I1211 15:05:37.641309 15749 net.cpp:129] Top shape: 1 448 17 35 (266560)
I1211 15:05:37.641311 15749 net.cpp:137] Memory required for data: 270227920
I1211 15:05:37.641314 15749 layer_factory.hpp:77] Creating layer conv2_10/x1
I1211 15:05:37.641326 15749 net.cpp:84] Creating Layer conv2_10/x1
I1211 15:05:37.641330 15749 net.cpp:406] conv2_10/x1 <- conv2_10/x1/bn
I1211 15:05:37.641335 15749 net.cpp:380] conv2_10/x1 -> conv2_10/x1
I1211 15:05:37.644340 15749 net.cpp:122] Setting up conv2_10/x1
I1211 15:05:37.644368 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.644372 15749 net.cpp:137] Memory required for data: 270532560
I1211 15:05:37.644381 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/bn
I1211 15:05:37.644389 15749 net.cpp:84] Creating Layer conv2_10/x2/bn
I1211 15:05:37.644394 15749 net.cpp:406] conv2_10/x2/bn <- conv2_10/x1
I1211 15:05:37.644402 15749 net.cpp:380] conv2_10/x2/bn -> conv2_10/x2/bn
I1211 15:05:37.644783 15749 net.cpp:122] Setting up conv2_10/x2/bn
I1211 15:05:37.644789 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.644793 15749 net.cpp:137] Memory required for data: 270837200
I1211 15:05:37.644798 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/scale
I1211 15:05:37.644805 15749 net.cpp:84] Creating Layer conv2_10/x2/scale
I1211 15:05:37.644809 15749 net.cpp:406] conv2_10/x2/scale <- conv2_10/x2/bn
I1211 15:05:37.644812 15749 net.cpp:367] conv2_10/x2/scale -> conv2_10/x2/bn (in-place)
I1211 15:05:37.644876 15749 layer_factory.hpp:77] Creating layer conv2_10/x2/scale
I1211 15:05:37.645092 15749 net.cpp:122] Setting up conv2_10/x2/scale
I1211 15:05:37.645098 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.645102 15749 net.cpp:137] Memory required for data: 271141840
I1211 15:05:37.645105 15749 layer_factory.hpp:77] Creating layer relu2_10/x2
I1211 15:05:37.645112 15749 net.cpp:84] Creating Layer relu2_10/x2
I1211 15:05:37.645115 15749 net.cpp:406] relu2_10/x2 <- conv2_10/x2/bn
I1211 15:05:37.645118 15749 net.cpp:367] relu2_10/x2 -> conv2_10/x2/bn (in-place)
I1211 15:05:37.645345 15749 net.cpp:122] Setting up relu2_10/x2
I1211 15:05:37.645354 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.645356 15749 net.cpp:137] Memory required for data: 271446480
I1211 15:05:37.645359 15749 layer_factory.hpp:77] Creating layer conv2_10/x2
I1211 15:05:37.645370 15749 net.cpp:84] Creating Layer conv2_10/x2
I1211 15:05:37.645372 15749 net.cpp:406] conv2_10/x2 <- conv2_10/x2/bn
I1211 15:05:37.645377 15749 net.cpp:380] conv2_10/x2 -> conv2_10/x2
I1211 15:05:37.647956 15749 net.cpp:122] Setting up conv2_10/x2
I1211 15:05:37.647984 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.647987 15749 net.cpp:137] Memory required for data: 271522640
I1211 15:05:37.648000 15749 layer_factory.hpp:77] Creating layer concat2_10
I1211 15:05:37.648010 15749 net.cpp:84] Creating Layer concat2_10
I1211 15:05:37.648015 15749 net.cpp:406] concat2_10 <- concat2_9_concat2_9_0_split_1
I1211 15:05:37.648021 15749 net.cpp:406] concat2_10 <- conv2_10/x2
I1211 15:05:37.648028 15749 net.cpp:380] concat2_10 -> concat2_10
I1211 15:05:37.648078 15749 net.cpp:122] Setting up concat2_10
I1211 15:05:37.648084 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.648087 15749 net.cpp:137] Memory required for data: 272665040
I1211 15:05:37.648089 15749 layer_factory.hpp:77] Creating layer concat2_10_concat2_10_0_split
I1211 15:05:37.648094 15749 net.cpp:84] Creating Layer concat2_10_concat2_10_0_split
I1211 15:05:37.648098 15749 net.cpp:406] concat2_10_concat2_10_0_split <- concat2_10
I1211 15:05:37.648102 15749 net.cpp:380] concat2_10_concat2_10_0_split -> concat2_10_concat2_10_0_split_0
I1211 15:05:37.648106 15749 net.cpp:380] concat2_10_concat2_10_0_split -> concat2_10_concat2_10_0_split_1
I1211 15:05:37.648166 15749 net.cpp:122] Setting up concat2_10_concat2_10_0_split
I1211 15:05:37.648171 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.648175 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.648176 15749 net.cpp:137] Memory required for data: 274949840
I1211 15:05:37.648180 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/bn
I1211 15:05:37.648185 15749 net.cpp:84] Creating Layer conv2_11/x1/bn
I1211 15:05:37.648188 15749 net.cpp:406] conv2_11/x1/bn <- concat2_10_concat2_10_0_split_0
I1211 15:05:37.648192 15749 net.cpp:380] conv2_11/x1/bn -> conv2_11/x1/bn
I1211 15:05:37.648636 15749 net.cpp:122] Setting up conv2_11/x1/bn
I1211 15:05:37.648643 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.648645 15749 net.cpp:137] Memory required for data: 276092240
I1211 15:05:37.648651 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/scale
I1211 15:05:37.648660 15749 net.cpp:84] Creating Layer conv2_11/x1/scale
I1211 15:05:37.648663 15749 net.cpp:406] conv2_11/x1/scale <- conv2_11/x1/bn
I1211 15:05:37.648667 15749 net.cpp:367] conv2_11/x1/scale -> conv2_11/x1/bn (in-place)
I1211 15:05:37.648752 15749 layer_factory.hpp:77] Creating layer conv2_11/x1/scale
I1211 15:05:37.649013 15749 net.cpp:122] Setting up conv2_11/x1/scale
I1211 15:05:37.649020 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.649022 15749 net.cpp:137] Memory required for data: 277234640
I1211 15:05:37.649039 15749 layer_factory.hpp:77] Creating layer relu2_11/x1
I1211 15:05:37.649044 15749 net.cpp:84] Creating Layer relu2_11/x1
I1211 15:05:37.649047 15749 net.cpp:406] relu2_11/x1 <- conv2_11/x1/bn
I1211 15:05:37.649050 15749 net.cpp:367] relu2_11/x1 -> conv2_11/x1/bn (in-place)
I1211 15:05:37.649610 15749 net.cpp:122] Setting up relu2_11/x1
I1211 15:05:37.649621 15749 net.cpp:129] Top shape: 1 480 17 35 (285600)
I1211 15:05:37.649622 15749 net.cpp:137] Memory required for data: 278377040
I1211 15:05:37.649626 15749 layer_factory.hpp:77] Creating layer conv2_11/x1
I1211 15:05:37.649636 15749 net.cpp:84] Creating Layer conv2_11/x1
I1211 15:05:37.649639 15749 net.cpp:406] conv2_11/x1 <- conv2_11/x1/bn
I1211 15:05:37.649646 15749 net.cpp:380] conv2_11/x1 -> conv2_11/x1
I1211 15:05:37.661356 15749 net.cpp:122] Setting up conv2_11/x1
I1211 15:05:37.661396 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.661401 15749 net.cpp:137] Memory required for data: 278681680
I1211 15:05:37.661413 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/bn
I1211 15:05:37.661428 15749 net.cpp:84] Creating Layer conv2_11/x2/bn
I1211 15:05:37.661435 15749 net.cpp:406] conv2_11/x2/bn <- conv2_11/x1
I1211 15:05:37.661444 15749 net.cpp:380] conv2_11/x2/bn -> conv2_11/x2/bn
I1211 15:05:37.662014 15749 net.cpp:122] Setting up conv2_11/x2/bn
I1211 15:05:37.662032 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.662036 15749 net.cpp:137] Memory required for data: 278986320
I1211 15:05:37.662047 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/scale
I1211 15:05:37.662066 15749 net.cpp:84] Creating Layer conv2_11/x2/scale
I1211 15:05:37.662072 15749 net.cpp:406] conv2_11/x2/scale <- conv2_11/x2/bn
I1211 15:05:37.662078 15749 net.cpp:367] conv2_11/x2/scale -> conv2_11/x2/bn (in-place)
I1211 15:05:37.662169 15749 layer_factory.hpp:77] Creating layer conv2_11/x2/scale
I1211 15:05:37.662479 15749 net.cpp:122] Setting up conv2_11/x2/scale
I1211 15:05:37.662490 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.662494 15749 net.cpp:137] Memory required for data: 279290960
I1211 15:05:37.662503 15749 layer_factory.hpp:77] Creating layer relu2_11/x2
I1211 15:05:37.662511 15749 net.cpp:84] Creating Layer relu2_11/x2
I1211 15:05:37.662515 15749 net.cpp:406] relu2_11/x2 <- conv2_11/x2/bn
I1211 15:05:37.662521 15749 net.cpp:367] relu2_11/x2 -> conv2_11/x2/bn (in-place)
I1211 15:05:37.662896 15749 net.cpp:122] Setting up relu2_11/x2
I1211 15:05:37.662909 15749 net.cpp:129] Top shape: 1 128 17 35 (76160)
I1211 15:05:37.662912 15749 net.cpp:137] Memory required for data: 279595600
I1211 15:05:37.662917 15749 layer_factory.hpp:77] Creating layer conv2_11/x2
I1211 15:05:37.662931 15749 net.cpp:84] Creating Layer conv2_11/x2
I1211 15:05:37.662936 15749 net.cpp:406] conv2_11/x2 <- conv2_11/x2/bn
I1211 15:05:37.662945 15749 net.cpp:380] conv2_11/x2 -> conv2_11/x2
I1211 15:05:37.735656 15749 net.cpp:122] Setting up conv2_11/x2
I1211 15:05:37.735693 15749 net.cpp:129] Top shape: 1 32 17 35 (19040)
I1211 15:05:37.735698 15749 net.cpp:137] Memory required for data: 279671760
I1211 15:05:37.735710 15749 layer_factory.hpp:77] Creating layer concat2_11
I1211 15:05:37.735725 15749 net.cpp:84] Creating Layer concat2_11
I1211 15:05:37.735733 15749 net.cpp:406] concat2_11 <- concat2_10_concat2_10_0_split_1
I1211 15:05:37.735741 15749 net.cpp:406] concat2_11 <- conv2_11/x2
I1211 15:05:37.740833 15749 net.cpp:380] concat2_11 -> concat2_11
I1211 15:05:37.740991 15749 net.cpp:122] Setting up concat2_11
I1211 15:05:37.741006 15749 net.cpp:129] Top shape: 1 512 17 35 (304640)
I1211 15:05:37.741010 15749 net.cpp:137] Memory required for data: 280890320
I1211 15:05:37.741015 15749 layer_factory.hpp:77] Creating layer tpp5
I1211 15:05:37.741025 15749 net.cpp:84] Creating Layer tpp5
I1211 15:05:37.741030 15749 net.cpp:406] tpp5 <- concat2_11
I1211 15:05:37.741039 15749 net.cpp:380] tpp5 -> tpp5
I1211 15:05:37.742063 15749 net.cpp:122] Setting up tpp5
I1211 15:05:37.742079 15749 net.cpp:129] Top shape: 1 7680 (7680)
I1211 15:05:37.742084 15749 net.cpp:137] Memory required for data: 280921040
I1211 15:05:37.742089 15749 layer_factory.hpp:77] Creating layer fc6_d
I1211 15:05:37.742099 15749 net.cpp:84] Creating Layer fc6_d
I1211 15:05:37.742103 15749 net.cpp:406] fc6_d <- tpp5
I1211 15:05:37.742111 15749 net.cpp:380] fc6_d -> fc6_d
I1211 15:05:41.914537 15749 net.cpp:122] Setting up fc6_d
I1211 15:05:41.914579 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:41.914584 15749 net.cpp:137] Memory required for data: 280937424
I1211 15:05:41.914597 15749 layer_factory.hpp:77] Creating layer relu6
I1211 15:05:41.914608 15749 net.cpp:84] Creating Layer relu6
I1211 15:05:41.914614 15749 net.cpp:406] relu6 <- fc6_d
I1211 15:05:41.914623 15749 net.cpp:367] relu6 -> fc6_d (in-place)
I1211 15:05:41.915433 15749 net.cpp:122] Setting up relu6
I1211 15:05:41.915460 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:41.915465 15749 net.cpp:137] Memory required for data: 280953808
I1211 15:05:41.915472 15749 layer_factory.hpp:77] Creating layer fc7_d
I1211 15:05:41.915485 15749 net.cpp:84] Creating Layer fc7_d
I1211 15:05:41.915491 15749 net.cpp:406] fc7_d <- fc6_d
I1211 15:05:41.915500 15749 net.cpp:380] fc7_d -> fc7_d
I1211 15:05:44.172791 15749 net.cpp:122] Setting up fc7_d
I1211 15:05:44.172834 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:44.172838 15749 net.cpp:137] Memory required for data: 280970192
I1211 15:05:44.172848 15749 layer_factory.hpp:77] Creating layer relu7
I1211 15:05:44.172857 15749 net.cpp:84] Creating Layer relu7
I1211 15:05:44.172863 15749 net.cpp:406] relu7 <- fc7_d
I1211 15:05:44.172873 15749 net.cpp:367] relu7 -> fc7_d (in-place)
I1211 15:05:44.173550 15749 net.cpp:122] Setting up relu7
I1211 15:05:44.173565 15749 net.cpp:129] Top shape: 1 4096 (4096)
I1211 15:05:44.173568 15749 net.cpp:137] Memory required for data: 280986576
I1211 15:05:44.173571 15749 layer_factory.hpp:77] Creating layer fc8_d
I1211 15:05:44.173579 15749 net.cpp:84] Creating Layer fc8_d
I1211 15:05:44.173583 15749 net.cpp:406] fc8_d <- fc7_d
I1211 15:05:44.173588 15749 net.cpp:380] fc8_d -> fc8_d
I1211 15:05:44.319290 15749 net.cpp:122] Setting up fc8_d
I1211 15:05:44.319329 15749 net.cpp:129] Top shape: 1 604 (604)
I1211 15:05:44.319334 15749 net.cpp:137] Memory required for data: 280988992
I1211 15:05:44.319345 15749 layer_factory.hpp:77] Creating layer fc8_d_fc8_d_0_split
I1211 15:05:44.319357 15749 net.cpp:84] Creating Layer fc8_d_fc8_d_0_split
I1211 15:05:44.319365 15749 net.cpp:406] fc8_d_fc8_d_0_split <- fc8_d
I1211 15:05:44.319372 15749 net.cpp:380] fc8_d_fc8_d_0_split -> fc8_d_fc8_d_0_split_0
I1211 15:05:44.319386 15749 net.cpp:380] fc8_d_fc8_d_0_split -> fc8_d_fc8_d_0_split_1
I1211 15:05:44.319464 15749 net.cpp:122] Setting up fc8_d_fc8_d_0_split
I1211 15:05:44.319473 15749 net.cpp:129] Top shape: 1 604 (604)
I1211 15:05:44.319478 15749 net.cpp:129] Top shape: 1 604 (604)
I1211 15:05:44.319483 15749 net.cpp:137] Memory required for data: 280993824
I1211 15:05:44.319486 15749 layer_factory.hpp:77] Creating layer sigmoid
I1211 15:05:44.319494 15749 net.cpp:84] Creating Layer sigmoid
I1211 15:05:44.319499 15749 net.cpp:406] sigmoid <- fc8_d_fc8_d_0_split_0
I1211 15:05:44.319505 15749 net.cpp:380] sigmoid -> sigmoid
I1211 15:05:44.319936 15749 net.cpp:122] Setting up sigmoid
I1211 15:05:44.319949 15749 net.cpp:129] Top shape: 1 604 (604)
I1211 15:05:44.319953 15749 net.cpp:137] Memory required for data: 280996240
I1211 15:05:44.319958 15749 layer_factory.hpp:77] Creating layer silence
I1211 15:05:44.319967 15749 net.cpp:84] Creating Layer silence
I1211 15:05:44.319972 15749 net.cpp:406] silence <- sigmoid
I1211 15:05:44.319977 15749 net.cpp:122] Setting up silence
I1211 15:05:44.319980 15749 net.cpp:137] Memory required for data: 280996240
I1211 15:05:44.319984 15749 layer_factory.hpp:77] Creating layer loss
I1211 15:05:44.319993 15749 net.cpp:84] Creating Layer loss
I1211 15:05:44.319996 15749 net.cpp:406] loss <- fc8_d_fc8_d_0_split_1
I1211 15:05:44.320001 15749 net.cpp:406] loss <- phocs
I1211 15:05:44.320008 15749 net.cpp:380] loss -> loss
I1211 15:05:44.320091 15749 net.cpp:122] Setting up loss
I1211 15:05:44.320102 15749 net.cpp:129] Top shape: (1)
I1211 15:05:44.320106 15749 net.cpp:132]     with loss weight 1
I1211 15:05:44.320119 15749 net.cpp:137] Memory required for data: 280996244
I1211 15:05:44.320123 15749 net.cpp:198] loss needs backward computation.
I1211 15:05:44.320128 15749 net.cpp:200] silence does not need backward computation.
I1211 15:05:44.320132 15749 net.cpp:200] sigmoid does not need backward computation.
I1211 15:05:44.320137 15749 net.cpp:198] fc8_d_fc8_d_0_split needs backward computation.
I1211 15:05:44.320140 15749 net.cpp:198] fc8_d needs backward computation.
I1211 15:05:44.320144 15749 net.cpp:198] relu7 needs backward computation.
I1211 15:05:44.320148 15749 net.cpp:198] fc7_d needs backward computation.
I1211 15:05:44.320152 15749 net.cpp:198] relu6 needs backward computation.
I1211 15:05:44.320156 15749 net.cpp:198] fc6_d needs backward computation.
I1211 15:05:44.320161 15749 net.cpp:198] tpp5 needs backward computation.
I1211 15:05:44.320165 15749 net.cpp:198] concat2_11 needs backward computation.
I1211 15:05:44.320170 15749 net.cpp:198] conv2_11/x2 needs backward computation.
I1211 15:05:44.320174 15749 net.cpp:198] relu2_11/x2 needs backward computation.
I1211 15:05:44.320178 15749 net.cpp:198] conv2_11/x2/scale needs backward computation.
I1211 15:05:44.320183 15749 net.cpp:198] conv2_11/x2/bn needs backward computation.
I1211 15:05:44.320188 15749 net.cpp:198] conv2_11/x1 needs backward computation.
I1211 15:05:44.320191 15749 net.cpp:198] relu2_11/x1 needs backward computation.
I1211 15:05:44.320201 15749 net.cpp:198] conv2_11/x1/scale needs backward computation.
I1211 15:05:44.320205 15749 net.cpp:198] conv2_11/x1/bn needs backward computation.
I1211 15:05:44.320210 15749 net.cpp:198] concat2_10_concat2_10_0_split needs backward computation.
I1211 15:05:44.320214 15749 net.cpp:198] concat2_10 needs backward computation.
I1211 15:05:44.320219 15749 net.cpp:198] conv2_10/x2 needs backward computation.
I1211 15:05:44.320225 15749 net.cpp:198] relu2_10/x2 needs backward computation.
I1211 15:05:44.320228 15749 net.cpp:198] conv2_10/x2/scale needs backward computation.
I1211 15:05:44.320232 15749 net.cpp:198] conv2_10/x2/bn needs backward computation.
I1211 15:05:44.320236 15749 net.cpp:198] conv2_10/x1 needs backward computation.
I1211 15:05:44.320240 15749 net.cpp:198] relu2_10/x1 needs backward computation.
I1211 15:05:44.320245 15749 net.cpp:198] conv2_10/x1/scale needs backward computation.
I1211 15:05:44.320250 15749 net.cpp:198] conv2_10/x1/bn needs backward computation.
I1211 15:05:44.320253 15749 net.cpp:198] concat2_9_concat2_9_0_split needs backward computation.
I1211 15:05:44.320258 15749 net.cpp:198] concat2_9 needs backward computation.
I1211 15:05:44.320263 15749 net.cpp:198] conv2_9/x2 needs backward computation.
I1211 15:05:44.320267 15749 net.cpp:198] relu2_9/x2 needs backward computation.
I1211 15:05:44.320271 15749 net.cpp:198] conv2_9/x2/scale needs backward computation.
I1211 15:05:44.320276 15749 net.cpp:198] conv2_9/x2/bn needs backward computation.
I1211 15:05:44.320281 15749 net.cpp:198] conv2_9/x1 needs backward computation.
I1211 15:05:44.320284 15749 net.cpp:198] relu2_9/x1 needs backward computation.
I1211 15:05:44.320288 15749 net.cpp:198] conv2_9/x1/scale needs backward computation.
I1211 15:05:44.320292 15749 net.cpp:198] conv2_9/x1/bn needs backward computation.
I1211 15:05:44.320297 15749 net.cpp:198] concat2_8_concat2_8_0_split needs backward computation.
I1211 15:05:44.320302 15749 net.cpp:198] concat2_8 needs backward computation.
I1211 15:05:44.320307 15749 net.cpp:198] conv2_8/x2 needs backward computation.
I1211 15:05:44.320310 15749 net.cpp:198] relu2_8/x2 needs backward computation.
I1211 15:05:44.320314 15749 net.cpp:198] conv2_8/x2/scale needs backward computation.
I1211 15:05:44.320318 15749 net.cpp:198] conv2_8/x2/bn needs backward computation.
I1211 15:05:44.320322 15749 net.cpp:198] conv2_8/x1 needs backward computation.
I1211 15:05:44.320327 15749 net.cpp:198] relu2_8/x1 needs backward computation.
I1211 15:05:44.320332 15749 net.cpp:198] conv2_8/x1/scale needs backward computation.
I1211 15:05:44.320335 15749 net.cpp:198] conv2_8/x1/bn needs backward computation.
I1211 15:05:44.320339 15749 net.cpp:198] concat2_7_concat2_7_0_split needs backward computation.
I1211 15:05:44.320344 15749 net.cpp:198] concat2_7 needs backward computation.
I1211 15:05:44.320348 15749 net.cpp:198] conv2_7/x2 needs backward computation.
I1211 15:05:44.320353 15749 net.cpp:198] relu2_7/x2 needs backward computation.
I1211 15:05:44.320358 15749 net.cpp:198] conv2_7/x2/scale needs backward computation.
I1211 15:05:44.320361 15749 net.cpp:198] conv2_7/x2/bn needs backward computation.
I1211 15:05:44.320365 15749 net.cpp:198] conv2_7/x1 needs backward computation.
I1211 15:05:44.320370 15749 net.cpp:198] relu2_7/x1 needs backward computation.
I1211 15:05:44.320374 15749 net.cpp:198] conv2_7/x1/scale needs backward computation.
I1211 15:05:44.320379 15749 net.cpp:198] conv2_7/x1/bn needs backward computation.
I1211 15:05:44.320382 15749 net.cpp:198] concat2_6_concat2_6_0_split needs backward computation.
I1211 15:05:44.320387 15749 net.cpp:198] concat2_6 needs backward computation.
I1211 15:05:44.320392 15749 net.cpp:198] conv2_6/x2 needs backward computation.
I1211 15:05:44.320396 15749 net.cpp:198] relu2_6/x2 needs backward computation.
I1211 15:05:44.320400 15749 net.cpp:198] conv2_6/x2/scale needs backward computation.
I1211 15:05:44.320405 15749 net.cpp:198] conv2_6/x2/bn needs backward computation.
I1211 15:05:44.320410 15749 net.cpp:198] conv2_6/x1 needs backward computation.
I1211 15:05:44.320417 15749 net.cpp:198] relu2_6/x1 needs backward computation.
I1211 15:05:44.320421 15749 net.cpp:198] conv2_6/x1/scale needs backward computation.
I1211 15:05:44.320425 15749 net.cpp:198] conv2_6/x1/bn needs backward computation.
I1211 15:05:44.320430 15749 net.cpp:198] concat2_5_concat2_5_0_split needs backward computation.
I1211 15:05:44.320435 15749 net.cpp:198] concat2_5 needs backward computation.
I1211 15:05:44.320441 15749 net.cpp:198] conv2_5/x2 needs backward computation.
I1211 15:05:44.320444 15749 net.cpp:198] relu2_5/x2 needs backward computation.
I1211 15:05:44.320448 15749 net.cpp:198] conv2_5/x2/scale needs backward computation.
I1211 15:05:44.320453 15749 net.cpp:198] conv2_5/x2/bn needs backward computation.
I1211 15:05:44.320457 15749 net.cpp:198] conv2_5/x1 needs backward computation.
I1211 15:05:44.320461 15749 net.cpp:198] relu2_5/x1 needs backward computation.
I1211 15:05:44.320466 15749 net.cpp:198] conv2_5/x1/scale needs backward computation.
I1211 15:05:44.320469 15749 net.cpp:198] conv2_5/x1/bn needs backward computation.
I1211 15:05:44.320474 15749 net.cpp:198] concat2_4_concat2_4_0_split needs backward computation.
I1211 15:05:44.320478 15749 net.cpp:198] concat2_4 needs backward computation.
I1211 15:05:44.320483 15749 net.cpp:198] conv2_4/x2 needs backward computation.
I1211 15:05:44.320487 15749 net.cpp:198] relu2_4/x2 needs backward computation.
I1211 15:05:44.320492 15749 net.cpp:198] conv2_4/x2/scale needs backward computation.
I1211 15:05:44.320495 15749 net.cpp:198] conv2_4/x2/bn needs backward computation.
I1211 15:05:44.320500 15749 net.cpp:198] conv2_4/x1 needs backward computation.
I1211 15:05:44.320504 15749 net.cpp:198] relu2_4/x1 needs backward computation.
I1211 15:05:44.320508 15749 net.cpp:198] conv2_4/x1/scale needs backward computation.
I1211 15:05:44.320513 15749 net.cpp:198] conv2_4/x1/bn needs backward computation.
I1211 15:05:44.320518 15749 net.cpp:198] concat2_3_concat2_3_0_split needs backward computation.
I1211 15:05:44.320521 15749 net.cpp:198] concat2_3 needs backward computation.
I1211 15:05:44.320528 15749 net.cpp:198] conv2_3/x2 needs backward computation.
I1211 15:05:44.320531 15749 net.cpp:198] relu2_3/x2 needs backward computation.
I1211 15:05:44.320536 15749 net.cpp:198] conv2_3/x2/scale needs backward computation.
I1211 15:05:44.320540 15749 net.cpp:198] conv2_3/x2/bn needs backward computation.
I1211 15:05:44.320544 15749 net.cpp:198] conv2_3/x1 needs backward computation.
I1211 15:05:44.320549 15749 net.cpp:198] relu2_3/x1 needs backward computation.
I1211 15:05:44.320554 15749 net.cpp:198] conv2_3/x1/scale needs backward computation.
I1211 15:05:44.320557 15749 net.cpp:198] conv2_3/x1/bn needs backward computation.
I1211 15:05:44.320561 15749 net.cpp:198] concat2_2_concat2_2_0_split needs backward computation.
I1211 15:05:44.320566 15749 net.cpp:198] concat2_2 needs backward computation.
I1211 15:05:44.320571 15749 net.cpp:198] conv2_2/x2 needs backward computation.
I1211 15:05:44.320575 15749 net.cpp:198] relu2_2/x2 needs backward computation.
I1211 15:05:44.320580 15749 net.cpp:198] conv2_2/x2/scale needs backward computation.
I1211 15:05:44.320583 15749 net.cpp:198] conv2_2/x2/bn needs backward computation.
I1211 15:05:44.320588 15749 net.cpp:198] conv2_2/x1 needs backward computation.
I1211 15:05:44.320592 15749 net.cpp:198] relu2_2/x1 needs backward computation.
I1211 15:05:44.320596 15749 net.cpp:198] conv2_2/x1/scale needs backward computation.
I1211 15:05:44.320600 15749 net.cpp:198] conv2_2/x1/bn needs backward computation.
I1211 15:05:44.320605 15749 net.cpp:198] concat2_1_concat2_1_0_split needs backward computation.
I1211 15:05:44.320610 15749 net.cpp:198] concat2_1 needs backward computation.
I1211 15:05:44.320614 15749 net.cpp:198] conv2_1/x2 needs backward computation.
I1211 15:05:44.320619 15749 net.cpp:198] relu2_1/x2 needs backward computation.
I1211 15:05:44.320623 15749 net.cpp:198] conv2_1/x2/scale needs backward computation.
I1211 15:05:44.320627 15749 net.cpp:198] conv2_1/x2/bn needs backward computation.
I1211 15:05:44.320634 15749 net.cpp:198] conv2_1/x1 needs backward computation.
I1211 15:05:44.320638 15749 net.cpp:198] relu2_1/x1 needs backward computation.
I1211 15:05:44.320642 15749 net.cpp:198] conv2_1/x1/scale needs backward computation.
I1211 15:05:44.320647 15749 net.cpp:198] conv2_1/x1/bn needs backward computation.
I1211 15:05:44.320652 15749 net.cpp:198] concat2_0_concat2_0_0_split needs backward computation.
I1211 15:05:44.320655 15749 net.cpp:198] concat2_0 needs backward computation.
I1211 15:05:44.320663 15749 net.cpp:198] conv2_0/x2 needs backward computation.
I1211 15:05:44.320668 15749 net.cpp:198] relu2_0/x2 needs backward computation.
I1211 15:05:44.320672 15749 net.cpp:198] conv2_0/x2/scale needs backward computation.
I1211 15:05:44.320677 15749 net.cpp:198] conv2_0/x2/bn needs backward computation.
I1211 15:05:44.320682 15749 net.cpp:198] conv2_0/x1 needs backward computation.
I1211 15:05:44.320685 15749 net.cpp:198] relu2_0/x1 needs backward computation.
I1211 15:05:44.320689 15749 net.cpp:198] conv2_0/x1/scale needs backward computation.
I1211 15:05:44.320693 15749 net.cpp:198] conv2_0/x1/bn needs backward computation.
I1211 15:05:44.320698 15749 net.cpp:198] pool1_pool1_0_split needs backward computation.
I1211 15:05:44.320703 15749 net.cpp:198] pool1 needs backward computation.
I1211 15:05:44.320708 15749 net.cpp:198] conv1_blk needs backward computation.
I1211 15:05:44.320713 15749 net.cpp:198] ReLU2 needs backward computation.
I1211 15:05:44.320716 15749 net.cpp:198] Scale2 needs backward computation.
I1211 15:05:44.320720 15749 net.cpp:198] BatchNorm2 needs backward computation.
I1211 15:05:44.320725 15749 net.cpp:198] concat1_5 needs backward computation.
I1211 15:05:44.320731 15749 net.cpp:198] conv1_5/x2 needs backward computation.
I1211 15:05:44.320736 15749 net.cpp:198] relu1_5/x2 needs backward computation.
I1211 15:05:44.320740 15749 net.cpp:198] conv1_5/x2/scale needs backward computation.
I1211 15:05:44.320744 15749 net.cpp:198] conv1_5/x2/bn needs backward computation.
I1211 15:05:44.320749 15749 net.cpp:198] conv1_5/x1 needs backward computation.
I1211 15:05:44.320753 15749 net.cpp:198] relu1_5/x1 needs backward computation.
I1211 15:05:44.320757 15749 net.cpp:198] conv1_5/x1/scale needs backward computation.
I1211 15:05:44.320761 15749 net.cpp:198] conv1_5/x1/bn needs backward computation.
I1211 15:05:44.320766 15749 net.cpp:198] concat1_4_concat1_4_0_split needs backward computation.
I1211 15:05:44.320771 15749 net.cpp:198] concat1_4 needs backward computation.
I1211 15:05:44.320776 15749 net.cpp:198] conv1_4/x2 needs backward computation.
I1211 15:05:44.320781 15749 net.cpp:198] relu1_4/x2 needs backward computation.
I1211 15:05:44.320785 15749 net.cpp:198] conv1_4/x2/scale needs backward computation.
I1211 15:05:44.320789 15749 net.cpp:198] conv1_4/x2/bn needs backward computation.
I1211 15:05:44.320794 15749 net.cpp:198] conv1_4/x1 needs backward computation.
I1211 15:05:44.320798 15749 net.cpp:198] relu1_4/x1 needs backward computation.
I1211 15:05:44.320802 15749 net.cpp:198] conv1_4/x1/scale needs backward computation.
I1211 15:05:44.320807 15749 net.cpp:198] conv1_4/x1/bn needs backward computation.
I1211 15:05:44.320811 15749 net.cpp:198] concat1_3_concat1_3_0_split needs backward computation.
I1211 15:05:44.320816 15749 net.cpp:198] concat1_3 needs backward computation.
I1211 15:05:44.320822 15749 net.cpp:198] conv1_3/x2 needs backward computation.
I1211 15:05:44.320825 15749 net.cpp:198] relu1_3/x2 needs backward computation.
I1211 15:05:44.320830 15749 net.cpp:198] conv1_3/x2/scale needs backward computation.
I1211 15:05:44.320834 15749 net.cpp:198] conv1_3/x2/bn needs backward computation.
I1211 15:05:44.320838 15749 net.cpp:198] conv1_3/x1 needs backward computation.
I1211 15:05:44.320842 15749 net.cpp:198] relu1_3/x1 needs backward computation.
I1211 15:05:44.320847 15749 net.cpp:198] conv1_3/x1/scale needs backward computation.
I1211 15:05:44.320852 15749 net.cpp:198] conv1_3/x1/bn needs backward computation.
I1211 15:05:44.320858 15749 net.cpp:198] concat1_2_concat1_2_0_split needs backward computation.
I1211 15:05:44.320863 15749 net.cpp:198] concat1_2 needs backward computation.
I1211 15:05:44.320868 15749 net.cpp:198] conv1_2/x2 needs backward computation.
I1211 15:05:44.320873 15749 net.cpp:198] relu1_2/x2 needs backward computation.
I1211 15:05:44.320876 15749 net.cpp:198] conv1_2/x2/scale needs backward computation.
I1211 15:05:44.320880 15749 net.cpp:198] conv1_2/x2/bn needs backward computation.
I1211 15:05:44.320885 15749 net.cpp:198] conv1_2/x1 needs backward computation.
I1211 15:05:44.320889 15749 net.cpp:198] relu1_2/x1 needs backward computation.
I1211 15:05:44.320894 15749 net.cpp:198] conv1_2/x1/scale needs backward computation.
I1211 15:05:44.320897 15749 net.cpp:198] conv1_2/x1/bn needs backward computation.
I1211 15:05:44.320902 15749 net.cpp:198] concat1_1_concat1_1_0_split needs backward computation.
I1211 15:05:44.320906 15749 net.cpp:198] concat1_1 needs backward computation.
I1211 15:05:44.320911 15749 net.cpp:198] conv1_1/x2 needs backward computation.
I1211 15:05:44.320916 15749 net.cpp:198] relu1_1/x2 needs backward computation.
I1211 15:05:44.320920 15749 net.cpp:198] conv1_1/x2/scale needs backward computation.
I1211 15:05:44.320924 15749 net.cpp:198] conv1_1/x2/bn needs backward computation.
I1211 15:05:44.320929 15749 net.cpp:198] conv1_1/x1 needs backward computation.
I1211 15:05:44.320933 15749 net.cpp:198] relu1_1/x1 needs backward computation.
I1211 15:05:44.320937 15749 net.cpp:198] conv1_1/x1/scale needs backward computation.
I1211 15:05:44.320941 15749 net.cpp:198] conv1_1/x1/bn needs backward computation.
I1211 15:05:44.320946 15749 net.cpp:198] concat1_0_concat1_0_0_split needs backward computation.
I1211 15:05:44.320950 15749 net.cpp:198] concat1_0 needs backward computation.
I1211 15:05:44.320955 15749 net.cpp:198] conv1_0/x2 needs backward computation.
I1211 15:05:44.320960 15749 net.cpp:198] relu1_0/x2 needs backward computation.
I1211 15:05:44.320963 15749 net.cpp:198] conv1_0/x2/scale needs backward computation.
I1211 15:05:44.320967 15749 net.cpp:198] conv1_0/x2/bn needs backward computation.
I1211 15:05:44.320972 15749 net.cpp:198] conv1_0/x1 needs backward computation.
I1211 15:05:44.320976 15749 net.cpp:198] relu1_0/x1 needs backward computation.
I1211 15:05:44.320981 15749 net.cpp:198] conv1_0/x1/scale needs backward computation.
I1211 15:05:44.320984 15749 net.cpp:198] conv1_0/x1/bn needs backward computation.
I1211 15:05:44.320989 15749 net.cpp:198] pool0_pool0_0_split needs backward computation.
I1211 15:05:44.320996 15749 net.cpp:198] pool0 needs backward computation.
I1211 15:05:44.321000 15749 net.cpp:198] conv0_blk needs backward computation.
I1211 15:05:44.321004 15749 net.cpp:198] ReLU1 needs backward computation.
I1211 15:05:44.321009 15749 net.cpp:198] Scale1 needs backward computation.
I1211 15:05:44.321013 15749 net.cpp:198] BatchNorm1 needs backward computation.
I1211 15:05:44.321018 15749 net.cpp:198] concat0_2 needs backward computation.
I1211 15:05:44.321023 15749 net.cpp:198] conv0_2/x2 needs backward computation.
I1211 15:05:44.321028 15749 net.cpp:198] relu0_2/x2 needs backward computation.
I1211 15:05:44.321033 15749 net.cpp:198] conv0_2/x2/scale needs backward computation.
I1211 15:05:44.321036 15749 net.cpp:198] conv0_2/x2/bn needs backward computation.
I1211 15:05:44.321040 15749 net.cpp:198] conv0_2/x1 needs backward computation.
I1211 15:05:44.321045 15749 net.cpp:198] relu0_2/x1 needs backward computation.
I1211 15:05:44.321049 15749 net.cpp:198] conv0_2/x1/scale needs backward computation.
I1211 15:05:44.321053 15749 net.cpp:198] conv0_2/x1/bn needs backward computation.
I1211 15:05:44.321058 15749 net.cpp:198] concat0_1_concat0_1_0_split needs backward computation.
I1211 15:05:44.321063 15749 net.cpp:198] concat0_1 needs backward computation.
I1211 15:05:44.321069 15749 net.cpp:198] conv0_1/x2 needs backward computation.
I1211 15:05:44.321074 15749 net.cpp:198] relu0_1/x2 needs backward computation.
I1211 15:05:44.321077 15749 net.cpp:198] conv0_1/x2/scale needs backward computation.
I1211 15:05:44.321084 15749 net.cpp:198] conv0_1/x2/bn needs backward computation.
I1211 15:05:44.321089 15749 net.cpp:198] conv0_1/x1 needs backward computation.
I1211 15:05:44.321092 15749 net.cpp:198] relu0_1/x1 needs backward computation.
I1211 15:05:44.321096 15749 net.cpp:198] conv0_1/x1/scale needs backward computation.
I1211 15:05:44.321100 15749 net.cpp:198] conv0_1/x1/bn needs backward computation.
I1211 15:05:44.321106 15749 net.cpp:198] concat0_0_concat0_0_0_split needs backward computation.
I1211 15:05:44.321110 15749 net.cpp:198] concat0_0 needs backward computation.
I1211 15:05:44.321116 15749 net.cpp:198] conv0_0/x2 needs backward computation.
I1211 15:05:44.321120 15749 net.cpp:198] relu0_0/x2 needs backward computation.
I1211 15:05:44.321125 15749 net.cpp:198] conv0_0/x2/scale needs backward computation.
I1211 15:05:44.321130 15749 net.cpp:198] conv0_0/x2/bn needs backward computation.
I1211 15:05:44.321133 15749 net.cpp:198] conv0_0/x1 needs backward computation.
I1211 15:05:44.321137 15749 net.cpp:198] relu0_0/x1 needs backward computation.
I1211 15:05:44.321141 15749 net.cpp:198] conv0_0/x1/scale needs backward computation.
I1211 15:05:44.321146 15749 net.cpp:198] conv0_0/x1/bn needs backward computation.
I1211 15:05:44.321151 15749 net.cpp:198] conv_init_conv_init_0_split needs backward computation.
I1211 15:05:44.321156 15749 net.cpp:198] conv_init needs backward computation.
I1211 15:05:44.321161 15749 net.cpp:200] phocs does not need backward computation.
I1211 15:05:44.321164 15749 net.cpp:200] word_images does not need backward computation.
I1211 15:05:44.321168 15749 net.cpp:242] This network produces output label
I1211 15:05:44.321173 15749 net.cpp:242] This network produces output label_phocs
I1211 15:05:44.321178 15749 net.cpp:242] This network produces output loss
I1211 15:05:44.321326 15749 net.cpp:255] Network initialization done.
I1211 15:05:44.322234 15749 solver.cpp:56] Solver scaffolding done.
[2017-12-11 15:05:44,343, PHOCNetTrainer] Running pre-train evaluation
I1211 15:06:27.489019 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:06:27.489033 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 15:06:28,505, PHOCNetTrainer] mAP: 0.019318
[2017-12-11 15:06:28,505, PHOCNetTrainer] Finished Setup, running SGD
I1211 15:06:28.527896 15749 solver.cpp:330] Iteration 0, Testing net (#0)
I1211 15:06:28.555371 15749 net.cpp:676] Ignoring source layer drop6
I1211 15:06:28.566001 15749 net.cpp:676] Ignoring source layer drop7
I1211 15:07:07.607830 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:07:07.607957 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:07:08.059911 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 15:07:08.059957 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 15:07:08.059968 15749 solver.cpp:397]     Test net output #2: loss = nan (* 1 = nan loss)
I1211 15:07:09.485008 15749 solver.cpp:218] Iteration 0 (-6.93592e+07 iter/s, 40.9496s/100 iters), loss = 2428.8
I1211 15:07:09.485321 15749 solver.cpp:237]     Train net output #0: label = 648
I1211 15:07:09.485435 15749 solver.cpp:237]     Train net output #1: label_phocs = 648
I1211 15:07:09.485450 15749 solver.cpp:237]     Train net output #2: loss = 2023.75 (* 1 = 2023.75 loss)
I1211 15:07:09.485460 15749 sgd_solver.cpp:116] Iteration 0, lr = 0.0001
I1211 15:09:40.256536 15749 solver.cpp:218] Iteration 100 (0.663255 iter/s, 150.771s/100 iters), loss = 129.136
I1211 15:09:40.256603 15749 solver.cpp:237]     Train net output #0: label = 1110
I1211 15:09:40.256623 15749 solver.cpp:237]     Train net output #1: label_phocs = 1110
I1211 15:09:40.256630 15749 solver.cpp:237]     Train net output #2: loss = 104.891 (* 1 = 104.891 loss)
I1211 15:09:40.256638 15749 sgd_solver.cpp:116] Iteration 100, lr = 0.0001
I1211 15:12:02.377331 15749 solver.cpp:218] Iteration 200 (0.703627 iter/s, 142.121s/100 iters), loss = 94.8997
I1211 15:12:02.377415 15749 solver.cpp:237]     Train net output #0: label = 874
I1211 15:12:02.377444 15749 solver.cpp:237]     Train net output #1: label_phocs = 874
I1211 15:12:02.377456 15749 solver.cpp:237]     Train net output #2: loss = 114.012 (* 1 = 114.012 loss)
I1211 15:12:02.377465 15749 sgd_solver.cpp:116] Iteration 200, lr = 0.0001
I1211 15:14:20.235982 15749 solver.cpp:218] Iteration 300 (0.725381 iter/s, 137.859s/100 iters), loss = 92.4578
I1211 15:14:20.236073 15749 solver.cpp:237]     Train net output #0: label = 1035
I1211 15:14:20.236099 15749 solver.cpp:237]     Train net output #1: label_phocs = 1035
I1211 15:14:20.236111 15749 solver.cpp:237]     Train net output #2: loss = 99.1288 (* 1 = 99.1288 loss)
I1211 15:14:20.236121 15749 sgd_solver.cpp:116] Iteration 300, lr = 0.0001
I1211 15:16:43.858300 15749 solver.cpp:218] Iteration 400 (0.696271 iter/s, 143.622s/100 iters), loss = 93.9782
I1211 15:16:43.858381 15749 solver.cpp:237]     Train net output #0: label = 692
I1211 15:16:43.858403 15749 solver.cpp:237]     Train net output #1: label_phocs = 692
I1211 15:16:43.858414 15749 solver.cpp:237]     Train net output #2: loss = 91.7097 (* 1 = 91.7097 loss)
I1211 15:16:43.858423 15749 sgd_solver.cpp:116] Iteration 400, lr = 0.0001
[2017-12-11 15:19:02,895, PHOCNetTrainer] Running test evaluation
[2017-12-11 15:19:02,895, PHOCNetTrainer] Evaluating CNN after 0 steps:
I1211 15:19:31.403833 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:19:31.404011 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 15:19:32,690, PHOCNetTrainer] mAP: 0.086294
I1211 15:19:32.692481 15749 solver.cpp:330] Iteration 500, Testing net (#0)
I1211 15:19:32.692674 15749 net.cpp:676] Ignoring source layer drop6
I1211 15:19:32.692683 15749 net.cpp:676] Ignoring source layer drop7
I1211 15:20:22.987924 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:20:22.988281 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:20:23.437481 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 15:20:23.437520 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 15:20:23.437528 15749 solver.cpp:397]     Test net output #2: loss = 70.9971 (* 1 = 70.9971 loss)
I1211 15:20:24.527070 15749 solver.cpp:218] Iteration 500 (0.453168 iter/s, 220.669s/100 iters), loss = 98.9986
I1211 15:20:24.527151 15749 solver.cpp:237]     Train net output #0: label = 451
I1211 15:20:24.527175 15749 solver.cpp:237]     Train net output #1: label_phocs = 451
I1211 15:20:24.527187 15749 solver.cpp:237]     Train net output #2: loss = 121.541 (* 1 = 121.541 loss)
I1211 15:20:24.527196 15749 sgd_solver.cpp:116] Iteration 500, lr = 0.0001
I1211 15:22:54.464942 15749 solver.cpp:218] Iteration 600 (0.666943 iter/s, 149.938s/100 iters), loss = 91.6867
I1211 15:22:54.465030 15749 solver.cpp:237]     Train net output #0: label = 539
I1211 15:22:54.465054 15749 solver.cpp:237]     Train net output #1: label_phocs = 539
I1211 15:22:54.465066 15749 solver.cpp:237]     Train net output #2: loss = 106.317 (* 1 = 106.317 loss)
I1211 15:22:54.465075 15749 sgd_solver.cpp:116] Iteration 600, lr = 0.0001
I1211 15:25:26.234376 15749 solver.cpp:218] Iteration 700 (0.658966 iter/s, 151.753s/100 iters), loss = 91.6604
I1211 15:25:26.234467 15749 solver.cpp:237]     Train net output #0: label = 777
I1211 15:25:26.234490 15749 solver.cpp:237]     Train net output #1: label_phocs = 777
I1211 15:25:26.234503 15749 solver.cpp:237]     Train net output #2: loss = 93.2103 (* 1 = 93.2103 loss)
I1211 15:25:26.234513 15749 sgd_solver.cpp:116] Iteration 700, lr = 0.0001
I1211 15:28:04.269484 15749 solver.cpp:218] Iteration 800 (0.632922 iter/s, 157.997s/100 iters), loss = 91.8444
I1211 15:28:04.269568 15749 solver.cpp:237]     Train net output #0: label = 591
I1211 15:28:04.269592 15749 solver.cpp:237]     Train net output #1: label_phocs = 591
I1211 15:28:04.269603 15749 solver.cpp:237]     Train net output #2: loss = 99.3372 (* 1 = 99.3372 loss)
I1211 15:28:04.269613 15749 sgd_solver.cpp:116] Iteration 800, lr = 0.0001
I1211 15:30:33.707780 15749 solver.cpp:218] Iteration 900 (0.669186 iter/s, 149.435s/100 iters), loss = 91.2594
I1211 15:30:33.707857 15749 solver.cpp:237]     Train net output #0: label = 564
I1211 15:30:33.707880 15749 solver.cpp:237]     Train net output #1: label_phocs = 564
I1211 15:30:33.707893 15749 solver.cpp:237]     Train net output #2: loss = 84.0393 (* 1 = 84.0393 loss)
I1211 15:30:33.707902 15749 sgd_solver.cpp:116] Iteration 900, lr = 0.0001
[2017-12-11 15:32:55,425, PHOCNetTrainer] Running test evaluation
[2017-12-11 15:32:55,425, PHOCNetTrainer] Evaluating CNN after 500 steps:
I1211 15:33:49.299854 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:33:49.299975 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 15:33:50,161, PHOCNetTrainer] mAP: 0.067331
I1211 15:33:50.162415 15749 solver.cpp:330] Iteration 1000, Testing net (#0)
I1211 15:33:50.162592 15749 net.cpp:676] Ignoring source layer drop6
I1211 15:33:50.162600 15749 net.cpp:676] Ignoring source layer drop7
I1211 15:34:31.591683 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:34:31.591809 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:34:32.296983 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 15:34:32.297024 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 15:34:32.297031 15749 solver.cpp:397]     Test net output #2: loss = 71.0264 (* 1 = 71.0264 loss)
I1211 15:34:34.852561 15749 solver.cpp:218] Iteration 1000 (0.414708 iter/s, 241.133s/100 iters), loss = 91.6946
I1211 15:34:34.852639 15749 solver.cpp:237]     Train net output #0: label = 962
I1211 15:34:34.852663 15749 solver.cpp:237]     Train net output #1: label_phocs = 962
I1211 15:34:34.852674 15749 solver.cpp:237]     Train net output #2: loss = 81.9474 (* 1 = 81.9474 loss)
I1211 15:34:34.852684 15749 sgd_solver.cpp:116] Iteration 1000, lr = 0.0001
I1211 15:37:06.207129 15749 solver.cpp:218] Iteration 1100 (0.6607 iter/s, 151.355s/100 iters), loss = 88.6392
I1211 15:37:06.207219 15749 solver.cpp:237]     Train net output #0: label = 69
I1211 15:37:06.207242 15749 solver.cpp:237]     Train net output #1: label_phocs = 69
I1211 15:37:06.207254 15749 solver.cpp:237]     Train net output #2: loss = 75.2847 (* 1 = 75.2847 loss)
I1211 15:37:06.207263 15749 sgd_solver.cpp:116] Iteration 1100, lr = 0.0001
I1211 15:39:34.558060 15749 solver.cpp:218] Iteration 1200 (0.674077 iter/s, 148.351s/100 iters), loss = 89.6688
I1211 15:39:34.558146 15749 solver.cpp:237]     Train net output #0: label = 110
I1211 15:39:34.558171 15749 solver.cpp:237]     Train net output #1: label_phocs = 110
I1211 15:39:34.558182 15749 solver.cpp:237]     Train net output #2: loss = 98.3791 (* 1 = 98.3791 loss)
I1211 15:39:34.558192 15749 sgd_solver.cpp:116] Iteration 1200, lr = 0.0001
I1211 15:42:02.232801 15749 solver.cpp:218] Iteration 1300 (0.677263 iter/s, 147.653s/100 iters), loss = 90.5057
I1211 15:42:02.232877 15749 solver.cpp:237]     Train net output #0: label = 251
I1211 15:42:02.232900 15749 solver.cpp:237]     Train net output #1: label_phocs = 251
I1211 15:42:02.232911 15749 solver.cpp:237]     Train net output #2: loss = 93.7062 (* 1 = 93.7062 loss)
I1211 15:42:02.232920 15749 sgd_solver.cpp:116] Iteration 1300, lr = 0.0001
I1211 15:44:25.972086 15749 solver.cpp:218] Iteration 1400 (0.695704 iter/s, 143.739s/100 iters), loss = 88.7645
I1211 15:44:25.972179 15749 solver.cpp:237]     Train net output #0: label = 837
I1211 15:44:25.972203 15749 solver.cpp:237]     Train net output #1: label_phocs = 837
I1211 15:44:25.972215 15749 solver.cpp:237]     Train net output #2: loss = 133.015 (* 1 = 133.015 loss)
I1211 15:44:25.972224 15749 sgd_solver.cpp:116] Iteration 1400, lr = 0.0001
[2017-12-11 15:46:35,833, PHOCNetTrainer] Running test evaluation
[2017-12-11 15:46:35,833, PHOCNetTrainer] Evaluating CNN after 1000 steps:
I1211 15:47:15.822928 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:47:15.822944 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 15:47:17,452, PHOCNetTrainer] mAP: 0.071946
I1211 15:47:17.453655 15749 solver.cpp:330] Iteration 1500, Testing net (#0)
I1211 15:47:17.453858 15749 net.cpp:676] Ignoring source layer drop6
I1211 15:47:17.453868 15749 net.cpp:676] Ignoring source layer drop7
I1211 15:48:06.611853 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:48:06.611977 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 15:48:07.287619 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 15:48:07.287667 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 15:48:07.287680 15749 solver.cpp:397]     Test net output #2: loss = 72.2426 (* 1 = 72.2426 loss)
I1211 15:48:08.692860 15749 solver.cpp:218] Iteration 1500 (0.449026 iter/s, 222.704s/100 iters), loss = 79.7521
I1211 15:48:08.692945 15749 solver.cpp:237]     Train net output #0: label = 52
I1211 15:48:08.692970 15749 solver.cpp:237]     Train net output #1: label_phocs = 52
I1211 15:48:08.692981 15749 solver.cpp:237]     Train net output #2: loss = 50.4048 (* 1 = 50.4048 loss)
I1211 15:48:08.692991 15749 sgd_solver.cpp:116] Iteration 1500, lr = 0.0001
I1211 15:50:38.787127 15749 solver.cpp:218] Iteration 1600 (0.666248 iter/s, 150.094s/100 iters), loss = 91.8424
I1211 15:50:38.787204 15749 solver.cpp:237]     Train net output #0: label = 507
I1211 15:50:38.787226 15749 solver.cpp:237]     Train net output #1: label_phocs = 507
I1211 15:50:38.787240 15749 solver.cpp:237]     Train net output #2: loss = 92.4834 (* 1 = 92.4834 loss)
I1211 15:50:38.787248 15749 sgd_solver.cpp:116] Iteration 1600, lr = 0.0001
I1211 15:53:02.995227 15749 solver.cpp:218] Iteration 1700 (0.69363 iter/s, 144.169s/100 iters), loss = 88.3669
I1211 15:53:02.995316 15749 solver.cpp:237]     Train net output #0: label = 695
I1211 15:53:02.995340 15749 solver.cpp:237]     Train net output #1: label_phocs = 695
I1211 15:53:02.995353 15749 solver.cpp:237]     Train net output #2: loss = 87.6085 (* 1 = 87.6085 loss)
I1211 15:53:02.995362 15749 sgd_solver.cpp:116] Iteration 1700, lr = 0.0001
I1211 15:55:29.600565 15749 solver.cpp:218] Iteration 1800 (0.682104 iter/s, 146.605s/100 iters), loss = 88.3313
I1211 15:55:29.600661 15749 solver.cpp:237]     Train net output #0: label = 353
I1211 15:55:29.600684 15749 solver.cpp:237]     Train net output #1: label_phocs = 353
I1211 15:55:29.600697 15749 solver.cpp:237]     Train net output #2: loss = 146.268 (* 1 = 146.268 loss)
I1211 15:55:29.600706 15749 sgd_solver.cpp:116] Iteration 1800, lr = 0.0001
I1211 15:58:01.493674 15749 solver.cpp:218] Iteration 1900 (0.658358 iter/s, 151.893s/100 iters), loss = 88.4681
I1211 15:58:01.493759 15749 solver.cpp:237]     Train net output #0: label = 59
I1211 15:58:01.493784 15749 solver.cpp:237]     Train net output #1: label_phocs = 59
I1211 15:58:01.493796 15749 solver.cpp:237]     Train net output #2: loss = 23.4595 (* 1 = 23.4595 loss)
I1211 15:58:01.493805 15749 sgd_solver.cpp:116] Iteration 1900, lr = 0.0001
[2017-12-11 16:00:23,534, PHOCNetTrainer] Running test evaluation
[2017-12-11 16:00:23,534, PHOCNetTrainer] Evaluating CNN after 1500 steps:
I1211 16:00:57.671612 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:00:57.671880 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 16:01:00,982, PHOCNetTrainer] mAP: 0.071526
I1211 16:01:00.983508 15749 solver.cpp:330] Iteration 2000, Testing net (#0)
I1211 16:01:00.983688 15749 net.cpp:676] Ignoring source layer drop6
I1211 16:01:00.983695 15749 net.cpp:676] Ignoring source layer drop7
I1211 16:01:46.320585 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:01:46.320597 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:01:46.638366 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 16:01:46.638409 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 16:01:46.638420 15749 solver.cpp:397]     Test net output #2: loss = 73.2957 (* 1 = 73.2957 loss)
I1211 16:01:47.932358 15749 solver.cpp:218] Iteration 2000 (0.441656 iter/s, 226.42s/100 iters), loss = 94.4701
I1211 16:01:47.932437 15749 solver.cpp:237]     Train net output #0: label = 597
I1211 16:01:47.932462 15749 solver.cpp:237]     Train net output #1: label_phocs = 597
I1211 16:01:47.932474 15749 solver.cpp:237]     Train net output #2: loss = 84.2599 (* 1 = 84.2599 loss)
I1211 16:01:47.932483 15749 sgd_solver.cpp:116] Iteration 2000, lr = 0.0001
I1211 16:04:09.509502 15749 solver.cpp:218] Iteration 2100 (0.706329 iter/s, 141.577s/100 iters), loss = 88.4116
I1211 16:04:09.509577 15749 solver.cpp:237]     Train net output #0: label = 824
I1211 16:04:09.509596 15749 solver.cpp:237]     Train net output #1: label_phocs = 824
I1211 16:04:09.509604 15749 solver.cpp:237]     Train net output #2: loss = 127.192 (* 1 = 127.192 loss)
I1211 16:04:09.509613 15749 sgd_solver.cpp:116] Iteration 2100, lr = 0.0001
I1211 16:06:33.587785 15749 solver.cpp:218] Iteration 2200 (0.694187 iter/s, 144.053s/100 iters), loss = 85.8965
I1211 16:06:33.587867 15749 solver.cpp:237]     Train net output #0: label = 368
I1211 16:06:33.587890 15749 solver.cpp:237]     Train net output #1: label_phocs = 368
I1211 16:06:33.587903 15749 solver.cpp:237]     Train net output #2: loss = 46.8503 (* 1 = 46.8503 loss)
I1211 16:06:33.587911 15749 sgd_solver.cpp:116] Iteration 2200, lr = 0.0001
I1211 16:09:44.345474 15749 solver.cpp:218] Iteration 2300 (0.52429 iter/s, 190.734s/100 iters), loss = 87.4358
I1211 16:09:44.346737 15749 solver.cpp:237]     Train net output #0: label = 881
I1211 16:09:44.346766 15749 solver.cpp:237]     Train net output #1: label_phocs = 881
I1211 16:09:44.346778 15749 solver.cpp:237]     Train net output #2: loss = 54.7933 (* 1 = 54.7933 loss)
I1211 16:09:44.346787 15749 sgd_solver.cpp:116] Iteration 2300, lr = 0.0001
I1211 16:13:04.248662 15749 solver.cpp:218] Iteration 2400 (0.500245 iter/s, 199.902s/100 iters), loss = 87.4184
I1211 16:13:04.248760 15749 solver.cpp:237]     Train net output #0: label = 844
I1211 16:13:04.248785 15749 solver.cpp:237]     Train net output #1: label_phocs = 844
I1211 16:13:04.248796 15749 solver.cpp:237]     Train net output #2: loss = 66.2145 (* 1 = 66.2145 loss)
I1211 16:13:04.248805 15749 sgd_solver.cpp:116] Iteration 2400, lr = 0.0001
[2017-12-11 16:15:31,861, PHOCNetTrainer] Running test evaluation
[2017-12-11 16:15:31,861, PHOCNetTrainer] Evaluating CNN after 2000 steps:
I1211 16:16:18.971863 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:16:18.972008 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 16:16:21,095, PHOCNetTrainer] mAP: 0.087035
I1211 16:16:21.096882 15749 solver.cpp:330] Iteration 2500, Testing net (#0)
I1211 16:16:21.097123 15749 net.cpp:676] Ignoring source layer drop6
I1211 16:16:21.097139 15749 net.cpp:676] Ignoring source layer drop7
I1211 16:17:01.335965 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:17:01.336119 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:17:01.731681 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 16:17:01.731730 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 16:17:01.731742 15749 solver.cpp:397]     Test net output #2: loss = 73.6898 (* 1 = 73.6898 loss)
I1211 16:17:03.293546 15749 solver.cpp:218] Iteration 2500 (0.418331 iter/s, 239.045s/100 iters), loss = 95.5364
I1211 16:17:03.293625 15749 solver.cpp:237]     Train net output #0: label = 333
I1211 16:17:03.293648 15749 solver.cpp:237]     Train net output #1: label_phocs = 333
I1211 16:17:03.293660 15749 solver.cpp:237]     Train net output #2: loss = 119.357 (* 1 = 119.357 loss)
I1211 16:17:03.293669 15749 sgd_solver.cpp:116] Iteration 2500, lr = 0.0001
I1211 16:19:33.247910 15749 solver.cpp:218] Iteration 2600 (0.66687 iter/s, 149.954s/100 iters), loss = 87.286
I1211 16:19:33.248008 15749 solver.cpp:237]     Train net output #0: label = 981
I1211 16:19:33.248036 15749 solver.cpp:237]     Train net output #1: label_phocs = 981
I1211 16:19:33.248057 15749 solver.cpp:237]     Train net output #2: loss = 47.4827 (* 1 = 47.4827 loss)
I1211 16:19:33.248070 15749 sgd_solver.cpp:116] Iteration 2600, lr = 0.0001
I1211 16:22:04.048708 15749 solver.cpp:218] Iteration 2700 (0.663139 iter/s, 150.798s/100 iters), loss = 85.1342
I1211 16:22:04.048789 15749 solver.cpp:237]     Train net output #0: label = 925
I1211 16:22:04.048813 15749 solver.cpp:237]     Train net output #1: label_phocs = 925
I1211 16:22:04.048825 15749 solver.cpp:237]     Train net output #2: loss = 96.7966 (* 1 = 96.7966 loss)
I1211 16:22:04.048835 15749 sgd_solver.cpp:116] Iteration 2700, lr = 0.0001
I1211 16:24:34.123901 15749 solver.cpp:218] Iteration 2800 (0.666369 iter/s, 150.067s/100 iters), loss = 85.3583
I1211 16:24:34.123976 15749 solver.cpp:237]     Train net output #0: label = 181
I1211 16:24:34.124001 15749 solver.cpp:237]     Train net output #1: label_phocs = 181
I1211 16:24:34.124012 15749 solver.cpp:237]     Train net output #2: loss = 72.4615 (* 1 = 72.4615 loss)
I1211 16:24:34.124022 15749 sgd_solver.cpp:116] Iteration 2800, lr = 0.0001
I1211 16:26:57.452585 15749 solver.cpp:218] Iteration 2900 (0.697697 iter/s, 143.329s/100 iters), loss = 85.4905
I1211 16:26:57.482261 15749 solver.cpp:237]     Train net output #0: label = 841
I1211 16:26:57.482311 15749 solver.cpp:237]     Train net output #1: label_phocs = 841
I1211 16:26:57.482323 15749 solver.cpp:237]     Train net output #2: loss = 85.9457 (* 1 = 85.9457 loss)
I1211 16:26:57.482332 15749 sgd_solver.cpp:116] Iteration 2900, lr = 0.0001
[2017-12-11 16:29:27,192, PHOCNetTrainer] Running test evaluation
[2017-12-11 16:29:27,193, PHOCNetTrainer] Evaluating CNN after 2500 steps:
I1211 16:30:02.175454 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:30:02.175511 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 16:30:03,454, PHOCNetTrainer] mAP: 0.107198
I1211 16:30:03.456429 15749 solver.cpp:330] Iteration 3000, Testing net (#0)
I1211 16:30:03.456661 15749 net.cpp:676] Ignoring source layer drop6
I1211 16:30:03.456676 15749 net.cpp:676] Ignoring source layer drop7
I1211 16:30:48.319862 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:30:48.320005 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:30:49.074721 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 16:30:49.074769 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 16:30:49.074780 15749 solver.cpp:397]     Test net output #2: loss = 71.9986 (* 1 = 71.9986 loss)
I1211 16:30:50.609843 15749 solver.cpp:218] Iteration 3000 (0.429014 iter/s, 233.092s/100 iters), loss = 88.9386
I1211 16:30:50.609921 15749 solver.cpp:237]     Train net output #0: label = 564
I1211 16:30:50.609943 15749 solver.cpp:237]     Train net output #1: label_phocs = 564
I1211 16:30:50.609956 15749 solver.cpp:237]     Train net output #2: loss = 79.4572 (* 1 = 79.4572 loss)
I1211 16:30:50.609964 15749 sgd_solver.cpp:116] Iteration 3000, lr = 0.0001
I1211 16:33:15.090219 15749 solver.cpp:218] Iteration 3100 (0.692136 iter/s, 144.48s/100 iters), loss = 84.9524
I1211 16:33:15.090298 15749 solver.cpp:237]     Train net output #0: label = 814
I1211 16:33:15.090322 15749 solver.cpp:237]     Train net output #1: label_phocs = 814
I1211 16:33:15.090332 15749 solver.cpp:237]     Train net output #2: loss = 88.1841 (* 1 = 88.1841 loss)
I1211 16:33:15.090342 15749 sgd_solver.cpp:116] Iteration 3100, lr = 0.0001
I1211 16:35:40.887620 15749 solver.cpp:218] Iteration 3200 (0.685883 iter/s, 145.797s/100 iters), loss = 86.1876
I1211 16:35:40.887689 15749 solver.cpp:237]     Train net output #0: label = 559
I1211 16:35:40.887709 15749 solver.cpp:237]     Train net output #1: label_phocs = 559
I1211 16:35:40.887717 15749 solver.cpp:237]     Train net output #2: loss = 102.169 (* 1 = 102.169 loss)
I1211 16:35:40.887723 15749 sgd_solver.cpp:116] Iteration 3200, lr = 0.0001
I1211 16:38:02.395479 15749 solver.cpp:218] Iteration 3300 (0.706675 iter/s, 141.508s/100 iters), loss = 84.295
I1211 16:38:02.395556 15749 solver.cpp:237]     Train net output #0: label = 341
I1211 16:38:02.395587 15749 solver.cpp:237]     Train net output #1: label_phocs = 341
I1211 16:38:02.395601 15749 solver.cpp:237]     Train net output #2: loss = 116.832 (* 1 = 116.832 loss)
I1211 16:38:02.395609 15749 sgd_solver.cpp:116] Iteration 3300, lr = 0.0001
I1211 16:40:33.608464 15749 solver.cpp:218] Iteration 3400 (0.661535 iter/s, 151.163s/100 iters), loss = 84.2553
I1211 16:40:33.608541 15749 solver.cpp:237]     Train net output #0: label = 1079
I1211 16:40:33.608564 15749 solver.cpp:237]     Train net output #1: label_phocs = 1079
I1211 16:40:33.608577 15749 solver.cpp:237]     Train net output #2: loss = 68.4166 (* 1 = 68.4166 loss)
I1211 16:40:33.608585 15749 sgd_solver.cpp:116] Iteration 3400, lr = 0.0001
[2017-12-11 16:43:00,666, PHOCNetTrainer] Running test evaluation
[2017-12-11 16:43:00,666, PHOCNetTrainer] Evaluating CNN after 3000 steps:
I1211 16:43:52.808060 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:43:52.808264 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 16:43:53,807, PHOCNetTrainer] mAP: 0.134278
I1211 16:43:53.809208 15749 solver.cpp:330] Iteration 3500, Testing net (#0)
I1211 16:43:53.809401 15749 net.cpp:676] Ignoring source layer drop6
I1211 16:43:53.809412 15749 net.cpp:676] Ignoring source layer drop7
I1211 16:44:43.383841 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:44:43.383930 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 16:44:44.366897 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 16:44:44.366948 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 16:44:44.366960 15749 solver.cpp:397]     Test net output #2: loss = 71.4669 (* 1 = 71.4669 loss)
I1211 16:44:45.863966 15749 solver.cpp:218] Iteration 3500 (0.396512 iter/s, 252.199s/100 iters), loss = 86.1524
I1211 16:44:45.864055 15749 solver.cpp:237]     Train net output #0: label = 68
I1211 16:44:45.864078 15749 solver.cpp:237]     Train net output #1: label_phocs = 68
I1211 16:44:45.864090 15749 solver.cpp:237]     Train net output #2: loss = 67.158 (* 1 = 67.158 loss)
I1211 16:44:45.864100 15749 sgd_solver.cpp:116] Iteration 3500, lr = 0.0001
I1211 16:47:10.712239 15749 solver.cpp:218] Iteration 3600 (0.690378 iter/s, 144.848s/100 iters), loss = 83.8972
I1211 16:47:10.712330 15749 solver.cpp:237]     Train net output #0: label = 357
I1211 16:47:10.712355 15749 solver.cpp:237]     Train net output #1: label_phocs = 357
I1211 16:47:10.712368 15749 solver.cpp:237]     Train net output #2: loss = 87.9184 (* 1 = 87.9184 loss)
I1211 16:47:10.712376 15749 sgd_solver.cpp:116] Iteration 3600, lr = 0.0001
I1211 16:49:40.591084 15749 solver.cpp:218] Iteration 3700 (0.667243 iter/s, 149.87s/100 iters), loss = 82.9967
I1211 16:49:40.591161 15749 solver.cpp:237]     Train net output #0: label = 338
I1211 16:49:40.591181 15749 solver.cpp:237]     Train net output #1: label_phocs = 338
I1211 16:49:40.591188 15749 solver.cpp:237]     Train net output #2: loss = 90.6164 (* 1 = 90.6164 loss)
I1211 16:49:40.591195 15749 sgd_solver.cpp:116] Iteration 3700, lr = 0.0001
I1211 16:52:57.761293 15749 solver.cpp:218] Iteration 3800 (0.507222 iter/s, 197.152s/100 iters), loss = 81.3373
I1211 16:52:57.761370 15749 solver.cpp:237]     Train net output #0: label = 1098
I1211 16:52:57.761399 15749 solver.cpp:237]     Train net output #1: label_phocs = 1098
I1211 16:52:57.761411 15749 solver.cpp:237]     Train net output #2: loss = 69.8506 (* 1 = 69.8506 loss)
I1211 16:52:57.761420 15749 sgd_solver.cpp:116] Iteration 3800, lr = 0.0001
I1211 16:56:12.497032 15749 solver.cpp:218] Iteration 3900 (0.513534 iter/s, 194.729s/100 iters), loss = 82.6121
I1211 16:56:12.497123 15749 solver.cpp:237]     Train net output #0: label = 938
I1211 16:56:12.497145 15749 solver.cpp:237]     Train net output #1: label_phocs = 938
I1211 16:56:12.497158 15749 solver.cpp:237]     Train net output #2: loss = 101.598 (* 1 = 101.598 loss)
I1211 16:56:12.497167 15749 sgd_solver.cpp:116] Iteration 3900, lr = 0.0001
[2017-12-11 16:59:32,856, PHOCNetTrainer] Running test evaluation
[2017-12-11 16:59:32,856, PHOCNetTrainer] Evaluating CNN after 3500 steps:
I1211 17:00:45.404518 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:00:45.404517 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 17:00:46,968, PHOCNetTrainer] mAP: 0.149938
I1211 17:00:46.970332 15749 solver.cpp:330] Iteration 4000, Testing net (#0)
I1211 17:00:46.970531 15749 net.cpp:676] Ignoring source layer drop6
I1211 17:00:46.970541 15749 net.cpp:676] Ignoring source layer drop7
I1211 17:01:53.167835 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:01:53.168030 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:01:54.020421 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 17:01:54.020457 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 17:01:54.020463 15749 solver.cpp:397]     Test net output #2: loss = 70.7851 (* 1 = 70.7851 loss)
I1211 17:01:55.745719 15749 solver.cpp:218] Iteration 4000 (0.291334 iter/s, 343.249s/100 iters), loss = 91.3509
I1211 17:01:55.745929 15749 solver.cpp:237]     Train net output #0: label = 374
I1211 17:01:55.745993 15749 solver.cpp:237]     Train net output #1: label_phocs = 374
I1211 17:01:55.746021 15749 solver.cpp:237]     Train net output #2: loss = 95.3781 (* 1 = 95.3781 loss)
I1211 17:01:55.746042 15749 sgd_solver.cpp:116] Iteration 4000, lr = 0.0001
I1211 17:05:19.955147 15749 solver.cpp:218] Iteration 4100 (0.489694 iter/s, 204.209s/100 iters), loss = 79.833
I1211 17:05:19.955260 15749 solver.cpp:237]     Train net output #0: label = 475
I1211 17:05:19.955289 15749 solver.cpp:237]     Train net output #1: label_phocs = 475
I1211 17:05:19.955305 15749 solver.cpp:237]     Train net output #2: loss = 69.5073 (* 1 = 69.5073 loss)
I1211 17:05:19.955317 15749 sgd_solver.cpp:116] Iteration 4100, lr = 0.0001
I1211 17:08:39.645920 15749 solver.cpp:218] Iteration 4200 (0.500774 iter/s, 199.691s/100 iters), loss = 81.4934
I1211 17:08:39.646025 15749 solver.cpp:237]     Train net output #0: label = 797
I1211 17:08:39.646054 15749 solver.cpp:237]     Train net output #1: label_phocs = 797
I1211 17:08:39.646067 15749 solver.cpp:237]     Train net output #2: loss = 33.5966 (* 1 = 33.5966 loss)
I1211 17:08:39.646078 15749 sgd_solver.cpp:116] Iteration 4200, lr = 0.0001
I1211 17:12:00.690001 15749 solver.cpp:218] Iteration 4300 (0.497403 iter/s, 201.044s/100 iters), loss = 80.9759
I1211 17:12:00.690085 15749 solver.cpp:237]     Train net output #0: label = 425
I1211 17:12:00.690109 15749 solver.cpp:237]     Train net output #1: label_phocs = 425
I1211 17:12:00.690121 15749 solver.cpp:237]     Train net output #2: loss = 62.5966 (* 1 = 62.5966 loss)
I1211 17:12:00.690130 15749 sgd_solver.cpp:116] Iteration 4300, lr = 0.0001
I1211 17:14:43.500371 15749 solver.cpp:218] Iteration 4400 (0.614211 iter/s, 162.81s/100 iters), loss = 80.6288
I1211 17:14:43.500444 15749 solver.cpp:237]     Train net output #0: label = 807
I1211 17:14:43.500463 15749 solver.cpp:237]     Train net output #1: label_phocs = 807
I1211 17:14:43.500473 15749 solver.cpp:237]     Train net output #2: loss = 65.6239 (* 1 = 65.6239 loss)
I1211 17:14:43.500479 15749 sgd_solver.cpp:116] Iteration 4400, lr = 0.0001
[2017-12-11 17:17:17,716, PHOCNetTrainer] Running test evaluation
[2017-12-11 17:17:17,716, PHOCNetTrainer] Evaluating CNN after 4000 steps:
I1211 17:17:59.374373 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:17:59.374850 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 17:18:00,590, PHOCNetTrainer] mAP: 0.209442
I1211 17:18:00.592480 15749 solver.cpp:330] Iteration 4500, Testing net (#0)
I1211 17:18:00.592707 15749 net.cpp:676] Ignoring source layer drop6
I1211 17:18:00.592720 15749 net.cpp:676] Ignoring source layer drop7
I1211 17:18:49.529965 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:18:49.532120 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:18:49.977422 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 17:18:49.977473 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 17:18:49.977485 15749 solver.cpp:397]     Test net output #2: loss = 68.3934 (* 1 = 68.3934 loss)
I1211 17:18:51.626111 15749 solver.cpp:218] Iteration 4500 (0.403021 iter/s, 248.126s/100 iters), loss = 88.5819
I1211 17:18:51.626180 15749 solver.cpp:237]     Train net output #0: label = 892
I1211 17:18:51.626199 15749 solver.cpp:237]     Train net output #1: label_phocs = 892
I1211 17:18:51.626207 15749 solver.cpp:237]     Train net output #2: loss = 120.571 (* 1 = 120.571 loss)
I1211 17:18:51.626214 15749 sgd_solver.cpp:116] Iteration 4500, lr = 0.0001
I1211 17:21:26.240420 15749 solver.cpp:218] Iteration 4600 (0.646771 iter/s, 154.614s/100 iters), loss = 78.7691
I1211 17:21:26.240510 15749 solver.cpp:237]     Train net output #0: label = 784
I1211 17:21:26.240535 15749 solver.cpp:237]     Train net output #1: label_phocs = 784
I1211 17:21:26.240547 15749 solver.cpp:237]     Train net output #2: loss = 61.6007 (* 1 = 61.6007 loss)
I1211 17:21:26.240558 15749 sgd_solver.cpp:116] Iteration 4600, lr = 0.0001
I1211 17:24:07.072743 15749 solver.cpp:218] Iteration 4700 (0.621766 iter/s, 160.832s/100 iters), loss = 78.1313
I1211 17:24:07.072840 15749 solver.cpp:237]     Train net output #0: label = 1111
I1211 17:24:07.072875 15749 solver.cpp:237]     Train net output #1: label_phocs = 1111
I1211 17:24:07.072892 15749 solver.cpp:237]     Train net output #2: loss = 55.0121 (* 1 = 55.0121 loss)
I1211 17:24:07.072904 15749 sgd_solver.cpp:116] Iteration 4700, lr = 0.0001
I1211 17:27:27.024598 15749 solver.cpp:218] Iteration 4800 (0.50012 iter/s, 199.952s/100 iters), loss = 78.5591
I1211 17:27:27.024710 15749 solver.cpp:237]     Train net output #0: label = 498
I1211 17:27:27.024741 15749 solver.cpp:237]     Train net output #1: label_phocs = 498
I1211 17:27:27.024758 15749 solver.cpp:237]     Train net output #2: loss = 59.4547 (* 1 = 59.4547 loss)
I1211 17:27:27.024770 15749 sgd_solver.cpp:116] Iteration 4800, lr = 0.0001
I1211 17:30:21.029745 15749 solver.cpp:218] Iteration 4900 (0.574696 iter/s, 174.005s/100 iters), loss = 77.7779
I1211 17:30:21.029826 15749 solver.cpp:237]     Train net output #0: label = 300
I1211 17:30:21.029846 15749 solver.cpp:237]     Train net output #1: label_phocs = 300
I1211 17:30:21.029855 15749 solver.cpp:237]     Train net output #2: loss = 58.1559 (* 1 = 58.1559 loss)
I1211 17:30:21.029862 15749 sgd_solver.cpp:116] Iteration 4900, lr = 0.0001
[2017-12-11 17:32:43,955, PHOCNetTrainer] Running test evaluation
[2017-12-11 17:32:43,955, PHOCNetTrainer] Evaluating CNN after 4500 steps:
I1211 17:33:30.888236 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:33:30.888232 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 17:33:32,116, PHOCNetTrainer] mAP: 0.271912
I1211 17:33:32.117897 15749 solver.cpp:330] Iteration 5000, Testing net (#0)
I1211 17:33:32.118083 15749 net.cpp:676] Ignoring source layer drop6
I1211 17:33:32.118093 15749 net.cpp:676] Ignoring source layer drop7
I1211 17:34:23.048079 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:34:23.048306 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:34:23.353622 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 17:34:23.353669 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 17:34:23.353680 15749 solver.cpp:397]     Test net output #2: loss = 65.872 (* 1 = 65.872 loss)
I1211 17:34:24.431190 15749 solver.cpp:218] Iteration 5000 (0.410844 iter/s, 243.401s/100 iters), loss = 78.0817
I1211 17:34:24.431264 15749 solver.cpp:237]     Train net output #0: label = 199
I1211 17:34:24.431288 15749 solver.cpp:237]     Train net output #1: label_phocs = 199
I1211 17:34:24.431299 15749 solver.cpp:237]     Train net output #2: loss = 111.637 (* 1 = 111.637 loss)
I1211 17:34:24.431316 15749 sgd_solver.cpp:116] Iteration 5000, lr = 0.0001
I1211 17:36:59.045586 15749 solver.cpp:218] Iteration 5100 (0.646889 iter/s, 154.586s/100 iters), loss = 77.2346
I1211 17:36:59.045670 15749 solver.cpp:237]     Train net output #0: label = 496
I1211 17:36:59.045694 15749 solver.cpp:237]     Train net output #1: label_phocs = 496
I1211 17:36:59.045706 15749 solver.cpp:237]     Train net output #2: loss = 84.5348 (* 1 = 84.5348 loss)
I1211 17:36:59.045714 15749 sgd_solver.cpp:116] Iteration 5100, lr = 0.0001
I1211 17:39:25.555632 15749 solver.cpp:218] Iteration 5200 (0.682882 iter/s, 146.438s/100 iters), loss = 75.7179
I1211 17:39:25.555712 15749 solver.cpp:237]     Train net output #0: label = 901
I1211 17:39:25.555737 15749 solver.cpp:237]     Train net output #1: label_phocs = 901
I1211 17:39:25.555752 15749 solver.cpp:237]     Train net output #2: loss = 131.521 (* 1 = 131.521 loss)
I1211 17:39:25.555761 15749 sgd_solver.cpp:116] Iteration 5200, lr = 0.0001
I1211 17:41:52.242631 15749 solver.cpp:218] Iteration 5300 (0.681724 iter/s, 146.687s/100 iters), loss = 74.2006
I1211 17:41:52.242717 15749 solver.cpp:237]     Train net output #0: label = 773
I1211 17:41:52.242739 15749 solver.cpp:237]     Train net output #1: label_phocs = 773
I1211 17:41:52.242751 15749 solver.cpp:237]     Train net output #2: loss = 53.6636 (* 1 = 53.6636 loss)
I1211 17:41:52.242760 15749 sgd_solver.cpp:116] Iteration 5300, lr = 0.0001
I1211 17:44:18.002915 15749 solver.cpp:218] Iteration 5400 (0.686302 iter/s, 145.708s/100 iters), loss = 75.0244
I1211 17:44:18.003021 15749 solver.cpp:237]     Train net output #0: label = 493
I1211 17:44:18.003044 15749 solver.cpp:237]     Train net output #1: label_phocs = 493
I1211 17:44:18.003057 15749 solver.cpp:237]     Train net output #2: loss = 31.1926 (* 1 = 31.1926 loss)
I1211 17:44:18.003067 15749 sgd_solver.cpp:116] Iteration 5400, lr = 0.0001
[2017-12-11 17:46:41,261, PHOCNetTrainer] Running test evaluation
[2017-12-11 17:46:41,261, PHOCNetTrainer] Evaluating CNN after 5000 steps:
I1211 17:47:25.841001 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:47:25.841007 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 17:47:28,874, PHOCNetTrainer] mAP: 0.319294
I1211 17:47:28.875708 15749 solver.cpp:330] Iteration 5500, Testing net (#0)
I1211 17:47:28.875924 15749 net.cpp:676] Ignoring source layer drop6
I1211 17:47:28.875934 15749 net.cpp:676] Ignoring source layer drop7
I1211 17:48:10.932085 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:48:10.932283 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 17:48:11.375108 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 17:48:11.375149 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 17:48:11.375160 15749 solver.cpp:397]     Test net output #2: loss = 65.4153 (* 1 = 65.4153 loss)
I1211 17:48:12.538388 15749 solver.cpp:218] Iteration 5500 (0.426375 iter/s, 234.535s/100 iters), loss = 69.3478
I1211 17:48:12.538468 15749 solver.cpp:237]     Train net output #0: label = 688
I1211 17:48:12.538492 15749 solver.cpp:237]     Train net output #1: label_phocs = 688
I1211 17:48:12.538504 15749 solver.cpp:237]     Train net output #2: loss = 17.7216 (* 1 = 17.7216 loss)
I1211 17:48:12.538514 15749 sgd_solver.cpp:116] Iteration 5500, lr = 0.0001
I1211 17:50:40.017778 15749 solver.cpp:218] Iteration 5600 (0.678253 iter/s, 147.438s/100 iters), loss = 74.6874
I1211 17:50:40.017863 15749 solver.cpp:237]     Train net output #0: label = 450
I1211 17:50:40.017887 15749 solver.cpp:237]     Train net output #1: label_phocs = 450
I1211 17:50:40.017899 15749 solver.cpp:237]     Train net output #2: loss = 78.0335 (* 1 = 78.0335 loss)
I1211 17:50:40.017910 15749 sgd_solver.cpp:116] Iteration 5600, lr = 0.0001
I1211 17:53:07.398434 15749 solver.cpp:218] Iteration 5700 (0.678515 iter/s, 147.381s/100 iters), loss = 74.617
I1211 17:53:07.398517 15749 solver.cpp:237]     Train net output #0: label = 433
I1211 17:53:07.398541 15749 solver.cpp:237]     Train net output #1: label_phocs = 433
I1211 17:53:07.398560 15749 solver.cpp:237]     Train net output #2: loss = 126.154 (* 1 = 126.154 loss)
I1211 17:53:07.398568 15749 sgd_solver.cpp:116] Iteration 5700, lr = 0.0001
I1211 17:55:30.171819 15749 solver.cpp:218] Iteration 5800 (0.700411 iter/s, 142.773s/100 iters), loss = 72.1281
I1211 17:55:30.171900 15749 solver.cpp:237]     Train net output #0: label = 1049
I1211 17:55:30.171924 15749 solver.cpp:237]     Train net output #1: label_phocs = 1049
I1211 17:55:30.171936 15749 solver.cpp:237]     Train net output #2: loss = 152.685 (* 1 = 152.685 loss)
I1211 17:55:30.171946 15749 sgd_solver.cpp:116] Iteration 5800, lr = 0.0001
I1211 17:57:56.376915 15749 solver.cpp:218] Iteration 5900 (0.683971 iter/s, 146.205s/100 iters), loss = 73.2306
I1211 17:57:56.376999 15749 solver.cpp:237]     Train net output #0: label = 809
I1211 17:57:56.377022 15749 solver.cpp:237]     Train net output #1: label_phocs = 809
I1211 17:57:56.377034 15749 solver.cpp:237]     Train net output #2: loss = 60.7 (* 1 = 60.7 loss)
I1211 17:57:56.377043 15749 sgd_solver.cpp:116] Iteration 5900, lr = 0.0001
[2017-12-11 18:00:17,096, PHOCNetTrainer] Running test evaluation
[2017-12-11 18:00:17,096, PHOCNetTrainer] Evaluating CNN after 5500 steps:
I1211 18:00:59.427857 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:00:59.427991 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 18:01:01,184, PHOCNetTrainer] mAP: 0.412508
I1211 18:01:01.186522 15749 solver.cpp:330] Iteration 6000, Testing net (#0)
I1211 18:01:01.186725 15749 net.cpp:676] Ignoring source layer drop6
I1211 18:01:01.186734 15749 net.cpp:676] Ignoring source layer drop7
I1211 18:01:41.898447 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:01:41.898452 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:01:42.438777 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 18:01:42.438827 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 18:01:42.438838 15749 solver.cpp:397]     Test net output #2: loss = 60.9699 (* 1 = 60.9699 loss)
I1211 18:01:44.033573 15749 solver.cpp:218] Iteration 6000 (0.439258 iter/s, 227.657s/100 iters), loss = 67.9417
I1211 18:01:44.033639 15749 solver.cpp:237]     Train net output #0: label = 56
I1211 18:01:44.033658 15749 solver.cpp:237]     Train net output #1: label_phocs = 56
I1211 18:01:44.033666 15749 solver.cpp:237]     Train net output #2: loss = 53.4151 (* 1 = 53.4151 loss)
I1211 18:01:44.033674 15749 sgd_solver.cpp:116] Iteration 6000, lr = 0.0001
I1211 18:04:07.984243 15749 solver.cpp:218] Iteration 6100 (0.694682 iter/s, 143.951s/100 iters), loss = 71.646
I1211 18:04:07.984329 15749 solver.cpp:237]     Train net output #0: label = 719
I1211 18:04:07.984354 15749 solver.cpp:237]     Train net output #1: label_phocs = 719
I1211 18:04:07.984365 15749 solver.cpp:237]     Train net output #2: loss = 49.3909 (* 1 = 49.3909 loss)
I1211 18:04:07.984375 15749 sgd_solver.cpp:116] Iteration 6100, lr = 0.0001
I1211 18:06:31.324769 15749 solver.cpp:218] Iteration 6200 (0.697639 iter/s, 143.341s/100 iters), loss = 70.7181
I1211 18:06:31.324851 15749 solver.cpp:237]     Train net output #0: label = 659
I1211 18:06:31.324877 15749 solver.cpp:237]     Train net output #1: label_phocs = 659
I1211 18:06:31.324889 15749 solver.cpp:237]     Train net output #2: loss = 52.2246 (* 1 = 52.2246 loss)
I1211 18:06:31.324898 15749 sgd_solver.cpp:116] Iteration 6200, lr = 0.0001
I1211 18:08:57.217831 15749 solver.cpp:218] Iteration 6300 (0.685434 iter/s, 145.893s/100 iters), loss = 69.8405
I1211 18:08:57.217918 15749 solver.cpp:237]     Train net output #0: label = 590
I1211 18:08:57.217942 15749 solver.cpp:237]     Train net output #1: label_phocs = 590
I1211 18:08:57.217954 15749 solver.cpp:237]     Train net output #2: loss = 94.0031 (* 1 = 94.0031 loss)
I1211 18:08:57.217963 15749 sgd_solver.cpp:116] Iteration 6300, lr = 0.0001
I1211 18:11:30.778435 15749 solver.cpp:218] Iteration 6400 (0.651209 iter/s, 153.561s/100 iters), loss = 68.7223
I1211 18:11:30.778514 15749 solver.cpp:237]     Train net output #0: label = 583
I1211 18:11:30.778538 15749 solver.cpp:237]     Train net output #1: label_phocs = 583
I1211 18:11:30.778550 15749 solver.cpp:237]     Train net output #2: loss = 57.4026 (* 1 = 57.4026 loss)
I1211 18:11:30.778559 15749 sgd_solver.cpp:116] Iteration 6400, lr = 0.0001
[2017-12-11 18:13:51,894, PHOCNetTrainer] Running test evaluation
[2017-12-11 18:13:51,895, PHOCNetTrainer] Evaluating CNN after 6000 steps:
I1211 18:14:45.007130 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:14:45.007158 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 18:14:46,777, PHOCNetTrainer] mAP: 0.459853
I1211 18:14:46.778889 15749 solver.cpp:330] Iteration 6500, Testing net (#0)
I1211 18:14:46.779083 15749 net.cpp:676] Ignoring source layer drop6
I1211 18:14:46.779093 15749 net.cpp:676] Ignoring source layer drop7
I1211 18:15:26.120674 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:15:26.120698 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:15:26.455873 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 18:15:26.455919 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 18:15:26.455931 15749 solver.cpp:397]     Test net output #2: loss = 56.8545 (* 1 = 56.8545 loss)
I1211 18:15:27.708639 15749 solver.cpp:218] Iteration 6500 (0.422065 iter/s, 236.93s/100 iters), loss = 67.5079
I1211 18:15:27.708714 15749 solver.cpp:237]     Train net output #0: label = 706
I1211 18:15:27.708735 15749 solver.cpp:237]     Train net output #1: label_phocs = 706
I1211 18:15:27.708746 15749 solver.cpp:237]     Train net output #2: loss = 43.7411 (* 1 = 43.7411 loss)
I1211 18:15:27.708755 15749 sgd_solver.cpp:116] Iteration 6500, lr = 0.0001
I1211 18:17:49.625504 15749 solver.cpp:218] Iteration 6600 (0.704638 iter/s, 141.917s/100 iters), loss = 68.4955
I1211 18:17:49.625571 15749 solver.cpp:237]     Train net output #0: label = 597
I1211 18:17:49.625591 15749 solver.cpp:237]     Train net output #1: label_phocs = 597
I1211 18:17:49.625599 15749 solver.cpp:237]     Train net output #2: loss = 82.2461 (* 1 = 82.2461 loss)
I1211 18:17:49.625607 15749 sgd_solver.cpp:116] Iteration 6600, lr = 0.0001
I1211 18:20:16.627240 15749 solver.cpp:218] Iteration 6700 (0.680264 iter/s, 147.002s/100 iters), loss = 67.0356
I1211 18:20:16.627326 15749 solver.cpp:237]     Train net output #0: label = 947
I1211 18:20:16.627349 15749 solver.cpp:237]     Train net output #1: label_phocs = 947
I1211 18:20:16.627360 15749 solver.cpp:237]     Train net output #2: loss = 59.4807 (* 1 = 59.4807 loss)
I1211 18:20:16.627369 15749 sgd_solver.cpp:116] Iteration 6700, lr = 0.0001
I1211 18:22:44.086326 15749 solver.cpp:218] Iteration 6800 (0.678161 iter/s, 147.458s/100 iters), loss = 65.9551
I1211 18:22:44.086410 15749 solver.cpp:237]     Train net output #0: label = 210
I1211 18:22:44.086436 15749 solver.cpp:237]     Train net output #1: label_phocs = 210
I1211 18:22:44.086447 15749 solver.cpp:237]     Train net output #2: loss = 57.7962 (* 1 = 57.7962 loss)
I1211 18:22:44.086457 15749 sgd_solver.cpp:116] Iteration 6800, lr = 0.0001
I1211 18:25:05.884033 15749 solver.cpp:218] Iteration 6900 (0.70523 iter/s, 141.798s/100 iters), loss = 66.6694
I1211 18:25:05.884116 15749 solver.cpp:237]     Train net output #0: label = 583
I1211 18:25:05.884140 15749 solver.cpp:237]     Train net output #1: label_phocs = 583
I1211 18:25:05.884152 15749 solver.cpp:237]     Train net output #2: loss = 48.3927 (* 1 = 48.3927 loss)
I1211 18:25:05.884161 15749 sgd_solver.cpp:116] Iteration 6900, lr = 0.0001
[2017-12-11 18:27:25,551, PHOCNetTrainer] Running test evaluation
[2017-12-11 18:27:25,552, PHOCNetTrainer] Evaluating CNN after 6500 steps:
I1211 18:28:01.056002 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:28:01.056033 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 18:28:02,257, PHOCNetTrainer] mAP: 0.499412
I1211 18:28:02.259105 15749 solver.cpp:330] Iteration 7000, Testing net (#0)
I1211 18:28:02.259297 15749 net.cpp:676] Ignoring source layer drop6
I1211 18:28:02.259306 15749 net.cpp:676] Ignoring source layer drop7
I1211 18:28:38.859848 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:28:38.859966 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:28:39.174643 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 18:28:39.174685 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 18:28:39.174695 15749 solver.cpp:397]     Test net output #2: loss = 56.4515 (* 1 = 56.4515 loss)
I1211 18:28:40.291106 15749 solver.cpp:218] Iteration 7000 (0.466402 iter/s, 214.407s/100 iters), loss = 64.4238
I1211 18:28:40.291179 15749 solver.cpp:237]     Train net output #0: label = 216
I1211 18:28:40.291203 15749 solver.cpp:237]     Train net output #1: label_phocs = 216
I1211 18:28:40.291213 15749 solver.cpp:237]     Train net output #2: loss = 43.9242 (* 1 = 43.9242 loss)
I1211 18:28:40.291223 15749 sgd_solver.cpp:116] Iteration 7000, lr = 0.0001
I1211 18:31:11.947414 15749 solver.cpp:218] Iteration 7100 (0.659455 iter/s, 151.64s/100 iters), loss = 64.133
I1211 18:31:11.947496 15749 solver.cpp:237]     Train net output #0: label = 1006
I1211 18:31:11.947518 15749 solver.cpp:237]     Train net output #1: label_phocs = 1006
I1211 18:31:11.947530 15749 solver.cpp:237]     Train net output #2: loss = 59.1513 (* 1 = 59.1513 loss)
I1211 18:31:11.947540 15749 sgd_solver.cpp:116] Iteration 7100, lr = 0.0001
I1211 18:33:35.033550 15749 solver.cpp:218] Iteration 7200 (0.69888 iter/s, 143.086s/100 iters), loss = 63.5839
I1211 18:33:35.033627 15749 solver.cpp:237]     Train net output #0: label = 538
I1211 18:33:35.033650 15749 solver.cpp:237]     Train net output #1: label_phocs = 538
I1211 18:33:35.033663 15749 solver.cpp:237]     Train net output #2: loss = 84.6881 (* 1 = 84.6881 loss)
I1211 18:33:35.033671 15749 sgd_solver.cpp:116] Iteration 7200, lr = 0.0001
I1211 18:35:59.573014 15749 solver.cpp:218] Iteration 7300 (0.691853 iter/s, 144.539s/100 iters), loss = 61.9488
I1211 18:35:59.573094 15749 solver.cpp:237]     Train net output #0: label = 684
I1211 18:35:59.573117 15749 solver.cpp:237]     Train net output #1: label_phocs = 684
I1211 18:35:59.573128 15749 solver.cpp:237]     Train net output #2: loss = 46.2832 (* 1 = 46.2832 loss)
I1211 18:35:59.573137 15749 sgd_solver.cpp:116] Iteration 7300, lr = 0.0001
I1211 18:38:20.583794 15749 solver.cpp:218] Iteration 7400 (0.709374 iter/s, 140.969s/100 iters), loss = 61.6702
I1211 18:38:20.583880 15749 solver.cpp:237]     Train net output #0: label = 772
I1211 18:38:20.583904 15749 solver.cpp:237]     Train net output #1: label_phocs = 772
I1211 18:38:20.583917 15749 solver.cpp:237]     Train net output #2: loss = 100.76 (* 1 = 100.76 loss)
I1211 18:38:20.583926 15749 sgd_solver.cpp:116] Iteration 7400, lr = 0.0001
[2017-12-11 18:40:48,125, PHOCNetTrainer] Running test evaluation
[2017-12-11 18:40:48,125, PHOCNetTrainer] Evaluating CNN after 7000 steps:
I1211 18:41:37.631861 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:41:37.631988 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 18:41:38,612, PHOCNetTrainer] mAP: 0.540157
I1211 18:41:38.613916 15749 solver.cpp:330] Iteration 7500, Testing net (#0)
I1211 18:41:38.614125 15749 net.cpp:676] Ignoring source layer drop6
I1211 18:41:38.614133 15749 net.cpp:676] Ignoring source layer drop7
I1211 18:42:23.963878 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:42:23.964113 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:42:24.267410 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 18:42:24.267452 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 18:42:24.267462 15749 solver.cpp:397]     Test net output #2: loss = 51.7198 (* 1 = 51.7198 loss)
I1211 18:42:25.439611 15749 solver.cpp:218] Iteration 7500 (0.408404 iter/s, 244.856s/100 iters), loss = 58.5484
I1211 18:42:25.439719 15749 solver.cpp:237]     Train net output #0: label = 432
I1211 18:42:25.439760 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1211 18:42:25.439782 15749 solver.cpp:237]     Train net output #2: loss = 69.3592 (* 1 = 69.3592 loss)
I1211 18:42:25.439797 15749 sgd_solver.cpp:116] Iteration 7500, lr = 0.0001
I1211 18:44:51.411285 15749 solver.cpp:218] Iteration 7600 (0.685065 iter/s, 145.972s/100 iters), loss = 60.6655
I1211 18:44:51.411370 15749 solver.cpp:237]     Train net output #0: label = 210
I1211 18:44:51.411393 15749 solver.cpp:237]     Train net output #1: label_phocs = 210
I1211 18:44:51.411406 15749 solver.cpp:237]     Train net output #2: loss = 42.9871 (* 1 = 42.9871 loss)
I1211 18:44:51.411413 15749 sgd_solver.cpp:116] Iteration 7600, lr = 0.0001
I1211 18:47:11.480922 15749 solver.cpp:218] Iteration 7700 (0.713931 iter/s, 140.07s/100 iters), loss = 60.4589
I1211 18:47:11.481003 15749 solver.cpp:237]     Train net output #0: label = 313
I1211 18:47:11.481025 15749 solver.cpp:237]     Train net output #1: label_phocs = 313
I1211 18:47:11.481037 15749 solver.cpp:237]     Train net output #2: loss = 62.531 (* 1 = 62.531 loss)
I1211 18:47:11.481045 15749 sgd_solver.cpp:116] Iteration 7700, lr = 0.0001
I1211 18:49:45.406375 15749 solver.cpp:218] Iteration 7800 (0.649698 iter/s, 153.918s/100 iters), loss = 59.7036
I1211 18:49:45.406467 15749 solver.cpp:237]     Train net output #0: label = 719
I1211 18:49:45.406491 15749 solver.cpp:237]     Train net output #1: label_phocs = 719
I1211 18:49:45.406502 15749 solver.cpp:237]     Train net output #2: loss = 73.4066 (* 1 = 73.4066 loss)
I1211 18:49:45.406512 15749 sgd_solver.cpp:116] Iteration 7800, lr = 0.0001
I1211 18:52:16.779536 15749 solver.cpp:218] Iteration 7900 (0.660805 iter/s, 151.331s/100 iters), loss = 57.7777
I1211 18:52:16.779613 15749 solver.cpp:237]     Train net output #0: label = 269
I1211 18:52:16.779635 15749 solver.cpp:237]     Train net output #1: label_phocs = 269
I1211 18:52:16.779645 15749 solver.cpp:237]     Train net output #2: loss = 44.1325 (* 1 = 44.1325 loss)
I1211 18:52:16.779652 15749 sgd_solver.cpp:116] Iteration 7900, lr = 0.0001
[2017-12-11 18:54:48,890, PHOCNetTrainer] Running test evaluation
[2017-12-11 18:54:48,890, PHOCNetTrainer] Evaluating CNN after 7500 steps:
I1211 18:55:35.673403 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:55:35.673427 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 18:55:38,473, PHOCNetTrainer] mAP: 0.577953
I1211 18:55:38.475107 15749 solver.cpp:330] Iteration 8000, Testing net (#0)
I1211 18:55:38.475332 15749 net.cpp:676] Ignoring source layer drop6
I1211 18:55:38.475343 15749 net.cpp:676] Ignoring source layer drop7
I1211 18:56:20.067967 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:56:20.068224 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 18:56:20.371454 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 18:56:20.371498 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 18:56:20.371510 15749 solver.cpp:397]     Test net output #2: loss = 50.8567 (* 1 = 50.8567 loss)
I1211 18:56:21.658879 15749 solver.cpp:218] Iteration 8000 (0.408399 iter/s, 244.858s/100 iters), loss = 46.6282
I1211 18:56:21.661104 15749 solver.cpp:237]     Train net output #0: label = 811
I1211 18:56:21.661132 15749 solver.cpp:237]     Train net output #1: label_phocs = 811
I1211 18:56:21.661145 15749 solver.cpp:237]     Train net output #2: loss = 75.3042 (* 1 = 75.3042 loss)
I1211 18:56:21.661154 15749 sgd_solver.cpp:116] Iteration 8000, lr = 0.0001
I1211 18:58:48.626524 15749 solver.cpp:218] Iteration 8100 (0.680498 iter/s, 146.951s/100 iters), loss = 57.0219
I1211 18:58:48.626607 15749 solver.cpp:237]     Train net output #0: label = 318
I1211 18:58:48.626631 15749 solver.cpp:237]     Train net output #1: label_phocs = 318
I1211 18:58:48.626642 15749 solver.cpp:237]     Train net output #2: loss = 30.007 (* 1 = 30.007 loss)
I1211 18:58:48.626657 15749 sgd_solver.cpp:116] Iteration 8100, lr = 0.0001
I1211 19:01:17.099805 15749 solver.cpp:218] Iteration 8200 (0.673658 iter/s, 148.443s/100 iters), loss = 55.3796
I1211 19:01:17.099889 15749 solver.cpp:237]     Train net output #0: label = 729
I1211 19:01:17.099912 15749 solver.cpp:237]     Train net output #1: label_phocs = 729
I1211 19:01:17.099925 15749 solver.cpp:237]     Train net output #2: loss = 35.8101 (* 1 = 35.8101 loss)
I1211 19:01:17.099932 15749 sgd_solver.cpp:116] Iteration 8200, lr = 0.0001
I1211 19:03:44.092808 15749 solver.cpp:218] Iteration 8300 (0.680417 iter/s, 146.969s/100 iters), loss = 54.9336
I1211 19:03:44.092897 15749 solver.cpp:237]     Train net output #0: label = 376
I1211 19:03:44.092921 15749 solver.cpp:237]     Train net output #1: label_phocs = 376
I1211 19:03:44.092933 15749 solver.cpp:237]     Train net output #2: loss = 71.0485 (* 1 = 71.0485 loss)
I1211 19:03:44.092943 15749 sgd_solver.cpp:116] Iteration 8300, lr = 0.0001
I1211 19:06:11.000357 15749 solver.cpp:218] Iteration 8400 (0.6807 iter/s, 146.908s/100 iters), loss = 53.164
I1211 19:06:11.000449 15749 solver.cpp:237]     Train net output #0: label = 66
I1211 19:06:11.000481 15749 solver.cpp:237]     Train net output #1: label_phocs = 66
I1211 19:06:11.000499 15749 solver.cpp:237]     Train net output #2: loss = 59.0944 (* 1 = 59.0944 loss)
I1211 19:06:11.000509 15749 sgd_solver.cpp:116] Iteration 8400, lr = 0.0001
[2017-12-11 19:08:32,726, PHOCNetTrainer] Running test evaluation
[2017-12-11 19:08:32,726, PHOCNetTrainer] Evaluating CNN after 8000 steps:
I1211 19:09:29.088871 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:09:29.088932 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 19:09:30,264, PHOCNetTrainer] mAP: 0.623316
I1211 19:09:30.265609 15749 solver.cpp:330] Iteration 8500, Testing net (#0)
I1211 19:09:30.265812 15749 net.cpp:676] Ignoring source layer drop6
I1211 19:09:30.265821 15749 net.cpp:676] Ignoring source layer drop7
I1211 19:10:11.268357 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:10:11.396718 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:10:12.031514 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 19:10:12.031560 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 19:10:12.031572 15749 solver.cpp:397]     Test net output #2: loss = 45.3313 (* 1 = 45.3313 loss)
I1211 19:10:14.131945 15749 solver.cpp:218] Iteration 8500 (0.4113 iter/s, 243.132s/100 iters), loss = 68.1795
I1211 19:10:14.132035 15749 solver.cpp:237]     Train net output #0: label = 32
I1211 19:10:14.132058 15749 solver.cpp:237]     Train net output #1: label_phocs = 32
I1211 19:10:14.132071 15749 solver.cpp:237]     Train net output #2: loss = 98.5655 (* 1 = 98.5655 loss)
I1211 19:10:14.132081 15749 sgd_solver.cpp:116] Iteration 8500, lr = 0.0001
I1211 19:12:40.300447 15749 solver.cpp:218] Iteration 8600 (0.684142 iter/s, 146.169s/100 iters), loss = 53.321
I1211 19:12:40.300519 15749 solver.cpp:237]     Train net output #0: label = 354
I1211 19:12:40.300539 15749 solver.cpp:237]     Train net output #1: label_phocs = 354
I1211 19:12:40.300546 15749 solver.cpp:237]     Train net output #2: loss = 84.249 (* 1 = 84.249 loss)
I1211 19:12:40.300554 15749 sgd_solver.cpp:116] Iteration 8600, lr = 0.0001
I1211 19:15:06.274698 15749 solver.cpp:218] Iteration 8700 (0.685052 iter/s, 145.974s/100 iters), loss = 53.57
I1211 19:15:06.274765 15749 solver.cpp:237]     Train net output #0: label = 302
I1211 19:15:06.274785 15749 solver.cpp:237]     Train net output #1: label_phocs = 302
I1211 19:15:06.274793 15749 solver.cpp:237]     Train net output #2: loss = 76.8331 (* 1 = 76.8331 loss)
I1211 19:15:06.274801 15749 sgd_solver.cpp:116] Iteration 8700, lr = 0.0001
I1211 19:17:35.761746 15749 solver.cpp:218] Iteration 8800 (0.669199 iter/s, 149.432s/100 iters), loss = 52.2642
I1211 19:17:35.761816 15749 solver.cpp:237]     Train net output #0: label = 810
I1211 19:17:35.761839 15749 solver.cpp:237]     Train net output #1: label_phocs = 810
I1211 19:17:35.761848 15749 solver.cpp:237]     Train net output #2: loss = 40.8763 (* 1 = 40.8763 loss)
I1211 19:17:35.761855 15749 sgd_solver.cpp:116] Iteration 8800, lr = 0.0001
I1211 19:20:01.609817 15749 solver.cpp:218] Iteration 8900 (0.685645 iter/s, 145.848s/100 iters), loss = 51.8717
I1211 19:20:01.609899 15749 solver.cpp:237]     Train net output #0: label = 1053
I1211 19:20:01.609922 15749 solver.cpp:237]     Train net output #1: label_phocs = 1053
I1211 19:20:01.609935 15749 solver.cpp:237]     Train net output #2: loss = 28.1845 (* 1 = 28.1845 loss)
I1211 19:20:01.609944 15749 sgd_solver.cpp:116] Iteration 8900, lr = 0.0001
[2017-12-11 19:22:24,846, PHOCNetTrainer] Running test evaluation
[2017-12-11 19:22:24,847, PHOCNetTrainer] Evaluating CNN after 8500 steps:
I1211 19:23:10.255867 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:23:10.256000 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 19:23:12,761, PHOCNetTrainer] mAP: 0.679978
I1211 19:23:12.762974 15749 solver.cpp:330] Iteration 9000, Testing net (#0)
I1211 19:23:12.763175 15749 net.cpp:676] Ignoring source layer drop6
I1211 19:23:12.763185 15749 net.cpp:676] Ignoring source layer drop7
I1211 19:23:57.063843 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:23:57.064031 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:23:57.374002 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 19:23:57.374037 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 19:23:57.374044 15749 solver.cpp:397]     Test net output #2: loss = 43.3965 (* 1 = 43.3965 loss)
I1211 19:23:58.267555 15749 solver.cpp:218] Iteration 9000 (0.422551 iter/s, 236.658s/100 iters), loss = 60.216
I1211 19:23:58.267630 15749 solver.cpp:237]     Train net output #0: label = 169
I1211 19:23:58.267652 15749 solver.cpp:237]     Train net output #1: label_phocs = 169
I1211 19:23:58.267663 15749 solver.cpp:237]     Train net output #2: loss = 57.7459 (* 1 = 57.7459 loss)
I1211 19:23:58.267671 15749 sgd_solver.cpp:116] Iteration 9000, lr = 0.0001
I1211 19:26:22.483573 15749 solver.cpp:218] Iteration 9100 (0.693404 iter/s, 144.216s/100 iters), loss = 49.3056
I1211 19:26:22.483661 15749 solver.cpp:237]     Train net output #0: label = 811
I1211 19:26:22.483685 15749 solver.cpp:237]     Train net output #1: label_phocs = 811
I1211 19:26:22.483697 15749 solver.cpp:237]     Train net output #2: loss = 84.6782 (* 1 = 84.6782 loss)
I1211 19:26:22.483707 15749 sgd_solver.cpp:116] Iteration 9100, lr = 0.0001
I1211 19:28:55.128106 15749 solver.cpp:218] Iteration 9200 (0.655138 iter/s, 152.64s/100 iters), loss = 48.618
I1211 19:28:55.128186 15749 solver.cpp:237]     Train net output #0: label = 555
I1211 19:28:55.128211 15749 solver.cpp:237]     Train net output #1: label_phocs = 555
I1211 19:28:55.128222 15749 solver.cpp:237]     Train net output #2: loss = 34.2976 (* 1 = 34.2976 loss)
I1211 19:28:55.128232 15749 sgd_solver.cpp:116] Iteration 9200, lr = 0.0001
I1211 19:31:15.002802 15749 solver.cpp:218] Iteration 9300 (0.714926 iter/s, 139.875s/100 iters), loss = 47.6858
I1211 19:31:15.002884 15749 solver.cpp:237]     Train net output #0: label = 963
I1211 19:31:15.002908 15749 solver.cpp:237]     Train net output #1: label_phocs = 963
I1211 19:31:15.002920 15749 solver.cpp:237]     Train net output #2: loss = 69.8843 (* 1 = 69.8843 loss)
I1211 19:31:15.002929 15749 sgd_solver.cpp:116] Iteration 9300, lr = 0.0001
I1211 19:33:38.646281 15749 solver.cpp:218] Iteration 9400 (0.696168 iter/s, 143.643s/100 iters), loss = 46.276
I1211 19:33:38.646363 15749 solver.cpp:237]     Train net output #0: label = 191
I1211 19:33:38.646386 15749 solver.cpp:237]     Train net output #1: label_phocs = 191
I1211 19:33:38.646397 15749 solver.cpp:237]     Train net output #2: loss = 54.6493 (* 1 = 54.6493 loss)
I1211 19:33:38.646411 15749 sgd_solver.cpp:116] Iteration 9400, lr = 0.0001
[2017-12-11 19:36:03,768, PHOCNetTrainer] Running test evaluation
[2017-12-11 19:36:03,769, PHOCNetTrainer] Evaluating CNN after 9000 steps:
I1211 19:36:51.859851 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:36:51.859967 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 19:36:52,826, PHOCNetTrainer] mAP: 0.710158
I1211 19:36:52.828014 15749 solver.cpp:330] Iteration 9500, Testing net (#0)
I1211 19:36:52.828212 15749 net.cpp:676] Ignoring source layer drop6
I1211 19:36:52.828222 15749 net.cpp:676] Ignoring source layer drop7
I1211 19:37:45.543829 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:37:45.544059 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:37:46.503232 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 19:37:46.503268 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 19:37:46.503274 15749 solver.cpp:397]     Test net output #2: loss = 41.2484 (* 1 = 41.2484 loss)
I1211 19:37:47.835690 15749 solver.cpp:218] Iteration 9500 (0.401338 iter/s, 249.167s/100 iters), loss = 34.0919
I1211 19:37:47.835774 15749 solver.cpp:237]     Train net output #0: label = 84
I1211 19:37:47.835798 15749 solver.cpp:237]     Train net output #1: label_phocs = 84
I1211 19:37:47.835810 15749 solver.cpp:237]     Train net output #2: loss = 31.5205 (* 1 = 31.5205 loss)
I1211 19:37:47.835819 15749 sgd_solver.cpp:116] Iteration 9500, lr = 0.0001
I1211 19:40:13.390015 15749 solver.cpp:218] Iteration 9600 (0.687029 iter/s, 145.554s/100 iters), loss = 44.6714
I1211 19:40:13.390092 15749 solver.cpp:237]     Train net output #0: label = 973
I1211 19:40:13.390116 15749 solver.cpp:237]     Train net output #1: label_phocs = 973
I1211 19:40:13.390128 15749 solver.cpp:237]     Train net output #2: loss = 39.315 (* 1 = 39.315 loss)
I1211 19:40:13.390137 15749 sgd_solver.cpp:116] Iteration 9600, lr = 0.0001
I1211 19:42:32.915844 15749 solver.cpp:218] Iteration 9700 (0.716713 iter/s, 139.526s/100 iters), loss = 45.5524
I1211 19:42:32.915926 15749 solver.cpp:237]     Train net output #0: label = 487
I1211 19:42:32.915949 15749 solver.cpp:237]     Train net output #1: label_phocs = 487
I1211 19:42:32.915961 15749 solver.cpp:237]     Train net output #2: loss = 27.1374 (* 1 = 27.1374 loss)
I1211 19:42:32.915971 15749 sgd_solver.cpp:116] Iteration 9700, lr = 0.0001
I1211 19:45:05.251704 15749 solver.cpp:218] Iteration 9800 (0.656472 iter/s, 152.329s/100 iters), loss = 44.1458
I1211 19:45:05.251798 15749 solver.cpp:237]     Train net output #0: label = 452
I1211 19:45:05.251823 15749 solver.cpp:237]     Train net output #1: label_phocs = 452
I1211 19:45:05.251834 15749 solver.cpp:237]     Train net output #2: loss = 59.1152 (* 1 = 59.1152 loss)
I1211 19:45:05.251844 15749 sgd_solver.cpp:116] Iteration 9800, lr = 0.0001
I1211 19:47:28.261862 15749 solver.cpp:218] Iteration 9900 (0.699289 iter/s, 143.002s/100 iters), loss = 43.1826
I1211 19:47:28.261951 15749 solver.cpp:237]     Train net output #0: label = 296
I1211 19:47:28.261976 15749 solver.cpp:237]     Train net output #1: label_phocs = 296
I1211 19:47:28.261988 15749 solver.cpp:237]     Train net output #2: loss = 51.3039 (* 1 = 51.3039 loss)
I1211 19:47:28.261997 15749 sgd_solver.cpp:116] Iteration 9900, lr = 0.0001
[2017-12-11 19:49:53,309, PHOCNetTrainer] Running test evaluation
[2017-12-11 19:49:53,309, PHOCNetTrainer] Evaluating CNN after 9500 steps:
I1211 19:50:34.847813 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:50:34.847985 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 19:50:36,647, PHOCNetTrainer] mAP: 0.697422
I1211 19:50:36.648087 15749 solver.cpp:330] Iteration 10000, Testing net (#0)
I1211 19:50:36.648280 15749 net.cpp:676] Ignoring source layer drop6
I1211 19:50:36.648288 15749 net.cpp:676] Ignoring source layer drop7
I1211 19:51:21.443464 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:51:21.443493 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 19:51:22.730628 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 19:51:22.730669 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 19:51:22.730676 15749 solver.cpp:397]     Test net output #2: loss = 39.8385 (* 1 = 39.8385 loss)
I1211 19:51:24.400215 15749 solver.cpp:218] Iteration 10000 (0.423555 iter/s, 236.097s/100 iters), loss = 45.9993
I1211 19:51:24.400291 15749 solver.cpp:237]     Train net output #0: label = 184
I1211 19:51:24.400315 15749 solver.cpp:237]     Train net output #1: label_phocs = 184
I1211 19:51:24.400326 15749 solver.cpp:237]     Train net output #2: loss = 23.2861 (* 1 = 23.2861 loss)
I1211 19:51:24.400334 15749 sgd_solver.cpp:116] Iteration 10000, lr = 0.0001
I1211 19:53:51.501176 15749 solver.cpp:218] Iteration 10100 (0.679805 iter/s, 147.101s/100 iters), loss = 42.667
I1211 19:53:51.501252 15749 solver.cpp:237]     Train net output #0: label = 193
I1211 19:53:51.501272 15749 solver.cpp:237]     Train net output #1: label_phocs = 193
I1211 19:53:51.501281 15749 solver.cpp:237]     Train net output #2: loss = 42.8491 (* 1 = 42.8491 loss)
I1211 19:53:51.501287 15749 sgd_solver.cpp:116] Iteration 10100, lr = 0.0001
I1211 19:56:17.162813 15749 solver.cpp:218] Iteration 10200 (0.686564 iter/s, 145.653s/100 iters), loss = 42.468
I1211 19:56:17.162886 15749 solver.cpp:237]     Train net output #0: label = 399
I1211 19:56:17.162905 15749 solver.cpp:237]     Train net output #1: label_phocs = 399
I1211 19:56:17.162914 15749 solver.cpp:237]     Train net output #2: loss = 15.0496 (* 1 = 15.0496 loss)
I1211 19:56:17.162920 15749 sgd_solver.cpp:116] Iteration 10200, lr = 0.0001
I1211 19:58:40.521742 15749 solver.cpp:218] Iteration 10300 (0.697727 iter/s, 143.323s/100 iters), loss = 41.5168
I1211 19:58:40.521827 15749 solver.cpp:237]     Train net output #0: label = 309
I1211 19:58:40.521852 15749 solver.cpp:237]     Train net output #1: label_phocs = 309
I1211 19:58:40.521862 15749 solver.cpp:237]     Train net output #2: loss = 62.5813 (* 1 = 62.5813 loss)
I1211 19:58:40.521872 15749 sgd_solver.cpp:116] Iteration 10300, lr = 0.0001
I1211 20:01:06.333320 15749 solver.cpp:218] Iteration 10400 (0.685817 iter/s, 145.812s/100 iters), loss = 41.1511
I1211 20:01:06.333412 15749 solver.cpp:237]     Train net output #0: label = 452
I1211 20:01:06.333438 15749 solver.cpp:237]     Train net output #1: label_phocs = 452
I1211 20:01:06.333451 15749 solver.cpp:237]     Train net output #2: loss = 53.0183 (* 1 = 53.0183 loss)
I1211 20:01:06.333461 15749 sgd_solver.cpp:116] Iteration 10400, lr = 0.0001
[2017-12-11 20:03:26,312, PHOCNetTrainer] Running test evaluation
[2017-12-11 20:03:26,312, PHOCNetTrainer] Evaluating CNN after 10000 steps:
I1211 20:04:07.096313 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:04:07.096320 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 20:04:09,095, PHOCNetTrainer] mAP: 0.748916
I1211 20:04:09.096698 15749 solver.cpp:330] Iteration 10500, Testing net (#0)
I1211 20:04:09.096902 15749 net.cpp:676] Ignoring source layer drop6
I1211 20:04:09.096911 15749 net.cpp:676] Ignoring source layer drop7
I1211 20:04:54.463861 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:04:54.463999 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:04:55.360066 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 20:04:55.360113 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 20:04:55.360126 15749 solver.cpp:397]     Test net output #2: loss = 36.1639 (* 1 = 36.1639 loss)
I1211 20:04:56.400650 15749 solver.cpp:218] Iteration 10500 (0.434655 iter/s, 230.067s/100 iters), loss = 35.9751
I1211 20:04:56.400724 15749 solver.cpp:237]     Train net output #0: label = 67
I1211 20:04:56.400748 15749 solver.cpp:237]     Train net output #1: label_phocs = 67
I1211 20:04:56.400759 15749 solver.cpp:237]     Train net output #2: loss = 31.742 (* 1 = 31.742 loss)
I1211 20:04:56.400768 15749 sgd_solver.cpp:116] Iteration 10500, lr = 0.0001
I1211 20:07:12.203521 15749 solver.cpp:218] Iteration 10600 (0.736631 iter/s, 135.753s/100 iters), loss = 39.9102
I1211 20:07:12.203624 15749 solver.cpp:237]     Train net output #0: label = 770
I1211 20:07:12.203649 15749 solver.cpp:237]     Train net output #1: label_phocs = 770
I1211 20:07:12.203661 15749 solver.cpp:237]     Train net output #2: loss = 29.3864 (* 1 = 29.3864 loss)
I1211 20:07:12.203670 15749 sgd_solver.cpp:116] Iteration 10600, lr = 0.0001
I1211 20:09:45.216814 15749 solver.cpp:218] Iteration 10700 (0.653538 iter/s, 153.013s/100 iters), loss = 38.6934
I1211 20:09:45.216879 15749 solver.cpp:237]     Train net output #0: label = 303
I1211 20:09:45.216898 15749 solver.cpp:237]     Train net output #1: label_phocs = 303
I1211 20:09:45.216907 15749 solver.cpp:237]     Train net output #2: loss = 62.8026 (* 1 = 62.8026 loss)
I1211 20:09:45.216913 15749 sgd_solver.cpp:116] Iteration 10700, lr = 0.0001
I1211 20:12:07.630185 15749 solver.cpp:218] Iteration 10800 (0.70254 iter/s, 142.341s/100 iters), loss = 38.1049
I1211 20:12:07.630273 15749 solver.cpp:237]     Train net output #0: label = 165
I1211 20:12:07.630297 15749 solver.cpp:237]     Train net output #1: label_phocs = 165
I1211 20:12:07.630309 15749 solver.cpp:237]     Train net output #2: loss = 60.0292 (* 1 = 60.0292 loss)
I1211 20:12:07.630318 15749 sgd_solver.cpp:116] Iteration 10800, lr = 0.0001
I1211 20:14:34.907193 15749 solver.cpp:218] Iteration 10900 (0.679197 iter/s, 147.233s/100 iters), loss = 38.7326
I1211 20:14:34.907294 15749 solver.cpp:237]     Train net output #0: label = 399
I1211 20:14:34.907317 15749 solver.cpp:237]     Train net output #1: label_phocs = 399
I1211 20:14:34.907330 15749 solver.cpp:237]     Train net output #2: loss = 13.8822 (* 1 = 13.8822 loss)
I1211 20:14:34.907340 15749 sgd_solver.cpp:116] Iteration 10900, lr = 0.0001
[2017-12-11 20:16:56,849, PHOCNetTrainer] Running test evaluation
[2017-12-11 20:16:56,849, PHOCNetTrainer] Evaluating CNN after 10500 steps:
I1211 20:17:36.359143 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:17:36.360740 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 20:17:39,094, PHOCNetTrainer] mAP: 0.767425
I1211 20:17:39.095809 15749 solver.cpp:330] Iteration 11000, Testing net (#0)
I1211 20:17:39.096015 15749 net.cpp:676] Ignoring source layer drop6
I1211 20:17:39.096025 15749 net.cpp:676] Ignoring source layer drop7
I1211 20:18:21.807482 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:18:21.807500 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:18:22.184283 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 20:18:22.184329 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 20:18:22.184340 15749 solver.cpp:397]     Test net output #2: loss = 35.8971 (* 1 = 35.8971 loss)
I1211 20:18:23.678234 15749 solver.cpp:218] Iteration 11000 (0.437118 iter/s, 228.771s/100 iters), loss = 40.8706
I1211 20:18:23.678323 15749 solver.cpp:237]     Train net output #0: label = 578
I1211 20:18:23.678347 15749 solver.cpp:237]     Train net output #1: label_phocs = 578
I1211 20:18:23.678359 15749 solver.cpp:237]     Train net output #2: loss = 81.6481 (* 1 = 81.6481 loss)
I1211 20:18:23.678369 15749 sgd_solver.cpp:116] Iteration 11000, lr = 0.0001
I1211 20:20:50.756347 15749 solver.cpp:218] Iteration 11100 (0.679911 iter/s, 147.078s/100 iters), loss = 37.5381
I1211 20:20:50.756422 15749 solver.cpp:237]     Train net output #0: label = 692
I1211 20:20:50.756446 15749 solver.cpp:237]     Train net output #1: label_phocs = 692
I1211 20:20:50.756458 15749 solver.cpp:237]     Train net output #2: loss = 33.7621 (* 1 = 33.7621 loss)
I1211 20:20:50.756466 15749 sgd_solver.cpp:116] Iteration 11100, lr = 0.0001
I1211 20:23:13.583786 15749 solver.cpp:218] Iteration 11200 (0.700194 iter/s, 142.818s/100 iters), loss = 35.4283
I1211 20:23:13.583866 15749 solver.cpp:237]     Train net output #0: label = 466
I1211 20:23:13.583890 15749 solver.cpp:237]     Train net output #1: label_phocs = 466
I1211 20:23:13.583907 15749 solver.cpp:237]     Train net output #2: loss = 30.9381 (* 1 = 30.9381 loss)
I1211 20:23:13.583917 15749 sgd_solver.cpp:116] Iteration 11200, lr = 0.0001
I1211 20:25:37.495004 15749 solver.cpp:218] Iteration 11300 (0.694873 iter/s, 143.911s/100 iters), loss = 35.9442
I1211 20:25:37.495085 15749 solver.cpp:237]     Train net output #0: label = 1087
I1211 20:25:37.495106 15749 solver.cpp:237]     Train net output #1: label_phocs = 1087
I1211 20:25:37.495120 15749 solver.cpp:237]     Train net output #2: loss = 24.7561 (* 1 = 24.7561 loss)
I1211 20:25:37.495128 15749 sgd_solver.cpp:116] Iteration 11300, lr = 0.0001
I1211 20:28:02.670161 15749 solver.cpp:218] Iteration 11400 (0.688823 iter/s, 145.175s/100 iters), loss = 34.3818
I1211 20:28:02.670248 15749 solver.cpp:237]     Train net output #0: label = 333
I1211 20:28:02.670271 15749 solver.cpp:237]     Train net output #1: label_phocs = 333
I1211 20:28:02.670284 15749 solver.cpp:237]     Train net output #2: loss = 58.3741 (* 1 = 58.3741 loss)
I1211 20:28:02.670291 15749 sgd_solver.cpp:116] Iteration 11400, lr = 0.0001
[2017-12-11 20:30:31,807, PHOCNetTrainer] Running test evaluation
[2017-12-11 20:30:31,807, PHOCNetTrainer] Evaluating CNN after 11000 steps:
I1211 20:31:22.551856 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:31:22.551869 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 20:31:25,966, PHOCNetTrainer] mAP: 0.785611
I1211 20:31:25.967429 15749 solver.cpp:330] Iteration 11500, Testing net (#0)
I1211 20:31:25.967629 15749 net.cpp:676] Ignoring source layer drop6
I1211 20:31:25.967636 15749 net.cpp:676] Ignoring source layer drop7
I1211 20:32:03.211835 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:32:03.211949 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:32:03.591234 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 20:32:03.591281 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 20:32:03.591292 15749 solver.cpp:397]     Test net output #2: loss = 32.4027 (* 1 = 32.4027 loss)
I1211 20:32:04.931077 15749 solver.cpp:218] Iteration 11500 (0.412778 iter/s, 242.261s/100 iters), loss = 37.5277
I1211 20:32:04.931136 15749 solver.cpp:237]     Train net output #0: label = 309
I1211 20:32:04.931155 15749 solver.cpp:237]     Train net output #1: label_phocs = 309
I1211 20:32:04.931164 15749 solver.cpp:237]     Train net output #2: loss = 63.3487 (* 1 = 63.3487 loss)
I1211 20:32:04.931169 15749 sgd_solver.cpp:116] Iteration 11500, lr = 0.0001
I1211 20:34:23.981287 15749 solver.cpp:218] Iteration 11600 (0.719165 iter/s, 139.05s/100 iters), loss = 35.5438
I1211 20:34:23.981367 15749 solver.cpp:237]     Train net output #0: label = 300
I1211 20:34:23.981390 15749 solver.cpp:237]     Train net output #1: label_phocs = 300
I1211 20:34:23.981402 15749 solver.cpp:237]     Train net output #2: loss = 41.941 (* 1 = 41.941 loss)
I1211 20:34:23.981411 15749 sgd_solver.cpp:116] Iteration 11600, lr = 0.0001
I1211 20:36:48.872992 15749 solver.cpp:218] Iteration 11700 (0.690171 iter/s, 144.892s/100 iters), loss = 33.922
I1211 20:36:48.873057 15749 solver.cpp:237]     Train net output #0: label = 597
I1211 20:36:48.873080 15749 solver.cpp:237]     Train net output #1: label_phocs = 597
I1211 20:36:48.873091 15749 solver.cpp:237]     Train net output #2: loss = 66.5995 (* 1 = 66.5995 loss)
I1211 20:36:48.873100 15749 sgd_solver.cpp:116] Iteration 11700, lr = 0.0001
I1211 20:39:12.249977 15749 solver.cpp:218] Iteration 11800 (0.697462 iter/s, 143.377s/100 iters), loss = 33.735
I1211 20:39:12.250072 15749 solver.cpp:237]     Train net output #0: label = 359
I1211 20:39:12.250097 15749 solver.cpp:237]     Train net output #1: label_phocs = 359
I1211 20:39:12.250109 15749 solver.cpp:237]     Train net output #2: loss = 50.5835 (* 1 = 50.5835 loss)
I1211 20:39:12.250118 15749 sgd_solver.cpp:116] Iteration 11800, lr = 0.0001
I1211 20:41:34.492924 15749 solver.cpp:218] Iteration 11900 (0.703083 iter/s, 142.231s/100 iters), loss = 33.6445
I1211 20:41:34.493021 15749 solver.cpp:237]     Train net output #0: label = 559
I1211 20:41:34.493044 15749 solver.cpp:237]     Train net output #1: label_phocs = 559
I1211 20:41:34.493057 15749 solver.cpp:237]     Train net output #2: loss = 49.08 (* 1 = 49.08 loss)
I1211 20:41:34.493065 15749 sgd_solver.cpp:116] Iteration 11900, lr = 0.0001
[2017-12-11 20:43:55,255, PHOCNetTrainer] Running test evaluation
[2017-12-11 20:43:55,255, PHOCNetTrainer] Evaluating CNN after 11500 steps:
I1211 20:44:40.431850 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:44:40.431979 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 20:44:42,141, PHOCNetTrainer] mAP: 0.813423
I1211 20:44:42.142484 15749 solver.cpp:330] Iteration 12000, Testing net (#0)
I1211 20:44:42.142694 15749 net.cpp:676] Ignoring source layer drop6
I1211 20:44:42.142704 15749 net.cpp:676] Ignoring source layer drop7
I1211 20:45:26.572031 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:45:26.572248 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:45:27.009065 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 20:45:27.009104 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 20:45:27.009112 15749 solver.cpp:397]     Test net output #2: loss = 30.3631 (* 1 = 30.3631 loss)
I1211 20:45:28.101125 15749 solver.cpp:218] Iteration 12000 (0.428095 iter/s, 233.593s/100 iters), loss = 29.1314
I1211 20:45:28.121649 15749 solver.cpp:237]     Train net output #0: label = 683
I1211 20:45:28.121700 15749 solver.cpp:237]     Train net output #1: label_phocs = 683
I1211 20:45:28.121711 15749 solver.cpp:237]     Train net output #2: loss = 62.574 (* 1 = 62.574 loss)
I1211 20:45:28.121719 15749 sgd_solver.cpp:116] Iteration 12000, lr = 0.0001
I1211 20:47:54.604054 15749 solver.cpp:218] Iteration 12100 (0.682675 iter/s, 146.482s/100 iters), loss = 30.9419
I1211 20:47:54.604133 15749 solver.cpp:237]     Train net output #0: label = 291
I1211 20:47:54.604156 15749 solver.cpp:237]     Train net output #1: label_phocs = 291
I1211 20:47:54.604168 15749 solver.cpp:237]     Train net output #2: loss = 10.6251 (* 1 = 10.6251 loss)
I1211 20:47:54.604176 15749 sgd_solver.cpp:116] Iteration 12100, lr = 0.0001
I1211 20:50:29.407166 15749 solver.cpp:218] Iteration 12200 (0.645982 iter/s, 154.803s/100 iters), loss = 31.2665
I1211 20:50:29.407258 15749 solver.cpp:237]     Train net output #0: label = 135
I1211 20:50:29.407280 15749 solver.cpp:237]     Train net output #1: label_phocs = 135
I1211 20:50:29.407292 15749 solver.cpp:237]     Train net output #2: loss = 16.4277 (* 1 = 16.4277 loss)
I1211 20:50:29.407301 15749 sgd_solver.cpp:116] Iteration 12200, lr = 0.0001
I1211 20:52:52.917794 15749 solver.cpp:218] Iteration 12300 (0.696813 iter/s, 143.511s/100 iters), loss = 30.6943
I1211 20:52:52.917881 15749 solver.cpp:237]     Train net output #0: label = 432
I1211 20:52:52.917904 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1211 20:52:52.917917 15749 solver.cpp:237]     Train net output #2: loss = 37.4647 (* 1 = 37.4647 loss)
I1211 20:52:52.917924 15749 sgd_solver.cpp:116] Iteration 12300, lr = 0.0001
I1211 20:55:15.502820 15749 solver.cpp:218] Iteration 12400 (0.701338 iter/s, 142.585s/100 iters), loss = 30.0498
I1211 20:55:15.502904 15749 solver.cpp:237]     Train net output #0: label = 1106
I1211 20:55:15.502928 15749 solver.cpp:237]     Train net output #1: label_phocs = 1106
I1211 20:55:15.502940 15749 solver.cpp:237]     Train net output #2: loss = 28.49 (* 1 = 28.49 loss)
I1211 20:55:15.502948 15749 sgd_solver.cpp:116] Iteration 12400, lr = 0.0001
[2017-12-11 20:57:32,328, PHOCNetTrainer] Running test evaluation
[2017-12-11 20:57:32,328, PHOCNetTrainer] Evaluating CNN after 12000 steps:
I1211 20:58:16.872043 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:58:16.872334 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 20:58:18,843, PHOCNetTrainer] mAP: 0.813499
I1211 20:58:18.845515 15749 solver.cpp:330] Iteration 12500, Testing net (#0)
I1211 20:58:18.845764 15749 net.cpp:676] Ignoring source layer drop6
I1211 20:58:18.845779 15749 net.cpp:676] Ignoring source layer drop7
I1211 20:58:57.443841 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:58:57.443964 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 20:58:58.065872 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 20:58:58.065918 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 20:58:58.065929 15749 solver.cpp:397]     Test net output #2: loss = 31.2182 (* 1 = 31.2182 loss)
I1211 20:59:00.014401 15749 solver.cpp:218] Iteration 12500 (0.445419 iter/s, 224.508s/100 iters), loss = 26.0265
I1211 20:59:00.014483 15749 solver.cpp:237]     Train net output #0: label = 138
I1211 20:59:00.014508 15749 solver.cpp:237]     Train net output #1: label_phocs = 138
I1211 20:59:00.014519 15749 solver.cpp:237]     Train net output #2: loss = 26.3059 (* 1 = 26.3059 loss)
I1211 20:59:00.014528 15749 sgd_solver.cpp:116] Iteration 12500, lr = 0.0001
I1211 21:01:26.716379 15749 solver.cpp:218] Iteration 12600 (0.681654 iter/s, 146.702s/100 iters), loss = 29.4477
I1211 21:01:26.716464 15749 solver.cpp:237]     Train net output #0: label = 719
I1211 21:01:26.716490 15749 solver.cpp:237]     Train net output #1: label_phocs = 719
I1211 21:01:26.716501 15749 solver.cpp:237]     Train net output #2: loss = 22.8498 (* 1 = 22.8498 loss)
I1211 21:01:26.716511 15749 sgd_solver.cpp:116] Iteration 12600, lr = 0.0001
I1211 21:03:52.246294 15749 solver.cpp:218] Iteration 12700 (0.687248 iter/s, 145.508s/100 iters), loss = 30.1711
I1211 21:03:52.246376 15749 solver.cpp:237]     Train net output #0: label = 775
I1211 21:03:52.246399 15749 solver.cpp:237]     Train net output #1: label_phocs = 775
I1211 21:03:52.246410 15749 solver.cpp:237]     Train net output #2: loss = 23.9773 (* 1 = 23.9773 loss)
I1211 21:03:52.246419 15749 sgd_solver.cpp:116] Iteration 12700, lr = 0.0001
I1211 21:06:17.146870 15749 solver.cpp:218] Iteration 12800 (0.690344 iter/s, 144.855s/100 iters), loss = 28.2876
I1211 21:06:17.146963 15749 solver.cpp:237]     Train net output #0: label = 770
I1211 21:06:17.146987 15749 solver.cpp:237]     Train net output #1: label_phocs = 770
I1211 21:06:17.146998 15749 solver.cpp:237]     Train net output #2: loss = 31.7553 (* 1 = 31.7553 loss)
I1211 21:06:17.147008 15749 sgd_solver.cpp:116] Iteration 12800, lr = 0.0001
I1211 21:08:45.814944 15749 solver.cpp:218] Iteration 12900 (0.672927 iter/s, 148.605s/100 iters), loss = 29.2174
I1211 21:08:45.815024 15749 solver.cpp:237]     Train net output #0: label = 810
I1211 21:08:45.815048 15749 solver.cpp:237]     Train net output #1: label_phocs = 810
I1211 21:08:45.815059 15749 solver.cpp:237]     Train net output #2: loss = 9.65396 (* 1 = 9.65396 loss)
I1211 21:08:45.815068 15749 sgd_solver.cpp:116] Iteration 12900, lr = 0.0001
[2017-12-11 21:11:08,800, PHOCNetTrainer] Running test evaluation
[2017-12-11 21:11:08,800, PHOCNetTrainer] Evaluating CNN after 12500 steps:
I1211 21:11:48.059978 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:11:48.059985 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 21:11:50,246, PHOCNetTrainer] mAP: 0.801083
I1211 21:11:50.248101 15749 solver.cpp:330] Iteration 13000, Testing net (#0)
I1211 21:11:50.248306 15749 net.cpp:676] Ignoring source layer drop6
I1211 21:11:50.248313 15749 net.cpp:676] Ignoring source layer drop7
I1211 21:12:33.731842 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:12:33.732074 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:12:34.277048 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 21:12:34.277087 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 21:12:34.277096 15749 solver.cpp:397]     Test net output #2: loss = 30.9254 (* 1 = 30.9254 loss)
I1211 21:12:35.608832 15749 solver.cpp:218] Iteration 13000 (0.435173 iter/s, 229.794s/100 iters), loss = 22.4034
I1211 21:12:35.608909 15749 solver.cpp:237]     Train net output #0: label = 389
I1211 21:12:35.608928 15749 solver.cpp:237]     Train net output #1: label_phocs = 389
I1211 21:12:35.608937 15749 solver.cpp:237]     Train net output #2: loss = 24.6009 (* 1 = 24.6009 loss)
I1211 21:12:35.608943 15749 sgd_solver.cpp:116] Iteration 13000, lr = 0.0001
I1211 21:15:01.260926 15749 solver.cpp:218] Iteration 13100 (0.686567 iter/s, 145.652s/100 iters), loss = 27.9777
I1211 21:15:01.260996 15749 solver.cpp:237]     Train net output #0: label = 480
I1211 21:15:01.261015 15749 solver.cpp:237]     Train net output #1: label_phocs = 480
I1211 21:15:01.261023 15749 solver.cpp:237]     Train net output #2: loss = 25.8704 (* 1 = 25.8704 loss)
I1211 21:15:01.261030 15749 sgd_solver.cpp:116] Iteration 13100, lr = 0.0001
I1211 21:17:23.786804 15749 solver.cpp:218] Iteration 13200 (0.701712 iter/s, 142.509s/100 iters), loss = 27.0599
I1211 21:17:23.786890 15749 solver.cpp:237]     Train net output #0: label = 955
I1211 21:17:23.786913 15749 solver.cpp:237]     Train net output #1: label_phocs = 955
I1211 21:17:23.786926 15749 solver.cpp:237]     Train net output #2: loss = 34.6005 (* 1 = 34.6005 loss)
I1211 21:17:23.786936 15749 sgd_solver.cpp:116] Iteration 13200, lr = 0.0001
I1211 21:19:43.808117 15749 solver.cpp:218] Iteration 13300 (0.714177 iter/s, 140.021s/100 iters), loss = 26.8247
I1211 21:19:43.808200 15749 solver.cpp:237]     Train net output #0: label = 567
I1211 21:19:43.808224 15749 solver.cpp:237]     Train net output #1: label_phocs = 567
I1211 21:19:43.808235 15749 solver.cpp:237]     Train net output #2: loss = 9.02185 (* 1 = 9.02185 loss)
I1211 21:19:43.808243 15749 sgd_solver.cpp:116] Iteration 13300, lr = 0.0001
I1211 21:22:00.763219 15749 solver.cpp:218] Iteration 13400 (0.730385 iter/s, 136.914s/100 iters), loss = 26.0646
I1211 21:22:00.763311 15749 solver.cpp:237]     Train net output #0: label = 1062
I1211 21:22:00.763337 15749 solver.cpp:237]     Train net output #1: label_phocs = 1062
I1211 21:22:00.763351 15749 solver.cpp:237]     Train net output #2: loss = 33.5099 (* 1 = 33.5099 loss)
I1211 21:22:00.763360 15749 sgd_solver.cpp:116] Iteration 13400, lr = 0.0001
[2017-12-11 21:24:31,455, PHOCNetTrainer] Running test evaluation
[2017-12-11 21:24:31,455, PHOCNetTrainer] Evaluating CNN after 13000 steps:
I1211 21:25:16.229966 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:25:16.231977 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 21:25:18,792, PHOCNetTrainer] mAP: 0.820534
I1211 21:25:18.793954 15749 solver.cpp:330] Iteration 13500, Testing net (#0)
I1211 21:25:18.794162 15749 net.cpp:676] Ignoring source layer drop6
I1211 21:25:18.794172 15749 net.cpp:676] Ignoring source layer drop7
I1211 21:26:04.907882 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:26:04.908128 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:26:05.812244 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 21:26:05.812280 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 21:26:05.812288 15749 solver.cpp:397]     Test net output #2: loss = 28.6475 (* 1 = 28.6475 loss)
I1211 21:26:07.068269 15749 solver.cpp:218] Iteration 13500 (0.40607 iter/s, 246.263s/100 iters), loss = 22.5216
I1211 21:26:07.068346 15749 solver.cpp:237]     Train net output #0: label = 16
I1211 21:26:07.068368 15749 solver.cpp:237]     Train net output #1: label_phocs = 16
I1211 21:26:07.068380 15749 solver.cpp:237]     Train net output #2: loss = 17.4673 (* 1 = 17.4673 loss)
I1211 21:26:07.068388 15749 sgd_solver.cpp:116] Iteration 13500, lr = 0.0001
I1211 21:28:28.614805 15749 solver.cpp:218] Iteration 13600 (0.706482 iter/s, 141.547s/100 iters), loss = 25.0775
I1211 21:28:28.614887 15749 solver.cpp:237]     Train net output #0: label = 497
I1211 21:28:28.614912 15749 solver.cpp:237]     Train net output #1: label_phocs = 497
I1211 21:28:28.614923 15749 solver.cpp:237]     Train net output #2: loss = 15.1715 (* 1 = 15.1715 loss)
I1211 21:28:28.614938 15749 sgd_solver.cpp:116] Iteration 13600, lr = 0.0001
I1211 21:30:48.209019 15749 solver.cpp:218] Iteration 13700 (0.716508 iter/s, 139.566s/100 iters), loss = 25.191
I1211 21:30:48.209102 15749 solver.cpp:237]     Train net output #0: label = 425
I1211 21:30:48.209125 15749 solver.cpp:237]     Train net output #1: label_phocs = 425
I1211 21:30:48.209136 15749 solver.cpp:237]     Train net output #2: loss = 8.04971 (* 1 = 8.04971 loss)
I1211 21:30:48.209146 15749 sgd_solver.cpp:116] Iteration 13700, lr = 0.0001
I1211 21:33:10.079208 15749 solver.cpp:218] Iteration 13800 (0.70487 iter/s, 141.87s/100 iters), loss = 24.9371
I1211 21:33:10.079298 15749 solver.cpp:237]     Train net output #0: label = 333
I1211 21:33:10.079325 15749 solver.cpp:237]     Train net output #1: label_phocs = 333
I1211 21:33:10.079340 15749 solver.cpp:237]     Train net output #2: loss = 41.7912 (* 1 = 41.7912 loss)
I1211 21:33:10.079351 15749 sgd_solver.cpp:116] Iteration 13800, lr = 0.0001
I1211 21:35:32.155803 15749 solver.cpp:218] Iteration 13900 (0.703973 iter/s, 142.051s/100 iters), loss = 24.3344
I1211 21:35:32.155886 15749 solver.cpp:237]     Train net output #0: label = 12
I1211 21:35:32.155910 15749 solver.cpp:237]     Train net output #1: label_phocs = 12
I1211 21:35:32.155922 15749 solver.cpp:237]     Train net output #2: loss = 41.0767 (* 1 = 41.0767 loss)
I1211 21:35:32.155931 15749 sgd_solver.cpp:116] Iteration 13900, lr = 0.0001
[2017-12-11 21:38:09,457, PHOCNetTrainer] Running test evaluation
[2017-12-11 21:38:09,457, PHOCNetTrainer] Evaluating CNN after 13500 steps:
I1211 21:38:55.059986 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:38:55.059991 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 21:38:56,258, PHOCNetTrainer] mAP: 0.836739
I1211 21:38:56.259919 15749 solver.cpp:330] Iteration 14000, Testing net (#0)
I1211 21:38:56.260149 15749 net.cpp:676] Ignoring source layer drop6
I1211 21:38:56.260156 15749 net.cpp:676] Ignoring source layer drop7
I1211 21:39:46.124588 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:39:46.124728 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:39:46.598732 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 21:39:46.598776 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 21:39:46.598788 15749 solver.cpp:397]     Test net output #2: loss = 26.1357 (* 1 = 26.1357 loss)
I1211 21:39:47.589021 15749 solver.cpp:218] Iteration 14000 (0.391492 iter/s, 255.433s/100 iters), loss = 20.0701
I1211 21:39:47.589100 15749 solver.cpp:237]     Train net output #0: label = 1001
I1211 21:39:47.589121 15749 solver.cpp:237]     Train net output #1: label_phocs = 1001
I1211 21:39:47.589133 15749 solver.cpp:237]     Train net output #2: loss = 10.1565 (* 1 = 10.1565 loss)
I1211 21:39:47.589143 15749 sgd_solver.cpp:116] Iteration 14000, lr = 0.0001
I1211 21:42:10.537436 15749 solver.cpp:218] Iteration 14100 (0.699553 iter/s, 142.948s/100 iters), loss = 23.5037
I1211 21:42:10.537520 15749 solver.cpp:237]     Train net output #0: label = 1041
I1211 21:42:10.537544 15749 solver.cpp:237]     Train net output #1: label_phocs = 1041
I1211 21:42:10.537556 15749 solver.cpp:237]     Train net output #2: loss = 44.5763 (* 1 = 44.5763 loss)
I1211 21:42:10.537565 15749 sgd_solver.cpp:116] Iteration 14100, lr = 0.0001
I1211 21:44:34.140796 15749 solver.cpp:218] Iteration 14200 (0.696362 iter/s, 143.603s/100 iters), loss = 24.1635
I1211 21:44:34.140875 15749 solver.cpp:237]     Train net output #0: label = 417
I1211 21:44:34.140898 15749 solver.cpp:237]     Train net output #1: label_phocs = 417
I1211 21:44:34.140909 15749 solver.cpp:237]     Train net output #2: loss = 17.2245 (* 1 = 17.2245 loss)
I1211 21:44:34.140918 15749 sgd_solver.cpp:116] Iteration 14200, lr = 0.0001
I1211 21:46:58.674990 15749 solver.cpp:218] Iteration 14300 (0.691878 iter/s, 144.534s/100 iters), loss = 23.5714
I1211 21:46:58.675060 15749 solver.cpp:237]     Train net output #0: label = 252
I1211 21:46:58.675084 15749 solver.cpp:237]     Train net output #1: label_phocs = 252
I1211 21:46:58.675093 15749 solver.cpp:237]     Train net output #2: loss = 30.8282 (* 1 = 30.8282 loss)
I1211 21:46:58.675099 15749 sgd_solver.cpp:116] Iteration 14300, lr = 0.0001
I1211 21:49:24.933676 15749 solver.cpp:218] Iteration 14400 (0.683744 iter/s, 146.253s/100 iters), loss = 23.4193
I1211 21:49:24.933763 15749 solver.cpp:237]     Train net output #0: label = 649
I1211 21:49:24.933785 15749 solver.cpp:237]     Train net output #1: label_phocs = 649
I1211 21:49:24.933797 15749 solver.cpp:237]     Train net output #2: loss = 25.7541 (* 1 = 25.7541 loss)
I1211 21:49:24.933806 15749 sgd_solver.cpp:116] Iteration 14400, lr = 0.0001
[2017-12-11 21:51:51,626, PHOCNetTrainer] Running test evaluation
[2017-12-11 21:51:51,626, PHOCNetTrainer] Evaluating CNN after 14000 steps:
I1211 21:52:23.327862 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:52:23.327986 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 21:52:26,120, PHOCNetTrainer] mAP: 0.839654
I1211 21:52:26.122496 15749 solver.cpp:330] Iteration 14500, Testing net (#0)
I1211 21:52:26.122722 15749 net.cpp:676] Ignoring source layer drop6
I1211 21:52:26.122735 15749 net.cpp:676] Ignoring source layer drop7
I1211 21:53:17.946894 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:53:17.946936 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 21:53:18.273960 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 21:53:18.274006 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 21:53:18.274018 15749 solver.cpp:397]     Test net output #2: loss = 26.4021 (* 1 = 26.4021 loss)
I1211 21:53:19.160250 15749 solver.cpp:218] Iteration 14500 (0.426953 iter/s, 234.218s/100 iters), loss = 21.5462
I1211 21:53:19.160328 15749 solver.cpp:237]     Train net output #0: label = 800
I1211 21:53:19.160351 15749 solver.cpp:237]     Train net output #1: label_phocs = 800
I1211 21:53:19.160364 15749 solver.cpp:237]     Train net output #2: loss = 11.3529 (* 1 = 11.3529 loss)
I1211 21:53:19.160372 15749 sgd_solver.cpp:116] Iteration 14500, lr = 0.0001
I1211 21:55:44.484697 15749 solver.cpp:218] Iteration 14600 (0.688116 iter/s, 145.324s/100 iters), loss = 22.1114
I1211 21:55:44.484778 15749 solver.cpp:237]     Train net output #0: label = 815
I1211 21:55:44.484802 15749 solver.cpp:237]     Train net output #1: label_phocs = 815
I1211 21:55:44.484814 15749 solver.cpp:237]     Train net output #2: loss = 31.8647 (* 1 = 31.8647 loss)
I1211 21:55:44.484823 15749 sgd_solver.cpp:116] Iteration 14600, lr = 0.0001
I1211 21:58:14.411787 15749 solver.cpp:218] Iteration 14700 (0.66702 iter/s, 149.921s/100 iters), loss = 22.6698
I1211 21:58:14.411871 15749 solver.cpp:237]     Train net output #0: label = 947
I1211 21:58:14.411895 15749 solver.cpp:237]     Train net output #1: label_phocs = 947
I1211 21:58:14.411906 15749 solver.cpp:237]     Train net output #2: loss = 17.1045 (* 1 = 17.1045 loss)
I1211 21:58:14.411914 15749 sgd_solver.cpp:116] Iteration 14700, lr = 0.0001
I1211 22:00:44.357642 15749 solver.cpp:218] Iteration 14800 (0.666907 iter/s, 149.946s/100 iters), loss = 21.2966
I1211 22:00:44.357729 15749 solver.cpp:237]     Train net output #0: label = 717
I1211 22:00:44.357753 15749 solver.cpp:237]     Train net output #1: label_phocs = 717
I1211 22:00:44.357764 15749 solver.cpp:237]     Train net output #2: loss = 19.2644 (* 1 = 19.2644 loss)
I1211 22:00:44.357774 15749 sgd_solver.cpp:116] Iteration 14800, lr = 0.0001
I1211 22:03:17.738256 15749 solver.cpp:218] Iteration 14900 (0.652011 iter/s, 153.372s/100 iters), loss = 20.2128
I1211 22:03:17.738345 15749 solver.cpp:237]     Train net output #0: label = 351
I1211 22:03:17.738368 15749 solver.cpp:237]     Train net output #1: label_phocs = 351
I1211 22:03:17.738379 15749 solver.cpp:237]     Train net output #2: loss = 6.08246 (* 1 = 6.08246 loss)
I1211 22:03:17.738387 15749 sgd_solver.cpp:116] Iteration 14900, lr = 0.0001
[2017-12-11 22:05:42,907, PHOCNetTrainer] Running test evaluation
[2017-12-11 22:05:42,942, PHOCNetTrainer] Evaluating CNN after 14500 steps:
I1211 22:06:29.391829 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:06:29.391971 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 22:06:31,298, PHOCNetTrainer] mAP: 0.854412
I1211 22:06:31.299823 15749 solver.cpp:330] Iteration 15000, Testing net (#0)
I1211 22:06:31.300014 15749 net.cpp:676] Ignoring source layer drop6
I1211 22:06:31.300024 15749 net.cpp:676] Ignoring source layer drop7
I1211 22:07:10.176015 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:07:10.176264 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:07:10.485407 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 22:07:10.485448 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 22:07:10.485460 15749 solver.cpp:397]     Test net output #2: loss = 24.8458 (* 1 = 24.8458 loss)
I1211 22:07:11.519745 15749 solver.cpp:218] Iteration 15000 (0.427765 iter/s, 233.773s/100 iters), loss = 17.4997
I1211 22:07:11.519821 15749 solver.cpp:237]     Train net output #0: label = 92
I1211 22:07:11.519845 15749 solver.cpp:237]     Train net output #1: label_phocs = 92
I1211 22:07:11.519856 15749 solver.cpp:237]     Train net output #2: loss = 10.446 (* 1 = 10.446 loss)
I1211 22:07:11.519865 15749 sgd_solver.cpp:116] Iteration 15000, lr = 0.0001
I1211 22:09:42.435791 15749 solver.cpp:218] Iteration 15100 (0.662871 iter/s, 150.859s/100 iters), loss = 20.8057
I1211 22:09:42.435874 15749 solver.cpp:237]     Train net output #0: label = 120
I1211 22:09:42.435899 15749 solver.cpp:237]     Train net output #1: label_phocs = 120
I1211 22:09:42.435910 15749 solver.cpp:237]     Train net output #2: loss = 2.12778 (* 1 = 2.12778 loss)
I1211 22:09:42.435920 15749 sgd_solver.cpp:116] Iteration 15100, lr = 0.0001
I1211 22:12:11.639725 15749 solver.cpp:218] Iteration 15200 (0.670224 iter/s, 149.204s/100 iters), loss = 20.3623
I1211 22:12:11.639818 15749 solver.cpp:237]     Train net output #0: label = 256
I1211 22:12:11.639844 15749 solver.cpp:237]     Train net output #1: label_phocs = 256
I1211 22:12:11.639858 15749 solver.cpp:237]     Train net output #2: loss = 14.9592 (* 1 = 14.9592 loss)
I1211 22:12:11.639866 15749 sgd_solver.cpp:116] Iteration 15200, lr = 0.0001
I1211 22:14:46.366132 15749 solver.cpp:218] Iteration 15300 (0.64636 iter/s, 154.713s/100 iters), loss = 20.6109
I1211 22:14:46.366219 15749 solver.cpp:237]     Train net output #0: label = 524
I1211 22:14:46.366243 15749 solver.cpp:237]     Train net output #1: label_phocs = 524
I1211 22:14:46.366255 15749 solver.cpp:237]     Train net output #2: loss = 32.9778 (* 1 = 32.9778 loss)
I1211 22:14:46.366264 15749 sgd_solver.cpp:116] Iteration 15300, lr = 0.0001
I1211 22:17:00.733023 15749 solver.cpp:218] Iteration 15400 (0.744294 iter/s, 134.355s/100 iters), loss = 20.357
I1211 22:17:00.733108 15749 solver.cpp:237]     Train net output #0: label = 578
I1211 22:17:00.733132 15749 solver.cpp:237]     Train net output #1: label_phocs = 578
I1211 22:17:00.733144 15749 solver.cpp:237]     Train net output #2: loss = 33.4966 (* 1 = 33.4966 loss)
I1211 22:17:00.733155 15749 sgd_solver.cpp:116] Iteration 15400, lr = 0.0001
[2017-12-11 22:19:34,238, PHOCNetTrainer] Running test evaluation
[2017-12-11 22:19:34,238, PHOCNetTrainer] Evaluating CNN after 15000 steps:
I1211 22:20:12.408002 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:20:12.408277 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 22:20:14,440, PHOCNetTrainer] mAP: 0.843949
I1211 22:20:14.441637 15749 solver.cpp:330] Iteration 15500, Testing net (#0)
I1211 22:20:14.441849 15749 net.cpp:676] Ignoring source layer drop6
I1211 22:20:14.441859 15749 net.cpp:676] Ignoring source layer drop7
I1211 22:20:53.783830 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:20:53.784013 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:20:54.159061 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 22:20:54.159106 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 22:20:54.159118 15749 solver.cpp:397]     Test net output #2: loss = 26.0451 (* 1 = 26.0451 loss)
I1211 22:20:55.757709 15749 solver.cpp:218] Iteration 15500 (0.42549 iter/s, 235.023s/100 iters), loss = 14.0552
I1211 22:20:55.757791 15749 solver.cpp:237]     Train net output #0: label = 801
I1211 22:20:55.757813 15749 solver.cpp:237]     Train net output #1: label_phocs = 801
I1211 22:20:55.757825 15749 solver.cpp:237]     Train net output #2: loss = 10.626 (* 1 = 10.626 loss)
I1211 22:20:55.757834 15749 sgd_solver.cpp:116] Iteration 15500, lr = 0.0001
I1211 22:23:24.298246 15749 solver.cpp:218] Iteration 15600 (0.673217 iter/s, 148.541s/100 iters), loss = 19.5045
I1211 22:23:24.298326 15749 solver.cpp:237]     Train net output #0: label = 280
I1211 22:23:24.298349 15749 solver.cpp:237]     Train net output #1: label_phocs = 280
I1211 22:23:24.298362 15749 solver.cpp:237]     Train net output #2: loss = 11.3623 (* 1 = 11.3623 loss)
I1211 22:23:24.298370 15749 sgd_solver.cpp:116] Iteration 15600, lr = 0.0001
I1211 22:25:45.793354 15749 solver.cpp:218] Iteration 15700 (0.706738 iter/s, 141.495s/100 iters), loss = 18.788
I1211 22:25:45.793450 15749 solver.cpp:237]     Train net output #0: label = 633
I1211 22:25:45.793473 15749 solver.cpp:237]     Train net output #1: label_phocs = 633
I1211 22:25:45.793484 15749 solver.cpp:237]     Train net output #2: loss = 30.6512 (* 1 = 30.6512 loss)
I1211 22:25:45.793493 15749 sgd_solver.cpp:116] Iteration 15700, lr = 0.0001
I1211 22:28:15.202857 15749 solver.cpp:218] Iteration 15800 (0.669354 iter/s, 149.398s/100 iters), loss = 19.429
I1211 22:28:15.202934 15749 solver.cpp:237]     Train net output #0: label = 289
I1211 22:28:15.202956 15749 solver.cpp:237]     Train net output #1: label_phocs = 289
I1211 22:28:15.202968 15749 solver.cpp:237]     Train net output #2: loss = 30.9987 (* 1 = 30.9987 loss)
I1211 22:28:15.202977 15749 sgd_solver.cpp:116] Iteration 15800, lr = 0.0001
I1211 22:30:34.328685 15749 solver.cpp:218] Iteration 15900 (0.718978 iter/s, 139.086s/100 iters), loss = 18.8043
I1211 22:30:34.328769 15749 solver.cpp:237]     Train net output #0: label = 400
I1211 22:30:34.328793 15749 solver.cpp:237]     Train net output #1: label_phocs = 400
I1211 22:30:34.328804 15749 solver.cpp:237]     Train net output #2: loss = 2.50036 (* 1 = 2.50036 loss)
I1211 22:30:34.328812 15749 sgd_solver.cpp:116] Iteration 15900, lr = 0.0001
[2017-12-11 22:33:05,258, PHOCNetTrainer] Running test evaluation
[2017-12-11 22:33:05,258, PHOCNetTrainer] Evaluating CNN after 15500 steps:
I1211 22:33:41.859994 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:33:41.860121 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 22:33:43,159, PHOCNetTrainer] mAP: 0.841806
I1211 22:33:43.161178 15749 solver.cpp:330] Iteration 16000, Testing net (#0)
I1211 22:33:43.161370 15749 net.cpp:676] Ignoring source layer drop6
I1211 22:33:43.161378 15749 net.cpp:676] Ignoring source layer drop7
I1211 22:34:21.023905 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:34:21.024199 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:34:21.510551 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 22:34:21.510586 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 22:34:21.510594 15749 solver.cpp:397]     Test net output #2: loss = 26.3196 (* 1 = 26.3196 loss)
I1211 22:34:22.809734 15749 solver.cpp:218] Iteration 16000 (0.437791 iter/s, 228.42s/100 iters), loss = 12.5648
I1211 22:34:22.809813 15749 solver.cpp:237]     Train net output #0: label = 31
I1211 22:34:22.809834 15749 solver.cpp:237]     Train net output #1: label_phocs = 31
I1211 22:34:22.809846 15749 solver.cpp:237]     Train net output #2: loss = 10.755 (* 1 = 10.755 loss)
I1211 22:34:22.809856 15749 sgd_solver.cpp:116] Iteration 16000, lr = 0.0001
I1211 22:36:36.811766 15749 solver.cpp:218] Iteration 16100 (0.746257 iter/s, 134.002s/100 iters), loss = 17.9948
I1211 22:36:36.811875 15749 solver.cpp:237]     Train net output #0: label = 969
I1211 22:36:36.811904 15749 solver.cpp:237]     Train net output #1: label_phocs = 969
I1211 22:36:36.811919 15749 solver.cpp:237]     Train net output #2: loss = 9.87889 (* 1 = 9.87889 loss)
I1211 22:36:36.811930 15749 sgd_solver.cpp:116] Iteration 16100, lr = 0.0001
I1211 22:39:08.799286 15749 solver.cpp:218] Iteration 16200 (0.657949 iter/s, 151.987s/100 iters), loss = 17.8573
I1211 22:39:08.799399 15749 solver.cpp:237]     Train net output #0: label = 384
I1211 22:39:08.799425 15749 solver.cpp:237]     Train net output #1: label_phocs = 384
I1211 22:39:08.799438 15749 solver.cpp:237]     Train net output #2: loss = 5.67045 (* 1 = 5.67045 loss)
I1211 22:39:08.799448 15749 sgd_solver.cpp:116] Iteration 16200, lr = 0.0001
I1211 22:41:40.055399 15749 solver.cpp:218] Iteration 16300 (0.661131 iter/s, 151.256s/100 iters), loss = 17.2801
I1211 22:41:40.055469 15749 solver.cpp:237]     Train net output #0: label = 280
I1211 22:41:40.055490 15749 solver.cpp:237]     Train net output #1: label_phocs = 280
I1211 22:41:40.055497 15749 solver.cpp:237]     Train net output #2: loss = 4.92709 (* 1 = 4.92709 loss)
I1211 22:41:40.055503 15749 sgd_solver.cpp:116] Iteration 16300, lr = 0.0001
I1211 22:44:02.256314 15749 solver.cpp:218] Iteration 16400 (0.70323 iter/s, 142.201s/100 iters), loss = 17.7997
I1211 22:44:02.256399 15749 solver.cpp:237]     Train net output #0: label = 177
I1211 22:44:02.256428 15749 solver.cpp:237]     Train net output #1: label_phocs = 177
I1211 22:44:02.256443 15749 solver.cpp:237]     Train net output #2: loss = 12.6998 (* 1 = 12.6998 loss)
I1211 22:44:02.256453 15749 sgd_solver.cpp:116] Iteration 16400, lr = 0.0001
[2017-12-11 22:46:26,400, PHOCNetTrainer] Running test evaluation
[2017-12-11 22:46:26,401, PHOCNetTrainer] Evaluating CNN after 16000 steps:
I1211 22:47:17.683928 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:47:17.683943 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 22:47:21,107, PHOCNetTrainer] mAP: 0.859529
I1211 22:47:21.109058 15749 solver.cpp:330] Iteration 16500, Testing net (#0)
I1211 22:47:21.109251 15749 net.cpp:676] Ignoring source layer drop6
I1211 22:47:21.109259 15749 net.cpp:676] Ignoring source layer drop7
I1211 22:47:57.187825 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:47:57.187953 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 22:47:57.497743 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 22:47:57.497788 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 22:47:57.497799 15749 solver.cpp:397]     Test net output #2: loss = 23.7452 (* 1 = 23.7452 loss)
I1211 22:47:59.100991 15749 solver.cpp:218] Iteration 16500 (0.422296 iter/s, 236.801s/100 iters), loss = 15.853
I1211 22:47:59.101068 15749 solver.cpp:237]     Train net output #0: label = 617
I1211 22:47:59.101092 15749 solver.cpp:237]     Train net output #1: label_phocs = 617
I1211 22:47:59.101104 15749 solver.cpp:237]     Train net output #2: loss = 15.3919 (* 1 = 15.3919 loss)
I1211 22:47:59.101112 15749 sgd_solver.cpp:116] Iteration 16500, lr = 0.0001
I1211 22:50:24.022111 15749 solver.cpp:218] Iteration 16600 (0.690032 iter/s, 144.921s/100 iters), loss = 16.7258
I1211 22:50:24.022182 15749 solver.cpp:237]     Train net output #0: label = 773
I1211 22:50:24.022204 15749 solver.cpp:237]     Train net output #1: label_phocs = 773
I1211 22:50:24.022215 15749 solver.cpp:237]     Train net output #2: loss = 12.0588 (* 1 = 12.0588 loss)
I1211 22:50:24.022224 15749 sgd_solver.cpp:116] Iteration 16600, lr = 0.0001
I1211 22:52:51.821768 15749 solver.cpp:218] Iteration 16700 (0.676592 iter/s, 147.8s/100 iters), loss = 16.4599
I1211 22:52:51.821868 15749 solver.cpp:237]     Train net output #0: label = 23
I1211 22:52:51.821892 15749 solver.cpp:237]     Train net output #1: label_phocs = 23
I1211 22:52:51.821907 15749 solver.cpp:237]     Train net output #2: loss = 5.18262 (* 1 = 5.18262 loss)
I1211 22:52:51.821918 15749 sgd_solver.cpp:116] Iteration 16700, lr = 0.0001
I1211 22:55:18.324806 15749 solver.cpp:218] Iteration 16800 (0.68258 iter/s, 146.503s/100 iters), loss = 15.6076
I1211 22:55:18.324873 15749 solver.cpp:237]     Train net output #0: label = 864
I1211 22:55:18.324892 15749 solver.cpp:237]     Train net output #1: label_phocs = 864
I1211 22:55:18.324900 15749 solver.cpp:237]     Train net output #2: loss = 8.72393 (* 1 = 8.72393 loss)
I1211 22:55:18.324906 15749 sgd_solver.cpp:116] Iteration 16800, lr = 0.0001
I1211 22:57:34.137686 15749 solver.cpp:218] Iteration 16900 (0.736307 iter/s, 135.813s/100 iters), loss = 15.8192
I1211 22:57:34.137760 15749 solver.cpp:237]     Train net output #0: label = 367
I1211 22:57:34.137784 15749 solver.cpp:237]     Train net output #1: label_phocs = 367
I1211 22:57:34.137796 15749 solver.cpp:237]     Train net output #2: loss = 19.4018 (* 1 = 19.4018 loss)
I1211 22:57:34.137804 15749 sgd_solver.cpp:116] Iteration 16900, lr = 0.0001
[2017-12-11 22:59:58,873, PHOCNetTrainer] Running test evaluation
[2017-12-11 22:59:58,873, PHOCNetTrainer] Evaluating CNN after 16500 steps:
I1211 23:00:30.483649 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:00:30.483781 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 23:00:31,422, PHOCNetTrainer] mAP: 0.848783
I1211 23:00:31.423753 15749 solver.cpp:330] Iteration 17000, Testing net (#0)
I1211 23:00:31.423943 15749 net.cpp:676] Ignoring source layer drop6
I1211 23:00:31.423951 15749 net.cpp:676] Ignoring source layer drop7
I1211 23:01:15.149943 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:01:15.149950 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:01:15.540295 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 23:01:15.540344 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 23:01:15.540356 15749 solver.cpp:397]     Test net output #2: loss = 23.558 (* 1 = 23.558 loss)
I1211 23:01:16.623380 15749 solver.cpp:218] Iteration 17000 (0.449467 iter/s, 222.486s/100 iters), loss = 11.2515
I1211 23:01:16.623468 15749 solver.cpp:237]     Train net output #0: label = 834
I1211 23:01:16.623492 15749 solver.cpp:237]     Train net output #1: label_phocs = 834
I1211 23:01:16.623505 15749 solver.cpp:237]     Train net output #2: loss = 17.8747 (* 1 = 17.8747 loss)
I1211 23:01:16.623514 15749 sgd_solver.cpp:116] Iteration 17000, lr = 0.0001
I1211 23:03:33.421267 15749 solver.cpp:218] Iteration 17100 (0.731006 iter/s, 136.798s/100 iters), loss = 15.5802
I1211 23:03:33.421345 15749 solver.cpp:237]     Train net output #0: label = 705
I1211 23:03:33.421368 15749 solver.cpp:237]     Train net output #1: label_phocs = 705
I1211 23:03:33.421380 15749 solver.cpp:237]     Train net output #2: loss = 19.4378 (* 1 = 19.4378 loss)
I1211 23:03:33.421389 15749 sgd_solver.cpp:116] Iteration 17100, lr = 0.0001
I1211 23:05:54.027724 15749 solver.cpp:218] Iteration 17200 (0.711205 iter/s, 140.606s/100 iters), loss = 16.0168
I1211 23:05:54.027794 15749 solver.cpp:237]     Train net output #0: label = 592
I1211 23:05:54.027815 15749 solver.cpp:237]     Train net output #1: label_phocs = 592
I1211 23:05:54.027823 15749 solver.cpp:237]     Train net output #2: loss = 41.144 (* 1 = 41.144 loss)
I1211 23:05:54.027830 15749 sgd_solver.cpp:116] Iteration 17200, lr = 0.0001
I1211 23:08:28.223580 15749 solver.cpp:218] Iteration 17300 (0.648789 iter/s, 154.133s/100 iters), loss = 14.902
I1211 23:08:28.223670 15749 solver.cpp:237]     Train net output #0: label = 965
I1211 23:08:28.223704 15749 solver.cpp:237]     Train net output #1: label_phocs = 965
I1211 23:08:28.223721 15749 solver.cpp:237]     Train net output #2: loss = 17.0547 (* 1 = 17.0547 loss)
I1211 23:08:28.223732 15749 sgd_solver.cpp:116] Iteration 17300, lr = 0.0001
I1211 23:10:49.955160 15749 solver.cpp:218] Iteration 17400 (0.705947 iter/s, 141.654s/100 iters), loss = 14.9412
I1211 23:10:49.955258 15749 solver.cpp:237]     Train net output #0: label = 475
I1211 23:10:49.955281 15749 solver.cpp:237]     Train net output #1: label_phocs = 475
I1211 23:10:49.955293 15749 solver.cpp:237]     Train net output #2: loss = 3.41491 (* 1 = 3.41491 loss)
I1211 23:10:49.955302 15749 sgd_solver.cpp:116] Iteration 17400, lr = 0.0001
[2017-12-11 23:13:13,285, PHOCNetTrainer] Running test evaluation
[2017-12-11 23:13:13,285, PHOCNetTrainer] Evaluating CNN after 17000 steps:
I1211 23:13:48.970288 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:13:48.970296 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 23:13:49,860, PHOCNetTrainer] mAP: 0.875757
I1211 23:13:49.861694 15749 solver.cpp:330] Iteration 17500, Testing net (#0)
I1211 23:13:49.861871 15749 net.cpp:676] Ignoring source layer drop6
I1211 23:13:49.861877 15749 net.cpp:676] Ignoring source layer drop7
I1211 23:14:27.950755 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:14:27.950831 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:14:28.983500 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 23:14:28.983537 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 23:14:28.983546 15749 solver.cpp:397]     Test net output #2: loss = 21.7742 (* 1 = 21.7742 loss)
I1211 23:14:30.109136 15749 solver.cpp:218] Iteration 17500 (0.454227 iter/s, 220.154s/100 iters), loss = 11.1755
I1211 23:14:30.109215 15749 solver.cpp:237]     Train net output #0: label = 871
I1211 23:14:30.109237 15749 solver.cpp:237]     Train net output #1: label_phocs = 871
I1211 23:14:30.109249 15749 solver.cpp:237]     Train net output #2: loss = 10.7122 (* 1 = 10.7122 loss)
I1211 23:14:30.109259 15749 sgd_solver.cpp:116] Iteration 17500, lr = 0.0001
I1211 23:16:55.995081 15749 solver.cpp:218] Iteration 17600 (0.685467 iter/s, 145.886s/100 iters), loss = 15.1151
I1211 23:16:55.995164 15749 solver.cpp:237]     Train net output #0: label = 654
I1211 23:16:55.995183 15749 solver.cpp:237]     Train net output #1: label_phocs = 654
I1211 23:16:55.995191 15749 solver.cpp:237]     Train net output #2: loss = 14.1498 (* 1 = 14.1498 loss)
I1211 23:16:55.995198 15749 sgd_solver.cpp:116] Iteration 17600, lr = 0.0001
I1211 23:19:14.681038 15749 solver.cpp:218] Iteration 17700 (0.721161 iter/s, 138.665s/100 iters), loss = 14.6837
I1211 23:19:14.681105 15749 solver.cpp:237]     Train net output #0: label = 889
I1211 23:19:14.681124 15749 solver.cpp:237]     Train net output #1: label_phocs = 889
I1211 23:19:14.681131 15749 solver.cpp:237]     Train net output #2: loss = 4.70545 (* 1 = 4.70545 loss)
I1211 23:19:14.681138 15749 sgd_solver.cpp:116] Iteration 17700, lr = 0.0001
I1211 23:21:35.549401 15749 solver.cpp:218] Iteration 17800 (0.709883 iter/s, 140.868s/100 iters), loss = 14.3204
I1211 23:21:35.549484 15749 solver.cpp:237]     Train net output #0: label = 769
I1211 23:21:35.549509 15749 solver.cpp:237]     Train net output #1: label_phocs = 769
I1211 23:21:35.549520 15749 solver.cpp:237]     Train net output #2: loss = 14.5272 (* 1 = 14.5272 loss)
I1211 23:21:35.549528 15749 sgd_solver.cpp:116] Iteration 17800, lr = 0.0001
I1211 23:24:04.074992 15749 solver.cpp:218] Iteration 17900 (0.673399 iter/s, 148.5s/100 iters), loss = 14.7769
I1211 23:24:04.075091 15749 solver.cpp:237]     Train net output #0: label = 693
I1211 23:24:04.075114 15749 solver.cpp:237]     Train net output #1: label_phocs = 693
I1211 23:24:04.075126 15749 solver.cpp:237]     Train net output #2: loss = 15.3709 (* 1 = 15.3709 loss)
I1211 23:24:04.075136 15749 sgd_solver.cpp:116] Iteration 17900, lr = 0.0001
[2017-12-11 23:26:24,213, PHOCNetTrainer] Running test evaluation
[2017-12-11 23:26:24,213, PHOCNetTrainer] Evaluating CNN after 17500 steps:
I1211 23:27:07.623881 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:27:07.624147 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 23:27:10,872, PHOCNetTrainer] mAP: 0.857373
I1211 23:27:10.874414 15749 solver.cpp:330] Iteration 18000, Testing net (#0)
I1211 23:27:10.874603 15749 net.cpp:676] Ignoring source layer drop6
I1211 23:27:10.874611 15749 net.cpp:676] Ignoring source layer drop7
I1211 23:27:55.235849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:27:55.235975 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:27:56.083556 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 23:27:56.083606 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 23:27:56.083618 15749 solver.cpp:397]     Test net output #2: loss = 22.736 (* 1 = 22.736 loss)
I1211 23:27:57.984972 15749 solver.cpp:218] Iteration 18000 (0.427547 iter/s, 233.892s/100 iters), loss = 15.257
I1211 23:27:57.985050 15749 solver.cpp:237]     Train net output #0: label = 474
I1211 23:27:57.985074 15749 solver.cpp:237]     Train net output #1: label_phocs = 474
I1211 23:27:57.985085 15749 solver.cpp:237]     Train net output #2: loss = 32.7669 (* 1 = 32.7669 loss)
I1211 23:27:57.985095 15749 sgd_solver.cpp:116] Iteration 18000, lr = 0.0001
I1211 23:30:26.512852 15749 solver.cpp:218] Iteration 18100 (0.673274 iter/s, 148.528s/100 iters), loss = 13.2415
I1211 23:30:26.512913 15749 solver.cpp:237]     Train net output #0: label = 60
I1211 23:30:26.512933 15749 solver.cpp:237]     Train net output #1: label_phocs = 60
I1211 23:30:26.512939 15749 solver.cpp:237]     Train net output #2: loss = 6.47528 (* 1 = 6.47528 loss)
I1211 23:30:26.512945 15749 sgd_solver.cpp:116] Iteration 18100, lr = 0.0001
I1211 23:32:47.563671 15749 solver.cpp:218] Iteration 18200 (0.708964 iter/s, 141.051s/100 iters), loss = 14.1868
I1211 23:32:47.563741 15749 solver.cpp:237]     Train net output #0: label = 81
I1211 23:32:47.563768 15749 solver.cpp:237]     Train net output #1: label_phocs = 81
I1211 23:32:47.563777 15749 solver.cpp:237]     Train net output #2: loss = 7.29553 (* 1 = 7.29553 loss)
I1211 23:32:47.563783 15749 sgd_solver.cpp:116] Iteration 18200, lr = 0.0001
I1211 23:35:03.502961 15749 solver.cpp:218] Iteration 18300 (0.735623 iter/s, 135.939s/100 iters), loss = 13.9229
I1211 23:35:03.503044 15749 solver.cpp:237]     Train net output #0: label = 868
I1211 23:35:03.503068 15749 solver.cpp:237]     Train net output #1: label_phocs = 868
I1211 23:35:03.503079 15749 solver.cpp:237]     Train net output #2: loss = 0.8174 (* 1 = 0.8174 loss)
I1211 23:35:03.503088 15749 sgd_solver.cpp:116] Iteration 18300, lr = 0.0001
I1211 23:37:19.104972 15749 solver.cpp:218] Iteration 18400 (0.737711 iter/s, 135.554s/100 iters), loss = 13.7997
I1211 23:37:19.105058 15749 solver.cpp:237]     Train net output #0: label = 858
I1211 23:37:19.105082 15749 solver.cpp:237]     Train net output #1: label_phocs = 858
I1211 23:37:19.105093 15749 solver.cpp:237]     Train net output #2: loss = 9.43965 (* 1 = 9.43965 loss)
I1211 23:37:19.105103 15749 sgd_solver.cpp:116] Iteration 18400, lr = 0.0001
[2017-12-11 23:39:46,832, PHOCNetTrainer] Running test evaluation
[2017-12-11 23:39:46,832, PHOCNetTrainer] Evaluating CNN after 18000 steps:
I1211 23:40:29.798758 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:40:29.798924 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 23:40:32,485, PHOCNetTrainer] mAP: 0.877232
I1211 23:40:32.487455 15749 solver.cpp:330] Iteration 18500, Testing net (#0)
I1211 23:40:32.487643 15749 net.cpp:676] Ignoring source layer drop6
I1211 23:40:32.487653 15749 net.cpp:676] Ignoring source layer drop7
I1211 23:41:16.615864 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:41:16.615994 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:41:17.184478 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 23:41:17.184525 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 23:41:17.184537 15749 solver.cpp:397]     Test net output #2: loss = 21.0738 (* 1 = 21.0738 loss)
I1211 23:41:18.594161 15749 solver.cpp:218] Iteration 18500 (0.417555 iter/s, 239.489s/100 iters), loss = 16.0416
I1211 23:41:18.594244 15749 solver.cpp:237]     Train net output #0: label = 232
I1211 23:41:18.594267 15749 solver.cpp:237]     Train net output #1: label_phocs = 232
I1211 23:41:18.594280 15749 solver.cpp:237]     Train net output #2: loss = 9.45625 (* 1 = 9.45625 loss)
I1211 23:41:18.594288 15749 sgd_solver.cpp:116] Iteration 18500, lr = 0.0001
I1211 23:43:42.802712 15749 solver.cpp:218] Iteration 18600 (0.69344 iter/s, 144.209s/100 iters), loss = 12.4625
I1211 23:43:42.802799 15749 solver.cpp:237]     Train net output #0: label = 543
I1211 23:43:42.802824 15749 solver.cpp:237]     Train net output #1: label_phocs = 543
I1211 23:43:42.802835 15749 solver.cpp:237]     Train net output #2: loss = 11.7354 (* 1 = 11.7354 loss)
I1211 23:43:42.802845 15749 sgd_solver.cpp:116] Iteration 18600, lr = 0.0001
I1211 23:46:08.027953 15749 solver.cpp:218] Iteration 18700 (0.688586 iter/s, 145.225s/100 iters), loss = 13.2165
I1211 23:46:08.028020 15749 solver.cpp:237]     Train net output #0: label = 206
I1211 23:46:08.028039 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1211 23:46:08.028048 15749 solver.cpp:237]     Train net output #2: loss = 4.49764 (* 1 = 4.49764 loss)
I1211 23:46:08.028053 15749 sgd_solver.cpp:116] Iteration 18700, lr = 0.0001
I1211 23:48:30.107311 15749 solver.cpp:218] Iteration 18800 (0.703913 iter/s, 142.063s/100 iters), loss = 12.495
I1211 23:48:30.107388 15749 solver.cpp:237]     Train net output #0: label = 28
I1211 23:48:30.107411 15749 solver.cpp:237]     Train net output #1: label_phocs = 28
I1211 23:48:30.107422 15749 solver.cpp:237]     Train net output #2: loss = 4.10982 (* 1 = 4.10982 loss)
I1211 23:48:30.107431 15749 sgd_solver.cpp:116] Iteration 18800, lr = 0.0001
I1211 23:50:45.019608 15749 solver.cpp:218] Iteration 18900 (0.741222 iter/s, 134.912s/100 iters), loss = 12.4743
I1211 23:50:45.019695 15749 solver.cpp:237]     Train net output #0: label = 968
I1211 23:50:45.019718 15749 solver.cpp:237]     Train net output #1: label_phocs = 968
I1211 23:50:45.019731 15749 solver.cpp:237]     Train net output #2: loss = 9.90868 (* 1 = 9.90868 loss)
I1211 23:50:45.019739 15749 sgd_solver.cpp:116] Iteration 18900, lr = 0.0001
[2017-12-11 23:53:09,398, PHOCNetTrainer] Running test evaluation
[2017-12-11 23:53:09,399, PHOCNetTrainer] Evaluating CNN after 18500 steps:
I1211 23:53:58.519507 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:53:58.519526 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-11 23:53:59,903, PHOCNetTrainer] mAP: 0.869477
I1211 23:53:59.904927 15749 solver.cpp:330] Iteration 19000, Testing net (#0)
I1211 23:53:59.905119 15749 net.cpp:676] Ignoring source layer drop6
I1211 23:53:59.905128 15749 net.cpp:676] Ignoring source layer drop7
I1211 23:54:33.998795 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:54:33.998790 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1211 23:54:34.385601 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1211 23:54:34.385637 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1211 23:54:34.385648 15749 solver.cpp:397]     Test net output #2: loss = 21.5873 (* 1 = 21.5873 loss)
I1211 23:54:35.839787 15749 solver.cpp:218] Iteration 19000 (0.433245 iter/s, 230.816s/100 iters), loss = 11.5818
I1211 23:54:35.839869 15749 solver.cpp:237]     Train net output #0: label = 859
I1211 23:54:35.839891 15749 solver.cpp:237]     Train net output #1: label_phocs = 859
I1211 23:54:35.839903 15749 solver.cpp:237]     Train net output #2: loss = 28.5489 (* 1 = 28.5489 loss)
I1211 23:54:35.839912 15749 sgd_solver.cpp:116] Iteration 19000, lr = 0.0001
I1211 23:56:59.956012 15749 solver.cpp:218] Iteration 19100 (0.694006 iter/s, 144.091s/100 iters), loss = 11.9755
I1211 23:56:59.956094 15749 solver.cpp:237]     Train net output #0: label = 629
I1211 23:56:59.956120 15749 solver.cpp:237]     Train net output #1: label_phocs = 629
I1211 23:56:59.956135 15749 solver.cpp:237]     Train net output #2: loss = 8.07547 (* 1 = 8.07547 loss)
I1211 23:56:59.956143 15749 sgd_solver.cpp:116] Iteration 19100, lr = 0.0001
I1211 23:59:26.374516 15749 solver.cpp:218] Iteration 19200 (0.682974 iter/s, 146.419s/100 iters), loss = 11.6207
I1211 23:59:26.374603 15749 solver.cpp:237]     Train net output #0: label = 792
I1211 23:59:26.374626 15749 solver.cpp:237]     Train net output #1: label_phocs = 792
I1211 23:59:26.374639 15749 solver.cpp:237]     Train net output #2: loss = 2.09956 (* 1 = 2.09956 loss)
I1211 23:59:26.374646 15749 sgd_solver.cpp:116] Iteration 19200, lr = 0.0001
I1212 00:01:44.439771 15749 solver.cpp:218] Iteration 19300 (0.724307 iter/s, 138.063s/100 iters), loss = 11.479
I1212 00:01:44.439860 15749 solver.cpp:237]     Train net output #0: label = 858
I1212 00:01:44.439884 15749 solver.cpp:237]     Train net output #1: label_phocs = 858
I1212 00:01:44.439896 15749 solver.cpp:237]     Train net output #2: loss = 7.49972 (* 1 = 7.49972 loss)
I1212 00:01:44.439904 15749 sgd_solver.cpp:116] Iteration 19300, lr = 0.0001
I1212 00:04:07.122123 15749 solver.cpp:218] Iteration 19400 (0.700858 iter/s, 142.682s/100 iters), loss = 12.2754
I1212 00:04:07.122217 15749 solver.cpp:237]     Train net output #0: label = 671
I1212 00:04:07.122237 15749 solver.cpp:237]     Train net output #1: label_phocs = 671
I1212 00:04:07.122246 15749 solver.cpp:237]     Train net output #2: loss = 26.3963 (* 1 = 26.3963 loss)
I1212 00:04:07.122253 15749 sgd_solver.cpp:116] Iteration 19400, lr = 0.0001
[2017-12-12 00:06:34,606, PHOCNetTrainer] Running test evaluation
[2017-12-12 00:06:34,606, PHOCNetTrainer] Evaluating CNN after 19000 steps:
I1212 00:07:14.743849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:07:14.743973 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 00:07:16,967, PHOCNetTrainer] mAP: 0.869024
I1212 00:07:16.969529 15749 solver.cpp:330] Iteration 19500, Testing net (#0)
I1212 00:07:16.969743 15749 net.cpp:676] Ignoring source layer drop6
I1212 00:07:16.969753 15749 net.cpp:676] Ignoring source layer drop7
I1212 00:08:05.942574 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:08:05.942579 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:08:06.567353 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 00:08:06.567389 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 00:08:06.567396 15749 solver.cpp:397]     Test net output #2: loss = 21.3143 (* 1 = 21.3143 loss)
I1212 00:08:08.025794 15749 solver.cpp:218] Iteration 19500 (0.415104 iter/s, 240.904s/100 iters), loss = 15.5428
I1212 00:08:08.025878 15749 solver.cpp:237]     Train net output #0: label = 1063
I1212 00:08:08.025902 15749 solver.cpp:237]     Train net output #1: label_phocs = 1063
I1212 00:08:08.025913 15749 solver.cpp:237]     Train net output #2: loss = 41.2327 (* 1 = 41.2327 loss)
I1212 00:08:08.025923 15749 sgd_solver.cpp:116] Iteration 19500, lr = 0.0001
I1212 00:10:36.063634 15749 solver.cpp:218] Iteration 19600 (0.675503 iter/s, 148.038s/100 iters), loss = 11.9146
I1212 00:10:36.063715 15749 solver.cpp:237]     Train net output #0: label = 250
I1212 00:10:36.063738 15749 solver.cpp:237]     Train net output #1: label_phocs = 250
I1212 00:10:36.063752 15749 solver.cpp:237]     Train net output #2: loss = 11.9295 (* 1 = 11.9295 loss)
I1212 00:10:36.063762 15749 sgd_solver.cpp:116] Iteration 19600, lr = 0.0001
I1212 00:13:04.609196 15749 solver.cpp:218] Iteration 19700 (0.673294 iter/s, 148.523s/100 iters), loss = 11.2037
I1212 00:13:04.609278 15749 solver.cpp:237]     Train net output #0: label = 303
I1212 00:13:04.609303 15749 solver.cpp:237]     Train net output #1: label_phocs = 303
I1212 00:13:04.609315 15749 solver.cpp:237]     Train net output #2: loss = 14.1099 (* 1 = 14.1099 loss)
I1212 00:13:04.609324 15749 sgd_solver.cpp:116] Iteration 19700, lr = 0.0001
I1212 00:15:28.252259 15749 solver.cpp:218] Iteration 19800 (0.69617 iter/s, 143.643s/100 iters), loss = 11.2691
I1212 00:15:28.252338 15749 solver.cpp:237]     Train net output #0: label = 419
I1212 00:15:28.252362 15749 solver.cpp:237]     Train net output #1: label_phocs = 419
I1212 00:15:28.252374 15749 solver.cpp:237]     Train net output #2: loss = 7.23038 (* 1 = 7.23038 loss)
I1212 00:15:28.252382 15749 sgd_solver.cpp:116] Iteration 19800, lr = 0.0001
I1212 00:17:56.390090 15749 solver.cpp:218] Iteration 19900 (0.675047 iter/s, 148.138s/100 iters), loss = 11.4487
I1212 00:17:56.390159 15749 solver.cpp:237]     Train net output #0: label = 968
I1212 00:17:56.390177 15749 solver.cpp:237]     Train net output #1: label_phocs = 968
I1212 00:17:56.390184 15749 solver.cpp:237]     Train net output #2: loss = 3.83469 (* 1 = 3.83469 loss)
I1212 00:17:56.390190 15749 sgd_solver.cpp:116] Iteration 19900, lr = 0.0001
[2017-12-12 00:20:25,572, PHOCNetTrainer] Running test evaluation
[2017-12-12 00:20:25,572, PHOCNetTrainer] Evaluating CNN after 19500 steps:
I1212 00:21:05.201035 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:21:05.201167 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 00:21:07,508, PHOCNetTrainer] mAP: 0.873557
I1212 00:21:07.510175 15749 solver.cpp:330] Iteration 20000, Testing net (#0)
I1212 00:21:07.510365 15749 net.cpp:676] Ignoring source layer drop6
I1212 00:21:07.510375 15749 net.cpp:676] Ignoring source layer drop7
I1212 00:21:45.443965 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:21:45.444123 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:21:45.835286 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 00:21:45.835331 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 00:21:45.835342 15749 solver.cpp:397]     Test net output #2: loss = 20.5083 (* 1 = 20.5083 loss)
I1212 00:21:47.533097 15749 solver.cpp:218] Iteration 20000 (0.432684 iter/s, 231.115s/100 iters), loss = 4.79179
I1212 00:21:47.533174 15749 solver.cpp:237]     Train net output #0: label = 995
I1212 00:21:47.533197 15749 solver.cpp:237]     Train net output #1: label_phocs = 995
I1212 00:21:47.533208 15749 solver.cpp:237]     Train net output #2: loss = 2.49813 (* 1 = 2.49813 loss)
I1212 00:21:47.533216 15749 sgd_solver.cpp:116] Iteration 20000, lr = 0.0001
I1212 00:24:16.048154 15749 solver.cpp:218] Iteration 20100 (0.673483 iter/s, 148.482s/100 iters), loss = 11.3361
I1212 00:24:16.048249 15749 solver.cpp:237]     Train net output #0: label = 808
I1212 00:24:16.048272 15749 solver.cpp:237]     Train net output #1: label_phocs = 808
I1212 00:24:16.048285 15749 solver.cpp:237]     Train net output #2: loss = 16.8556 (* 1 = 16.8556 loss)
I1212 00:24:16.048293 15749 sgd_solver.cpp:116] Iteration 20100, lr = 0.0001
I1212 00:26:45.863252 15749 solver.cpp:218] Iteration 20200 (0.66749 iter/s, 149.815s/100 iters), loss = 10.2866
I1212 00:26:45.863339 15749 solver.cpp:237]     Train net output #0: label = 1098
I1212 00:26:45.863363 15749 solver.cpp:237]     Train net output #1: label_phocs = 1098
I1212 00:26:45.863374 15749 solver.cpp:237]     Train net output #2: loss = 6.22575 (* 1 = 6.22575 loss)
I1212 00:26:45.863382 15749 sgd_solver.cpp:116] Iteration 20200, lr = 0.0001
I1212 00:29:04.808388 15749 solver.cpp:218] Iteration 20300 (0.719709 iter/s, 138.945s/100 iters), loss = 10.9732
I1212 00:29:04.808470 15749 solver.cpp:237]     Train net output #0: label = 995
I1212 00:29:04.808493 15749 solver.cpp:237]     Train net output #1: label_phocs = 995
I1212 00:29:04.808506 15749 solver.cpp:237]     Train net output #2: loss = 11.6753 (* 1 = 11.6753 loss)
I1212 00:29:04.808513 15749 sgd_solver.cpp:116] Iteration 20300, lr = 0.0001
I1212 00:31:30.633188 15749 solver.cpp:218] Iteration 20400 (0.685807 iter/s, 145.814s/100 iters), loss = 10.4823
I1212 00:31:30.633272 15749 solver.cpp:237]     Train net output #0: label = 1034
I1212 00:31:30.633296 15749 solver.cpp:237]     Train net output #1: label_phocs = 1034
I1212 00:31:30.633308 15749 solver.cpp:237]     Train net output #2: loss = 11.4176 (* 1 = 11.4176 loss)
I1212 00:31:30.633323 15749 sgd_solver.cpp:116] Iteration 20400, lr = 0.0001
[2017-12-12 00:33:51,524, PHOCNetTrainer] Running test evaluation
[2017-12-12 00:33:51,524, PHOCNetTrainer] Evaluating CNN after 20000 steps:
I1212 00:34:41.224026 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:34:41.224035 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 00:34:43,673, PHOCNetTrainer] mAP: 0.841267
I1212 00:34:43.675282 15749 solver.cpp:330] Iteration 20500, Testing net (#0)
I1212 00:34:43.675472 15749 net.cpp:676] Ignoring source layer drop6
I1212 00:34:43.675482 15749 net.cpp:676] Ignoring source layer drop7
I1212 00:35:21.348131 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:35:21.348145 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:35:21.673240 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 00:35:21.673279 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 00:35:21.673286 15749 solver.cpp:397]     Test net output #2: loss = 24.9201 (* 1 = 24.9201 loss)
I1212 00:35:23.470856 15749 solver.cpp:218] Iteration 20500 (0.429508 iter/s, 232.825s/100 iters), loss = 8.60816
I1212 00:35:23.470937 15749 solver.cpp:237]     Train net output #0: label = 959
I1212 00:35:23.470959 15749 solver.cpp:237]     Train net output #1: label_phocs = 959
I1212 00:35:23.470971 15749 solver.cpp:237]     Train net output #2: loss = 4.75733 (* 1 = 4.75733 loss)
I1212 00:35:23.470979 15749 sgd_solver.cpp:116] Iteration 20500, lr = 0.0001
I1212 00:37:43.875896 15749 solver.cpp:218] Iteration 20600 (0.712225 iter/s, 140.405s/100 iters), loss = 10.5198
I1212 00:37:43.875984 15749 solver.cpp:237]     Train net output #0: label = 87
I1212 00:37:43.876009 15749 solver.cpp:237]     Train net output #1: label_phocs = 87
I1212 00:37:43.876021 15749 solver.cpp:237]     Train net output #2: loss = 3.75661 (* 1 = 3.75661 loss)
I1212 00:37:43.876030 15749 sgd_solver.cpp:116] Iteration 20600, lr = 0.0001
I1212 00:40:16.741047 15749 solver.cpp:218] Iteration 20700 (0.654171 iter/s, 152.865s/100 iters), loss = 10.1372
I1212 00:40:16.741127 15749 solver.cpp:237]     Train net output #0: label = 868
I1212 00:40:16.741152 15749 solver.cpp:237]     Train net output #1: label_phocs = 868
I1212 00:40:16.741163 15749 solver.cpp:237]     Train net output #2: loss = 7.47536 (* 1 = 7.47536 loss)
I1212 00:40:16.741171 15749 sgd_solver.cpp:116] Iteration 20700, lr = 0.0001
I1212 00:42:37.188496 15749 solver.cpp:218] Iteration 20800 (0.71201 iter/s, 140.447s/100 iters), loss = 10.3167
I1212 00:42:37.188578 15749 solver.cpp:237]     Train net output #0: label = 238
I1212 00:42:37.188603 15749 solver.cpp:237]     Train net output #1: label_phocs = 238
I1212 00:42:37.188616 15749 solver.cpp:237]     Train net output #2: loss = 6.48617 (* 1 = 6.48617 loss)
I1212 00:42:37.188624 15749 sgd_solver.cpp:116] Iteration 20800, lr = 0.0001
I1212 00:45:03.836582 15749 solver.cpp:218] Iteration 20900 (0.681957 iter/s, 146.637s/100 iters), loss = 10.078
I1212 00:45:03.836674 15749 solver.cpp:237]     Train net output #0: label = 518
I1212 00:45:03.836699 15749 solver.cpp:237]     Train net output #1: label_phocs = 518
I1212 00:45:03.836710 15749 solver.cpp:237]     Train net output #2: loss = 4.56662 (* 1 = 4.56662 loss)
I1212 00:45:03.836719 15749 sgd_solver.cpp:116] Iteration 20900, lr = 0.0001
[2017-12-12 00:47:27,206, PHOCNetTrainer] Running test evaluation
[2017-12-12 00:47:27,206, PHOCNetTrainer] Evaluating CNN after 20500 steps:
I1212 00:48:22.733078 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:48:22.733134 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 00:48:23,626, PHOCNetTrainer] mAP: 0.894836
I1212 00:48:23.627643 15749 solver.cpp:330] Iteration 21000, Testing net (#0)
I1212 00:48:23.627826 15749 net.cpp:676] Ignoring source layer drop6
I1212 00:48:23.627833 15749 net.cpp:676] Ignoring source layer drop7
I1212 00:49:06.339917 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:49:06.340051 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 00:49:06.862367 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 00:49:06.862409 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 00:49:06.862421 15749 solver.cpp:397]     Test net output #2: loss = 18.8873 (* 1 = 18.8873 loss)
I1212 00:49:08.264127 15749 solver.cpp:218] Iteration 21000 (0.409119 iter/s, 244.428s/100 iters), loss = 7.8047
I1212 00:49:08.264206 15749 solver.cpp:237]     Train net output #0: label = 1001
I1212 00:49:08.264230 15749 solver.cpp:237]     Train net output #1: label_phocs = 1001
I1212 00:49:08.264240 15749 solver.cpp:237]     Train net output #2: loss = 2.73375 (* 1 = 2.73375 loss)
I1212 00:49:08.264250 15749 sgd_solver.cpp:116] Iteration 21000, lr = 0.0001
I1212 00:51:40.775843 15749 solver.cpp:218] Iteration 21100 (0.655757 iter/s, 152.496s/100 iters), loss = 10.2579
I1212 00:51:40.775933 15749 solver.cpp:237]     Train net output #0: label = 706
I1212 00:51:40.775957 15749 solver.cpp:237]     Train net output #1: label_phocs = 706
I1212 00:51:40.775969 15749 solver.cpp:237]     Train net output #2: loss = 2.77868 (* 1 = 2.77868 loss)
I1212 00:51:40.775979 15749 sgd_solver.cpp:116] Iteration 21100, lr = 0.0001
I1212 00:54:05.650806 15749 solver.cpp:218] Iteration 21200 (0.69025 iter/s, 144.875s/100 iters), loss = 9.50916
I1212 00:54:05.650871 15749 solver.cpp:237]     Train net output #0: label = 597
I1212 00:54:05.650889 15749 solver.cpp:237]     Train net output #1: label_phocs = 597
I1212 00:54:05.650897 15749 solver.cpp:237]     Train net output #2: loss = 4.19891 (* 1 = 4.19891 loss)
I1212 00:54:05.650903 15749 sgd_solver.cpp:116] Iteration 21200, lr = 0.0001
I1212 00:56:31.261900 15749 solver.cpp:218] Iteration 21300 (0.686761 iter/s, 145.611s/100 iters), loss = 9.71895
I1212 00:56:31.261989 15749 solver.cpp:237]     Train net output #0: label = 120
I1212 00:56:31.262012 15749 solver.cpp:237]     Train net output #1: label_phocs = 120
I1212 00:56:31.262024 15749 solver.cpp:237]     Train net output #2: loss = 2.80937 (* 1 = 2.80937 loss)
I1212 00:56:31.262033 15749 sgd_solver.cpp:116] Iteration 21300, lr = 0.0001
I1212 00:59:08.877399 15749 solver.cpp:218] Iteration 21400 (0.634456 iter/s, 157.615s/100 iters), loss = 9.6016
I1212 00:59:08.877490 15749 solver.cpp:237]     Train net output #0: label = 971
I1212 00:59:08.877516 15749 solver.cpp:237]     Train net output #1: label_phocs = 971
I1212 00:59:08.877530 15749 solver.cpp:237]     Train net output #2: loss = 17.5611 (* 1 = 17.5611 loss)
I1212 00:59:08.877540 15749 sgd_solver.cpp:116] Iteration 21400, lr = 0.0001
[2017-12-12 01:01:33,746, PHOCNetTrainer] Running test evaluation
[2017-12-12 01:01:33,746, PHOCNetTrainer] Evaluating CNN after 21000 steps:
I1212 01:02:12.559860 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:02:12.559993 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 01:02:13,723, PHOCNetTrainer] mAP: 0.890978
I1212 01:02:13.725481 15749 solver.cpp:330] Iteration 21500, Testing net (#0)
I1212 01:02:13.725670 15749 net.cpp:676] Ignoring source layer drop6
I1212 01:02:13.725679 15749 net.cpp:676] Ignoring source layer drop7
I1212 01:03:01.846297 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:03:01.846341 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:03:02.162047 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 01:03:02.162086 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 01:03:02.162094 15749 solver.cpp:397]     Test net output #2: loss = 19.3833 (* 1 = 19.3833 loss)
I1212 01:03:03.251668 15749 solver.cpp:218] Iteration 21500 (0.426668 iter/s, 234.374s/100 iters), loss = 10.2343
I1212 01:03:03.251744 15749 solver.cpp:237]     Train net output #0: label = 262
I1212 01:03:03.251773 15749 solver.cpp:237]     Train net output #1: label_phocs = 262
I1212 01:03:03.251785 15749 solver.cpp:237]     Train net output #2: loss = 14.4412 (* 1 = 14.4412 loss)
I1212 01:03:03.251802 15749 sgd_solver.cpp:116] Iteration 21500, lr = 0.0001
I1212 01:05:25.505820 15749 solver.cpp:218] Iteration 21600 (0.70306 iter/s, 142.235s/100 iters), loss = 9.85481
I1212 01:05:25.505892 15749 solver.cpp:237]     Train net output #0: label = 712
I1212 01:05:25.505913 15749 solver.cpp:237]     Train net output #1: label_phocs = 712
I1212 01:05:25.505920 15749 solver.cpp:237]     Train net output #2: loss = 19.0554 (* 1 = 19.0554 loss)
I1212 01:05:25.505928 15749 sgd_solver.cpp:116] Iteration 21600, lr = 0.0001
I1212 01:07:51.393021 15749 solver.cpp:218] Iteration 21700 (0.685493 iter/s, 145.88s/100 iters), loss = 8.67385
I1212 01:07:51.393101 15749 solver.cpp:237]     Train net output #0: label = 801
I1212 01:07:51.393123 15749 solver.cpp:237]     Train net output #1: label_phocs = 801
I1212 01:07:51.393136 15749 solver.cpp:237]     Train net output #2: loss = 16.06 (* 1 = 16.06 loss)
I1212 01:07:51.393143 15749 sgd_solver.cpp:116] Iteration 21700, lr = 0.0001
I1212 01:10:16.567528 15749 solver.cpp:218] Iteration 21800 (0.688826 iter/s, 145.174s/100 iters), loss = 9.2813
I1212 01:10:16.567608 15749 solver.cpp:237]     Train net output #0: label = 460
I1212 01:10:16.567633 15749 solver.cpp:237]     Train net output #1: label_phocs = 460
I1212 01:10:16.567644 15749 solver.cpp:237]     Train net output #2: loss = 13.9774 (* 1 = 13.9774 loss)
I1212 01:10:16.567653 15749 sgd_solver.cpp:116] Iteration 21800, lr = 0.0001
I1212 01:12:44.419003 15749 solver.cpp:218] Iteration 21900 (0.67646 iter/s, 147.828s/100 iters), loss = 8.87207
I1212 01:12:44.419082 15749 solver.cpp:237]     Train net output #0: label = 609
I1212 01:12:44.419106 15749 solver.cpp:237]     Train net output #1: label_phocs = 609
I1212 01:12:44.419116 15749 solver.cpp:237]     Train net output #2: loss = 2.48503 (* 1 = 2.48503 loss)
I1212 01:12:44.419124 15749 sgd_solver.cpp:116] Iteration 21900, lr = 0.0001
[2017-12-12 01:15:12,088, PHOCNetTrainer] Running test evaluation
[2017-12-12 01:15:12,088, PHOCNetTrainer] Evaluating CNN after 21500 steps:
I1212 01:15:52.511862 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:15:52.563925 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 01:15:53,575, PHOCNetTrainer] mAP: 0.895975
I1212 01:15:53.576567 15749 solver.cpp:330] Iteration 22000, Testing net (#0)
I1212 01:15:53.576757 15749 net.cpp:676] Ignoring source layer drop6
I1212 01:15:53.576767 15749 net.cpp:676] Ignoring source layer drop7
I1212 01:16:40.075866 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:16:40.076113 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:16:40.394538 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 01:16:40.394584 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 01:16:40.394595 15749 solver.cpp:397]     Test net output #2: loss = 18.4706 (* 1 = 18.4706 loss)
I1212 01:16:41.539744 15749 solver.cpp:218] Iteration 22000 (0.421726 iter/s, 237.121s/100 iters), loss = 8.84965
I1212 01:16:41.539835 15749 solver.cpp:237]     Train net output #0: label = 1039
I1212 01:16:41.539860 15749 solver.cpp:237]     Train net output #1: label_phocs = 1039
I1212 01:16:41.539872 15749 solver.cpp:237]     Train net output #2: loss = 3.75323 (* 1 = 3.75323 loss)
I1212 01:16:41.539881 15749 sgd_solver.cpp:116] Iteration 22000, lr = 0.0001
I1212 01:19:06.441450 15749 solver.cpp:218] Iteration 22100 (0.690123 iter/s, 144.902s/100 iters), loss = 8.60732
I1212 01:19:06.441529 15749 solver.cpp:237]     Train net output #0: label = 278
I1212 01:19:06.441553 15749 solver.cpp:237]     Train net output #1: label_phocs = 278
I1212 01:19:06.441565 15749 solver.cpp:237]     Train net output #2: loss = 1.57118 (* 1 = 1.57118 loss)
I1212 01:19:06.441573 15749 sgd_solver.cpp:116] Iteration 22100, lr = 0.0001
I1212 01:21:32.347800 15749 solver.cpp:218] Iteration 22200 (0.685459 iter/s, 145.888s/100 iters), loss = 8.94778
I1212 01:21:32.347883 15749 solver.cpp:237]     Train net output #0: label = 440
I1212 01:21:32.347914 15749 solver.cpp:237]     Train net output #1: label_phocs = 440
I1212 01:21:32.347926 15749 solver.cpp:237]     Train net output #2: loss = 3.08797 (* 1 = 3.08797 loss)
I1212 01:21:32.347936 15749 sgd_solver.cpp:116] Iteration 22200, lr = 0.0001
I1212 01:24:05.455212 15749 solver.cpp:218] Iteration 22300 (0.653136 iter/s, 153.107s/100 iters), loss = 9.4747
I1212 01:24:05.455317 15749 solver.cpp:237]     Train net output #0: label = 774
I1212 01:24:05.455348 15749 solver.cpp:237]     Train net output #1: label_phocs = 774
I1212 01:24:05.455363 15749 solver.cpp:237]     Train net output #2: loss = 22.1039 (* 1 = 22.1039 loss)
I1212 01:24:05.455376 15749 sgd_solver.cpp:116] Iteration 22300, lr = 0.0001
I1212 01:26:27.993760 15749 solver.cpp:218] Iteration 22400 (0.701565 iter/s, 142.539s/100 iters), loss = 8.57424
I1212 01:26:27.993844 15749 solver.cpp:237]     Train net output #0: label = 962
I1212 01:26:27.993867 15749 solver.cpp:237]     Train net output #1: label_phocs = 962
I1212 01:26:27.993880 15749 solver.cpp:237]     Train net output #2: loss = 1.33147 (* 1 = 1.33147 loss)
I1212 01:26:27.993888 15749 sgd_solver.cpp:116] Iteration 22400, lr = 0.0001
[2017-12-12 01:28:47,733, PHOCNetTrainer] Running test evaluation
[2017-12-12 01:28:47,734, PHOCNetTrainer] Evaluating CNN after 22000 steps:
I1212 01:29:30.309018 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:29:30.309190 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 01:29:31,371, PHOCNetTrainer] mAP: 0.866843
I1212 01:29:31.373248 15749 solver.cpp:330] Iteration 22500, Testing net (#0)
I1212 01:29:31.373457 15749 net.cpp:676] Ignoring source layer drop6
I1212 01:29:31.373468 15749 net.cpp:676] Ignoring source layer drop7
I1212 01:30:01.425655 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:30:01.425901 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:30:02.310984 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 01:30:02.311029 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 01:30:02.311040 15749 solver.cpp:397]     Test net output #2: loss = 22.2111 (* 1 = 22.2111 loss)
I1212 01:30:03.877980 15749 solver.cpp:218] Iteration 22500 (0.463249 iter/s, 215.867s/100 iters), loss = 10.4957
I1212 01:30:03.886111 15749 solver.cpp:237]     Train net output #0: label = 884
I1212 01:30:03.886164 15749 solver.cpp:237]     Train net output #1: label_phocs = 884
I1212 01:30:03.886178 15749 solver.cpp:237]     Train net output #2: loss = 17.6708 (* 1 = 17.6708 loss)
I1212 01:30:03.886188 15749 sgd_solver.cpp:116] Iteration 22500, lr = 0.0001
I1212 01:32:29.806219 15749 solver.cpp:218] Iteration 22600 (0.685348 iter/s, 145.911s/100 iters), loss = 8.53133
I1212 01:32:29.827883 15749 solver.cpp:237]     Train net output #0: label = 1046
I1212 01:32:29.827944 15749 solver.cpp:237]     Train net output #1: label_phocs = 1046
I1212 01:32:29.827962 15749 solver.cpp:237]     Train net output #2: loss = 6.21333 (* 1 = 6.21333 loss)
I1212 01:32:29.827975 15749 sgd_solver.cpp:116] Iteration 22600, lr = 0.0001
I1212 01:34:56.047092 15749 solver.cpp:218] Iteration 22700 (0.683999 iter/s, 146.199s/100 iters), loss = 7.94552
I1212 01:34:56.047181 15749 solver.cpp:237]     Train net output #0: label = 1034
I1212 01:34:56.047205 15749 solver.cpp:237]     Train net output #1: label_phocs = 1034
I1212 01:34:56.047219 15749 solver.cpp:237]     Train net output #2: loss = 17.135 (* 1 = 17.135 loss)
I1212 01:34:56.047227 15749 sgd_solver.cpp:116] Iteration 22700, lr = 0.0001
I1212 01:37:24.417845 15749 solver.cpp:218] Iteration 22800 (0.673987 iter/s, 148.371s/100 iters), loss = 8.16054
I1212 01:37:24.417938 15749 solver.cpp:237]     Train net output #0: label = 210
I1212 01:37:24.417963 15749 solver.cpp:237]     Train net output #1: label_phocs = 210
I1212 01:37:24.417974 15749 solver.cpp:237]     Train net output #2: loss = 1.34501 (* 1 = 1.34501 loss)
I1212 01:37:24.417982 15749 sgd_solver.cpp:116] Iteration 22800, lr = 0.0001
I1212 01:39:58.160951 15749 solver.cpp:218] Iteration 22900 (0.650793 iter/s, 153.659s/100 iters), loss = 8.88587
I1212 01:39:58.161025 15749 solver.cpp:237]     Train net output #0: label = 541
I1212 01:39:58.161043 15749 solver.cpp:237]     Train net output #1: label_phocs = 541
I1212 01:39:58.161051 15749 solver.cpp:237]     Train net output #2: loss = 3.71453 (* 1 = 3.71453 loss)
I1212 01:39:58.161058 15749 sgd_solver.cpp:116] Iteration 22900, lr = 0.0001
[2017-12-12 01:42:16,862, PHOCNetTrainer] Running test evaluation
[2017-12-12 01:42:16,862, PHOCNetTrainer] Evaluating CNN after 22500 steps:
I1212 01:42:55.799852 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:42:55.800081 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 01:42:56,947, PHOCNetTrainer] mAP: 0.883018
I1212 01:42:56.948752 15749 solver.cpp:330] Iteration 23000, Testing net (#0)
I1212 01:42:56.948951 15749 net.cpp:676] Ignoring source layer drop6
I1212 01:42:56.948961 15749 net.cpp:676] Ignoring source layer drop7
I1212 01:43:43.490486 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:43:43.490494 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:43:43.960212 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 01:43:43.960252 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 01:43:43.960259 15749 solver.cpp:397]     Test net output #2: loss = 19.058 (* 1 = 19.058 loss)
I1212 01:43:45.299993 15749 solver.cpp:218] Iteration 23000 (0.440265 iter/s, 227.136s/100 iters), loss = 8.97212
I1212 01:43:45.300074 15749 solver.cpp:237]     Train net output #0: label = 420
I1212 01:43:45.300096 15749 solver.cpp:237]     Train net output #1: label_phocs = 420
I1212 01:43:45.300108 15749 solver.cpp:237]     Train net output #2: loss = 10.2886 (* 1 = 10.2886 loss)
I1212 01:43:45.300117 15749 sgd_solver.cpp:116] Iteration 23000, lr = 0.0001
I1212 01:46:10.509227 15749 solver.cpp:218] Iteration 23100 (0.688752 iter/s, 145.19s/100 iters), loss = 8.18823
I1212 01:46:10.509306 15749 solver.cpp:237]     Train net output #0: label = 268
I1212 01:46:10.509330 15749 solver.cpp:237]     Train net output #1: label_phocs = 268
I1212 01:46:10.509341 15749 solver.cpp:237]     Train net output #2: loss = 8.44111 (* 1 = 8.44111 loss)
I1212 01:46:10.509348 15749 sgd_solver.cpp:116] Iteration 23100, lr = 0.0001
I1212 01:48:30.735215 15749 solver.cpp:218] Iteration 23200 (0.713135 iter/s, 140.226s/100 iters), loss = 7.55063
I1212 01:48:30.735299 15749 solver.cpp:237]     Train net output #0: label = 678
I1212 01:48:30.735322 15749 solver.cpp:237]     Train net output #1: label_phocs = 678
I1212 01:48:30.735334 15749 solver.cpp:237]     Train net output #2: loss = 2.32959 (* 1 = 2.32959 loss)
I1212 01:48:30.735342 15749 sgd_solver.cpp:116] Iteration 23200, lr = 0.0001
I1212 01:50:56.789363 15749 solver.cpp:218] Iteration 23300 (0.684678 iter/s, 146.054s/100 iters), loss = 7.58321
I1212 01:50:56.789446 15749 solver.cpp:237]     Train net output #0: label = 386
I1212 01:50:56.789470 15749 solver.cpp:237]     Train net output #1: label_phocs = 386
I1212 01:50:56.789482 15749 solver.cpp:237]     Train net output #2: loss = 0.866466 (* 1 = 0.866466 loss)
I1212 01:50:56.789491 15749 sgd_solver.cpp:116] Iteration 23300, lr = 0.0001
I1212 01:53:27.545415 15749 solver.cpp:218] Iteration 23400 (0.663323 iter/s, 150.756s/100 iters), loss = 8.11804
I1212 01:53:27.545492 15749 solver.cpp:237]     Train net output #0: label = 119
I1212 01:53:27.545516 15749 solver.cpp:237]     Train net output #1: label_phocs = 119
I1212 01:53:27.545527 15749 solver.cpp:237]     Train net output #2: loss = 7.87918 (* 1 = 7.87918 loss)
I1212 01:53:27.545536 15749 sgd_solver.cpp:116] Iteration 23400, lr = 0.0001
[2017-12-12 01:55:51,790, PHOCNetTrainer] Running test evaluation
[2017-12-12 01:55:51,790, PHOCNetTrainer] Evaluating CNN after 23000 steps:
I1212 01:56:38.156900 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:56:38.156908 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 01:56:39,938, PHOCNetTrainer] mAP: 0.893532
I1212 01:56:39.988530 15749 solver.cpp:330] Iteration 23500, Testing net (#0)
I1212 01:56:39.988739 15749 net.cpp:676] Ignoring source layer drop6
I1212 01:56:39.988749 15749 net.cpp:676] Ignoring source layer drop7
I1212 01:57:19.611932 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:57:19.612017 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 01:57:20.061354 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 01:57:20.061399 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 01:57:20.061410 15749 solver.cpp:397]     Test net output #2: loss = 17.7253 (* 1 = 17.7253 loss)
I1212 01:57:21.338881 15749 solver.cpp:218] Iteration 23500 (0.427728 iter/s, 233.793s/100 iters), loss = 5.47416
I1212 01:57:21.338948 15749 solver.cpp:237]     Train net output #0: label = 196
I1212 01:57:21.338970 15749 solver.cpp:237]     Train net output #1: label_phocs = 196
I1212 01:57:21.338982 15749 solver.cpp:237]     Train net output #2: loss = 1.11636 (* 1 = 1.11636 loss)
I1212 01:57:21.338990 15749 sgd_solver.cpp:116] Iteration 23500, lr = 0.0001
I1212 01:59:39.885730 15749 solver.cpp:218] Iteration 23600 (0.721961 iter/s, 138.512s/100 iters), loss = 7.17804
I1212 01:59:39.885823 15749 solver.cpp:237]     Train net output #0: label = 261
I1212 01:59:39.885848 15749 solver.cpp:237]     Train net output #1: label_phocs = 261
I1212 01:59:39.885859 15749 solver.cpp:237]     Train net output #2: loss = 10.4887 (* 1 = 10.4887 loss)
I1212 01:59:39.885869 15749 sgd_solver.cpp:116] Iteration 23600, lr = 0.0001
I1212 02:02:03.005790 15749 solver.cpp:218] Iteration 23700 (0.698717 iter/s, 143.119s/100 iters), loss = 6.902
I1212 02:02:03.005875 15749 solver.cpp:237]     Train net output #0: label = 1107
I1212 02:02:03.005899 15749 solver.cpp:237]     Train net output #1: label_phocs = 1107
I1212 02:02:03.005910 15749 solver.cpp:237]     Train net output #2: loss = 7.50902 (* 1 = 7.50902 loss)
I1212 02:02:03.005919 15749 sgd_solver.cpp:116] Iteration 23700, lr = 0.0001
I1212 02:04:26.177042 15749 solver.cpp:218] Iteration 23800 (0.698603 iter/s, 143.143s/100 iters), loss = 7.67308
I1212 02:04:26.177126 15749 solver.cpp:237]     Train net output #0: label = 808
I1212 02:04:26.177150 15749 solver.cpp:237]     Train net output #1: label_phocs = 808
I1212 02:04:26.177161 15749 solver.cpp:237]     Train net output #2: loss = 6.86547 (* 1 = 6.86547 loss)
I1212 02:04:26.177170 15749 sgd_solver.cpp:116] Iteration 23800, lr = 0.0001
I1212 02:06:46.892361 15749 solver.cpp:218] Iteration 23900 (0.710655 iter/s, 140.715s/100 iters), loss = 7.32649
I1212 02:06:46.892457 15749 solver.cpp:237]     Train net output #0: label = 534
I1212 02:06:46.892479 15749 solver.cpp:237]     Train net output #1: label_phocs = 534
I1212 02:06:46.892491 15749 solver.cpp:237]     Train net output #2: loss = 1.99993 (* 1 = 1.99993 loss)
I1212 02:06:46.892500 15749 sgd_solver.cpp:116] Iteration 23900, lr = 0.0001
[2017-12-12 02:09:12,141, PHOCNetTrainer] Running test evaluation
[2017-12-12 02:09:12,142, PHOCNetTrainer] Evaluating CNN after 23500 steps:
I1212 02:10:03.347136 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:10:03.347167 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 02:10:04,361, PHOCNetTrainer] mAP: 0.876843
I1212 02:10:04.363484 15749 solver.cpp:330] Iteration 24000, Testing net (#0)
I1212 02:10:04.363672 15749 net.cpp:676] Ignoring source layer drop6
I1212 02:10:04.363680 15749 net.cpp:676] Ignoring source layer drop7
I1212 02:10:46.045140 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:10:46.045202 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:10:47.844625 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 02:10:47.844676 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 02:10:47.844687 15749 solver.cpp:397]     Test net output #2: loss = 20.8497 (* 1 = 20.8497 loss)
I1212 02:10:49.154413 15749 solver.cpp:218] Iteration 24000 (0.412809 iter/s, 242.243s/100 iters), loss = 4.35907
I1212 02:10:49.154492 15749 solver.cpp:237]     Train net output #0: label = 268
I1212 02:10:49.154516 15749 solver.cpp:237]     Train net output #1: label_phocs = 268
I1212 02:10:49.154527 15749 solver.cpp:237]     Train net output #2: loss = 0.353336 (* 1 = 0.353336 loss)
I1212 02:10:49.154537 15749 sgd_solver.cpp:116] Iteration 24000, lr = 0.0001
I1212 02:13:16.353025 15749 solver.cpp:218] Iteration 24100 (0.679354 iter/s, 147.199s/100 iters), loss = 7.72675
I1212 02:13:16.353107 15749 solver.cpp:237]     Train net output #0: label = 425
I1212 02:13:16.353132 15749 solver.cpp:237]     Train net output #1: label_phocs = 425
I1212 02:13:16.353145 15749 solver.cpp:237]     Train net output #2: loss = 10.1951 (* 1 = 10.1951 loss)
I1212 02:13:16.353155 15749 sgd_solver.cpp:116] Iteration 24100, lr = 0.0001
I1212 02:15:40.455715 15749 solver.cpp:218] Iteration 24200 (0.69395 iter/s, 144.103s/100 iters), loss = 7.29616
I1212 02:15:40.455814 15749 solver.cpp:237]     Train net output #0: label = 200
I1212 02:15:40.455838 15749 solver.cpp:237]     Train net output #1: label_phocs = 200
I1212 02:15:40.455849 15749 solver.cpp:237]     Train net output #2: loss = 7.34196 (* 1 = 7.34196 loss)
I1212 02:15:40.455859 15749 sgd_solver.cpp:116] Iteration 24200, lr = 0.0001
I1212 02:18:04.835911 15749 solver.cpp:218] Iteration 24300 (0.692616 iter/s, 144.38s/100 iters), loss = 7.42956
I1212 02:18:04.835991 15749 solver.cpp:237]     Train net output #0: label = 604
I1212 02:18:04.836015 15749 solver.cpp:237]     Train net output #1: label_phocs = 604
I1212 02:18:04.836027 15749 solver.cpp:237]     Train net output #2: loss = 2.19112 (* 1 = 2.19112 loss)
I1212 02:18:04.836036 15749 sgd_solver.cpp:116] Iteration 24300, lr = 0.0001
I1212 02:20:33.928582 15749 solver.cpp:218] Iteration 24400 (0.670724 iter/s, 149.093s/100 iters), loss = 7.03472
I1212 02:20:33.929040 15749 solver.cpp:237]     Train net output #0: label = 1033
I1212 02:20:33.929071 15749 solver.cpp:237]     Train net output #1: label_phocs = 1033
I1212 02:20:33.929083 15749 solver.cpp:237]     Train net output #2: loss = 10.2687 (* 1 = 10.2687 loss)
I1212 02:20:33.929092 15749 sgd_solver.cpp:116] Iteration 24400, lr = 0.0001
[2017-12-12 02:22:52,124, PHOCNetTrainer] Running test evaluation
[2017-12-12 02:22:52,124, PHOCNetTrainer] Evaluating CNN after 24000 steps:
I1212 02:23:44.607787 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:23:44.608023 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 02:23:45,840, PHOCNetTrainer] mAP: 0.893877
I1212 02:23:45.842347 15749 solver.cpp:330] Iteration 24500, Testing net (#0)
I1212 02:23:45.842536 15749 net.cpp:676] Ignoring source layer drop6
I1212 02:23:45.842545 15749 net.cpp:676] Ignoring source layer drop7
I1212 02:24:27.575830 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:24:27.575963 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:24:27.883859 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 02:24:27.883903 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 02:24:27.883914 15749 solver.cpp:397]     Test net output #2: loss = 18.8024 (* 1 = 18.8024 loss)
I1212 02:24:29.077206 15749 solver.cpp:218] Iteration 24500 (0.425264 iter/s, 235.148s/100 iters), loss = 8.61331
I1212 02:24:29.077287 15749 solver.cpp:237]     Train net output #0: label = 872
I1212 02:24:29.077313 15749 solver.cpp:237]     Train net output #1: label_phocs = 872
I1212 02:24:29.077327 15749 solver.cpp:237]     Train net output #2: loss = 35.4552 (* 1 = 35.4552 loss)
I1212 02:24:29.077337 15749 sgd_solver.cpp:116] Iteration 24500, lr = 0.0001
I1212 02:26:57.713642 15749 solver.cpp:218] Iteration 24600 (0.672787 iter/s, 148.635s/100 iters), loss = 6.65838
I1212 02:26:57.713731 15749 solver.cpp:237]     Train net output #0: label = 732
I1212 02:26:57.713759 15749 solver.cpp:237]     Train net output #1: label_phocs = 732
I1212 02:26:57.713771 15749 solver.cpp:237]     Train net output #2: loss = 13.0642 (* 1 = 13.0642 loss)
I1212 02:26:57.713780 15749 sgd_solver.cpp:116] Iteration 24600, lr = 0.0001
I1212 02:29:29.651507 15749 solver.cpp:218] Iteration 24700 (0.658278 iter/s, 151.912s/100 iters), loss = 7.28037
I1212 02:29:29.651584 15749 solver.cpp:237]     Train net output #0: label = 693
I1212 02:29:29.651608 15749 solver.cpp:237]     Train net output #1: label_phocs = 693
I1212 02:29:29.651619 15749 solver.cpp:237]     Train net output #2: loss = 2.86215 (* 1 = 2.86215 loss)
I1212 02:29:29.651628 15749 sgd_solver.cpp:116] Iteration 24700, lr = 0.0001
I1212 02:31:52.491014 15749 solver.cpp:218] Iteration 24800 (0.700087 iter/s, 142.839s/100 iters), loss = 7.0966
I1212 02:31:52.491112 15749 solver.cpp:237]     Train net output #0: label = 1123
I1212 02:31:52.491138 15749 solver.cpp:237]     Train net output #1: label_phocs = 1123
I1212 02:31:52.491152 15749 solver.cpp:237]     Train net output #2: loss = 11.0982 (* 1 = 11.0982 loss)
I1212 02:31:52.491160 15749 sgd_solver.cpp:116] Iteration 24800, lr = 0.0001
I1212 02:34:15.441745 15749 solver.cpp:218] Iteration 24900 (0.699542 iter/s, 142.951s/100 iters), loss = 6.76722
I1212 02:34:15.441838 15749 solver.cpp:237]     Train net output #0: label = 43
I1212 02:34:15.441860 15749 solver.cpp:237]     Train net output #1: label_phocs = 43
I1212 02:34:15.441871 15749 solver.cpp:237]     Train net output #2: loss = 1.0714 (* 1 = 1.0714 loss)
I1212 02:34:15.441880 15749 sgd_solver.cpp:116] Iteration 24900, lr = 0.0001
[2017-12-12 02:36:35,867, PHOCNetTrainer] Running test evaluation
[2017-12-12 02:36:35,867, PHOCNetTrainer] Evaluating CNN after 24500 steps:
I1212 02:37:26.795121 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:37:26.795155 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 02:37:29,199, PHOCNetTrainer] mAP: 0.891310
I1212 02:37:29.201494 15749 solver.cpp:330] Iteration 25000, Testing net (#0)
I1212 02:37:29.201706 15749 net.cpp:676] Ignoring source layer drop6
I1212 02:37:29.201719 15749 net.cpp:676] Ignoring source layer drop7
I1212 02:38:17.108480 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:38:17.108659 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:38:17.483827 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 02:38:17.483861 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 02:38:17.483870 15749 solver.cpp:397]     Test net output #2: loss = 19.7038 (* 1 = 19.7038 loss)
I1212 02:38:18.497774 15749 solver.cpp:218] Iteration 25000 (0.411442 iter/s, 243.048s/100 iters), loss = 3.33827
I1212 02:38:18.497846 15749 solver.cpp:237]     Train net output #0: label = 1114
I1212 02:38:18.497869 15749 solver.cpp:237]     Train net output #1: label_phocs = 1114
I1212 02:38:18.497880 15749 solver.cpp:237]     Train net output #2: loss = 1.37762 (* 1 = 1.37762 loss)
I1212 02:38:18.497889 15749 sgd_solver.cpp:116] Iteration 25000, lr = 0.0001
I1212 02:40:42.768100 15749 solver.cpp:218] Iteration 25100 (0.693336 iter/s, 144.23s/100 iters), loss = 7.1983
I1212 02:40:42.768185 15749 solver.cpp:237]     Train net output #0: label = 877
I1212 02:40:42.768209 15749 solver.cpp:237]     Train net output #1: label_phocs = 877
I1212 02:40:42.768221 15749 solver.cpp:237]     Train net output #2: loss = 5.51373 (* 1 = 5.51373 loss)
I1212 02:40:42.768229 15749 sgd_solver.cpp:116] Iteration 25100, lr = 0.0001
I1212 02:43:04.812265 15749 solver.cpp:218] Iteration 25200 (0.704058 iter/s, 142.034s/100 iters), loss = 6.27031
I1212 02:43:04.812358 15749 solver.cpp:237]     Train net output #0: label = 1062
I1212 02:43:04.812382 15749 solver.cpp:237]     Train net output #1: label_phocs = 1062
I1212 02:43:04.812393 15749 solver.cpp:237]     Train net output #2: loss = 12.2237 (* 1 = 12.2237 loss)
I1212 02:43:04.812403 15749 sgd_solver.cpp:116] Iteration 25200, lr = 0.0001
I1212 02:45:37.701354 15749 solver.cpp:218] Iteration 25300 (0.654069 iter/s, 152.889s/100 iters), loss = 6.42983
I1212 02:45:37.701434 15749 solver.cpp:237]     Train net output #0: label = 535
I1212 02:45:37.701457 15749 solver.cpp:237]     Train net output #1: label_phocs = 535
I1212 02:45:37.701468 15749 solver.cpp:237]     Train net output #2: loss = 6.98385 (* 1 = 6.98385 loss)
I1212 02:45:37.701476 15749 sgd_solver.cpp:116] Iteration 25300, lr = 0.0001
I1212 02:48:03.572216 15749 solver.cpp:218] Iteration 25400 (0.685539 iter/s, 145.871s/100 iters), loss = 6.84164
I1212 02:48:03.572283 15749 solver.cpp:237]     Train net output #0: label = 529
I1212 02:48:03.572304 15749 solver.cpp:237]     Train net output #1: label_phocs = 529
I1212 02:48:03.572314 15749 solver.cpp:237]     Train net output #2: loss = 3.14017 (* 1 = 3.14017 loss)
I1212 02:48:03.572322 15749 sgd_solver.cpp:116] Iteration 25400, lr = 0.0001
[2017-12-12 02:50:26,019, PHOCNetTrainer] Running test evaluation
[2017-12-12 02:50:26,020, PHOCNetTrainer] Evaluating CNN after 25000 steps:
I1212 02:51:15.478282 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:51:15.478307 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 02:51:17,209, PHOCNetTrainer] mAP: 0.893916
I1212 02:51:17.210562 15749 solver.cpp:330] Iteration 25500, Testing net (#0)
I1212 02:51:17.210742 15749 net.cpp:676] Ignoring source layer drop6
I1212 02:51:17.210749 15749 net.cpp:676] Ignoring source layer drop7
I1212 02:51:51.019848 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:51:51.019975 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 02:51:51.775157 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 02:51:51.775193 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 02:51:51.775200 15749 solver.cpp:397]     Test net output #2: loss = 18.1954 (* 1 = 18.1954 loss)
I1212 02:51:53.142396 15749 solver.cpp:218] Iteration 25500 (0.435602 iter/s, 229.568s/100 iters), loss = 6.20948
I1212 02:51:53.142477 15749 solver.cpp:237]     Train net output #0: label = 489
I1212 02:51:53.142500 15749 solver.cpp:237]     Train net output #1: label_phocs = 489
I1212 02:51:53.142513 15749 solver.cpp:237]     Train net output #2: loss = 9.72986 (* 1 = 9.72986 loss)
I1212 02:51:53.142523 15749 sgd_solver.cpp:116] Iteration 25500, lr = 0.0001
I1212 02:54:22.113279 15749 solver.cpp:218] Iteration 25600 (0.671272 iter/s, 148.971s/100 iters), loss = 6.91112
I1212 02:54:22.113366 15749 solver.cpp:237]     Train net output #0: label = 250
I1212 02:54:22.113390 15749 solver.cpp:237]     Train net output #1: label_phocs = 250
I1212 02:54:22.113401 15749 solver.cpp:237]     Train net output #2: loss = 3.94719 (* 1 = 3.94719 loss)
I1212 02:54:22.113410 15749 sgd_solver.cpp:116] Iteration 25600, lr = 0.0001
I1212 02:56:53.885699 15749 solver.cpp:218] Iteration 25700 (0.658957 iter/s, 151.755s/100 iters), loss = 6.43663
I1212 02:56:53.885782 15749 solver.cpp:237]     Train net output #0: label = 1092
I1212 02:56:53.885807 15749 solver.cpp:237]     Train net output #1: label_phocs = 1092
I1212 02:56:53.885818 15749 solver.cpp:237]     Train net output #2: loss = 1.24349 (* 1 = 1.24349 loss)
I1212 02:56:53.885826 15749 sgd_solver.cpp:116] Iteration 25700, lr = 0.0001
I1212 02:59:20.257201 15749 solver.cpp:218] Iteration 25800 (0.683365 iter/s, 146.335s/100 iters), loss = 6.40207
I1212 02:59:20.257290 15749 solver.cpp:237]     Train net output #0: label = 135
I1212 02:59:20.257314 15749 solver.cpp:237]     Train net output #1: label_phocs = 135
I1212 02:59:20.257325 15749 solver.cpp:237]     Train net output #2: loss = 1.54187 (* 1 = 1.54187 loss)
I1212 02:59:20.257333 15749 sgd_solver.cpp:116] Iteration 25800, lr = 0.0001
I1212 03:01:48.545251 15749 solver.cpp:218] Iteration 25900 (0.674363 iter/s, 148.288s/100 iters), loss = 6.08524
I1212 03:01:48.545323 15749 solver.cpp:237]     Train net output #0: label = 770
I1212 03:01:48.545342 15749 solver.cpp:237]     Train net output #1: label_phocs = 770
I1212 03:01:48.545353 15749 solver.cpp:237]     Train net output #2: loss = 7.18297 (* 1 = 7.18297 loss)
I1212 03:01:48.545361 15749 sgd_solver.cpp:116] Iteration 25900, lr = 0.0001
[2017-12-12 03:04:24,044, PHOCNetTrainer] Running test evaluation
[2017-12-12 03:04:24,044, PHOCNetTrainer] Evaluating CNN after 25500 steps:
I1212 03:05:04.739859 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:05:04.739986 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 03:05:07,853, PHOCNetTrainer] mAP: 0.893333
I1212 03:05:07.854998 15749 solver.cpp:330] Iteration 26000, Testing net (#0)
I1212 03:05:07.863225 15749 net.cpp:676] Ignoring source layer drop6
I1212 03:05:07.863251 15749 net.cpp:676] Ignoring source layer drop7
I1212 03:05:59.410030 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:05:59.412135 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:05:59.729049 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 03:05:59.729089 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 03:05:59.729096 15749 solver.cpp:397]     Test net output #2: loss = 19.3235 (* 1 = 19.3235 loss)
I1212 03:06:01.039988 15749 solver.cpp:218] Iteration 26000 (0.396048 iter/s, 252.495s/100 iters), loss = 7.26419
I1212 03:06:01.040065 15749 solver.cpp:237]     Train net output #0: label = 689
I1212 03:06:01.040086 15749 solver.cpp:237]     Train net output #1: label_phocs = 689
I1212 03:06:01.040098 15749 solver.cpp:237]     Train net output #2: loss = 1.14466 (* 1 = 1.14466 loss)
I1212 03:06:01.040107 15749 sgd_solver.cpp:116] Iteration 26000, lr = 0.0001
I1212 03:08:26.448036 15749 solver.cpp:218] Iteration 26100 (0.68772 iter/s, 145.408s/100 iters), loss = 5.96758
I1212 03:08:26.448112 15749 solver.cpp:237]     Train net output #0: label = 187
I1212 03:08:26.448134 15749 solver.cpp:237]     Train net output #1: label_phocs = 187
I1212 03:08:26.448146 15749 solver.cpp:237]     Train net output #2: loss = 3.61052 (* 1 = 3.61052 loss)
I1212 03:08:26.448155 15749 sgd_solver.cpp:116] Iteration 26100, lr = 0.0001
I1212 03:10:50.334115 15749 solver.cpp:218] Iteration 26200 (0.694994 iter/s, 143.886s/100 iters), loss = 5.7373
I1212 03:10:50.334182 15749 solver.cpp:237]     Train net output #0: label = 1091
I1212 03:10:50.334203 15749 solver.cpp:237]     Train net output #1: label_phocs = 1091
I1212 03:10:50.334210 15749 solver.cpp:237]     Train net output #2: loss = 2.81081 (* 1 = 2.81081 loss)
I1212 03:10:50.334216 15749 sgd_solver.cpp:116] Iteration 26200, lr = 0.0001
I1212 03:13:13.584244 15749 solver.cpp:218] Iteration 26300 (0.69808 iter/s, 143.25s/100 iters), loss = 6.12115
I1212 03:13:13.584324 15749 solver.cpp:237]     Train net output #0: label = 276
I1212 03:13:13.584347 15749 solver.cpp:237]     Train net output #1: label_phocs = 276
I1212 03:13:13.584359 15749 solver.cpp:237]     Train net output #2: loss = 15.1465 (* 1 = 15.1465 loss)
I1212 03:13:13.584368 15749 sgd_solver.cpp:116] Iteration 26300, lr = 0.0001
I1212 03:15:37.636387 15749 solver.cpp:218] Iteration 26400 (0.694321 iter/s, 144.026s/100 iters), loss = 5.35458
I1212 03:15:37.636471 15749 solver.cpp:237]     Train net output #0: label = 1012
I1212 03:15:37.636493 15749 solver.cpp:237]     Train net output #1: label_phocs = 1012
I1212 03:15:37.636505 15749 solver.cpp:237]     Train net output #2: loss = 17.6619 (* 1 = 17.6619 loss)
I1212 03:15:37.636514 15749 sgd_solver.cpp:116] Iteration 26400, lr = 0.0001
[2017-12-12 03:18:09,127, PHOCNetTrainer] Running test evaluation
[2017-12-12 03:18:09,127, PHOCNetTrainer] Evaluating CNN after 26000 steps:
I1212 03:18:50.675843 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:18:50.675987 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 03:18:52,902, PHOCNetTrainer] mAP: 0.901060
I1212 03:18:52.903820 15749 solver.cpp:330] Iteration 26500, Testing net (#0)
I1212 03:18:52.904031 15749 net.cpp:676] Ignoring source layer drop6
I1212 03:18:52.904042 15749 net.cpp:676] Ignoring source layer drop7
I1212 03:19:41.178411 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:19:41.178664 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:19:41.855288 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 03:19:41.855340 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 03:19:41.855350 15749 solver.cpp:397]     Test net output #2: loss = 18.5837 (* 1 = 18.5837 loss)
I1212 03:19:43.771117 15749 solver.cpp:218] Iteration 26500 (0.406282 iter/s, 246.135s/100 iters), loss = 4.51186
I1212 03:19:43.771186 15749 solver.cpp:237]     Train net output #0: label = 770
I1212 03:19:43.771209 15749 solver.cpp:237]     Train net output #1: label_phocs = 770
I1212 03:19:43.771217 15749 solver.cpp:237]     Train net output #2: loss = 3.87965 (* 1 = 3.87965 loss)
I1212 03:19:43.771224 15749 sgd_solver.cpp:116] Iteration 26500, lr = 0.0001
I1212 03:22:04.890919 15749 solver.cpp:218] Iteration 26600 (0.708618 iter/s, 141.12s/100 iters), loss = 6.17362
I1212 03:22:04.891000 15749 solver.cpp:237]     Train net output #0: label = 734
I1212 03:22:04.891023 15749 solver.cpp:237]     Train net output #1: label_phocs = 734
I1212 03:22:04.891034 15749 solver.cpp:237]     Train net output #2: loss = 3.1045 (* 1 = 3.1045 loss)
I1212 03:22:04.891043 15749 sgd_solver.cpp:116] Iteration 26600, lr = 0.0001
I1212 03:24:37.054366 15749 solver.cpp:218] Iteration 26700 (0.657188 iter/s, 152.163s/100 iters), loss = 5.825
I1212 03:24:37.054455 15749 solver.cpp:237]     Train net output #0: label = 735
I1212 03:24:37.054477 15749 solver.cpp:237]     Train net output #1: label_phocs = 735
I1212 03:24:37.054489 15749 solver.cpp:237]     Train net output #2: loss = 2.39085 (* 1 = 2.39085 loss)
I1212 03:24:37.054497 15749 sgd_solver.cpp:116] Iteration 26700, lr = 0.0001
I1212 03:27:10.505815 15749 solver.cpp:218] Iteration 26800 (0.651707 iter/s, 153.443s/100 iters), loss = 5.47215
I1212 03:27:10.505905 15749 solver.cpp:237]     Train net output #0: label = 146
I1212 03:27:10.505931 15749 solver.cpp:237]     Train net output #1: label_phocs = 146
I1212 03:27:10.505944 15749 solver.cpp:237]     Train net output #2: loss = 4.82334 (* 1 = 4.82334 loss)
I1212 03:27:10.505952 15749 sgd_solver.cpp:116] Iteration 26800, lr = 0.0001
I1212 03:29:40.242311 15749 solver.cpp:218] Iteration 26900 (0.66784 iter/s, 149.736s/100 iters), loss = 6.50711
I1212 03:29:40.242383 15749 solver.cpp:237]     Train net output #0: label = 332
I1212 03:29:40.242403 15749 solver.cpp:237]     Train net output #1: label_phocs = 332
I1212 03:29:40.242410 15749 solver.cpp:237]     Train net output #2: loss = 2.62465 (* 1 = 2.62465 loss)
I1212 03:29:40.242417 15749 sgd_solver.cpp:116] Iteration 26900, lr = 0.0001
[2017-12-12 03:32:05,809, PHOCNetTrainer] Running test evaluation
[2017-12-12 03:32:05,809, PHOCNetTrainer] Evaluating CNN after 26500 steps:
I1212 03:32:51.253557 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:32:51.253566 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 03:32:53,730, PHOCNetTrainer] mAP: 0.889491
I1212 03:32:53.732256 15749 solver.cpp:330] Iteration 27000, Testing net (#0)
I1212 03:32:53.732513 15749 net.cpp:676] Ignoring source layer drop6
I1212 03:32:53.732527 15749 net.cpp:676] Ignoring source layer drop7
I1212 03:33:28.848161 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:33:28.848291 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:33:29.236698 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 03:33:29.236743 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 03:33:29.236754 15749 solver.cpp:397]     Test net output #2: loss = 19.1111 (* 1 = 19.1111 loss)
I1212 03:33:31.249066 15749 solver.cpp:218] Iteration 27000 (0.432943 iter/s, 230.977s/100 iters), loss = 4.62217
I1212 03:33:31.249150 15749 solver.cpp:237]     Train net output #0: label = 337
I1212 03:33:31.249168 15749 solver.cpp:237]     Train net output #1: label_phocs = 337
I1212 03:33:31.249186 15749 solver.cpp:237]     Train net output #2: loss = 1.95635 (* 1 = 1.95635 loss)
I1212 03:33:31.249194 15749 sgd_solver.cpp:116] Iteration 27000, lr = 0.0001
I1212 03:35:53.266499 15749 solver.cpp:218] Iteration 27100 (0.704139 iter/s, 142.017s/100 iters), loss = 5.95212
I1212 03:35:53.266574 15749 solver.cpp:237]     Train net output #0: label = 1101
I1212 03:35:53.266599 15749 solver.cpp:237]     Train net output #1: label_phocs = 1101
I1212 03:35:53.266611 15749 solver.cpp:237]     Train net output #2: loss = 11.8541 (* 1 = 11.8541 loss)
I1212 03:35:53.266620 15749 sgd_solver.cpp:116] Iteration 27100, lr = 0.0001
I1212 03:38:25.502249 15749 solver.cpp:218] Iteration 27200 (0.656876 iter/s, 152.236s/100 iters), loss = 5.68492
I1212 03:38:25.502351 15749 solver.cpp:237]     Train net output #0: label = 503
I1212 03:38:25.502385 15749 solver.cpp:237]     Train net output #1: label_phocs = 503
I1212 03:38:25.502396 15749 solver.cpp:237]     Train net output #2: loss = 0.253964 (* 1 = 0.253964 loss)
I1212 03:38:25.502404 15749 sgd_solver.cpp:116] Iteration 27200, lr = 0.0001
I1212 03:40:59.244673 15749 solver.cpp:218] Iteration 27300 (0.650518 iter/s, 153.724s/100 iters), loss = 5.60991
I1212 03:40:59.244763 15749 solver.cpp:237]     Train net output #0: label = 545
I1212 03:40:59.244787 15749 solver.cpp:237]     Train net output #1: label_phocs = 545
I1212 03:40:59.244798 15749 solver.cpp:237]     Train net output #2: loss = 4.73921 (* 1 = 4.73921 loss)
I1212 03:40:59.244807 15749 sgd_solver.cpp:116] Iteration 27300, lr = 0.0001
I1212 03:43:28.522626 15749 solver.cpp:218] Iteration 27400 (0.67007 iter/s, 149.238s/100 iters), loss = 5.4915
I1212 03:43:28.522711 15749 solver.cpp:237]     Train net output #0: label = 859
I1212 03:43:28.522735 15749 solver.cpp:237]     Train net output #1: label_phocs = 859
I1212 03:43:28.522747 15749 solver.cpp:237]     Train net output #2: loss = 16.5399 (* 1 = 16.5399 loss)
I1212 03:43:28.522758 15749 sgd_solver.cpp:116] Iteration 27400, lr = 0.0001
[2017-12-12 03:45:52,820, PHOCNetTrainer] Running test evaluation
[2017-12-12 03:45:52,820, PHOCNetTrainer] Evaluating CNN after 27000 steps:
I1212 03:46:35.673704 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:46:35.673712 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 03:46:37,942, PHOCNetTrainer] mAP: 0.888586
I1212 03:46:37.943950 15749 solver.cpp:330] Iteration 27500, Testing net (#0)
I1212 03:46:37.944146 15749 net.cpp:676] Ignoring source layer drop6
I1212 03:46:37.944155 15749 net.cpp:676] Ignoring source layer drop7
I1212 03:47:18.596936 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:47:18.596953 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 03:47:18.918020 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 03:47:18.918062 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 03:47:18.918073 15749 solver.cpp:397]     Test net output #2: loss = 18.6584 (* 1 = 18.6584 loss)
I1212 03:47:20.177608 15749 solver.cpp:218] Iteration 27500 (0.431676 iter/s, 231.655s/100 iters), loss = 11.2022
I1212 03:47:20.177683 15749 solver.cpp:237]     Train net output #0: label = 148
I1212 03:47:20.177706 15749 solver.cpp:237]     Train net output #1: label_phocs = 148
I1212 03:47:20.177716 15749 solver.cpp:237]     Train net output #2: loss = 3.08715 (* 1 = 3.08715 loss)
I1212 03:47:20.177726 15749 sgd_solver.cpp:116] Iteration 27500, lr = 0.0001
I1212 03:49:39.435184 15749 solver.cpp:218] Iteration 27600 (0.718094 iter/s, 139.258s/100 iters), loss = 5.59836
I1212 03:49:39.435266 15749 solver.cpp:237]     Train net output #0: label = 678
I1212 03:49:39.435289 15749 solver.cpp:237]     Train net output #1: label_phocs = 678
I1212 03:49:39.435299 15749 solver.cpp:237]     Train net output #2: loss = 1.82009 (* 1 = 1.82009 loss)
I1212 03:49:39.435308 15749 sgd_solver.cpp:116] Iteration 27600, lr = 0.0001
I1212 03:52:01.623668 15749 solver.cpp:218] Iteration 27700 (0.703402 iter/s, 142.166s/100 iters), loss = 5.72018
I1212 03:52:01.623767 15749 solver.cpp:237]     Train net output #0: label = 847
I1212 03:52:01.623792 15749 solver.cpp:237]     Train net output #1: label_phocs = 847
I1212 03:52:01.623805 15749 solver.cpp:237]     Train net output #2: loss = 4.49603 (* 1 = 4.49603 loss)
I1212 03:52:01.623813 15749 sgd_solver.cpp:116] Iteration 27700, lr = 0.0001
I1212 03:54:29.481019 15749 solver.cpp:218] Iteration 27800 (0.676437 iter/s, 147.833s/100 iters), loss = 5.44581
I1212 03:54:29.481106 15749 solver.cpp:237]     Train net output #0: label = 295
I1212 03:54:29.481129 15749 solver.cpp:237]     Train net output #1: label_phocs = 295
I1212 03:54:29.481140 15749 solver.cpp:237]     Train net output #2: loss = 3.71989 (* 1 = 3.71989 loss)
I1212 03:54:29.481148 15749 sgd_solver.cpp:116] Iteration 27800, lr = 0.0001
I1212 03:56:54.143914 15749 solver.cpp:218] Iteration 27900 (0.691303 iter/s, 144.654s/100 iters), loss = 5.54043
I1212 03:56:54.144001 15749 solver.cpp:237]     Train net output #0: label = 651
I1212 03:56:54.144024 15749 solver.cpp:237]     Train net output #1: label_phocs = 651
I1212 03:56:54.144037 15749 solver.cpp:237]     Train net output #2: loss = 3.01011 (* 1 = 3.01011 loss)
I1212 03:56:54.144045 15749 sgd_solver.cpp:116] Iteration 27900, lr = 0.0001
[2017-12-12 03:59:17,360, PHOCNetTrainer] Running test evaluation
[2017-12-12 03:59:17,360, PHOCNetTrainer] Evaluating CNN after 27500 steps:
I1212 04:00:06.247743 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:00:06.247756 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 04:00:07,714, PHOCNetTrainer] mAP: 0.907521
I1212 04:00:07.770900 15749 solver.cpp:330] Iteration 28000, Testing net (#0)
I1212 04:00:07.771116 15749 net.cpp:676] Ignoring source layer drop6
I1212 04:00:07.771126 15749 net.cpp:676] Ignoring source layer drop7
I1212 04:00:43.464845 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:00:43.464862 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:00:44.230320 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 04:00:44.230358 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 04:00:44.230366 15749 solver.cpp:397]     Test net output #2: loss = 16.2838 (* 1 = 16.2838 loss)
I1212 04:00:46.064224 15749 solver.cpp:218] Iteration 28000 (0.431183 iter/s, 231.92s/100 iters), loss = 5.4218
I1212 04:00:46.064299 15749 solver.cpp:237]     Train net output #0: label = 599
I1212 04:00:46.064323 15749 solver.cpp:237]     Train net output #1: label_phocs = 599
I1212 04:00:46.064334 15749 solver.cpp:237]     Train net output #2: loss = 9.98877 (* 1 = 9.98877 loss)
I1212 04:00:46.064343 15749 sgd_solver.cpp:116] Iteration 28000, lr = 0.0001
I1212 04:03:21.008796 15749 solver.cpp:218] Iteration 28100 (0.645408 iter/s, 154.941s/100 iters), loss = 5.66756
I1212 04:03:21.008877 15749 solver.cpp:237]     Train net output #0: label = 737
I1212 04:03:21.008900 15749 solver.cpp:237]     Train net output #1: label_phocs = 737
I1212 04:03:21.008911 15749 solver.cpp:237]     Train net output #2: loss = 5.03626 (* 1 = 5.03626 loss)
I1212 04:03:21.008920 15749 sgd_solver.cpp:116] Iteration 28100, lr = 0.0001
I1212 04:05:55.915313 15749 solver.cpp:218] Iteration 28200 (0.64564 iter/s, 154.885s/100 iters), loss = 5.51668
I1212 04:05:55.915395 15749 solver.cpp:237]     Train net output #0: label = 330
I1212 04:05:55.915418 15749 solver.cpp:237]     Train net output #1: label_phocs = 330
I1212 04:05:55.915431 15749 solver.cpp:237]     Train net output #2: loss = 0.562201 (* 1 = 0.562201 loss)
I1212 04:05:55.915439 15749 sgd_solver.cpp:116] Iteration 28200, lr = 0.0001
I1212 04:08:20.148805 15749 solver.cpp:218] Iteration 28300 (0.69332 iter/s, 144.233s/100 iters), loss = 4.98664
I1212 04:08:20.148887 15749 solver.cpp:237]     Train net output #0: label = 848
I1212 04:08:20.148911 15749 solver.cpp:237]     Train net output #1: label_phocs = 848
I1212 04:08:20.148922 15749 solver.cpp:237]     Train net output #2: loss = 2.93928 (* 1 = 2.93928 loss)
I1212 04:08:20.148936 15749 sgd_solver.cpp:116] Iteration 28300, lr = 0.0001
I1212 04:10:51.046007 15749 solver.cpp:218] Iteration 28400 (0.662703 iter/s, 150.897s/100 iters), loss = 5.3029
I1212 04:10:51.046082 15749 solver.cpp:237]     Train net output #0: label = 844
I1212 04:10:51.046105 15749 solver.cpp:237]     Train net output #1: label_phocs = 844
I1212 04:10:51.046118 15749 solver.cpp:237]     Train net output #2: loss = 4.37819 (* 1 = 4.37819 loss)
I1212 04:10:51.046126 15749 sgd_solver.cpp:116] Iteration 28400, lr = 0.0001
[2017-12-12 04:13:10,328, PHOCNetTrainer] Running test evaluation
[2017-12-12 04:13:10,329, PHOCNetTrainer] Evaluating CNN after 28000 steps:
I1212 04:13:59.569903 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:13:59.569949 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 04:14:01,527, PHOCNetTrainer] mAP: 0.903029
I1212 04:14:01.529382 15749 solver.cpp:330] Iteration 28500, Testing net (#0)
I1212 04:14:01.529579 15749 net.cpp:676] Ignoring source layer drop6
I1212 04:14:01.529588 15749 net.cpp:676] Ignoring source layer drop7
I1212 04:14:35.519868 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:14:35.519992 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:14:36.239002 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 04:14:36.239044 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 04:14:36.239055 15749 solver.cpp:397]     Test net output #2: loss = 15.9583 (* 1 = 15.9583 loss)
I1212 04:14:37.668285 15749 solver.cpp:218] Iteration 28500 (0.441263 iter/s, 226.622s/100 iters), loss = 4.69577
I1212 04:14:37.668355 15749 solver.cpp:237]     Train net output #0: label = 949
I1212 04:14:37.668377 15749 solver.cpp:237]     Train net output #1: label_phocs = 949
I1212 04:14:37.668390 15749 solver.cpp:237]     Train net output #2: loss = 1.11433 (* 1 = 1.11433 loss)
I1212 04:14:37.668398 15749 sgd_solver.cpp:116] Iteration 28500, lr = 0.0001
I1212 04:16:57.212738 15749 solver.cpp:218] Iteration 28600 (0.716618 iter/s, 139.544s/100 iters), loss = 4.90803
I1212 04:16:57.212816 15749 solver.cpp:237]     Train net output #0: label = 792
I1212 04:16:57.212841 15749 solver.cpp:237]     Train net output #1: label_phocs = 792
I1212 04:16:57.212852 15749 solver.cpp:237]     Train net output #2: loss = 2.86269 (* 1 = 2.86269 loss)
I1212 04:16:57.212862 15749 sgd_solver.cpp:116] Iteration 28600, lr = 0.0001
I1212 04:19:21.432360 15749 solver.cpp:218] Iteration 28700 (0.693387 iter/s, 144.22s/100 iters), loss = 4.81706
I1212 04:19:21.432441 15749 solver.cpp:237]     Train net output #0: label = 251
I1212 04:19:21.432461 15749 solver.cpp:237]     Train net output #1: label_phocs = 251
I1212 04:19:21.432471 15749 solver.cpp:237]     Train net output #2: loss = 11.5315 (* 1 = 11.5315 loss)
I1212 04:19:21.432477 15749 sgd_solver.cpp:116] Iteration 28700, lr = 0.0001
I1212 04:21:54.080071 15749 solver.cpp:218] Iteration 28800 (0.65513 iter/s, 152.641s/100 iters), loss = 4.86563
I1212 04:21:54.080163 15749 solver.cpp:237]     Train net output #0: label = 460
I1212 04:21:54.080186 15749 solver.cpp:237]     Train net output #1: label_phocs = 460
I1212 04:21:54.080199 15749 solver.cpp:237]     Train net output #2: loss = 6.26787 (* 1 = 6.26787 loss)
I1212 04:21:54.080207 15749 sgd_solver.cpp:116] Iteration 28800, lr = 0.0001
I1212 04:24:25.636445 15749 solver.cpp:218] Iteration 28900 (0.65982 iter/s, 151.556s/100 iters), loss = 4.98735
I1212 04:24:25.636526 15749 solver.cpp:237]     Train net output #0: label = 1115
I1212 04:24:25.636549 15749 solver.cpp:237]     Train net output #1: label_phocs = 1115
I1212 04:24:25.636561 15749 solver.cpp:237]     Train net output #2: loss = 0.215831 (* 1 = 0.215831 loss)
I1212 04:24:25.636570 15749 sgd_solver.cpp:116] Iteration 28900, lr = 0.0001
[2017-12-12 04:26:47,566, PHOCNetTrainer] Running test evaluation
[2017-12-12 04:26:47,566, PHOCNetTrainer] Evaluating CNN after 28500 steps:
I1212 04:27:30.654707 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:27:30.654844 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 04:27:33,185, PHOCNetTrainer] mAP: 0.908363
I1212 04:27:33.186832 15749 solver.cpp:330] Iteration 29000, Testing net (#0)
I1212 04:27:33.187017 15749 net.cpp:676] Ignoring source layer drop6
I1212 04:27:33.187026 15749 net.cpp:676] Ignoring source layer drop7
I1212 04:28:09.459857 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:28:09.460098 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:28:09.835465 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 04:28:09.835506 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 04:28:09.835515 15749 solver.cpp:397]     Test net output #2: loss = 16.8013 (* 1 = 16.8013 loss)
I1212 04:28:11.843539 15749 solver.cpp:218] Iteration 29000 (0.442073 iter/s, 226.207s/100 iters), loss = 2.6706
I1212 04:28:11.843618 15749 solver.cpp:237]     Train net output #0: label = 687
I1212 04:28:11.843641 15749 solver.cpp:237]     Train net output #1: label_phocs = 687
I1212 04:28:11.843652 15749 solver.cpp:237]     Train net output #2: loss = 1.34872 (* 1 = 1.34872 loss)
I1212 04:28:11.843660 15749 sgd_solver.cpp:116] Iteration 29000, lr = 0.0001
I1212 04:30:37.754163 15749 solver.cpp:218] Iteration 29100 (0.685351 iter/s, 145.911s/100 iters), loss = 4.9493
I1212 04:30:37.754247 15749 solver.cpp:237]     Train net output #0: label = 573
I1212 04:30:37.754271 15749 solver.cpp:237]     Train net output #1: label_phocs = 573
I1212 04:30:37.754282 15749 solver.cpp:237]     Train net output #2: loss = 3.57792 (* 1 = 3.57792 loss)
I1212 04:30:37.754292 15749 sgd_solver.cpp:116] Iteration 29100, lr = 0.0001
I1212 04:33:00.970871 15749 solver.cpp:218] Iteration 29200 (0.698268 iter/s, 143.212s/100 iters), loss = 4.67836
I1212 04:33:00.970942 15749 solver.cpp:237]     Train net output #0: label = 492
I1212 04:33:00.970963 15749 solver.cpp:237]     Train net output #1: label_phocs = 492
I1212 04:33:00.970969 15749 solver.cpp:237]     Train net output #2: loss = 3.61915 (* 1 = 3.61915 loss)
I1212 04:33:00.970976 15749 sgd_solver.cpp:116] Iteration 29200, lr = 0.0001
I1212 04:35:28.210821 15749 solver.cpp:218] Iteration 29300 (0.679163 iter/s, 147.24s/100 iters), loss = 5.24822
I1212 04:35:28.210911 15749 solver.cpp:237]     Train net output #0: label = 445
I1212 04:35:28.210934 15749 solver.cpp:237]     Train net output #1: label_phocs = 445
I1212 04:35:28.210945 15749 solver.cpp:237]     Train net output #2: loss = 5.39972 (* 1 = 5.39972 loss)
I1212 04:35:28.210954 15749 sgd_solver.cpp:116] Iteration 29300, lr = 0.0001
I1212 04:37:57.617966 15749 solver.cpp:218] Iteration 29400 (0.669312 iter/s, 149.407s/100 iters), loss = 4.98339
I1212 04:37:57.618059 15749 solver.cpp:237]     Train net output #0: label = 963
I1212 04:37:57.618083 15749 solver.cpp:237]     Train net output #1: label_phocs = 963
I1212 04:37:57.618096 15749 solver.cpp:237]     Train net output #2: loss = 22.4446 (* 1 = 22.4446 loss)
I1212 04:37:57.618105 15749 sgd_solver.cpp:116] Iteration 29400, lr = 0.0001
[2017-12-12 04:40:29,548, PHOCNetTrainer] Running test evaluation
[2017-12-12 04:40:29,548, PHOCNetTrainer] Evaluating CNN after 29000 steps:
I1212 04:41:19.683941 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:41:19.684000 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 04:41:20,936, PHOCNetTrainer] mAP: 0.901525
I1212 04:41:20.937746 15749 solver.cpp:330] Iteration 29500, Testing net (#0)
I1212 04:41:20.937942 15749 net.cpp:676] Ignoring source layer drop6
I1212 04:41:20.937949 15749 net.cpp:676] Ignoring source layer drop7
I1212 04:41:59.860230 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:41:59.860383 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:42:00.245882 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 04:42:00.245921 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 04:42:00.245935 15749 solver.cpp:397]     Test net output #2: loss = 17.3535 (* 1 = 17.3535 loss)
I1212 04:42:01.531431 15749 solver.cpp:218] Iteration 29500 (0.409982 iter/s, 243.913s/100 iters), loss = 5.0722
I1212 04:42:01.531505 15749 solver.cpp:237]     Train net output #0: label = 53
I1212 04:42:01.531528 15749 solver.cpp:237]     Train net output #1: label_phocs = 53
I1212 04:42:01.531539 15749 solver.cpp:237]     Train net output #2: loss = 0.0539367 (* 1 = 0.0539367 loss)
I1212 04:42:01.531548 15749 sgd_solver.cpp:116] Iteration 29500, lr = 0.0001
I1212 04:44:18.985590 15749 solver.cpp:218] Iteration 29600 (0.727515 iter/s, 137.454s/100 iters), loss = 4.72515
I1212 04:44:18.985666 15749 solver.cpp:237]     Train net output #0: label = 717
I1212 04:44:18.985690 15749 solver.cpp:237]     Train net output #1: label_phocs = 717
I1212 04:44:18.985702 15749 solver.cpp:237]     Train net output #2: loss = 2.24622 (* 1 = 2.24622 loss)
I1212 04:44:18.985710 15749 sgd_solver.cpp:116] Iteration 29600, lr = 0.0001
I1212 04:46:42.621403 15749 solver.cpp:218] Iteration 29700 (0.696274 iter/s, 143.622s/100 iters), loss = 4.38745
I1212 04:46:42.621475 15749 solver.cpp:237]     Train net output #0: label = 1075
I1212 04:46:42.621495 15749 solver.cpp:237]     Train net output #1: label_phocs = 1075
I1212 04:46:42.621502 15749 solver.cpp:237]     Train net output #2: loss = 5.09887 (* 1 = 5.09887 loss)
I1212 04:46:42.621510 15749 sgd_solver.cpp:116] Iteration 29700, lr = 0.0001
I1212 04:49:10.706742 15749 solver.cpp:218] Iteration 29800 (0.675289 iter/s, 148.085s/100 iters), loss = 4.82361
I1212 04:49:10.706822 15749 solver.cpp:237]     Train net output #0: label = 784
I1212 04:49:10.706846 15749 solver.cpp:237]     Train net output #1: label_phocs = 784
I1212 04:49:10.706858 15749 solver.cpp:237]     Train net output #2: loss = 5.82807 (* 1 = 5.82807 loss)
I1212 04:49:10.706866 15749 sgd_solver.cpp:116] Iteration 29800, lr = 0.0001
I1212 04:51:33.941004 15749 solver.cpp:218] Iteration 29900 (0.698157 iter/s, 143.234s/100 iters), loss = 4.6465
I1212 04:51:33.941078 15749 solver.cpp:237]     Train net output #0: label = 8
I1212 04:51:33.941102 15749 solver.cpp:237]     Train net output #1: label_phocs = 8
I1212 04:51:33.941113 15749 solver.cpp:237]     Train net output #2: loss = 3.94284 (* 1 = 3.94284 loss)
I1212 04:51:33.941123 15749 sgd_solver.cpp:116] Iteration 29900, lr = 0.0001
[2017-12-12 04:53:54,837, PHOCNetTrainer] Running test evaluation
[2017-12-12 04:53:54,837, PHOCNetTrainer] Evaluating CNN after 29500 steps:
I1212 04:54:37.051849 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:54:37.051986 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 04:54:38,829, PHOCNetTrainer] mAP: 0.902907
I1212 04:54:38.831259 15749 solver.cpp:330] Iteration 30000, Testing net (#0)
I1212 04:54:38.831463 15749 net.cpp:676] Ignoring source layer drop6
I1212 04:54:38.831473 15749 net.cpp:676] Ignoring source layer drop7
I1212 04:55:20.827839 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:55:20.827955 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 04:55:21.144178 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 04:55:21.144220 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 04:55:21.144232 15749 solver.cpp:397]     Test net output #2: loss = 17.4008 (* 1 = 17.4008 loss)
I1212 04:55:22.240767 15749 solver.cpp:218] Iteration 30000 (0.438021 iter/s, 228.3s/100 iters), loss = 7.16981
I1212 04:55:22.240828 15749 solver.cpp:237]     Train net output #0: label = 571
I1212 04:55:22.240847 15749 solver.cpp:237]     Train net output #1: label_phocs = 571
I1212 04:55:22.240854 15749 solver.cpp:237]     Train net output #2: loss = 1.68369 (* 1 = 1.68369 loss)
I1212 04:55:22.240860 15749 sgd_solver.cpp:116] Iteration 30000, lr = 0.0001
I1212 04:57:48.555310 15749 solver.cpp:218] Iteration 30100 (0.683459 iter/s, 146.315s/100 iters), loss = 4.85648
I1212 04:57:48.555384 15749 solver.cpp:237]     Train net output #0: label = 367
I1212 04:57:48.555403 15749 solver.cpp:237]     Train net output #1: label_phocs = 367
I1212 04:57:48.555411 15749 solver.cpp:237]     Train net output #2: loss = 0.633078 (* 1 = 0.633078 loss)
I1212 04:57:48.555418 15749 sgd_solver.cpp:116] Iteration 30100, lr = 0.0001
I1212 05:00:19.003794 15749 solver.cpp:218] Iteration 30200 (0.664777 iter/s, 150.426s/100 iters), loss = 4.63281
I1212 05:00:19.003890 15749 solver.cpp:237]     Train net output #0: label = 723
I1212 05:00:19.003914 15749 solver.cpp:237]     Train net output #1: label_phocs = 723
I1212 05:00:19.003926 15749 solver.cpp:237]     Train net output #2: loss = 0.493782 (* 1 = 0.493782 loss)
I1212 05:00:19.003934 15749 sgd_solver.cpp:116] Iteration 30200, lr = 0.0001
I1212 05:02:50.496749 15749 solver.cpp:218] Iteration 30300 (0.660097 iter/s, 151.493s/100 iters), loss = 4.85161
I1212 05:02:50.496831 15749 solver.cpp:237]     Train net output #0: label = 1058
I1212 05:02:50.496855 15749 solver.cpp:237]     Train net output #1: label_phocs = 1058
I1212 05:02:50.496865 15749 solver.cpp:237]     Train net output #2: loss = 1.10191 (* 1 = 1.10191 loss)
I1212 05:02:50.496873 15749 sgd_solver.cpp:116] Iteration 30300, lr = 0.0001
I1212 05:05:15.984654 15749 solver.cpp:218] Iteration 30400 (0.687343 iter/s, 145.488s/100 iters), loss = 4.23306
I1212 05:05:15.984726 15749 solver.cpp:237]     Train net output #0: label = 400
I1212 05:05:15.984745 15749 solver.cpp:237]     Train net output #1: label_phocs = 400
I1212 05:05:15.984753 15749 solver.cpp:237]     Train net output #2: loss = 0.312029 (* 1 = 0.312029 loss)
I1212 05:05:15.984760 15749 sgd_solver.cpp:116] Iteration 30400, lr = 0.0001
[2017-12-12 05:07:36,867, PHOCNetTrainer] Running test evaluation
[2017-12-12 05:07:36,867, PHOCNetTrainer] Evaluating CNN after 30000 steps:
I1212 05:08:18.987992 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:08:18.988121 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 05:08:21,557, PHOCNetTrainer] mAP: 0.905067
I1212 05:08:21.558506 15749 solver.cpp:330] Iteration 30500, Testing net (#0)
I1212 05:08:21.558698 15749 net.cpp:676] Ignoring source layer drop6
I1212 05:08:21.558707 15749 net.cpp:676] Ignoring source layer drop7
I1212 05:09:00.988591 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:09:00.988600 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:09:01.298951 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 05:09:01.298982 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 05:09:01.298990 15749 solver.cpp:397]     Test net output #2: loss = 16.9923 (* 1 = 16.9923 loss)
I1212 05:09:02.276785 15749 solver.cpp:218] Iteration 30500 (0.441907 iter/s, 226.292s/100 iters), loss = 4.46402
I1212 05:09:02.276849 15749 solver.cpp:237]     Train net output #0: label = 1100
I1212 05:09:02.276868 15749 solver.cpp:237]     Train net output #1: label_phocs = 1100
I1212 05:09:02.276876 15749 solver.cpp:237]     Train net output #2: loss = 10.5331 (* 1 = 10.5331 loss)
I1212 05:09:02.276882 15749 sgd_solver.cpp:116] Iteration 30500, lr = 0.0001
I1212 05:11:35.939782 15749 solver.cpp:218] Iteration 30600 (0.650895 iter/s, 153.635s/100 iters), loss = 4.42979
I1212 05:11:35.939863 15749 solver.cpp:237]     Train net output #0: label = 1021
I1212 05:11:35.939887 15749 solver.cpp:237]     Train net output #1: label_phocs = 1021
I1212 05:11:35.939898 15749 solver.cpp:237]     Train net output #2: loss = 1.95931 (* 1 = 1.95931 loss)
I1212 05:11:35.939906 15749 sgd_solver.cpp:116] Iteration 30600, lr = 0.0001
I1212 05:14:11.286626 15749 solver.cpp:218] Iteration 30700 (0.643733 iter/s, 155.344s/100 iters), loss = 3.99067
I1212 05:14:11.286743 15749 solver.cpp:237]     Train net output #0: label = 137
I1212 05:14:11.286778 15749 solver.cpp:237]     Train net output #1: label_phocs = 137
I1212 05:14:11.286798 15749 solver.cpp:237]     Train net output #2: loss = 1.57005 (* 1 = 1.57005 loss)
I1212 05:14:11.286813 15749 sgd_solver.cpp:116] Iteration 30700, lr = 0.0001
I1212 05:16:36.089823 15749 solver.cpp:218] Iteration 30800 (0.690631 iter/s, 144.795s/100 iters), loss = 4.31461
I1212 05:16:36.089910 15749 solver.cpp:237]     Train net output #0: label = 909
I1212 05:16:36.089936 15749 solver.cpp:237]     Train net output #1: label_phocs = 909
I1212 05:16:36.089948 15749 solver.cpp:237]     Train net output #2: loss = 32.3008 (* 1 = 32.3008 loss)
I1212 05:16:36.089957 15749 sgd_solver.cpp:116] Iteration 30800, lr = 0.0001
I1212 05:19:05.211805 15749 solver.cpp:218] Iteration 30900 (0.670665 iter/s, 149.106s/100 iters), loss = 4.61203
I1212 05:19:05.211895 15749 solver.cpp:237]     Train net output #0: label = 521
I1212 05:19:05.211918 15749 solver.cpp:237]     Train net output #1: label_phocs = 521
I1212 05:19:05.211930 15749 solver.cpp:237]     Train net output #2: loss = 17.026 (* 1 = 17.026 loss)
I1212 05:19:05.211940 15749 sgd_solver.cpp:116] Iteration 30900, lr = 0.0001
[2017-12-12 05:21:20,842, PHOCNetTrainer] Running test evaluation
[2017-12-12 05:21:20,842, PHOCNetTrainer] Evaluating CNN after 30500 steps:
I1212 05:22:00.500061 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:22:00.500176 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 05:22:02,129, PHOCNetTrainer] mAP: 0.889512
I1212 05:22:02.131167 15749 solver.cpp:330] Iteration 31000, Testing net (#0)
I1212 05:22:02.131408 15749 net.cpp:676] Ignoring source layer drop6
I1212 05:22:02.131418 15749 net.cpp:676] Ignoring source layer drop7
I1212 05:22:45.227911 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:22:45.228088 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:22:45.684275 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 05:22:45.684319 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 05:22:45.684330 15749 solver.cpp:397]     Test net output #2: loss = 19.1571 (* 1 = 19.1571 loss)
I1212 05:22:47.163308 15749 solver.cpp:218] Iteration 31000 (0.450592 iter/s, 221.93s/100 iters), loss = 4.37363
I1212 05:22:47.163388 15749 solver.cpp:237]     Train net output #0: label = 206
I1212 05:22:47.163410 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1212 05:22:47.163421 15749 solver.cpp:237]     Train net output #2: loss = 2.82181 (* 1 = 2.82181 loss)
I1212 05:22:47.163430 15749 sgd_solver.cpp:116] Iteration 31000, lr = 0.0001
I1212 05:25:10.830940 15749 solver.cpp:218] Iteration 31100 (0.696051 iter/s, 143.668s/100 iters), loss = 4.2654
I1212 05:25:10.831002 15749 solver.cpp:237]     Train net output #0: label = 585
I1212 05:25:10.831022 15749 solver.cpp:237]     Train net output #1: label_phocs = 585
I1212 05:25:10.831028 15749 solver.cpp:237]     Train net output #2: loss = 3.05522 (* 1 = 3.05522 loss)
I1212 05:25:10.831034 15749 sgd_solver.cpp:116] Iteration 31100, lr = 0.0001
I1212 05:27:29.203387 15749 solver.cpp:218] Iteration 31200 (0.722687 iter/s, 138.372s/100 iters), loss = 4.10266
I1212 05:27:29.203461 15749 solver.cpp:237]     Train net output #0: label = 691
I1212 05:27:29.203486 15749 solver.cpp:237]     Train net output #1: label_phocs = 691
I1212 05:27:29.203497 15749 solver.cpp:237]     Train net output #2: loss = 2.44238 (* 1 = 2.44238 loss)
I1212 05:27:29.203505 15749 sgd_solver.cpp:116] Iteration 31200, lr = 0.0001
I1212 05:29:50.946135 15749 solver.cpp:218] Iteration 31300 (0.70553 iter/s, 141.737s/100 iters), loss = 4.52224
I1212 05:29:50.946215 15749 solver.cpp:237]     Train net output #0: label = 311
I1212 05:29:50.946238 15749 solver.cpp:237]     Train net output #1: label_phocs = 311
I1212 05:29:50.946250 15749 solver.cpp:237]     Train net output #2: loss = 4.75088 (* 1 = 4.75088 loss)
I1212 05:29:50.946259 15749 sgd_solver.cpp:116] Iteration 31300, lr = 0.0001
I1212 05:32:17.123507 15749 solver.cpp:218] Iteration 31400 (0.684101 iter/s, 146.177s/100 iters), loss = 4.24778
I1212 05:32:17.123596 15749 solver.cpp:237]     Train net output #0: label = 347
I1212 05:32:17.123625 15749 solver.cpp:237]     Train net output #1: label_phocs = 347
I1212 05:32:17.123638 15749 solver.cpp:237]     Train net output #2: loss = 0.253667 (* 1 = 0.253667 loss)
I1212 05:32:17.123647 15749 sgd_solver.cpp:116] Iteration 31400, lr = 0.0001
[2017-12-12 05:34:44,184, PHOCNetTrainer] Running test evaluation
[2017-12-12 05:34:44,184, PHOCNetTrainer] Evaluating CNN after 31000 steps:
I1212 05:35:24.851841 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:35:24.851963 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 05:35:25,951, PHOCNetTrainer] mAP: 0.908953
I1212 05:35:25.953495 15749 solver.cpp:330] Iteration 31500, Testing net (#0)
I1212 05:35:25.953685 15749 net.cpp:676] Ignoring source layer drop6
I1212 05:35:25.953693 15749 net.cpp:676] Ignoring source layer drop7
I1212 05:36:00.307875 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:36:00.308120 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:36:01.434708 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 05:36:01.434752 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 05:36:01.434763 15749 solver.cpp:397]     Test net output #2: loss = 16.2595 (* 1 = 16.2595 loss)
I1212 05:36:03.723460 15749 solver.cpp:218] Iteration 31500 (0.441426 iter/s, 226.539s/100 iters), loss = 3.82231
I1212 05:36:03.723537 15749 solver.cpp:237]     Train net output #0: label = 382
I1212 05:36:03.723559 15749 solver.cpp:237]     Train net output #1: label_phocs = 382
I1212 05:36:03.723570 15749 solver.cpp:237]     Train net output #2: loss = 0.974836 (* 1 = 0.974836 loss)
I1212 05:36:03.723579 15749 sgd_solver.cpp:116] Iteration 31500, lr = 0.0001
I1212 05:38:20.807323 15749 solver.cpp:218] Iteration 31600 (0.72948 iter/s, 137.084s/100 iters), loss = 4.0727
I1212 05:38:20.807407 15749 solver.cpp:237]     Train net output #0: label = 102
I1212 05:38:20.807432 15749 solver.cpp:237]     Train net output #1: label_phocs = 102
I1212 05:38:20.807443 15749 solver.cpp:237]     Train net output #2: loss = 1.05651 (* 1 = 1.05651 loss)
I1212 05:38:20.807452 15749 sgd_solver.cpp:116] Iteration 31600, lr = 0.0001
I1212 05:40:48.334342 15749 solver.cpp:218] Iteration 31700 (0.677842 iter/s, 147.527s/100 iters), loss = 4.18518
I1212 05:40:48.334417 15749 solver.cpp:237]     Train net output #0: label = 458
I1212 05:40:48.334440 15749 solver.cpp:237]     Train net output #1: label_phocs = 458
I1212 05:40:48.334451 15749 solver.cpp:237]     Train net output #2: loss = 4.91304 (* 1 = 4.91304 loss)
I1212 05:40:48.334460 15749 sgd_solver.cpp:116] Iteration 31700, lr = 0.0001
I1212 05:43:15.189023 15749 solver.cpp:218] Iteration 31800 (0.680945 iter/s, 146.855s/100 iters), loss = 3.95228
I1212 05:43:15.189112 15749 solver.cpp:237]     Train net output #0: label = 1055
I1212 05:43:15.189136 15749 solver.cpp:237]     Train net output #1: label_phocs = 1055
I1212 05:43:15.189147 15749 solver.cpp:237]     Train net output #2: loss = 7.00429 (* 1 = 7.00429 loss)
I1212 05:43:15.189157 15749 sgd_solver.cpp:116] Iteration 31800, lr = 0.0001
I1212 05:45:48.816104 15749 solver.cpp:218] Iteration 31900 (0.651112 iter/s, 153.583s/100 iters), loss = 4.02035
I1212 05:45:48.816184 15749 solver.cpp:237]     Train net output #0: label = 1095
I1212 05:45:48.816206 15749 solver.cpp:237]     Train net output #1: label_phocs = 1095
I1212 05:45:48.816218 15749 solver.cpp:237]     Train net output #2: loss = 0.240948 (* 1 = 0.240948 loss)
I1212 05:45:48.816227 15749 sgd_solver.cpp:116] Iteration 31900, lr = 0.0001
[2017-12-12 05:48:23,350, PHOCNetTrainer] Running test evaluation
[2017-12-12 05:48:23,350, PHOCNetTrainer] Evaluating CNN after 31500 steps:
I1212 05:49:09.759963 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:49:09.759968 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 05:49:13,310, PHOCNetTrainer] mAP: 0.876494
I1212 05:49:13.311548 15749 solver.cpp:330] Iteration 32000, Testing net (#0)
I1212 05:49:13.311738 15749 net.cpp:676] Ignoring source layer drop6
I1212 05:49:13.311745 15749 net.cpp:676] Ignoring source layer drop7
I1212 05:50:01.260152 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:50:01.260397 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 05:50:01.986727 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 05:50:01.986779 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 05:50:01.986796 15749 solver.cpp:397]     Test net output #2: loss = 20.6948 (* 1 = 20.6948 loss)
I1212 05:50:03.888815 15749 solver.cpp:218] Iteration 32000 (0.39207 iter/s, 255.057s/100 iters), loss = 3.69748
I1212 05:50:03.888898 15749 solver.cpp:237]     Train net output #0: label = 542
I1212 05:50:03.888924 15749 solver.cpp:237]     Train net output #1: label_phocs = 542
I1212 05:50:03.888936 15749 solver.cpp:237]     Train net output #2: loss = 0.481541 (* 1 = 0.481541 loss)
I1212 05:50:03.888945 15749 sgd_solver.cpp:116] Iteration 32000, lr = 0.0001
I1212 05:52:29.400169 15749 solver.cpp:218] Iteration 32100 (0.68745 iter/s, 145.465s/100 iters), loss = 4.02154
I1212 05:52:29.400249 15749 solver.cpp:237]     Train net output #0: label = 347
I1212 05:52:29.400270 15749 solver.cpp:237]     Train net output #1: label_phocs = 347
I1212 05:52:29.400281 15749 solver.cpp:237]     Train net output #2: loss = 6.12152 (* 1 = 6.12152 loss)
I1212 05:52:29.400290 15749 sgd_solver.cpp:116] Iteration 32100, lr = 0.0001
I1212 05:54:49.627974 15749 solver.cpp:218] Iteration 32200 (0.713125 iter/s, 140.228s/100 iters), loss = 4.07353
I1212 05:54:49.628057 15749 solver.cpp:237]     Train net output #0: label = 493
I1212 05:54:49.628082 15749 solver.cpp:237]     Train net output #1: label_phocs = 493
I1212 05:54:49.628093 15749 solver.cpp:237]     Train net output #2: loss = 0.628342 (* 1 = 0.628342 loss)
I1212 05:54:49.628101 15749 sgd_solver.cpp:116] Iteration 32200, lr = 0.0001
I1212 05:57:17.229476 15749 solver.cpp:218] Iteration 32300 (0.677567 iter/s, 147.587s/100 iters), loss = 3.75539
I1212 05:57:17.229562 15749 solver.cpp:237]     Train net output #0: label = 775
I1212 05:57:17.229585 15749 solver.cpp:237]     Train net output #1: label_phocs = 775
I1212 05:57:17.229598 15749 solver.cpp:237]     Train net output #2: loss = 0.462414 (* 1 = 0.462414 loss)
I1212 05:57:17.229606 15749 sgd_solver.cpp:116] Iteration 32300, lr = 0.0001
I1212 05:59:43.846123 15749 solver.cpp:218] Iteration 32400 (0.682097 iter/s, 146.607s/100 iters), loss = 4.16138
I1212 05:59:43.846200 15749 solver.cpp:237]     Train net output #0: label = 704
I1212 05:59:43.846223 15749 solver.cpp:237]     Train net output #1: label_phocs = 704
I1212 05:59:43.846235 15749 solver.cpp:237]     Train net output #2: loss = 0.440946 (* 1 = 0.440946 loss)
I1212 05:59:43.846245 15749 sgd_solver.cpp:116] Iteration 32400, lr = 0.0001
[2017-12-12 06:02:14,114, PHOCNetTrainer] Running test evaluation
[2017-12-12 06:02:14,114, PHOCNetTrainer] Evaluating CNN after 32000 steps:
I1212 06:03:01.197307 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:03:01.197315 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 06:03:02,429, PHOCNetTrainer] mAP: 0.907256
I1212 06:03:02.430987 15749 solver.cpp:330] Iteration 32500, Testing net (#0)
I1212 06:03:02.431181 15749 net.cpp:676] Ignoring source layer drop6
I1212 06:03:02.431190 15749 net.cpp:676] Ignoring source layer drop7
I1212 06:03:45.619824 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:03:45.619962 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:03:45.998239 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 06:03:45.998284 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 06:03:45.998296 15749 solver.cpp:397]     Test net output #2: loss = 17.1627 (* 1 = 17.1627 loss)
I1212 06:03:47.028950 15749 solver.cpp:218] Iteration 32500 (0.411217 iter/s, 243.18s/100 iters), loss = 7.7986
I1212 06:03:47.029026 15749 solver.cpp:237]     Train net output #0: label = 1033
I1212 06:03:47.029057 15749 solver.cpp:237]     Train net output #1: label_phocs = 1033
I1212 06:03:47.029070 15749 solver.cpp:237]     Train net output #2: loss = 1.74739 (* 1 = 1.74739 loss)
I1212 06:03:47.029079 15749 sgd_solver.cpp:116] Iteration 32500, lr = 0.0001
I1212 06:06:09.348475 15749 solver.cpp:218] Iteration 32600 (0.702749 iter/s, 142.298s/100 iters), loss = 4.04117
I1212 06:06:09.348562 15749 solver.cpp:237]     Train net output #0: label = 800
I1212 06:06:09.348587 15749 solver.cpp:237]     Train net output #1: label_phocs = 800
I1212 06:06:09.348598 15749 solver.cpp:237]     Train net output #2: loss = 0.147024 (* 1 = 0.147024 loss)
I1212 06:06:09.348608 15749 sgd_solver.cpp:116] Iteration 32600, lr = 0.0001
I1212 06:08:25.281550 15749 solver.cpp:218] Iteration 32700 (0.735682 iter/s, 135.928s/100 iters), loss = 3.66682
I1212 06:08:25.281616 15749 solver.cpp:237]     Train net output #0: label = 670
I1212 06:08:25.281635 15749 solver.cpp:237]     Train net output #1: label_phocs = 670
I1212 06:08:25.281643 15749 solver.cpp:237]     Train net output #2: loss = 8.34841 (* 1 = 8.34841 loss)
I1212 06:08:25.281649 15749 sgd_solver.cpp:116] Iteration 32700, lr = 0.0001
I1212 06:10:53.426576 15749 solver.cpp:218] Iteration 32800 (0.675014 iter/s, 148.145s/100 iters), loss = 3.80482
I1212 06:10:53.426669 15749 solver.cpp:237]     Train net output #0: label = 1066
I1212 06:10:53.426693 15749 solver.cpp:237]     Train net output #1: label_phocs = 1066
I1212 06:10:53.426705 15749 solver.cpp:237]     Train net output #2: loss = 1.86884 (* 1 = 1.86884 loss)
I1212 06:10:53.426715 15749 sgd_solver.cpp:116] Iteration 32800, lr = 0.0001
I1212 06:13:16.797029 15749 solver.cpp:218] Iteration 32900 (0.697653 iter/s, 143.338s/100 iters), loss = 3.7199
I1212 06:13:16.798105 15749 solver.cpp:237]     Train net output #0: label = 41
I1212 06:13:16.798135 15749 solver.cpp:237]     Train net output #1: label_phocs = 41
I1212 06:13:16.798146 15749 solver.cpp:237]     Train net output #2: loss = 7.16782 (* 1 = 7.16782 loss)
I1212 06:13:16.798156 15749 sgd_solver.cpp:116] Iteration 32900, lr = 0.0001
[2017-12-12 06:15:35,566, PHOCNetTrainer] Running test evaluation
[2017-12-12 06:15:35,566, PHOCNetTrainer] Evaluating CNN after 32500 steps:
I1212 06:16:26.392956 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:16:26.392963 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 06:16:27,330, PHOCNetTrainer] mAP: 0.902911
I1212 06:16:27.331614 15749 solver.cpp:330] Iteration 33000, Testing net (#0)
I1212 06:16:27.331809 15749 net.cpp:676] Ignoring source layer drop6
I1212 06:16:27.331817 15749 net.cpp:676] Ignoring source layer drop7
I1212 06:16:56.086118 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:16:56.086127 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:16:56.664130 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 06:16:56.664181 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 06:16:56.664193 15749 solver.cpp:397]     Test net output #2: loss = 18.3001 (* 1 = 18.3001 loss)
I1212 06:16:58.446871 15749 solver.cpp:218] Iteration 33000 (0.451162 iter/s, 221.65s/100 iters), loss = 2.70152
I1212 06:16:58.446949 15749 solver.cpp:237]     Train net output #0: label = 326
I1212 06:16:58.446972 15749 solver.cpp:237]     Train net output #1: label_phocs = 326
I1212 06:16:58.446985 15749 solver.cpp:237]     Train net output #2: loss = 0.867547 (* 1 = 0.867547 loss)
I1212 06:16:58.446995 15749 sgd_solver.cpp:116] Iteration 33000, lr = 0.0001
I1212 06:19:16.047181 15749 solver.cpp:218] Iteration 33100 (0.726743 iter/s, 137.6s/100 iters), loss = 3.63009
I1212 06:19:16.047279 15749 solver.cpp:237]     Train net output #0: label = 567
I1212 06:19:16.047303 15749 solver.cpp:237]     Train net output #1: label_phocs = 567
I1212 06:19:16.047314 15749 solver.cpp:237]     Train net output #2: loss = 0.426431 (* 1 = 0.426431 loss)
I1212 06:19:16.047322 15749 sgd_solver.cpp:116] Iteration 33100, lr = 0.0001
I1212 06:21:39.377027 15749 solver.cpp:218] Iteration 33200 (0.697691 iter/s, 143.33s/100 iters), loss = 3.80495
I1212 06:21:39.377105 15749 solver.cpp:237]     Train net output #0: label = 24
I1212 06:21:39.377125 15749 solver.cpp:237]     Train net output #1: label_phocs = 24
I1212 06:21:39.377132 15749 solver.cpp:237]     Train net output #2: loss = 4.12668 (* 1 = 4.12668 loss)
I1212 06:21:39.377140 15749 sgd_solver.cpp:116] Iteration 33200, lr = 0.0001
I1212 06:23:59.959213 15749 solver.cpp:218] Iteration 33300 (0.711328 iter/s, 140.582s/100 iters), loss = 3.85304
I1212 06:23:59.959292 15749 solver.cpp:237]     Train net output #0: label = 555
I1212 06:23:59.959316 15749 solver.cpp:237]     Train net output #1: label_phocs = 555
I1212 06:23:59.959326 15749 solver.cpp:237]     Train net output #2: loss = 4.14176 (* 1 = 4.14176 loss)
I1212 06:23:59.959336 15749 sgd_solver.cpp:116] Iteration 33300, lr = 0.0001
I1212 06:26:17.418298 15749 solver.cpp:218] Iteration 33400 (0.727489 iter/s, 137.459s/100 iters), loss = 3.70666
I1212 06:26:17.418407 15749 solver.cpp:237]     Train net output #0: label = 1049
I1212 06:26:17.418432 15749 solver.cpp:237]     Train net output #1: label_phocs = 1049
I1212 06:26:17.418445 15749 solver.cpp:237]     Train net output #2: loss = 1.3108 (* 1 = 1.3108 loss)
I1212 06:26:17.418454 15749 sgd_solver.cpp:116] Iteration 33400, lr = 0.0001
[2017-12-12 06:28:36,630, PHOCNetTrainer] Running test evaluation
[2017-12-12 06:28:36,630, PHOCNetTrainer] Evaluating CNN after 33000 steps:
I1212 06:29:12.310539 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:29:12.310676 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 06:29:15,723, PHOCNetTrainer] mAP: 0.897412
I1212 06:29:15.725309 15749 solver.cpp:330] Iteration 33500, Testing net (#0)
I1212 06:29:15.725523 15749 net.cpp:676] Ignoring source layer drop6
I1212 06:29:15.725533 15749 net.cpp:676] Ignoring source layer drop7
I1212 06:30:04.363839 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:30:04.363976 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:30:04.671721 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 06:30:04.671758 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 06:30:04.671767 15749 solver.cpp:397]     Test net output #2: loss = 18.2887 (* 1 = 18.2887 loss)
I1212 06:30:05.670250 15749 solver.cpp:218] Iteration 33500 (0.438112 iter/s, 228.252s/100 iters), loss = 3.3568
I1212 06:30:05.670310 15749 solver.cpp:237]     Train net output #0: label = 620
I1212 06:30:05.670330 15749 solver.cpp:237]     Train net output #1: label_phocs = 620
I1212 06:30:05.670336 15749 solver.cpp:237]     Train net output #2: loss = 5.81756 (* 1 = 5.81756 loss)
I1212 06:30:05.670343 15749 sgd_solver.cpp:116] Iteration 33500, lr = 0.0001
I1212 06:32:33.346223 15749 solver.cpp:218] Iteration 33600 (0.677356 iter/s, 147.633s/100 iters), loss = 3.7645
I1212 06:32:33.346310 15749 solver.cpp:237]     Train net output #0: label = 335
I1212 06:32:33.346333 15749 solver.cpp:237]     Train net output #1: label_phocs = 335
I1212 06:32:33.346345 15749 solver.cpp:237]     Train net output #2: loss = 3.54605 (* 1 = 3.54605 loss)
I1212 06:32:33.346354 15749 sgd_solver.cpp:116] Iteration 33600, lr = 0.0001
I1212 06:35:02.024163 15749 solver.cpp:218] Iteration 33700 (0.672675 iter/s, 148.66s/100 iters), loss = 3.80455
I1212 06:35:02.024243 15749 solver.cpp:237]     Train net output #0: label = 252
I1212 06:35:02.024271 15749 solver.cpp:237]     Train net output #1: label_phocs = 252
I1212 06:35:02.024283 15749 solver.cpp:237]     Train net output #2: loss = 6.37284 (* 1 = 6.37284 loss)
I1212 06:35:02.024292 15749 sgd_solver.cpp:116] Iteration 33700, lr = 0.0001
I1212 06:37:31.225039 15749 solver.cpp:218] Iteration 33800 (0.670286 iter/s, 149.19s/100 iters), loss = 4.03196
I1212 06:37:31.225129 15749 solver.cpp:237]     Train net output #0: label = 1082
I1212 06:37:31.225152 15749 solver.cpp:237]     Train net output #1: label_phocs = 1082
I1212 06:37:31.225168 15749 solver.cpp:237]     Train net output #2: loss = 2.88273 (* 1 = 2.88273 loss)
I1212 06:37:31.225178 15749 sgd_solver.cpp:116] Iteration 33800, lr = 0.0001
I1212 06:39:49.955636 15749 solver.cpp:218] Iteration 33900 (0.720822 iter/s, 138.731s/100 iters), loss = 3.47915
I1212 06:39:49.955716 15749 solver.cpp:237]     Train net output #0: label = 789
I1212 06:39:49.955739 15749 solver.cpp:237]     Train net output #1: label_phocs = 789
I1212 06:39:49.955756 15749 solver.cpp:237]     Train net output #2: loss = 3.26327 (* 1 = 3.26327 loss)
I1212 06:39:49.955766 15749 sgd_solver.cpp:116] Iteration 33900, lr = 0.0001
[2017-12-12 06:42:05,461, PHOCNetTrainer] Running test evaluation
[2017-12-12 06:42:05,461, PHOCNetTrainer] Evaluating CNN after 33500 steps:
I1212 06:42:50.942195 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:42:50.942268 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 06:42:54,683, PHOCNetTrainer] mAP: 0.902482
I1212 06:42:54.685379 15749 solver.cpp:330] Iteration 34000, Testing net (#0)
I1212 06:42:54.685571 15749 net.cpp:676] Ignoring source layer drop6
I1212 06:42:54.685581 15749 net.cpp:676] Ignoring source layer drop7
I1212 06:43:36.219862 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:43:36.219997 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:43:36.539921 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 06:43:36.539961 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 06:43:36.539969 15749 solver.cpp:397]     Test net output #2: loss = 18.2202 (* 1 = 18.2202 loss)
I1212 06:43:37.561020 15749 solver.cpp:218] Iteration 34000 (0.439357 iter/s, 227.605s/100 iters), loss = 2.92795
I1212 06:43:37.561098 15749 solver.cpp:237]     Train net output #0: label = 975
I1212 06:43:37.561122 15749 solver.cpp:237]     Train net output #1: label_phocs = 975
I1212 06:43:37.561133 15749 solver.cpp:237]     Train net output #2: loss = 0.480863 (* 1 = 0.480863 loss)
I1212 06:43:37.561142 15749 sgd_solver.cpp:116] Iteration 34000, lr = 0.0001
I1212 06:46:04.458520 15749 solver.cpp:218] Iteration 34100 (0.680747 iter/s, 146.897s/100 iters), loss = 3.6159
I1212 06:46:04.458626 15749 solver.cpp:237]     Train net output #0: label = 36
I1212 06:46:04.458648 15749 solver.cpp:237]     Train net output #1: label_phocs = 36
I1212 06:46:04.458660 15749 solver.cpp:237]     Train net output #2: loss = 2.59865 (* 1 = 2.59865 loss)
I1212 06:46:04.458669 15749 sgd_solver.cpp:116] Iteration 34100, lr = 0.0001
I1212 06:48:28.858697 15749 solver.cpp:218] Iteration 34200 (0.69252 iter/s, 144.4s/100 iters), loss = 3.27549
I1212 06:48:28.858791 15749 solver.cpp:237]     Train net output #0: label = 243
I1212 06:48:28.858819 15749 solver.cpp:237]     Train net output #1: label_phocs = 243
I1212 06:48:28.858830 15749 solver.cpp:237]     Train net output #2: loss = 3.32442 (* 1 = 3.32442 loss)
I1212 06:48:28.858839 15749 sgd_solver.cpp:116] Iteration 34200, lr = 0.0001
I1212 06:50:45.962811 15749 solver.cpp:218] Iteration 34300 (0.729373 iter/s, 137.104s/100 iters), loss = 3.38272
I1212 06:50:45.962891 15749 solver.cpp:237]     Train net output #0: label = 599
I1212 06:50:45.962910 15749 solver.cpp:237]     Train net output #1: label_phocs = 599
I1212 06:50:45.962919 15749 solver.cpp:237]     Train net output #2: loss = 3.2261 (* 1 = 3.2261 loss)
I1212 06:50:45.962925 15749 sgd_solver.cpp:116] Iteration 34300, lr = 0.0001
I1212 06:53:09.935212 15749 solver.cpp:218] Iteration 34400 (0.694578 iter/s, 143.972s/100 iters), loss = 3.31486
I1212 06:53:09.935281 15749 solver.cpp:237]     Train net output #0: label = 322
I1212 06:53:09.935300 15749 solver.cpp:237]     Train net output #1: label_phocs = 322
I1212 06:53:09.935308 15749 solver.cpp:237]     Train net output #2: loss = 1.24824 (* 1 = 1.24824 loss)
I1212 06:53:09.935317 15749 sgd_solver.cpp:116] Iteration 34400, lr = 0.0001
[2017-12-12 06:55:31,175, PHOCNetTrainer] Running test evaluation
[2017-12-12 06:55:31,176, PHOCNetTrainer] Evaluating CNN after 34000 steps:
I1212 06:56:19.900782 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:56:19.900790 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 06:56:20,844, PHOCNetTrainer] mAP: 0.914812
I1212 06:56:20.845300 15749 solver.cpp:330] Iteration 34500, Testing net (#0)
I1212 06:56:20.845499 15749 net.cpp:676] Ignoring source layer drop6
I1212 06:56:20.845510 15749 net.cpp:676] Ignoring source layer drop7
I1212 06:56:54.283910 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:56:54.284145 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 06:56:55.960014 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 06:56:55.960060 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 06:56:55.960072 15749 solver.cpp:397]     Test net output #2: loss = 16.1234 (* 1 = 16.1234 loss)
I1212 06:56:57.357422 15749 solver.cpp:218] Iteration 34500 (0.439733 iter/s, 227.411s/100 iters), loss = 2.22111
I1212 06:56:57.357501 15749 solver.cpp:237]     Train net output #0: label = 711
I1212 06:56:57.357523 15749 solver.cpp:237]     Train net output #1: label_phocs = 711
I1212 06:56:57.357535 15749 solver.cpp:237]     Train net output #2: loss = 6.18169 (* 1 = 6.18169 loss)
I1212 06:56:57.357544 15749 sgd_solver.cpp:116] Iteration 34500, lr = 0.0001
I1212 06:59:23.210333 15749 solver.cpp:218] Iteration 34600 (0.685622 iter/s, 145.853s/100 iters), loss = 3.39895
I1212 06:59:23.210417 15749 solver.cpp:237]     Train net output #0: label = 532
I1212 06:59:23.210440 15749 solver.cpp:237]     Train net output #1: label_phocs = 532
I1212 06:59:23.210453 15749 solver.cpp:237]     Train net output #2: loss = 6.50737 (* 1 = 6.50737 loss)
I1212 06:59:23.210460 15749 sgd_solver.cpp:116] Iteration 34600, lr = 0.0001
I1212 07:01:39.655015 15749 solver.cpp:218] Iteration 34700 (0.732908 iter/s, 136.443s/100 iters), loss = 3.1345
I1212 07:01:39.655093 15749 solver.cpp:237]     Train net output #0: label = 145
I1212 07:01:39.655117 15749 solver.cpp:237]     Train net output #1: label_phocs = 145
I1212 07:01:39.655129 15749 solver.cpp:237]     Train net output #2: loss = 0.467595 (* 1 = 0.467595 loss)
I1212 07:01:39.655138 15749 sgd_solver.cpp:116] Iteration 34700, lr = 0.0001
I1212 07:03:54.548723 15749 solver.cpp:218] Iteration 34800 (0.741527 iter/s, 134.857s/100 iters), loss = 3.46911
I1212 07:03:54.548806 15749 solver.cpp:237]     Train net output #0: label = 544
I1212 07:03:54.548831 15749 solver.cpp:237]     Train net output #1: label_phocs = 544
I1212 07:03:54.548842 15749 solver.cpp:237]     Train net output #2: loss = 0.226555 (* 1 = 0.226555 loss)
I1212 07:03:54.548851 15749 sgd_solver.cpp:116] Iteration 34800, lr = 0.0001
I1212 07:06:21.825701 15749 solver.cpp:218] Iteration 34900 (0.678993 iter/s, 147.277s/100 iters), loss = 3.2589
I1212 07:06:21.825784 15749 solver.cpp:237]     Train net output #0: label = 903
I1212 07:06:21.825812 15749 solver.cpp:237]     Train net output #1: label_phocs = 903
I1212 07:06:21.825826 15749 solver.cpp:237]     Train net output #2: loss = 1.34757 (* 1 = 1.34757 loss)
I1212 07:06:21.825835 15749 sgd_solver.cpp:116] Iteration 34900, lr = 0.0001
[2017-12-12 07:08:46,962, PHOCNetTrainer] Running test evaluation
[2017-12-12 07:08:46,962, PHOCNetTrainer] Evaluating CNN after 34500 steps:
I1212 07:09:45.047863 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:09:45.047986 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 07:09:46,195, PHOCNetTrainer] mAP: 0.900399
I1212 07:09:46.196367 15749 solver.cpp:330] Iteration 35000, Testing net (#0)
I1212 07:09:46.196549 15749 net.cpp:676] Ignoring source layer drop6
I1212 07:09:46.196557 15749 net.cpp:676] Ignoring source layer drop7
I1212 07:10:22.955850 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:10:22.955986 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:10:23.554425 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 07:10:23.554461 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 07:10:23.554469 15749 solver.cpp:397]     Test net output #2: loss = 18.0777 (* 1 = 18.0777 loss)
I1212 07:10:24.950350 15749 solver.cpp:218] Iteration 35000 (0.411317 iter/s, 243.121s/100 iters), loss = 2.58506
I1212 07:10:24.950428 15749 solver.cpp:237]     Train net output #0: label = 298
I1212 07:10:24.950450 15749 solver.cpp:237]     Train net output #1: label_phocs = 298
I1212 07:10:24.950461 15749 solver.cpp:237]     Train net output #2: loss = 6.55811 (* 1 = 6.55811 loss)
I1212 07:10:24.950469 15749 sgd_solver.cpp:116] Iteration 35000, lr = 0.0001
I1212 07:13:03.822412 15749 solver.cpp:218] Iteration 35100 (0.629485 iter/s, 158.86s/100 iters), loss = 3.38223
I1212 07:13:03.822480 15749 solver.cpp:237]     Train net output #0: label = 412
I1212 07:13:03.822499 15749 solver.cpp:237]     Train net output #1: label_phocs = 412
I1212 07:13:03.822509 15749 solver.cpp:237]     Train net output #2: loss = 0.28949 (* 1 = 0.28949 loss)
I1212 07:13:03.822515 15749 sgd_solver.cpp:116] Iteration 35100, lr = 0.0001
I1212 07:15:31.766996 15749 solver.cpp:218] Iteration 35200 (0.675929 iter/s, 147.945s/100 iters), loss = 3.56081
I1212 07:15:31.767081 15749 solver.cpp:237]     Train net output #0: label = 662
I1212 07:15:31.767104 15749 solver.cpp:237]     Train net output #1: label_phocs = 662
I1212 07:15:31.767117 15749 solver.cpp:237]     Train net output #2: loss = 8.22942 (* 1 = 8.22942 loss)
I1212 07:15:31.767125 15749 sgd_solver.cpp:116] Iteration 35200, lr = 0.0001
I1212 07:17:59.748492 15749 solver.cpp:218] Iteration 35300 (0.675886 iter/s, 147.954s/100 iters), loss = 3.54827
I1212 07:17:59.748574 15749 solver.cpp:237]     Train net output #0: label = 367
I1212 07:17:59.748597 15749 solver.cpp:237]     Train net output #1: label_phocs = 367
I1212 07:17:59.748610 15749 solver.cpp:237]     Train net output #2: loss = 0.755477 (* 1 = 0.755477 loss)
I1212 07:17:59.748617 15749 sgd_solver.cpp:116] Iteration 35300, lr = 0.0001
I1212 07:20:27.405356 15749 solver.cpp:218] Iteration 35400 (0.677246 iter/s, 147.657s/100 iters), loss = 3.18739
I1212 07:20:27.405434 15749 solver.cpp:237]     Train net output #0: label = 113
I1212 07:20:27.405457 15749 solver.cpp:237]     Train net output #1: label_phocs = 113
I1212 07:20:27.405469 15749 solver.cpp:237]     Train net output #2: loss = 0.242162 (* 1 = 0.242162 loss)
I1212 07:20:27.405478 15749 sgd_solver.cpp:116] Iteration 35400, lr = 0.0001
[2017-12-12 07:22:52,857, PHOCNetTrainer] Running test evaluation
[2017-12-12 07:22:52,857, PHOCNetTrainer] Evaluating CNN after 35000 steps:
I1212 07:23:35.323850 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:23:35.323977 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 07:23:36,266, PHOCNetTrainer] mAP: 0.910956
I1212 07:23:36.267657 15749 solver.cpp:330] Iteration 35500, Testing net (#0)
I1212 07:23:36.267844 15749 net.cpp:676] Ignoring source layer drop6
I1212 07:23:36.267853 15749 net.cpp:676] Ignoring source layer drop7
I1212 07:24:28.328660 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:24:28.328675 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:24:28.647462 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 07:24:28.647501 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 07:24:28.647509 15749 solver.cpp:397]     Test net output #2: loss = 16.3916 (* 1 = 16.3916 loss)
I1212 07:24:29.936317 15749 solver.cpp:218] Iteration 35500 (0.412318 iter/s, 242.531s/100 iters), loss = 3.38476
I1212 07:24:29.936393 15749 solver.cpp:237]     Train net output #0: label = 359
I1212 07:24:29.936416 15749 solver.cpp:237]     Train net output #1: label_phocs = 359
I1212 07:24:29.936427 15749 solver.cpp:237]     Train net output #2: loss = 0.745966 (* 1 = 0.745966 loss)
I1212 07:24:29.936436 15749 sgd_solver.cpp:116] Iteration 35500, lr = 0.0001
I1212 07:26:45.998199 15749 solver.cpp:218] Iteration 35600 (0.73496 iter/s, 136.062s/100 iters), loss = 3.54092
I1212 07:26:45.998280 15749 solver.cpp:237]     Train net output #0: label = 412
I1212 07:26:45.998304 15749 solver.cpp:237]     Train net output #1: label_phocs = 412
I1212 07:26:45.998317 15749 solver.cpp:237]     Train net output #2: loss = 0.601678 (* 1 = 0.601678 loss)
I1212 07:26:45.998327 15749 sgd_solver.cpp:116] Iteration 35600, lr = 0.0001
I1212 07:29:15.657156 15749 solver.cpp:218] Iteration 35700 (0.668186 iter/s, 149.659s/100 iters), loss = 3.22368
I1212 07:29:15.657219 15749 solver.cpp:237]     Train net output #0: label = 465
I1212 07:29:15.657239 15749 solver.cpp:237]     Train net output #1: label_phocs = 465
I1212 07:29:15.657248 15749 solver.cpp:237]     Train net output #2: loss = 2.27757 (* 1 = 2.27757 loss)
I1212 07:29:15.657253 15749 sgd_solver.cpp:116] Iteration 35700, lr = 0.0001
I1212 07:31:46.643779 15749 solver.cpp:218] Iteration 35800 (0.662315 iter/s, 150.986s/100 iters), loss = 3.32711
I1212 07:31:46.643847 15749 solver.cpp:237]     Train net output #0: label = 42
I1212 07:31:46.643867 15749 solver.cpp:237]     Train net output #1: label_phocs = 42
I1212 07:31:46.643875 15749 solver.cpp:237]     Train net output #2: loss = 2.65724 (* 1 = 2.65724 loss)
I1212 07:31:46.643882 15749 sgd_solver.cpp:116] Iteration 35800, lr = 0.0001
I1212 07:34:20.059532 15749 solver.cpp:218] Iteration 35900 (0.651905 iter/s, 153.397s/100 iters), loss = 3.44531
I1212 07:34:20.059626 15749 solver.cpp:237]     Train net output #0: label = 537
I1212 07:34:20.059650 15749 solver.cpp:237]     Train net output #1: label_phocs = 537
I1212 07:34:20.059661 15749 solver.cpp:237]     Train net output #2: loss = 0.0790862 (* 1 = 0.0790862 loss)
I1212 07:34:20.059670 15749 sgd_solver.cpp:116] Iteration 35900, lr = 0.0001
[2017-12-12 07:36:43,002, PHOCNetTrainer] Running test evaluation
[2017-12-12 07:36:43,002, PHOCNetTrainer] Evaluating CNN after 35500 steps:
I1212 07:37:21.941856 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:37:21.941879 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 07:37:23,081, PHOCNetTrainer] mAP: 0.903974
I1212 07:37:23.082846 15749 solver.cpp:330] Iteration 36000, Testing net (#0)
I1212 07:37:23.083058 15749 net.cpp:676] Ignoring source layer drop6
I1212 07:37:23.083067 15749 net.cpp:676] Ignoring source layer drop7
I1212 07:38:16.623834 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:38:16.624017 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:38:17.608346 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 07:38:17.608393 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 07:38:17.608404 15749 solver.cpp:397]     Test net output #2: loss = 17.477 (* 1 = 17.477 loss)
I1212 07:38:19.051679 15749 solver.cpp:218] Iteration 36000 (0.418424 iter/s, 238.992s/100 iters), loss = 5.80666
I1212 07:38:19.051813 15749 solver.cpp:237]     Train net output #0: label = 242
I1212 07:38:19.051837 15749 solver.cpp:237]     Train net output #1: label_phocs = 242
I1212 07:38:19.051849 15749 solver.cpp:237]     Train net output #2: loss = 34.5358 (* 1 = 34.5358 loss)
I1212 07:38:19.051858 15749 sgd_solver.cpp:116] Iteration 36000, lr = 0.0001
I1212 07:40:42.532227 15749 solver.cpp:218] Iteration 36100 (0.697065 iter/s, 143.459s/100 iters), loss = 3.23168
I1212 07:40:42.532310 15749 solver.cpp:237]     Train net output #0: label = 155
I1212 07:40:42.532335 15749 solver.cpp:237]     Train net output #1: label_phocs = 155
I1212 07:40:42.532346 15749 solver.cpp:237]     Train net output #2: loss = 0.948986 (* 1 = 0.948986 loss)
I1212 07:40:42.532356 15749 sgd_solver.cpp:116] Iteration 36100, lr = 0.0001
I1212 07:43:09.830485 15749 solver.cpp:218] Iteration 36200 (0.678895 iter/s, 147.298s/100 iters), loss = 3.07154
I1212 07:43:09.830549 15749 solver.cpp:237]     Train net output #0: label = 26
I1212 07:43:09.830567 15749 solver.cpp:237]     Train net output #1: label_phocs = 26
I1212 07:43:09.830579 15749 solver.cpp:237]     Train net output #2: loss = 1.37409 (* 1 = 1.37409 loss)
I1212 07:43:09.830585 15749 sgd_solver.cpp:116] Iteration 36200, lr = 0.0001
I1212 07:45:29.981544 15749 solver.cpp:218] Iteration 36300 (0.713524 iter/s, 140.15s/100 iters), loss = 2.96761
I1212 07:45:29.981622 15749 solver.cpp:237]     Train net output #0: label = 901
I1212 07:45:29.981647 15749 solver.cpp:237]     Train net output #1: label_phocs = 901
I1212 07:45:29.981657 15749 solver.cpp:237]     Train net output #2: loss = 2.29062 (* 1 = 2.29062 loss)
I1212 07:45:29.981665 15749 sgd_solver.cpp:116] Iteration 36300, lr = 0.0001
I1212 07:47:57.494685 15749 solver.cpp:218] Iteration 36400 (0.677906 iter/s, 147.513s/100 iters), loss = 3.39165
I1212 07:47:57.494768 15749 solver.cpp:237]     Train net output #0: label = 608
I1212 07:47:57.494794 15749 solver.cpp:237]     Train net output #1: label_phocs = 608
I1212 07:47:57.494807 15749 solver.cpp:237]     Train net output #2: loss = 6.15315 (* 1 = 6.15315 loss)
I1212 07:47:57.494817 15749 sgd_solver.cpp:116] Iteration 36400, lr = 0.0001
[2017-12-12 07:50:23,038, PHOCNetTrainer] Running test evaluation
[2017-12-12 07:50:23,038, PHOCNetTrainer] Evaluating CNN after 36000 steps:
I1212 07:50:52.375815 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:50:52.375946 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 07:50:53,328, PHOCNetTrainer] mAP: 0.875217
I1212 07:50:53.329313 15749 solver.cpp:330] Iteration 36500, Testing net (#0)
I1212 07:50:53.329493 15749 net.cpp:676] Ignoring source layer drop6
I1212 07:50:53.329500 15749 net.cpp:676] Ignoring source layer drop7
I1212 07:51:30.931833 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:51:30.931969 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 07:51:32.315201 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 07:51:32.315245 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 07:51:32.315256 15749 solver.cpp:397]     Test net output #2: loss = 22.5449 (* 1 = 22.5449 loss)
I1212 07:51:34.034298 15749 solver.cpp:218] Iteration 36500 (0.461809 iter/s, 216.54s/100 iters), loss = 4.89448
I1212 07:51:34.034382 15749 solver.cpp:237]     Train net output #0: label = 760
I1212 07:51:34.034405 15749 solver.cpp:237]     Train net output #1: label_phocs = 760
I1212 07:51:34.034416 15749 solver.cpp:237]     Train net output #2: loss = 2.45592 (* 1 = 2.45592 loss)
I1212 07:51:34.034426 15749 sgd_solver.cpp:116] Iteration 36500, lr = 0.0001
I1212 07:53:56.274704 15749 solver.cpp:218] Iteration 36600 (0.703105 iter/s, 142.226s/100 iters), loss = 3.25314
I1212 07:53:56.274788 15749 solver.cpp:237]     Train net output #0: label = 234
I1212 07:53:56.274811 15749 solver.cpp:237]     Train net output #1: label_phocs = 234
I1212 07:53:56.274823 15749 solver.cpp:237]     Train net output #2: loss = 0.165056 (* 1 = 0.165056 loss)
I1212 07:53:56.274832 15749 sgd_solver.cpp:116] Iteration 36600, lr = 0.0001
I1212 07:56:21.564951 15749 solver.cpp:218] Iteration 36700 (0.688499 iter/s, 145.243s/100 iters), loss = 3.1732
I1212 07:56:21.565037 15749 solver.cpp:237]     Train net output #0: label = 478
I1212 07:56:21.565060 15749 solver.cpp:237]     Train net output #1: label_phocs = 478
I1212 07:56:21.565071 15749 solver.cpp:237]     Train net output #2: loss = 4.96692 (* 1 = 4.96692 loss)
I1212 07:56:21.565080 15749 sgd_solver.cpp:116] Iteration 36700, lr = 0.0001
I1212 07:58:35.108769 15749 solver.cpp:218] Iteration 36800 (0.748873 iter/s, 133.534s/100 iters), loss = 2.89022
I1212 07:58:35.108865 15749 solver.cpp:237]     Train net output #0: label = 93
I1212 07:58:35.108888 15749 solver.cpp:237]     Train net output #1: label_phocs = 93
I1212 07:58:35.108901 15749 solver.cpp:237]     Train net output #2: loss = 2.17398 (* 1 = 2.17398 loss)
I1212 07:58:35.108909 15749 sgd_solver.cpp:116] Iteration 36800, lr = 0.0001
I1212 08:00:59.721226 15749 solver.cpp:218] Iteration 36900 (0.691504 iter/s, 144.612s/100 iters), loss = 2.94696
I1212 08:00:59.721314 15749 solver.cpp:237]     Train net output #0: label = 220
I1212 08:00:59.721338 15749 solver.cpp:237]     Train net output #1: label_phocs = 220
I1212 08:00:59.721349 15749 solver.cpp:237]     Train net output #2: loss = 1.90996 (* 1 = 1.90996 loss)
I1212 08:00:59.721359 15749 sgd_solver.cpp:116] Iteration 36900, lr = 0.0001
[2017-12-12 08:03:26,621, PHOCNetTrainer] Running test evaluation
[2017-12-12 08:03:26,621, PHOCNetTrainer] Evaluating CNN after 36500 steps:
I1212 08:04:14.135864 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:04:14.135993 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 08:04:15,301, PHOCNetTrainer] mAP: 0.899985
I1212 08:04:15.303231 15749 solver.cpp:330] Iteration 37000, Testing net (#0)
I1212 08:04:15.303421 15749 net.cpp:676] Ignoring source layer drop6
I1212 08:04:15.303431 15749 net.cpp:676] Ignoring source layer drop7
I1212 08:04:56.868223 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:04:56.868399 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:04:57.176669 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 08:04:57.176712 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 08:04:57.176723 15749 solver.cpp:397]     Test net output #2: loss = 18.3405 (* 1 = 18.3405 loss)
I1212 08:04:59.118764 15749 solver.cpp:218] Iteration 37000 (0.417784 iter/s, 239.358s/100 iters), loss = 3.64144
I1212 08:04:59.118841 15749 solver.cpp:237]     Train net output #0: label = 737
I1212 08:04:59.118865 15749 solver.cpp:237]     Train net output #1: label_phocs = 737
I1212 08:04:59.118875 15749 solver.cpp:237]     Train net output #2: loss = 1.48222 (* 1 = 1.48222 loss)
I1212 08:04:59.118885 15749 sgd_solver.cpp:116] Iteration 37000, lr = 0.0001
I1212 08:07:13.621575 15749 solver.cpp:218] Iteration 37100 (0.743618 iter/s, 134.478s/100 iters), loss = 3.16616
I1212 08:07:13.621645 15749 solver.cpp:237]     Train net output #0: label = 521
I1212 08:07:13.621668 15749 solver.cpp:237]     Train net output #1: label_phocs = 521
I1212 08:07:13.621675 15749 solver.cpp:237]     Train net output #2: loss = 11.9554 (* 1 = 11.9554 loss)
I1212 08:07:13.621683 15749 sgd_solver.cpp:116] Iteration 37100, lr = 0.0001
I1212 08:09:42.357340 15749 solver.cpp:218] Iteration 37200 (0.672333 iter/s, 148.736s/100 iters), loss = 3.23924
I1212 08:09:42.357425 15749 solver.cpp:237]     Train net output #0: label = 414
I1212 08:09:42.357450 15749 solver.cpp:237]     Train net output #1: label_phocs = 414
I1212 08:09:42.357462 15749 solver.cpp:237]     Train net output #2: loss = 19.0664 (* 1 = 19.0664 loss)
I1212 08:09:42.357471 15749 sgd_solver.cpp:116] Iteration 37200, lr = 0.0001
I1212 08:11:57.865233 15749 solver.cpp:218] Iteration 37300 (0.737965 iter/s, 135.508s/100 iters), loss = 2.91587
I1212 08:11:57.865317 15749 solver.cpp:237]     Train net output #0: label = 973
I1212 08:11:57.865341 15749 solver.cpp:237]     Train net output #1: label_phocs = 973
I1212 08:11:57.865353 15749 solver.cpp:237]     Train net output #2: loss = 0.232833 (* 1 = 0.232833 loss)
I1212 08:11:57.865362 15749 sgd_solver.cpp:116] Iteration 37300, lr = 0.0001
I1212 08:14:15.116171 15749 solver.cpp:218] Iteration 37400 (0.728629 iter/s, 137.244s/100 iters), loss = 2.88121
I1212 08:14:15.116255 15749 solver.cpp:237]     Train net output #0: label = 379
I1212 08:14:15.116277 15749 solver.cpp:237]     Train net output #1: label_phocs = 379
I1212 08:14:15.116289 15749 solver.cpp:237]     Train net output #2: loss = 12.3945 (* 1 = 12.3945 loss)
I1212 08:14:15.116298 15749 sgd_solver.cpp:116] Iteration 37400, lr = 0.0001
[2017-12-12 08:16:29,868, PHOCNetTrainer] Running test evaluation
[2017-12-12 08:16:29,868, PHOCNetTrainer] Evaluating CNN after 37000 steps:
I1212 08:17:17.939833 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:17:17.939951 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 08:17:19,009, PHOCNetTrainer] mAP: 0.905133
I1212 08:17:19.011443 15749 solver.cpp:330] Iteration 37500, Testing net (#0)
I1212 08:17:19.011638 15749 net.cpp:676] Ignoring source layer drop6
I1212 08:17:19.011648 15749 net.cpp:676] Ignoring source layer drop7
I1212 08:18:03.896818 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:18:03.896858 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:18:04.218933 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 08:18:04.218979 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 08:18:04.218991 15749 solver.cpp:397]     Test net output #2: loss = 18.7761 (* 1 = 18.7761 loss)
I1212 08:18:06.151589 15749 solver.cpp:218] Iteration 37500 (0.432869 iter/s, 231.017s/100 iters), loss = 2.03102
I1212 08:18:06.151670 15749 solver.cpp:237]     Train net output #0: label = 170
I1212 08:18:06.151695 15749 solver.cpp:237]     Train net output #1: label_phocs = 170
I1212 08:18:06.151706 15749 solver.cpp:237]     Train net output #2: loss = 0.69878 (* 1 = 0.69878 loss)
I1212 08:18:06.151716 15749 sgd_solver.cpp:116] Iteration 37500, lr = 0.0001
I1212 08:20:21.336647 15749 solver.cpp:218] Iteration 37600 (0.739896 iter/s, 135.154s/100 iters), loss = 2.98446
I1212 08:20:21.336735 15749 solver.cpp:237]     Train net output #0: label = 852
I1212 08:20:21.336758 15749 solver.cpp:237]     Train net output #1: label_phocs = 852
I1212 08:20:21.336771 15749 solver.cpp:237]     Train net output #2: loss = 0.498104 (* 1 = 0.498104 loss)
I1212 08:20:21.336779 15749 sgd_solver.cpp:116] Iteration 37600, lr = 0.0001
I1212 08:22:39.644657 15749 solver.cpp:218] Iteration 37700 (0.723108 iter/s, 138.292s/100 iters), loss = 2.89031
I1212 08:22:39.644732 15749 solver.cpp:237]     Train net output #0: label = 617
I1212 08:22:39.644752 15749 solver.cpp:237]     Train net output #1: label_phocs = 617
I1212 08:22:39.644759 15749 solver.cpp:237]     Train net output #2: loss = 5.15797 (* 1 = 5.15797 loss)
I1212 08:22:39.644765 15749 sgd_solver.cpp:116] Iteration 37700, lr = 0.0001
I1212 08:25:09.980401 15749 solver.cpp:218] Iteration 37800 (0.665203 iter/s, 150.33s/100 iters), loss = 2.49903
I1212 08:25:09.980479 15749 solver.cpp:237]     Train net output #0: label = 1098
I1212 08:25:09.980500 15749 solver.cpp:237]     Train net output #1: label_phocs = 1098
I1212 08:25:09.980512 15749 solver.cpp:237]     Train net output #2: loss = 0.59221 (* 1 = 0.59221 loss)
I1212 08:25:09.980520 15749 sgd_solver.cpp:116] Iteration 37800, lr = 0.0001
I1212 08:27:32.942261 15749 solver.cpp:218] Iteration 37900 (0.699487 iter/s, 142.962s/100 iters), loss = 2.89809
I1212 08:27:32.942340 15749 solver.cpp:237]     Train net output #0: label = 10
I1212 08:27:32.942363 15749 solver.cpp:237]     Train net output #1: label_phocs = 10
I1212 08:27:32.942374 15749 solver.cpp:237]     Train net output #2: loss = 0.270102 (* 1 = 0.270102 loss)
I1212 08:27:32.942382 15749 sgd_solver.cpp:116] Iteration 37900, lr = 0.0001
[2017-12-12 08:29:52,742, PHOCNetTrainer] Running test evaluation
[2017-12-12 08:29:52,742, PHOCNetTrainer] Evaluating CNN after 37500 steps:
I1212 08:30:34.125543 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:30:34.125769 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 08:30:35,822, PHOCNetTrainer] mAP: 0.905628
I1212 08:30:35.832283 15749 solver.cpp:330] Iteration 38000, Testing net (#0)
I1212 08:30:35.832505 15749 net.cpp:676] Ignoring source layer drop6
I1212 08:30:35.832518 15749 net.cpp:676] Ignoring source layer drop7
I1212 08:31:17.687885 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:31:17.688176 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:31:19.112435 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 08:31:19.112480 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 08:31:19.112491 15749 solver.cpp:397]     Test net output #2: loss = 17.2827 (* 1 = 17.2827 loss)
I1212 08:31:20.587496 15749 solver.cpp:218] Iteration 38000 (0.43928 iter/s, 227.645s/100 iters), loss = 2.26906
I1212 08:31:20.587571 15749 solver.cpp:237]     Train net output #0: label = 997
I1212 08:31:20.587592 15749 solver.cpp:237]     Train net output #1: label_phocs = 997
I1212 08:31:20.587599 15749 solver.cpp:237]     Train net output #2: loss = 0.437123 (* 1 = 0.437123 loss)
I1212 08:31:20.587606 15749 sgd_solver.cpp:116] Iteration 38000, lr = 0.0001
I1212 08:33:45.130740 15749 solver.cpp:218] Iteration 38100 (0.691835 iter/s, 144.543s/100 iters), loss = 2.77358
I1212 08:33:45.130822 15749 solver.cpp:237]     Train net output #0: label = 1100
I1212 08:33:45.130846 15749 solver.cpp:237]     Train net output #1: label_phocs = 1100
I1212 08:33:45.130858 15749 solver.cpp:237]     Train net output #2: loss = 0.150989 (* 1 = 0.150989 loss)
I1212 08:33:45.130867 15749 sgd_solver.cpp:116] Iteration 38100, lr = 0.0001
I1212 08:36:09.425865 15749 solver.cpp:218] Iteration 38200 (0.693024 iter/s, 144.295s/100 iters), loss = 2.58732
I1212 08:36:09.425959 15749 solver.cpp:237]     Train net output #0: label = 387
I1212 08:36:09.425983 15749 solver.cpp:237]     Train net output #1: label_phocs = 387
I1212 08:36:09.425994 15749 solver.cpp:237]     Train net output #2: loss = 0.788738 (* 1 = 0.788738 loss)
I1212 08:36:09.426003 15749 sgd_solver.cpp:116] Iteration 38200, lr = 0.0001
I1212 08:38:39.554147 15749 solver.cpp:218] Iteration 38300 (0.666195 iter/s, 150.106s/100 iters), loss = 2.59284
I1212 08:38:39.554244 15749 solver.cpp:237]     Train net output #0: label = 873
I1212 08:38:39.554275 15749 solver.cpp:237]     Train net output #1: label_phocs = 873
I1212 08:38:39.554291 15749 solver.cpp:237]     Train net output #2: loss = 0.207948 (* 1 = 0.207948 loss)
I1212 08:38:39.554301 15749 sgd_solver.cpp:116] Iteration 38300, lr = 0.0001
I1212 08:41:05.035109 15749 solver.cpp:218] Iteration 38400 (0.687455 iter/s, 145.464s/100 iters), loss = 2.7565
I1212 08:41:05.035192 15749 solver.cpp:237]     Train net output #0: label = 446
I1212 08:41:05.035218 15749 solver.cpp:237]     Train net output #1: label_phocs = 446
I1212 08:41:05.035230 15749 solver.cpp:237]     Train net output #2: loss = 2.29913 (* 1 = 2.29913 loss)
I1212 08:41:05.035240 15749 sgd_solver.cpp:116] Iteration 38400, lr = 0.0001
[2017-12-12 08:43:33,423, PHOCNetTrainer] Running test evaluation
[2017-12-12 08:43:33,423, PHOCNetTrainer] Evaluating CNN after 38000 steps:
I1212 08:44:06.363849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:44:06.363972 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 08:44:07,290, PHOCNetTrainer] mAP: 0.912825
I1212 08:44:07.291066 15749 solver.cpp:330] Iteration 38500, Testing net (#0)
I1212 08:44:07.291252 15749 net.cpp:676] Ignoring source layer drop6
I1212 08:44:07.291260 15749 net.cpp:676] Ignoring source layer drop7
I1212 08:44:57.027981 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:44:57.028141 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:44:57.458479 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 08:44:57.458528 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 08:44:57.458539 15749 solver.cpp:397]     Test net output #2: loss = 16.5258 (* 1 = 16.5258 loss)
I1212 08:44:58.657004 15749 solver.cpp:218] Iteration 38500 (0.428063 iter/s, 233.611s/100 iters), loss = 4.05194
I1212 08:44:58.657074 15749 solver.cpp:237]     Train net output #0: label = 247
I1212 08:44:58.657097 15749 solver.cpp:237]     Train net output #1: label_phocs = 247
I1212 08:44:58.657109 15749 solver.cpp:237]     Train net output #2: loss = 5.17686 (* 1 = 5.17686 loss)
I1212 08:44:58.657116 15749 sgd_solver.cpp:116] Iteration 38500, lr = 0.0001
I1212 08:47:20.600509 15749 solver.cpp:218] Iteration 38600 (0.704506 iter/s, 141.943s/100 iters), loss = 3.01013
I1212 08:47:20.600586 15749 solver.cpp:237]     Train net output #0: label = 248
I1212 08:47:20.600610 15749 solver.cpp:237]     Train net output #1: label_phocs = 248
I1212 08:47:20.600621 15749 solver.cpp:237]     Train net output #2: loss = 0.159891 (* 1 = 0.159891 loss)
I1212 08:47:20.600636 15749 sgd_solver.cpp:116] Iteration 38600, lr = 0.0001
I1212 08:49:46.839818 15749 solver.cpp:218] Iteration 38700 (0.683811 iter/s, 146.239s/100 iters), loss = 2.77369
I1212 08:49:46.839897 15749 solver.cpp:237]     Train net output #0: label = 535
I1212 08:49:46.839920 15749 solver.cpp:237]     Train net output #1: label_phocs = 535
I1212 08:49:46.839931 15749 solver.cpp:237]     Train net output #2: loss = 7.19477 (* 1 = 7.19477 loss)
I1212 08:49:46.839939 15749 sgd_solver.cpp:116] Iteration 38700, lr = 0.0001
I1212 08:52:10.577049 15749 solver.cpp:218] Iteration 38800 (0.695714 iter/s, 143.737s/100 iters), loss = 2.84657
I1212 08:52:10.577118 15749 solver.cpp:237]     Train net output #0: label = 958
I1212 08:52:10.577136 15749 solver.cpp:237]     Train net output #1: label_phocs = 958
I1212 08:52:10.577144 15749 solver.cpp:237]     Train net output #2: loss = 0.71241 (* 1 = 0.71241 loss)
I1212 08:52:10.577150 15749 sgd_solver.cpp:116] Iteration 38800, lr = 0.0001
I1212 08:54:33.032254 15749 solver.cpp:218] Iteration 38900 (0.701975 iter/s, 142.455s/100 iters), loss = 2.98444
I1212 08:54:33.032341 15749 solver.cpp:237]     Train net output #0: label = 933
I1212 08:54:33.032364 15749 solver.cpp:237]     Train net output #1: label_phocs = 933
I1212 08:54:33.032377 15749 solver.cpp:237]     Train net output #2: loss = 1.71503 (* 1 = 1.71503 loss)
I1212 08:54:33.032384 15749 sgd_solver.cpp:116] Iteration 38900, lr = 0.0001
[2017-12-12 08:56:52,024, PHOCNetTrainer] Running test evaluation
[2017-12-12 08:56:52,024, PHOCNetTrainer] Evaluating CNN after 38500 steps:
I1212 08:57:42.627856 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:57:42.627985 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 08:57:45,638, PHOCNetTrainer] mAP: 0.920759
I1212 08:57:45.648243 15749 solver.cpp:330] Iteration 39000, Testing net (#0)
I1212 08:57:45.648461 15749 net.cpp:676] Ignoring source layer drop6
I1212 08:57:45.648471 15749 net.cpp:676] Ignoring source layer drop7
I1212 08:58:28.467907 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:58:28.468196 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 08:58:28.914165 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 08:58:28.914216 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 08:58:28.914234 15749 solver.cpp:397]     Test net output #2: loss = 15.6564 (* 1 = 15.6564 loss)
I1212 08:58:30.743783 15749 solver.cpp:218] Iteration 39000 (0.420722 iter/s, 237.687s/100 iters), loss = 1.47983
I1212 08:58:30.743862 15749 solver.cpp:237]     Train net output #0: label = 977
I1212 08:58:30.743886 15749 solver.cpp:237]     Train net output #1: label_phocs = 977
I1212 08:58:30.743897 15749 solver.cpp:237]     Train net output #2: loss = 1.4515 (* 1 = 1.4515 loss)
I1212 08:58:30.743906 15749 sgd_solver.cpp:116] Iteration 39000, lr = 0.0001
I1212 09:00:50.854907 15749 solver.cpp:218] Iteration 39100 (0.713719 iter/s, 140.111s/100 iters), loss = 2.73489
I1212 09:00:50.854988 15749 solver.cpp:237]     Train net output #0: label = 481
I1212 09:00:50.855013 15749 solver.cpp:237]     Train net output #1: label_phocs = 481
I1212 09:00:50.855024 15749 solver.cpp:237]     Train net output #2: loss = 3.74812 (* 1 = 3.74812 loss)
I1212 09:00:50.855033 15749 sgd_solver.cpp:116] Iteration 39100, lr = 0.0001
I1212 09:03:15.332098 15749 solver.cpp:218] Iteration 39200 (0.692151 iter/s, 144.477s/100 iters), loss = 2.54938
I1212 09:03:15.332191 15749 solver.cpp:237]     Train net output #0: label = 463
I1212 09:03:15.332217 15749 solver.cpp:237]     Train net output #1: label_phocs = 463
I1212 09:03:15.332229 15749 solver.cpp:237]     Train net output #2: loss = 3.65002 (* 1 = 3.65002 loss)
I1212 09:03:15.332238 15749 sgd_solver.cpp:116] Iteration 39200, lr = 0.0001
I1212 09:05:37.023541 15749 solver.cpp:218] Iteration 39300 (0.705759 iter/s, 141.691s/100 iters), loss = 2.75815
I1212 09:05:37.023630 15749 solver.cpp:237]     Train net output #0: label = 437
I1212 09:05:37.023655 15749 solver.cpp:237]     Train net output #1: label_phocs = 437
I1212 09:05:37.023667 15749 solver.cpp:237]     Train net output #2: loss = 10.2761 (* 1 = 10.2761 loss)
I1212 09:05:37.023676 15749 sgd_solver.cpp:116] Iteration 39300, lr = 0.0001
I1212 09:08:09.565424 15749 solver.cpp:218] Iteration 39400 (0.655558 iter/s, 152.542s/100 iters), loss = 2.6585
I1212 09:08:09.565507 15749 solver.cpp:237]     Train net output #0: label = 1064
I1212 09:08:09.565533 15749 solver.cpp:237]     Train net output #1: label_phocs = 1064
I1212 09:08:09.565546 15749 solver.cpp:237]     Train net output #2: loss = 0.555034 (* 1 = 0.555034 loss)
I1212 09:08:09.565553 15749 sgd_solver.cpp:116] Iteration 39400, lr = 0.0001
[2017-12-12 09:10:43,789, PHOCNetTrainer] Running test evaluation
[2017-12-12 09:10:43,789, PHOCNetTrainer] Evaluating CNN after 39000 steps:
I1212 09:11:30.042343 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:11:30.042480 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 09:11:33,381, PHOCNetTrainer] mAP: 0.909435
I1212 09:11:33.383044 15749 solver.cpp:330] Iteration 39500, Testing net (#0)
I1212 09:11:33.383244 15749 net.cpp:676] Ignoring source layer drop6
I1212 09:11:33.383253 15749 net.cpp:676] Ignoring source layer drop7
I1212 09:12:09.975538 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:12:09.975641 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:12:10.286072 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 09:12:10.286113 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 09:12:10.286124 15749 solver.cpp:397]     Test net output #2: loss = 17.1979 (* 1 = 17.1979 loss)
I1212 09:12:11.084954 15749 solver.cpp:218] Iteration 39500 (0.414045 iter/s, 241.519s/100 iters), loss = 1.95928
I1212 09:12:11.085016 15749 solver.cpp:237]     Train net output #0: label = 315
I1212 09:12:11.085034 15749 solver.cpp:237]     Train net output #1: label_phocs = 315
I1212 09:12:11.085042 15749 solver.cpp:237]     Train net output #2: loss = 1.92637 (* 1 = 1.92637 loss)
I1212 09:12:11.085048 15749 sgd_solver.cpp:116] Iteration 39500, lr = 0.0001
I1212 09:14:30.589905 15749 solver.cpp:218] Iteration 39600 (0.716874 iter/s, 139.495s/100 iters), loss = 2.68326
I1212 09:14:30.589987 15749 solver.cpp:237]     Train net output #0: label = 390
I1212 09:14:30.590010 15749 solver.cpp:237]     Train net output #1: label_phocs = 390
I1212 09:14:30.590021 15749 solver.cpp:237]     Train net output #2: loss = 0.137772 (* 1 = 0.137772 loss)
I1212 09:14:30.590029 15749 sgd_solver.cpp:116] Iteration 39600, lr = 0.0001
I1212 09:16:58.688030 15749 solver.cpp:218] Iteration 39700 (0.675228 iter/s, 148.098s/100 iters), loss = 2.55651
I1212 09:16:58.688110 15749 solver.cpp:237]     Train net output #0: label = 971
I1212 09:16:58.688133 15749 solver.cpp:237]     Train net output #1: label_phocs = 971
I1212 09:16:58.688145 15749 solver.cpp:237]     Train net output #2: loss = 7.80487 (* 1 = 7.80487 loss)
I1212 09:16:58.688154 15749 sgd_solver.cpp:116] Iteration 39700, lr = 0.0001
I1212 09:19:22.297567 15749 solver.cpp:218] Iteration 39800 (0.696435 iter/s, 143.588s/100 iters), loss = 2.69988
I1212 09:19:22.297652 15749 solver.cpp:237]     Train net output #0: label = 858
I1212 09:19:22.297674 15749 solver.cpp:237]     Train net output #1: label_phocs = 858
I1212 09:19:22.297685 15749 solver.cpp:237]     Train net output #2: loss = 1.3114 (* 1 = 1.3114 loss)
I1212 09:19:22.297694 15749 sgd_solver.cpp:116] Iteration 39800, lr = 0.0001
I1212 09:21:53.242844 15749 solver.cpp:218] Iteration 39900 (0.662492 iter/s, 150.945s/100 iters), loss = 2.46149
I1212 09:21:53.242929 15749 solver.cpp:237]     Train net output #0: label = 296
I1212 09:21:53.242954 15749 solver.cpp:237]     Train net output #1: label_phocs = 296
I1212 09:21:53.242964 15749 solver.cpp:237]     Train net output #2: loss = 2.16967 (* 1 = 2.16967 loss)
I1212 09:21:53.242977 15749 sgd_solver.cpp:116] Iteration 39900, lr = 0.0001
[2017-12-12 09:24:16,293, PHOCNetTrainer] Running test evaluation
[2017-12-12 09:24:16,293, PHOCNetTrainer] Evaluating CNN after 39500 steps:
I1212 09:25:07.747849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:25:07.747982 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 09:25:09,221, PHOCNetTrainer] mAP: 0.916471
I1212 09:25:09.222798 15749 solver.cpp:330] Iteration 40000, Testing net (#0)
I1212 09:25:09.222988 15749 net.cpp:676] Ignoring source layer drop6
I1212 09:25:09.222997 15749 net.cpp:676] Ignoring source layer drop7
I1212 09:25:47.451973 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:25:47.452139 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:25:47.877279 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 09:25:47.877321 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 09:25:47.877332 15749 solver.cpp:397]     Test net output #2: loss = 16.1207 (* 1 = 16.1207 loss)
I1212 09:25:49.836278 15749 solver.cpp:218] Iteration 40000 (0.422666 iter/s, 236.593s/100 iters), loss = 5.16657
I1212 09:25:49.836362 15749 solver.cpp:237]     Train net output #0: label = 872
I1212 09:25:49.836385 15749 solver.cpp:237]     Train net output #1: label_phocs = 872
I1212 09:25:49.836396 15749 solver.cpp:237]     Train net output #2: loss = 5.2484 (* 1 = 5.2484 loss)
I1212 09:25:49.836405 15749 sgd_solver.cpp:116] Iteration 40000, lr = 0.0001
I1212 09:28:17.272130 15749 solver.cpp:218] Iteration 40100 (0.678464 iter/s, 147.392s/100 iters), loss = 2.57931
I1212 09:28:17.272236 15749 solver.cpp:237]     Train net output #0: label = 713
I1212 09:28:17.272271 15749 solver.cpp:237]     Train net output #1: label_phocs = 713
I1212 09:28:17.272291 15749 solver.cpp:237]     Train net output #2: loss = 0.315015 (* 1 = 0.315015 loss)
I1212 09:28:17.272305 15749 sgd_solver.cpp:116] Iteration 40100, lr = 0.0001
I1212 09:30:45.189174 15749 solver.cpp:218] Iteration 40200 (0.676116 iter/s, 147.904s/100 iters), loss = 2.4874
I1212 09:30:45.189258 15749 solver.cpp:237]     Train net output #0: label = 865
I1212 09:30:45.189281 15749 solver.cpp:237]     Train net output #1: label_phocs = 865
I1212 09:30:45.189292 15749 solver.cpp:237]     Train net output #2: loss = 2.28869 (* 1 = 2.28869 loss)
I1212 09:30:45.189301 15749 sgd_solver.cpp:116] Iteration 40200, lr = 0.0001
I1212 09:33:02.343677 15749 solver.cpp:218] Iteration 40300 (0.729129 iter/s, 137.15s/100 iters), loss = 2.39834
I1212 09:33:02.356230 15749 solver.cpp:237]     Train net output #0: label = 790
I1212 09:33:02.356277 15749 solver.cpp:237]     Train net output #1: label_phocs = 790
I1212 09:33:02.356287 15749 solver.cpp:237]     Train net output #2: loss = 2.87197 (* 1 = 2.87197 loss)
I1212 09:33:02.356292 15749 sgd_solver.cpp:116] Iteration 40300, lr = 0.0001
I1212 09:35:26.695477 15749 solver.cpp:218] Iteration 40400 (0.692812 iter/s, 144.339s/100 iters), loss = 2.49581
I1212 09:35:26.695546 15749 solver.cpp:237]     Train net output #0: label = 518
I1212 09:35:26.695565 15749 solver.cpp:237]     Train net output #1: label_phocs = 518
I1212 09:35:26.695574 15749 solver.cpp:237]     Train net output #2: loss = 2.14949 (* 1 = 2.14949 loss)
I1212 09:35:26.695580 15749 sgd_solver.cpp:116] Iteration 40400, lr = 0.0001
[2017-12-12 09:37:53,318, PHOCNetTrainer] Running test evaluation
[2017-12-12 09:37:53,318, PHOCNetTrainer] Evaluating CNN after 40000 steps:
I1212 09:38:39.319115 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:38:39.319144 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 09:38:40,392, PHOCNetTrainer] mAP: 0.881212
I1212 09:38:40.393599 15749 solver.cpp:330] Iteration 40500, Testing net (#0)
I1212 09:38:40.393796 15749 net.cpp:676] Ignoring source layer drop6
I1212 09:38:40.393805 15749 net.cpp:676] Ignoring source layer drop7
I1212 09:39:18.487853 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:39:18.487979 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:39:19.047783 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 09:39:19.047823 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 09:39:19.047835 15749 solver.cpp:397]     Test net output #2: loss = 21.1035 (* 1 = 21.1035 loss)
I1212 09:39:20.798292 15749 solver.cpp:218] Iteration 40500 (0.427163 iter/s, 234.103s/100 iters), loss = 6.09437
I1212 09:39:20.798364 15749 solver.cpp:237]     Train net output #0: label = 761
I1212 09:39:20.798387 15749 solver.cpp:237]     Train net output #1: label_phocs = 761
I1212 09:39:20.798398 15749 solver.cpp:237]     Train net output #2: loss = 2.08136 (* 1 = 2.08136 loss)
I1212 09:39:20.798406 15749 sgd_solver.cpp:116] Iteration 40500, lr = 0.0001
I1212 09:41:45.633445 15749 solver.cpp:218] Iteration 40600 (0.69044 iter/s, 144.835s/100 iters), loss = 2.49578
I1212 09:41:45.633515 15749 solver.cpp:237]     Train net output #0: label = 165
I1212 09:41:45.633534 15749 solver.cpp:237]     Train net output #1: label_phocs = 165
I1212 09:41:45.633543 15749 solver.cpp:237]     Train net output #2: loss = 0.9421 (* 1 = 0.9421 loss)
I1212 09:41:45.633549 15749 sgd_solver.cpp:116] Iteration 40600, lr = 0.0001
I1212 09:44:10.360200 15749 solver.cpp:218] Iteration 40700 (0.690957 iter/s, 144.727s/100 iters), loss = 2.25762
I1212 09:44:10.360282 15749 solver.cpp:237]     Train net output #0: label = 18
I1212 09:44:10.360306 15749 solver.cpp:237]     Train net output #1: label_phocs = 18
I1212 09:44:10.360317 15749 solver.cpp:237]     Train net output #2: loss = 0.178798 (* 1 = 0.178798 loss)
I1212 09:44:10.360327 15749 sgd_solver.cpp:116] Iteration 40700, lr = 0.0001
I1212 09:46:34.329530 15749 solver.cpp:218] Iteration 40800 (0.694744 iter/s, 143.938s/100 iters), loss = 2.72505
I1212 09:46:34.329602 15749 solver.cpp:237]     Train net output #0: label = 744
I1212 09:46:34.329620 15749 solver.cpp:237]     Train net output #1: label_phocs = 744
I1212 09:46:34.329629 15749 solver.cpp:237]     Train net output #2: loss = 0.138417 (* 1 = 0.138417 loss)
I1212 09:46:34.329637 15749 sgd_solver.cpp:116] Iteration 40800, lr = 0.0001
I1212 09:49:01.828044 15749 solver.cpp:218] Iteration 40900 (0.677973 iter/s, 147.499s/100 iters), loss = 2.3458
I1212 09:49:01.828138 15749 solver.cpp:237]     Train net output #0: label = 300
I1212 09:49:01.828163 15749 solver.cpp:237]     Train net output #1: label_phocs = 300
I1212 09:49:01.828174 15749 solver.cpp:237]     Train net output #2: loss = 1.20564 (* 1 = 1.20564 loss)
I1212 09:49:01.828184 15749 sgd_solver.cpp:116] Iteration 40900, lr = 0.0001
[2017-12-12 09:51:17,372, PHOCNetTrainer] Running test evaluation
[2017-12-12 09:51:17,372, PHOCNetTrainer] Evaluating CNN after 40500 steps:
I1212 09:52:11.346760 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:52:11.346902 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 09:52:14,149, PHOCNetTrainer] mAP: 0.911407
I1212 09:52:14.151260 15749 solver.cpp:330] Iteration 41000, Testing net (#0)
I1212 09:52:14.151455 15749 net.cpp:676] Ignoring source layer drop6
I1212 09:52:14.151465 15749 net.cpp:676] Ignoring source layer drop7
I1212 09:52:54.518100 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:52:54.518158 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 09:52:54.836702 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 09:52:54.836750 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 09:52:54.836761 15749 solver.cpp:397]     Test net output #2: loss = 16.8437 (* 1 = 16.8437 loss)
I1212 09:52:56.072424 15749 solver.cpp:218] Iteration 41000 (0.426907 iter/s, 234.243s/100 iters), loss = 2.49136
I1212 09:52:56.072515 15749 solver.cpp:237]     Train net output #0: label = 103
I1212 09:52:56.072538 15749 solver.cpp:237]     Train net output #1: label_phocs = 103
I1212 09:52:56.072549 15749 solver.cpp:237]     Train net output #2: loss = 3.23429 (* 1 = 3.23429 loss)
I1212 09:52:56.072566 15749 sgd_solver.cpp:116] Iteration 41000, lr = 0.0001
I1212 09:55:23.534291 15749 solver.cpp:218] Iteration 41100 (0.678141 iter/s, 147.462s/100 iters), loss = 2.48144
I1212 09:55:23.534358 15749 solver.cpp:237]     Train net output #0: label = 246
I1212 09:55:23.534377 15749 solver.cpp:237]     Train net output #1: label_phocs = 246
I1212 09:55:23.534384 15749 solver.cpp:237]     Train net output #2: loss = 0.245549 (* 1 = 0.245549 loss)
I1212 09:55:23.534391 15749 sgd_solver.cpp:116] Iteration 41100, lr = 0.0001
I1212 09:57:50.696847 15749 solver.cpp:218] Iteration 41200 (0.67952 iter/s, 147.163s/100 iters), loss = 2.42504
I1212 09:57:50.696924 15749 solver.cpp:237]     Train net output #0: label = 768
I1212 09:57:50.696949 15749 solver.cpp:237]     Train net output #1: label_phocs = 768
I1212 09:57:50.696960 15749 solver.cpp:237]     Train net output #2: loss = 0.00856074 (* 1 = 0.00856074 loss)
I1212 09:57:50.696969 15749 sgd_solver.cpp:116] Iteration 41200, lr = 0.0001
I1212 10:00:10.823511 15749 solver.cpp:218] Iteration 41300 (0.713673 iter/s, 140.12s/100 iters), loss = 2.41854
I1212 10:00:10.823603 15749 solver.cpp:237]     Train net output #0: label = 200
I1212 10:00:10.823627 15749 solver.cpp:237]     Train net output #1: label_phocs = 200
I1212 10:00:10.823640 15749 solver.cpp:237]     Train net output #2: loss = 0.112165 (* 1 = 0.112165 loss)
I1212 10:00:10.823649 15749 sgd_solver.cpp:116] Iteration 41300, lr = 0.0001
I1212 10:02:32.770401 15749 solver.cpp:218] Iteration 41400 (0.704489 iter/s, 141.947s/100 iters), loss = 2.62418
I1212 10:02:32.770483 15749 solver.cpp:237]     Train net output #0: label = 1107
I1212 10:02:32.770509 15749 solver.cpp:237]     Train net output #1: label_phocs = 1107
I1212 10:02:32.770520 15749 solver.cpp:237]     Train net output #2: loss = 1.16829 (* 1 = 1.16829 loss)
I1212 10:02:32.770529 15749 sgd_solver.cpp:116] Iteration 41400, lr = 0.0001
[2017-12-12 10:04:51,441, PHOCNetTrainer] Running test evaluation
[2017-12-12 10:04:51,441, PHOCNetTrainer] Evaluating CNN after 41000 steps:
I1212 10:05:41.074259 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:05:41.074276 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 10:05:43,047, PHOCNetTrainer] mAP: 0.915090
I1212 10:05:43.049042 15749 solver.cpp:330] Iteration 41500, Testing net (#0)
I1212 10:05:43.049233 15749 net.cpp:676] Ignoring source layer drop6
I1212 10:05:43.049243 15749 net.cpp:676] Ignoring source layer drop7
I1212 10:06:20.551964 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:06:20.552337 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:06:21.286032 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 10:06:21.286072 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 10:06:21.286079 15749 solver.cpp:397]     Test net output #2: loss = 16.7916 (* 1 = 16.7916 loss)
I1212 10:06:22.717358 15749 solver.cpp:218] Iteration 41500 (0.434883 iter/s, 229.947s/100 iters), loss = 1.92095
I1212 10:06:22.717434 15749 solver.cpp:237]     Train net output #0: label = 396
I1212 10:06:22.717456 15749 solver.cpp:237]     Train net output #1: label_phocs = 396
I1212 10:06:22.717468 15749 solver.cpp:237]     Train net output #2: loss = 0.784579 (* 1 = 0.784579 loss)
I1212 10:06:22.717476 15749 sgd_solver.cpp:116] Iteration 41500, lr = 0.0001
I1212 10:08:48.220880 15749 solver.cpp:218] Iteration 41600 (0.687268 iter/s, 145.504s/100 iters), loss = 2.29841
I1212 10:08:48.220973 15749 solver.cpp:237]     Train net output #0: label = 782
I1212 10:08:48.220999 15749 solver.cpp:237]     Train net output #1: label_phocs = 782
I1212 10:08:48.221011 15749 solver.cpp:237]     Train net output #2: loss = 0.55083 (* 1 = 0.55083 loss)
I1212 10:08:48.221020 15749 sgd_solver.cpp:116] Iteration 41600, lr = 0.0001
I1212 10:11:22.394301 15749 solver.cpp:218] Iteration 41700 (0.648681 iter/s, 154.159s/100 iters), loss = 2.47034
I1212 10:11:22.394392 15749 solver.cpp:237]     Train net output #0: label = 780
I1212 10:11:22.394423 15749 solver.cpp:237]     Train net output #1: label_phocs = 780
I1212 10:11:22.394434 15749 solver.cpp:237]     Train net output #2: loss = 0.793739 (* 1 = 0.793739 loss)
I1212 10:11:22.394443 15749 sgd_solver.cpp:116] Iteration 41700, lr = 0.0001
I1212 10:13:40.791177 15749 solver.cpp:218] Iteration 41800 (0.72256 iter/s, 138.397s/100 iters), loss = 2.84487
I1212 10:13:40.791260 15749 solver.cpp:237]     Train net output #0: label = 950
I1212 10:13:40.791283 15749 solver.cpp:237]     Train net output #1: label_phocs = 950
I1212 10:13:40.791294 15749 solver.cpp:237]     Train net output #2: loss = 2.62854 (* 1 = 2.62854 loss)
I1212 10:13:40.791303 15749 sgd_solver.cpp:116] Iteration 41800, lr = 0.0001
I1212 10:16:01.591258 15749 solver.cpp:218] Iteration 41900 (0.71023 iter/s, 140.799s/100 iters), loss = 2.33395
I1212 10:16:01.591337 15749 solver.cpp:237]     Train net output #0: label = 874
I1212 10:16:01.591361 15749 solver.cpp:237]     Train net output #1: label_phocs = 874
I1212 10:16:01.591372 15749 solver.cpp:237]     Train net output #2: loss = 6.62303 (* 1 = 6.62303 loss)
I1212 10:16:01.591379 15749 sgd_solver.cpp:116] Iteration 41900, lr = 0.0001
[2017-12-12 10:18:19,913, PHOCNetTrainer] Running test evaluation
[2017-12-12 10:18:19,913, PHOCNetTrainer] Evaluating CNN after 41500 steps:
I1212 10:19:14.916823 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:19:14.916826 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 10:19:17,579, PHOCNetTrainer] mAP: 0.915926
I1212 10:19:17.581483 15749 solver.cpp:330] Iteration 42000, Testing net (#0)
I1212 10:19:17.581697 15749 net.cpp:676] Ignoring source layer drop6
I1212 10:19:17.581708 15749 net.cpp:676] Ignoring source layer drop7
I1212 10:19:57.183368 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:19:57.183364 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:19:57.719369 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 10:19:57.719410 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 10:19:57.719419 15749 solver.cpp:397]     Test net output #2: loss = 15.9505 (* 1 = 15.9505 loss)
I1212 10:19:58.841028 15749 solver.cpp:218] Iteration 42000 (0.421499 iter/s, 237.249s/100 iters), loss = 2.79301
I1212 10:19:58.841109 15749 solver.cpp:237]     Train net output #0: label = 637
I1212 10:19:58.841133 15749 solver.cpp:237]     Train net output #1: label_phocs = 637
I1212 10:19:58.841145 15749 solver.cpp:237]     Train net output #2: loss = 3.82781 (* 1 = 3.82781 loss)
I1212 10:19:58.841153 15749 sgd_solver.cpp:116] Iteration 42000, lr = 0.0001
I1212 10:22:22.553625 15749 solver.cpp:218] Iteration 42100 (0.695833 iter/s, 143.713s/100 iters), loss = 2.34119
I1212 10:22:22.553707 15749 solver.cpp:237]     Train net output #0: label = 160
I1212 10:22:22.553730 15749 solver.cpp:237]     Train net output #1: label_phocs = 160
I1212 10:22:22.553741 15749 solver.cpp:237]     Train net output #2: loss = 1.02165 (* 1 = 1.02165 loss)
I1212 10:22:22.553750 15749 sgd_solver.cpp:116] Iteration 42100, lr = 0.0001
I1212 10:24:49.354833 15749 solver.cpp:218] Iteration 42200 (0.681193 iter/s, 146.801s/100 iters), loss = 2.19333
I1212 10:24:49.354912 15749 solver.cpp:237]     Train net output #0: label = 463
I1212 10:24:49.354935 15749 solver.cpp:237]     Train net output #1: label_phocs = 463
I1212 10:24:49.354948 15749 solver.cpp:237]     Train net output #2: loss = 3.7391 (* 1 = 3.7391 loss)
I1212 10:24:49.354955 15749 sgd_solver.cpp:116] Iteration 42200, lr = 0.0001
I1212 10:27:19.144989 15749 solver.cpp:218] Iteration 42300 (0.667601 iter/s, 149.79s/100 iters), loss = 2.14487
I1212 10:27:19.145067 15749 solver.cpp:237]     Train net output #0: label = 868
I1212 10:27:19.145092 15749 solver.cpp:237]     Train net output #1: label_phocs = 868
I1212 10:27:19.145104 15749 solver.cpp:237]     Train net output #2: loss = 1.24922 (* 1 = 1.24922 loss)
I1212 10:27:19.145113 15749 sgd_solver.cpp:116] Iteration 42300, lr = 0.0001
I1212 10:29:41.976475 15749 solver.cpp:218] Iteration 42400 (0.700155 iter/s, 142.826s/100 iters), loss = 2.27345
I1212 10:29:41.976555 15749 solver.cpp:237]     Train net output #0: label = 420
I1212 10:29:41.976578 15749 solver.cpp:237]     Train net output #1: label_phocs = 420
I1212 10:29:41.976590 15749 solver.cpp:237]     Train net output #2: loss = 10.4663 (* 1 = 10.4663 loss)
I1212 10:29:41.976598 15749 sgd_solver.cpp:116] Iteration 42400, lr = 0.0001
[2017-12-12 10:32:08,913, PHOCNetTrainer] Running test evaluation
[2017-12-12 10:32:08,913, PHOCNetTrainer] Evaluating CNN after 42000 steps:
I1212 10:33:01.099849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:33:01.099975 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 10:33:02,919, PHOCNetTrainer] mAP: 0.895938
I1212 10:33:02.920856 15749 solver.cpp:330] Iteration 42500, Testing net (#0)
I1212 10:33:02.921054 15749 net.cpp:676] Ignoring source layer drop6
I1212 10:33:02.921063 15749 net.cpp:676] Ignoring source layer drop7
I1212 10:33:43.147974 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:33:43.148133 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:33:43.906754 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 10:33:43.906802 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 10:33:43.906814 15749 solver.cpp:397]     Test net output #2: loss = 19.0184 (* 1 = 19.0184 loss)
I1212 10:33:45.063882 15749 solver.cpp:218] Iteration 42500 (0.411375 iter/s, 243.087s/100 iters), loss = 3.14478
I1212 10:33:45.063978 15749 solver.cpp:237]     Train net output #0: label = 87
I1212 10:33:45.064018 15749 solver.cpp:237]     Train net output #1: label_phocs = 87
I1212 10:33:45.064029 15749 solver.cpp:237]     Train net output #2: loss = 1.97948 (* 1 = 1.97948 loss)
I1212 10:33:45.064038 15749 sgd_solver.cpp:116] Iteration 42500, lr = 0.0001
I1212 10:36:05.385200 15749 solver.cpp:218] Iteration 42600 (0.71265 iter/s, 140.321s/100 iters), loss = 2.4429
I1212 10:36:05.385284 15749 solver.cpp:237]     Train net output #0: label = 872
I1212 10:36:05.385309 15749 solver.cpp:237]     Train net output #1: label_phocs = 872
I1212 10:36:05.385321 15749 solver.cpp:237]     Train net output #2: loss = 23.2077 (* 1 = 23.2077 loss)
I1212 10:36:05.385331 15749 sgd_solver.cpp:116] Iteration 42600, lr = 0.0001
I1212 10:38:31.456641 15749 solver.cpp:218] Iteration 42700 (0.684772 iter/s, 146.034s/100 iters), loss = 2.38057
I1212 10:38:31.456722 15749 solver.cpp:237]     Train net output #0: label = 394
I1212 10:38:31.456744 15749 solver.cpp:237]     Train net output #1: label_phocs = 394
I1212 10:38:31.456756 15749 solver.cpp:237]     Train net output #2: loss = 7.70569 (* 1 = 7.70569 loss)
I1212 10:38:31.456765 15749 sgd_solver.cpp:116] Iteration 42700, lr = 0.0001
I1212 10:41:08.944291 15749 solver.cpp:218] Iteration 42800 (0.635052 iter/s, 157.467s/100 iters), loss = 2.25712
I1212 10:41:08.944381 15749 solver.cpp:237]     Train net output #0: label = 385
I1212 10:41:08.944407 15749 solver.cpp:237]     Train net output #1: label_phocs = 385
I1212 10:41:08.944420 15749 solver.cpp:237]     Train net output #2: loss = 0.339776 (* 1 = 0.339776 loss)
I1212 10:41:08.944430 15749 sgd_solver.cpp:116] Iteration 42800, lr = 0.0001
I1212 10:43:38.983700 15749 solver.cpp:218] Iteration 42900 (0.666492 iter/s, 150.039s/100 iters), loss = 2.3922
I1212 10:43:38.983968 15749 solver.cpp:237]     Train net output #0: label = 738
I1212 10:43:38.983995 15749 solver.cpp:237]     Train net output #1: label_phocs = 738
I1212 10:43:38.984006 15749 solver.cpp:237]     Train net output #2: loss = 2.72315 (* 1 = 2.72315 loss)
I1212 10:43:38.984015 15749 sgd_solver.cpp:116] Iteration 42900, lr = 0.0001
[2017-12-12 10:46:05,770, PHOCNetTrainer] Running test evaluation
[2017-12-12 10:46:05,770, PHOCNetTrainer] Evaluating CNN after 42500 steps:
I1212 10:46:58.674229 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:46:58.674377 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 10:47:00,817, PHOCNetTrainer] mAP: 0.908272
I1212 10:47:00.818531 15749 solver.cpp:330] Iteration 43000, Testing net (#0)
I1212 10:47:00.818755 15749 net.cpp:676] Ignoring source layer drop6
I1212 10:47:00.818768 15749 net.cpp:676] Ignoring source layer drop7
I1212 10:47:35.324985 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:47:35.379863 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 10:47:36.280436 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 10:47:36.280481 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 10:47:36.280493 15749 solver.cpp:397]     Test net output #2: loss = 17.3746 (* 1 = 17.3746 loss)
I1212 10:47:37.921331 15749 solver.cpp:218] Iteration 43000 (0.418538 iter/s, 238.927s/100 iters), loss = 1.04317
I1212 10:47:37.921416 15749 solver.cpp:237]     Train net output #0: label = 206
I1212 10:47:37.921439 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1212 10:47:37.921452 15749 solver.cpp:237]     Train net output #2: loss = 0.00965608 (* 1 = 0.00965608 loss)
I1212 10:47:37.921461 15749 sgd_solver.cpp:116] Iteration 43000, lr = 0.0001
I1212 10:50:14.856822 15749 solver.cpp:218] Iteration 43100 (0.637205 iter/s, 156.935s/100 iters), loss = 2.23727
I1212 10:50:14.856911 15749 solver.cpp:237]     Train net output #0: label = 648
I1212 10:50:14.856933 15749 solver.cpp:237]     Train net output #1: label_phocs = 648
I1212 10:50:14.856945 15749 solver.cpp:237]     Train net output #2: loss = 0.296867 (* 1 = 0.296867 loss)
I1212 10:50:14.856954 15749 sgd_solver.cpp:116] Iteration 43100, lr = 0.0001
I1212 10:52:45.698092 15749 solver.cpp:218] Iteration 43200 (0.662949 iter/s, 150.841s/100 iters), loss = 2.30859
I1212 10:52:45.698179 15749 solver.cpp:237]     Train net output #0: label = 346
I1212 10:52:45.698205 15749 solver.cpp:237]     Train net output #1: label_phocs = 346
I1212 10:52:45.698218 15749 solver.cpp:237]     Train net output #2: loss = 0.213975 (* 1 = 0.213975 loss)
I1212 10:52:45.698227 15749 sgd_solver.cpp:116] Iteration 43200, lr = 0.0001
I1212 10:55:10.861341 15749 solver.cpp:218] Iteration 43300 (0.68893 iter/s, 145.153s/100 iters), loss = 2.057
I1212 10:55:10.861420 15749 solver.cpp:237]     Train net output #0: label = 158
I1212 10:55:10.861443 15749 solver.cpp:237]     Train net output #1: label_phocs = 158
I1212 10:55:10.861455 15749 solver.cpp:237]     Train net output #2: loss = 0.021963 (* 1 = 0.021963 loss)
I1212 10:55:10.861464 15749 sgd_solver.cpp:116] Iteration 43300, lr = 0.0001
I1212 10:57:41.710352 15749 solver.cpp:218] Iteration 43400 (0.662915 iter/s, 150.849s/100 iters), loss = 2.02291
I1212 10:57:41.710435 15749 solver.cpp:237]     Train net output #0: label = 990
I1212 10:57:41.710459 15749 solver.cpp:237]     Train net output #1: label_phocs = 990
I1212 10:57:41.710471 15749 solver.cpp:237]     Train net output #2: loss = 0.692878 (* 1 = 0.692878 loss)
I1212 10:57:41.710480 15749 sgd_solver.cpp:116] Iteration 43400, lr = 0.0001
[2017-12-12 11:00:10,933, PHOCNetTrainer] Running test evaluation
[2017-12-12 11:00:10,933, PHOCNetTrainer] Evaluating CNN after 43000 steps:
I1212 11:01:02.839874 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:01:02.840122 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 11:01:05,269, PHOCNetTrainer] mAP: 0.925550
I1212 11:01:05.271553 15749 solver.cpp:330] Iteration 43500, Testing net (#0)
I1212 11:01:05.271760 15749 net.cpp:676] Ignoring source layer drop6
I1212 11:01:05.271772 15749 net.cpp:676] Ignoring source layer drop7
I1212 11:02:04.345284 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:02:04.345343 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:02:04.870947 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 11:02:04.870983 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 11:02:04.870991 15749 solver.cpp:397]     Test net output #2: loss = 16.0801 (* 1 = 16.0801 loss)
I1212 11:02:06.350157 15749 solver.cpp:218] Iteration 43500 (0.377872 iter/s, 264.64s/100 iters), loss = 1.7469
I1212 11:02:06.350234 15749 solver.cpp:237]     Train net output #0: label = 657
I1212 11:02:06.350260 15749 solver.cpp:237]     Train net output #1: label_phocs = 657
I1212 11:02:06.350272 15749 solver.cpp:237]     Train net output #2: loss = 0.00310207 (* 1 = 0.00310207 loss)
I1212 11:02:06.350281 15749 sgd_solver.cpp:116] Iteration 43500, lr = 0.0001
I1212 11:05:35.077690 15749 solver.cpp:218] Iteration 43600 (0.479093 iter/s, 208.728s/100 iters), loss = 2.20537
I1212 11:05:35.077775 15749 solver.cpp:237]     Train net output #0: label = 323
I1212 11:05:35.077800 15749 solver.cpp:237]     Train net output #1: label_phocs = 323
I1212 11:05:35.077812 15749 solver.cpp:237]     Train net output #2: loss = 0.273892 (* 1 = 0.273892 loss)
I1212 11:05:35.077821 15749 sgd_solver.cpp:116] Iteration 43600, lr = 0.0001
I1212 11:09:03.774633 15749 solver.cpp:218] Iteration 43700 (0.479164 iter/s, 208.697s/100 iters), loss = 2.50891
I1212 11:09:03.774725 15749 solver.cpp:237]     Train net output #0: label = 827
I1212 11:09:03.774751 15749 solver.cpp:237]     Train net output #1: label_phocs = 827
I1212 11:09:03.774765 15749 solver.cpp:237]     Train net output #2: loss = 22.1172 (* 1 = 22.1172 loss)
I1212 11:09:03.774775 15749 sgd_solver.cpp:116] Iteration 43700, lr = 0.0001
I1212 11:12:34.098951 15749 solver.cpp:218] Iteration 43800 (0.475564 iter/s, 210.277s/100 iters), loss = 2.16811
I1212 11:12:34.099043 15749 solver.cpp:237]     Train net output #0: label = 366
I1212 11:12:34.099069 15749 solver.cpp:237]     Train net output #1: label_phocs = 366
I1212 11:12:34.099081 15749 solver.cpp:237]     Train net output #2: loss = 0.602675 (* 1 = 0.602675 loss)
I1212 11:12:34.099090 15749 sgd_solver.cpp:116] Iteration 43800, lr = 0.0001
I1212 11:15:56.449314 15749 solver.cpp:218] Iteration 43900 (0.494193 iter/s, 202.35s/100 iters), loss = 2.42098
I1212 11:15:56.449396 15749 solver.cpp:237]     Train net output #0: label = 1092
I1212 11:15:56.449420 15749 solver.cpp:237]     Train net output #1: label_phocs = 1092
I1212 11:15:56.449431 15749 solver.cpp:237]     Train net output #2: loss = 1.51797 (* 1 = 1.51797 loss)
I1212 11:15:56.449440 15749 sgd_solver.cpp:116] Iteration 43900, lr = 0.0001
[2017-12-12 11:19:22,859, PHOCNetTrainer] Running test evaluation
[2017-12-12 11:19:22,859, PHOCNetTrainer] Evaluating CNN after 43500 steps:
I1212 11:20:19.187827 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:20:19.188055 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 11:20:20,284, PHOCNetTrainer] mAP: 0.911849
I1212 11:20:20.285825 15749 solver.cpp:330] Iteration 44000, Testing net (#0)
I1212 11:20:20.286018 15749 net.cpp:676] Ignoring source layer drop6
I1212 11:20:20.286026 15749 net.cpp:676] Ignoring source layer drop7
I1212 11:21:00.373764 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:21:00.373909 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:21:00.793937 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 11:21:00.793988 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 11:21:00.793999 15749 solver.cpp:397]     Test net output #2: loss = 17.1753 (* 1 = 17.1753 loss)
I1212 11:21:02.391325 15749 solver.cpp:218] Iteration 44000 (0.326905 iter/s, 305.899s/100 iters), loss = 1.19536
I1212 11:21:02.391405 15749 solver.cpp:237]     Train net output #0: label = 835
I1212 11:21:02.391428 15749 solver.cpp:237]     Train net output #1: label_phocs = 835
I1212 11:21:02.391440 15749 solver.cpp:237]     Train net output #2: loss = 0.0896971 (* 1 = 0.0896971 loss)
I1212 11:21:02.391449 15749 sgd_solver.cpp:116] Iteration 44000, lr = 0.0001
I1212 11:23:30.748958 15749 solver.cpp:218] Iteration 44100 (0.674131 iter/s, 148.339s/100 iters), loss = 2.26264
I1212 11:23:30.749040 15749 solver.cpp:237]     Train net output #0: label = 226
I1212 11:23:30.749070 15749 solver.cpp:237]     Train net output #1: label_phocs = 226
I1212 11:23:30.749083 15749 solver.cpp:237]     Train net output #2: loss = 1.52894 (* 1 = 1.52894 loss)
I1212 11:23:30.749090 15749 sgd_solver.cpp:116] Iteration 44100, lr = 0.0001
I1212 11:26:16.306270 15749 solver.cpp:218] Iteration 44200 (0.604093 iter/s, 165.537s/100 iters), loss = 2.32767
I1212 11:26:16.306358 15749 solver.cpp:237]     Train net output #0: label = 464
I1212 11:26:16.306381 15749 solver.cpp:237]     Train net output #1: label_phocs = 464
I1212 11:26:16.306393 15749 solver.cpp:237]     Train net output #2: loss = 0.949072 (* 1 = 0.949072 loss)
I1212 11:26:16.306402 15749 sgd_solver.cpp:116] Iteration 44200, lr = 0.0001
I1212 11:29:42.800195 15749 solver.cpp:218] Iteration 44300 (0.484276 iter/s, 206.494s/100 iters), loss = 2.43865
I1212 11:29:42.801375 15749 solver.cpp:237]     Train net output #0: label = 748
I1212 11:29:42.801398 15749 solver.cpp:237]     Train net output #1: label_phocs = 748
I1212 11:29:42.801405 15749 solver.cpp:237]     Train net output #2: loss = 0.302091 (* 1 = 0.302091 loss)
I1212 11:29:42.801412 15749 sgd_solver.cpp:116] Iteration 44300, lr = 0.0001
I1212 11:33:03.611618 15749 solver.cpp:218] Iteration 44400 (0.498031 iter/s, 200.791s/100 iters), loss = 1.98338
I1212 11:33:03.611712 15749 solver.cpp:237]     Train net output #0: label = 112
I1212 11:33:03.611737 15749 solver.cpp:237]     Train net output #1: label_phocs = 112
I1212 11:33:03.611753 15749 solver.cpp:237]     Train net output #2: loss = 17.7842 (* 1 = 17.7842 loss)
I1212 11:33:03.611763 15749 sgd_solver.cpp:116] Iteration 44400, lr = 0.0001
[2017-12-12 11:36:20,976, PHOCNetTrainer] Running test evaluation
[2017-12-12 11:36:20,976, PHOCNetTrainer] Evaluating CNN after 44000 steps:
I1212 11:37:24.887861 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:37:24.888002 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 11:37:27,150, PHOCNetTrainer] mAP: 0.921569
I1212 11:37:27.152158 15749 solver.cpp:330] Iteration 44500, Testing net (#0)
I1212 11:37:27.152351 15749 net.cpp:676] Ignoring source layer drop6
I1212 11:37:27.152359 15749 net.cpp:676] Ignoring source layer drop7
I1212 11:38:34.583950 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:38:34.584077 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:38:35.966375 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 11:38:35.966424 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 11:38:35.966440 15749 solver.cpp:397]     Test net output #2: loss = 16.0366 (* 1 = 16.0366 loss)
I1212 11:38:38.133450 15749 solver.cpp:218] Iteration 44500 (0.298934 iter/s, 334.522s/100 iters), loss = 1.60715
I1212 11:38:38.133533 15749 solver.cpp:237]     Train net output #0: label = 445
I1212 11:38:38.133564 15749 solver.cpp:237]     Train net output #1: label_phocs = 445
I1212 11:38:38.133666 15749 solver.cpp:237]     Train net output #2: loss = 0.026207 (* 1 = 0.026207 loss)
I1212 11:38:38.133677 15749 sgd_solver.cpp:116] Iteration 44500, lr = 0.0001
I1212 11:41:58.501673 15749 solver.cpp:218] Iteration 44600 (0.499249 iter/s, 200.301s/100 iters), loss = 2.1152
I1212 11:41:58.501772 15749 solver.cpp:237]     Train net output #0: label = 743
I1212 11:41:58.501796 15749 solver.cpp:237]     Train net output #1: label_phocs = 743
I1212 11:41:58.501809 15749 solver.cpp:237]     Train net output #2: loss = 0.0802147 (* 1 = 0.0802147 loss)
I1212 11:41:58.501819 15749 sgd_solver.cpp:116] Iteration 44600, lr = 0.0001
I1212 11:45:19.578989 15749 solver.cpp:218] Iteration 44700 (0.497321 iter/s, 201.077s/100 iters), loss = 2.04886
I1212 11:45:19.580785 15749 solver.cpp:237]     Train net output #0: label = 651
I1212 11:45:19.580819 15749 solver.cpp:237]     Train net output #1: label_phocs = 651
I1212 11:45:19.580832 15749 solver.cpp:237]     Train net output #2: loss = 4.4804 (* 1 = 4.4804 loss)
I1212 11:45:19.580840 15749 sgd_solver.cpp:116] Iteration 44700, lr = 0.0001
I1212 11:48:40.502470 15749 solver.cpp:218] Iteration 44800 (0.497702 iter/s, 200.924s/100 iters), loss = 1.98768
I1212 11:48:40.503686 15749 solver.cpp:237]     Train net output #0: label = 1074
I1212 11:48:40.503736 15749 solver.cpp:237]     Train net output #1: label_phocs = 1074
I1212 11:48:40.503758 15749 solver.cpp:237]     Train net output #2: loss = 0.306405 (* 1 = 0.306405 loss)
I1212 11:48:40.503769 15749 sgd_solver.cpp:116] Iteration 44800, lr = 0.0001
I1212 11:51:55.861714 15749 solver.cpp:218] Iteration 44900 (0.512009 iter/s, 195.309s/100 iters), loss = 2.15315
I1212 11:51:55.861806 15749 solver.cpp:237]     Train net output #0: label = 472
I1212 11:51:55.861835 15749 solver.cpp:237]     Train net output #1: label_phocs = 472
I1212 11:51:55.861845 15749 solver.cpp:237]     Train net output #2: loss = 0.0636365 (* 1 = 0.0636365 loss)
I1212 11:51:55.861855 15749 sgd_solver.cpp:116] Iteration 44900, lr = 0.0001
[2017-12-12 11:55:18,509, PHOCNetTrainer] Running test evaluation
[2017-12-12 11:55:18,510, PHOCNetTrainer] Evaluating CNN after 44500 steps:
I1212 11:56:23.716176 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:56:23.716197 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 11:56:25,727, PHOCNetTrainer] mAP: 0.913492
I1212 11:56:25.731375 15749 solver.cpp:330] Iteration 45000, Testing net (#0)
I1212 11:56:25.731568 15749 net.cpp:676] Ignoring source layer drop6
I1212 11:56:25.731575 15749 net.cpp:676] Ignoring source layer drop7
I1212 11:57:34.594657 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:57:34.594674 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 11:57:34.973188 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 11:57:34.973237 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 11:57:34.973248 15749 solver.cpp:397]     Test net output #2: loss = 16.7488 (* 1 = 16.7488 loss)
I1212 11:57:36.332330 15749 solver.cpp:218] Iteration 45000 (0.293711 iter/s, 340.471s/100 iters), loss = 1.21733
I1212 11:57:36.332409 15749 solver.cpp:237]     Train net output #0: label = 614
I1212 11:57:36.332434 15749 solver.cpp:237]     Train net output #1: label_phocs = 614
I1212 11:57:36.332446 15749 solver.cpp:237]     Train net output #2: loss = 2.22618 (* 1 = 2.22618 loss)
I1212 11:57:36.332455 15749 sgd_solver.cpp:116] Iteration 45000, lr = 0.0001
I1212 12:01:01.871690 15749 solver.cpp:218] Iteration 45100 (0.486525 iter/s, 205.539s/100 iters), loss = 1.71031
I1212 12:01:01.871771 15749 solver.cpp:237]     Train net output #0: label = 400
I1212 12:01:01.871796 15749 solver.cpp:237]     Train net output #1: label_phocs = 400
I1212 12:01:01.871809 15749 solver.cpp:237]     Train net output #2: loss = 0.0285427 (* 1 = 0.0285427 loss)
I1212 12:01:01.871817 15749 sgd_solver.cpp:116] Iteration 45100, lr = 0.0001
I1212 12:03:26.264546 15749 solver.cpp:218] Iteration 45200 (0.692555 iter/s, 144.393s/100 iters), loss = 2.09702
I1212 12:03:26.264607 15749 solver.cpp:237]     Train net output #0: label = 401
I1212 12:03:26.264627 15749 solver.cpp:237]     Train net output #1: label_phocs = 401
I1212 12:03:26.264636 15749 solver.cpp:237]     Train net output #2: loss = 18.7589 (* 1 = 18.7589 loss)
I1212 12:03:26.264642 15749 sgd_solver.cpp:116] Iteration 45200, lr = 0.0001
I1212 12:05:51.414108 15749 solver.cpp:218] Iteration 45300 (0.688945 iter/s, 145.15s/100 iters), loss = 2.25784
I1212 12:05:51.414196 15749 solver.cpp:237]     Train net output #0: label = 95
I1212 12:05:51.414219 15749 solver.cpp:237]     Train net output #1: label_phocs = 95
I1212 12:05:51.414232 15749 solver.cpp:237]     Train net output #2: loss = 5.16197 (* 1 = 5.16197 loss)
I1212 12:05:51.414240 15749 sgd_solver.cpp:116] Iteration 45300, lr = 0.0001
I1212 12:08:21.249905 15749 solver.cpp:218] Iteration 45400 (0.667509 iter/s, 149.811s/100 iters), loss = 2.38521
I1212 12:08:21.249987 15749 solver.cpp:237]     Train net output #0: label = 299
I1212 12:08:21.250010 15749 solver.cpp:237]     Train net output #1: label_phocs = 299
I1212 12:08:21.250025 15749 solver.cpp:237]     Train net output #2: loss = 1.93034 (* 1 = 1.93034 loss)
I1212 12:08:21.250035 15749 sgd_solver.cpp:116] Iteration 45400, lr = 0.0001
[2017-12-12 12:10:56,609, PHOCNetTrainer] Running test evaluation
[2017-12-12 12:10:56,609, PHOCNetTrainer] Evaluating CNN after 45000 steps:
I1212 12:11:44.910166 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:11:44.910167 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 12:11:47,600, PHOCNetTrainer] mAP: 0.912018
I1212 12:11:47.601758 15749 solver.cpp:330] Iteration 45500, Testing net (#0)
I1212 12:11:47.601963 15749 net.cpp:676] Ignoring source layer drop6
I1212 12:11:47.601972 15749 net.cpp:676] Ignoring source layer drop7
I1212 12:12:43.131829 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:12:43.131969 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:12:43.712196 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 12:12:43.712247 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 12:12:43.712260 15749 solver.cpp:397]     Test net output #2: loss = 17.0218 (* 1 = 17.0218 loss)
I1212 12:12:45.536155 15749 solver.cpp:218] Iteration 45500 (0.378383 iter/s, 264.282s/100 iters), loss = 1.71584
I1212 12:12:45.536811 15749 solver.cpp:237]     Train net output #0: label = 558
I1212 12:12:45.536841 15749 solver.cpp:237]     Train net output #1: label_phocs = 558
I1212 12:12:45.536854 15749 solver.cpp:237]     Train net output #2: loss = 0.353884 (* 1 = 0.353884 loss)
I1212 12:12:45.536864 15749 sgd_solver.cpp:116] Iteration 45500, lr = 0.0001
I1212 12:16:20.460093 15749 solver.cpp:218] Iteration 45600 (0.465282 iter/s, 214.923s/100 iters), loss = 1.92294
I1212 12:16:20.461457 15749 solver.cpp:237]     Train net output #0: label = 606
I1212 12:16:20.461480 15749 solver.cpp:237]     Train net output #1: label_phocs = 606
I1212 12:16:20.461489 15749 solver.cpp:237]     Train net output #2: loss = 4.41244 (* 1 = 4.41244 loss)
I1212 12:16:20.461495 15749 sgd_solver.cpp:116] Iteration 45600, lr = 0.0001
I1212 12:19:51.552124 15749 solver.cpp:218] Iteration 45700 (0.473763 iter/s, 211.076s/100 iters), loss = 2.03366
I1212 12:19:51.552239 15749 solver.cpp:237]     Train net output #0: label = 464
I1212 12:19:51.552266 15749 solver.cpp:237]     Train net output #1: label_phocs = 464
I1212 12:19:51.552280 15749 solver.cpp:237]     Train net output #2: loss = 0.4976 (* 1 = 0.4976 loss)
I1212 12:19:51.552292 15749 sgd_solver.cpp:116] Iteration 45700, lr = 0.0001
I1212 12:22:37.482014 15749 solver.cpp:218] Iteration 45800 (0.602666 iter/s, 165.929s/100 iters), loss = 2.00585
I1212 12:22:37.482085 15749 solver.cpp:237]     Train net output #0: label = 738
I1212 12:22:37.482110 15749 solver.cpp:237]     Train net output #1: label_phocs = 738
I1212 12:22:37.482120 15749 solver.cpp:237]     Train net output #2: loss = 1.57963 (* 1 = 1.57963 loss)
I1212 12:22:37.482130 15749 sgd_solver.cpp:116] Iteration 45800, lr = 0.0001
I1212 12:25:01.676491 15749 solver.cpp:218] Iteration 45900 (0.693508 iter/s, 144.195s/100 iters), loss = 2.07207
I1212 12:25:01.676558 15749 solver.cpp:237]     Train net output #0: label = 732
I1212 12:25:01.676576 15749 solver.cpp:237]     Train net output #1: label_phocs = 732
I1212 12:25:01.676584 15749 solver.cpp:237]     Train net output #2: loss = 0.305617 (* 1 = 0.305617 loss)
I1212 12:25:01.676590 15749 sgd_solver.cpp:116] Iteration 45900, lr = 0.0001
[2017-12-12 12:27:29,915, PHOCNetTrainer] Running test evaluation
[2017-12-12 12:27:29,915, PHOCNetTrainer] Evaluating CNN after 45500 steps:
I1212 12:28:12.316040 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:28:12.316040 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 12:28:14,289, PHOCNetTrainer] mAP: 0.915224
I1212 12:28:14.291486 15749 solver.cpp:330] Iteration 46000, Testing net (#0)
I1212 12:28:14.291687 15749 net.cpp:676] Ignoring source layer drop6
I1212 12:28:14.291702 15749 net.cpp:676] Ignoring source layer drop7
I1212 12:28:50.550739 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:28:50.550743 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:28:51.657704 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 12:28:51.657749 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 12:28:51.657760 15749 solver.cpp:397]     Test net output #2: loss = 16.4959 (* 1 = 16.4959 loss)
I1212 12:28:52.488095 15749 solver.cpp:218] Iteration 46000 (0.433254 iter/s, 230.812s/100 iters), loss = 1.62618
I1212 12:28:52.488162 15749 solver.cpp:237]     Train net output #0: label = 540
I1212 12:28:52.488180 15749 solver.cpp:237]     Train net output #1: label_phocs = 540
I1212 12:28:52.488188 15749 solver.cpp:237]     Train net output #2: loss = 0.381392 (* 1 = 0.381392 loss)
I1212 12:28:52.488195 15749 sgd_solver.cpp:116] Iteration 46000, lr = 0.0001
I1212 12:31:20.765372 15749 solver.cpp:218] Iteration 46100 (0.674412 iter/s, 148.277s/100 iters), loss = 1.99124
I1212 12:31:20.765451 15749 solver.cpp:237]     Train net output #0: label = 233
I1212 12:31:20.765475 15749 solver.cpp:237]     Train net output #1: label_phocs = 233
I1212 12:31:20.765487 15749 solver.cpp:237]     Train net output #2: loss = 1.58451 (* 1 = 1.58451 loss)
I1212 12:31:20.765496 15749 sgd_solver.cpp:116] Iteration 46100, lr = 0.0001
I1212 12:33:55.492537 15749 solver.cpp:218] Iteration 46200 (0.646299 iter/s, 154.727s/100 iters), loss = 2.0263
I1212 12:33:55.492609 15749 solver.cpp:237]     Train net output #0: label = 1001
I1212 12:33:55.492627 15749 solver.cpp:237]     Train net output #1: label_phocs = 1001
I1212 12:33:55.492636 15749 solver.cpp:237]     Train net output #2: loss = 0.900185 (* 1 = 0.900185 loss)
I1212 12:33:55.492642 15749 sgd_solver.cpp:116] Iteration 46200, lr = 0.0001
I1212 12:36:52.106616 15749 solver.cpp:218] Iteration 46300 (0.566282 iter/s, 176.591s/100 iters), loss = 2.28576
I1212 12:36:52.106714 15749 solver.cpp:237]     Train net output #0: label = 669
I1212 12:36:52.106739 15749 solver.cpp:237]     Train net output #1: label_phocs = 669
I1212 12:36:52.106750 15749 solver.cpp:237]     Train net output #2: loss = 4.20966 (* 1 = 4.20966 loss)
I1212 12:36:52.106760 15749 sgd_solver.cpp:116] Iteration 46300, lr = 0.0001
I1212 12:40:21.033406 15749 solver.cpp:218] Iteration 46400 (0.478636 iter/s, 208.927s/100 iters), loss = 1.86775
I1212 12:40:21.033490 15749 solver.cpp:237]     Train net output #0: label = 393
I1212 12:40:21.033515 15749 solver.cpp:237]     Train net output #1: label_phocs = 393
I1212 12:40:21.033527 15749 solver.cpp:237]     Train net output #2: loss = 0.264857 (* 1 = 0.264857 loss)
I1212 12:40:21.033535 15749 sgd_solver.cpp:116] Iteration 46400, lr = 0.0001
[2017-12-12 12:43:28,739, PHOCNetTrainer] Running test evaluation
[2017-12-12 12:43:28,739, PHOCNetTrainer] Evaluating CNN after 46000 steps:
I1212 12:44:42.631827 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:44:42.631969 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 12:44:45,099, PHOCNetTrainer] mAP: 0.911925
I1212 12:44:45.100646 15749 solver.cpp:330] Iteration 46500, Testing net (#0)
I1212 12:44:45.100829 15749 net.cpp:676] Ignoring source layer drop6
I1212 12:44:45.100836 15749 net.cpp:676] Ignoring source layer drop7
I1212 12:45:56.757561 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:45:56.757572 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 12:45:57.526116 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 12:45:57.526170 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 12:45:57.526186 15749 solver.cpp:397]     Test net output #2: loss = 17.2529 (* 1 = 17.2529 loss)
I1212 12:46:00.446579 15749 solver.cpp:218] Iteration 46500 (0.294626 iter/s, 339.413s/100 iters), loss = 2.3369
I1212 12:46:00.446668 15749 solver.cpp:237]     Train net output #0: label = 915
I1212 12:46:00.446692 15749 solver.cpp:237]     Train net output #1: label_phocs = 915
I1212 12:46:00.446702 15749 solver.cpp:237]     Train net output #2: loss = 4.33717 (* 1 = 4.33717 loss)
I1212 12:46:00.446708 15749 sgd_solver.cpp:116] Iteration 46500, lr = 0.0001
I1212 12:49:25.790076 15749 solver.cpp:218] Iteration 46600 (0.487003 iter/s, 205.337s/100 iters), loss = 2.02131
I1212 12:49:25.790208 15749 solver.cpp:237]     Train net output #0: label = 897
I1212 12:49:25.790241 15749 solver.cpp:237]     Train net output #1: label_phocs = 897
I1212 12:49:25.790259 15749 solver.cpp:237]     Train net output #2: loss = 0.132483 (* 1 = 0.132483 loss)
I1212 12:49:25.790273 15749 sgd_solver.cpp:116] Iteration 46600, lr = 0.0001
I1212 12:52:57.518676 15749 solver.cpp:218] Iteration 46700 (0.472303 iter/s, 211.729s/100 iters), loss = 1.91928
I1212 12:52:57.518769 15749 solver.cpp:237]     Train net output #0: label = 1007
I1212 12:52:57.518795 15749 solver.cpp:237]     Train net output #1: label_phocs = 1007
I1212 12:52:57.518807 15749 solver.cpp:237]     Train net output #2: loss = 0.591735 (* 1 = 0.591735 loss)
I1212 12:52:57.518816 15749 sgd_solver.cpp:116] Iteration 46700, lr = 0.0001
I1212 12:56:31.131805 15749 solver.cpp:218] Iteration 46800 (0.468146 iter/s, 213.608s/100 iters), loss = 1.87163
I1212 12:56:31.131914 15749 solver.cpp:237]     Train net output #0: label = 587
I1212 12:56:31.131940 15749 solver.cpp:237]     Train net output #1: label_phocs = 587
I1212 12:56:31.131953 15749 solver.cpp:237]     Train net output #2: loss = 7.58975 (* 1 = 7.58975 loss)
I1212 12:56:31.131963 15749 sgd_solver.cpp:116] Iteration 46800, lr = 0.0001
I1212 12:59:19.895969 15749 solver.cpp:218] Iteration 46900 (0.592543 iter/s, 168.764s/100 iters), loss = 2.0404
I1212 12:59:19.896060 15749 solver.cpp:237]     Train net output #0: label = 65
I1212 12:59:19.896080 15749 solver.cpp:237]     Train net output #1: label_phocs = 65
I1212 12:59:19.896088 15749 solver.cpp:237]     Train net output #2: loss = 0.785635 (* 1 = 0.785635 loss)
I1212 12:59:19.896096 15749 sgd_solver.cpp:116] Iteration 46900, lr = 0.0001
[2017-12-12 13:02:14,437, PHOCNetTrainer] Running test evaluation
[2017-12-12 13:02:14,438, PHOCNetTrainer] Evaluating CNN after 46500 steps:
I1212 13:03:31.171880 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:03:31.172029 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 13:03:33,613, PHOCNetTrainer] mAP: 0.917219
I1212 13:03:33.615720 15749 solver.cpp:330] Iteration 47000, Testing net (#0)
I1212 13:03:33.616005 15749 net.cpp:676] Ignoring source layer drop6
I1212 13:03:33.616016 15749 net.cpp:676] Ignoring source layer drop7
I1212 13:04:48.004025 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:04:48.004215 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:04:49.767874 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 13:04:49.767942 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 13:04:49.767959 15749 solver.cpp:397]     Test net output #2: loss = 16.2733 (* 1 = 16.2733 loss)
I1212 13:04:51.614217 15749 solver.cpp:218] Iteration 47000 (0.301463 iter/s, 331.715s/100 iters), loss = 3.4104
I1212 13:04:51.614326 15749 solver.cpp:237]     Train net output #0: label = 745
I1212 13:04:51.614351 15749 solver.cpp:237]     Train net output #1: label_phocs = 745
I1212 13:04:51.614363 15749 solver.cpp:237]     Train net output #2: loss = 0.178824 (* 1 = 0.178824 loss)
I1212 13:04:51.614373 15749 sgd_solver.cpp:116] Iteration 47000, lr = 0.0001
I1212 13:08:24.045434 15749 solver.cpp:218] Iteration 47100 (0.470752 iter/s, 212.426s/100 iters), loss = 2.03622
I1212 13:08:24.045553 15749 solver.cpp:237]     Train net output #0: label = 566
I1212 13:08:24.045583 15749 solver.cpp:237]     Train net output #1: label_phocs = 566
I1212 13:08:24.045598 15749 solver.cpp:237]     Train net output #2: loss = 2.7668 (* 1 = 2.7668 loss)
I1212 13:08:24.045608 15749 sgd_solver.cpp:116] Iteration 47100, lr = 0.0001
I1212 13:11:52.898337 15749 solver.cpp:218] Iteration 47200 (0.478806 iter/s, 208.853s/100 iters), loss = 2.08848
I1212 13:11:52.898452 15749 solver.cpp:237]     Train net output #0: label = 1012
I1212 13:11:52.898480 15749 solver.cpp:237]     Train net output #1: label_phocs = 1012
I1212 13:11:52.898495 15749 solver.cpp:237]     Train net output #2: loss = 0.195376 (* 1 = 0.195376 loss)
I1212 13:11:52.898505 15749 sgd_solver.cpp:116] Iteration 47200, lr = 0.0001
I1212 13:15:27.171643 15749 solver.cpp:218] Iteration 47300 (0.466709 iter/s, 214.266s/100 iters), loss = 1.86353
I1212 13:15:27.171756 15749 solver.cpp:237]     Train net output #0: label = 1031
I1212 13:15:27.171787 15749 solver.cpp:237]     Train net output #1: label_phocs = 1031
I1212 13:15:27.171802 15749 solver.cpp:237]     Train net output #2: loss = 0.433447 (* 1 = 0.433447 loss)
I1212 13:15:27.171814 15749 sgd_solver.cpp:116] Iteration 47300, lr = 0.0001
I1212 13:18:55.249017 15749 solver.cpp:218] Iteration 47400 (0.480616 iter/s, 208.066s/100 iters), loss = 2.42556
I1212 13:18:55.249557 15749 solver.cpp:237]     Train net output #0: label = 850
I1212 13:18:55.249590 15749 solver.cpp:237]     Train net output #1: label_phocs = 850
I1212 13:18:55.249605 15749 solver.cpp:237]     Train net output #2: loss = 0.626031 (* 1 = 0.626031 loss)
I1212 13:18:55.249615 15749 sgd_solver.cpp:116] Iteration 47400, lr = 0.0001
[2017-12-12 13:22:28,604, PHOCNetTrainer] Running test evaluation
[2017-12-12 13:22:28,604, PHOCNetTrainer] Evaluating CNN after 47000 steps:
I1212 13:23:53.079926 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:23:53.080090 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 13:23:57,087, PHOCNetTrainer] mAP: 0.901451
I1212 13:23:57.088958 15749 solver.cpp:330] Iteration 47500, Testing net (#0)
I1212 13:23:57.089251 15749 net.cpp:676] Ignoring source layer drop6
I1212 13:23:57.089262 15749 net.cpp:676] Ignoring source layer drop7
I1212 13:25:13.287853 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:25:13.288015 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:25:14.186930 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 13:25:14.186985 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 13:25:14.186998 15749 solver.cpp:397]     Test net output #2: loss = 17.6325 (* 1 = 17.6325 loss)
I1212 13:25:16.587802 15749 solver.cpp:218] Iteration 47500 (0.262295 iter/s, 381.25s/100 iters), loss = 2.3803
I1212 13:25:16.587894 15749 solver.cpp:237]     Train net output #0: label = 135
I1212 13:25:16.587919 15749 solver.cpp:237]     Train net output #1: label_phocs = 135
I1212 13:25:16.587932 15749 solver.cpp:237]     Train net output #2: loss = 0.0473475 (* 1 = 0.0473475 loss)
I1212 13:25:16.587941 15749 sgd_solver.cpp:116] Iteration 47500, lr = 0.0001
I1212 13:28:27.759454 15749 solver.cpp:218] Iteration 47600 (0.52321 iter/s, 191.128s/100 iters), loss = 1.85485
I1212 13:28:27.759558 15749 solver.cpp:237]     Train net output #0: label = 313
I1212 13:28:27.759588 15749 solver.cpp:237]     Train net output #1: label_phocs = 313
I1212 13:28:27.759603 15749 solver.cpp:237]     Train net output #2: loss = 1.44069 (* 1 = 1.44069 loss)
I1212 13:28:27.759613 15749 sgd_solver.cpp:116] Iteration 47600, lr = 0.0001
I1212 13:31:21.707250 15749 solver.cpp:218] Iteration 47700 (0.575128 iter/s, 173.874s/100 iters), loss = 1.67649
I1212 13:31:21.707365 15749 solver.cpp:237]     Train net output #0: label = 37
I1212 13:31:21.707396 15749 solver.cpp:237]     Train net output #1: label_phocs = 37
I1212 13:31:21.707412 15749 solver.cpp:237]     Train net output #2: loss = 0.031553 (* 1 = 0.031553 loss)
I1212 13:31:21.707422 15749 sgd_solver.cpp:116] Iteration 47700, lr = 0.0001
I1212 13:34:21.836158 15749 solver.cpp:218] Iteration 47800 (0.55516 iter/s, 180.128s/100 iters), loss = 1.79629
I1212 13:34:21.836267 15749 solver.cpp:237]     Train net output #0: label = 1072
I1212 13:34:21.836295 15749 solver.cpp:237]     Train net output #1: label_phocs = 1072
I1212 13:34:21.836314 15749 solver.cpp:237]     Train net output #2: loss = 2.06391 (* 1 = 2.06391 loss)
I1212 13:34:21.836325 15749 sgd_solver.cpp:116] Iteration 47800, lr = 0.0001
I1212 13:37:16.727540 15749 solver.cpp:218] Iteration 47900 (0.571783 iter/s, 174.891s/100 iters), loss = 1.96616
I1212 13:37:16.727656 15749 solver.cpp:237]     Train net output #0: label = 39
I1212 13:37:16.727685 15749 solver.cpp:237]     Train net output #1: label_phocs = 39
I1212 13:37:16.727699 15749 solver.cpp:237]     Train net output #2: loss = 0.773499 (* 1 = 0.773499 loss)
I1212 13:37:16.727710 15749 sgd_solver.cpp:116] Iteration 47900, lr = 0.0001
[2017-12-12 13:40:14,532, PHOCNetTrainer] Running test evaluation
[2017-12-12 13:40:14,532, PHOCNetTrainer] Evaluating CNN after 47500 steps:
I1212 13:41:16.173177 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:41:16.173859 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 13:41:19,229, PHOCNetTrainer] mAP: 0.913420
I1212 13:41:19.231490 15749 solver.cpp:330] Iteration 48000, Testing net (#0)
I1212 13:41:19.231793 15749 net.cpp:676] Ignoring source layer drop6
I1212 13:41:19.231807 15749 net.cpp:676] Ignoring source layer drop7
I1212 13:42:08.067333 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:42:08.067492 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 13:42:09.235983 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 13:42:09.236043 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 13:42:09.236059 15749 solver.cpp:397]     Test net output #2: loss = 16.7526 (* 1 = 16.7526 loss)
I1212 13:42:10.079279 15749 solver.cpp:218] Iteration 48000 (0.340888 iter/s, 293.352s/100 iters), loss = 1.3987
I1212 13:42:10.079381 15749 solver.cpp:237]     Train net output #0: label = 160
I1212 13:42:10.079409 15749 solver.cpp:237]     Train net output #1: label_phocs = 160
I1212 13:42:10.079423 15749 solver.cpp:237]     Train net output #2: loss = 0.247985 (* 1 = 0.247985 loss)
I1212 13:42:10.079433 15749 sgd_solver.cpp:116] Iteration 48000, lr = 0.0001
I1212 13:45:07.278496 15749 solver.cpp:218] Iteration 48100 (0.564336 iter/s, 177.199s/100 iters), loss = 1.72387
I1212 13:45:07.278599 15749 solver.cpp:237]     Train net output #0: label = 722
I1212 13:45:07.278625 15749 solver.cpp:237]     Train net output #1: label_phocs = 722
I1212 13:45:07.278636 15749 solver.cpp:237]     Train net output #2: loss = 1.41197 (* 1 = 1.41197 loss)
I1212 13:45:07.278646 15749 sgd_solver.cpp:116] Iteration 48100, lr = 0.0001
I1212 13:48:17.051504 15749 solver.cpp:218] Iteration 48200 (0.527055 iter/s, 189.733s/100 iters), loss = 1.7981
I1212 13:48:17.051595 15749 solver.cpp:237]     Train net output #0: label = 1045
I1212 13:48:17.051620 15749 solver.cpp:237]     Train net output #1: label_phocs = 1045
I1212 13:48:17.051632 15749 solver.cpp:237]     Train net output #2: loss = 0.366356 (* 1 = 0.366356 loss)
I1212 13:48:17.051642 15749 sgd_solver.cpp:116] Iteration 48200, lr = 0.0001
I1212 13:52:07.011801 15749 solver.cpp:218] Iteration 48300 (0.434868 iter/s, 229.955s/100 iters), loss = 1.8111
I1212 13:52:07.011900 15749 solver.cpp:237]     Train net output #0: label = 69
I1212 13:52:07.011927 15749 solver.cpp:237]     Train net output #1: label_phocs = 69
I1212 13:52:07.011940 15749 solver.cpp:237]     Train net output #2: loss = 1.29502 (* 1 = 1.29502 loss)
I1212 13:52:07.011950 15749 sgd_solver.cpp:116] Iteration 48300, lr = 0.0001
I1212 13:55:37.616883 15749 solver.cpp:218] Iteration 48400 (0.474822 iter/s, 210.605s/100 iters), loss = 2.11139
I1212 13:55:37.617014 15749 solver.cpp:237]     Train net output #0: label = 208
I1212 13:55:37.617045 15749 solver.cpp:237]     Train net output #1: label_phocs = 208
I1212 13:55:37.617060 15749 solver.cpp:237]     Train net output #2: loss = 0.288562 (* 1 = 0.288562 loss)
I1212 13:55:37.617072 15749 sgd_solver.cpp:116] Iteration 48400, lr = 0.0001
[2017-12-12 13:59:03,883, PHOCNetTrainer] Running test evaluation
[2017-12-12 13:59:03,883, PHOCNetTrainer] Evaluating CNN after 48000 steps:
I1212 14:00:30.365752 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:00:30.365980 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 14:00:34,176, PHOCNetTrainer] mAP: 0.910483
I1212 14:00:34.177877 15749 solver.cpp:330] Iteration 48500, Testing net (#0)
I1212 14:00:34.178143 15749 net.cpp:676] Ignoring source layer drop6
I1212 14:00:34.178166 15749 net.cpp:676] Ignoring source layer drop7
I1212 14:01:49.131930 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:01:49.132071 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:01:50.841152 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 14:01:50.841203 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 14:01:50.841214 15749 solver.cpp:397]     Test net output #2: loss = 16.9998 (* 1 = 16.9998 loss)
I1212 14:01:52.590831 15749 solver.cpp:218] Iteration 48500 (0.266695 iter/s, 374.96s/100 iters), loss = 1.16902
I1212 14:01:52.590940 15749 solver.cpp:237]     Train net output #0: label = 428
I1212 14:01:52.590970 15749 solver.cpp:237]     Train net output #1: label_phocs = 428
I1212 14:01:52.590984 15749 solver.cpp:237]     Train net output #2: loss = 0.270897 (* 1 = 0.270897 loss)
I1212 14:01:52.590996 15749 sgd_solver.cpp:116] Iteration 48500, lr = 0.0001
I1212 14:05:22.868211 15749 solver.cpp:218] Iteration 48600 (0.475562 iter/s, 210.277s/100 iters), loss = 1.66285
I1212 14:05:22.868341 15749 solver.cpp:237]     Train net output #0: label = 583
I1212 14:05:22.868373 15749 solver.cpp:237]     Train net output #1: label_phocs = 583
I1212 14:05:22.868391 15749 solver.cpp:237]     Train net output #2: loss = 1.21395 (* 1 = 1.21395 loss)
I1212 14:05:22.868403 15749 sgd_solver.cpp:116] Iteration 48600, lr = 0.0001
I1212 14:08:48.270110 15749 solver.cpp:218] Iteration 48700 (0.486894 iter/s, 205.383s/100 iters), loss = 2.08546
I1212 14:08:48.270226 15749 solver.cpp:237]     Train net output #0: label = 1106
I1212 14:08:48.270256 15749 solver.cpp:237]     Train net output #1: label_phocs = 1106
I1212 14:08:48.270270 15749 solver.cpp:237]     Train net output #2: loss = 2.11722 (* 1 = 2.11722 loss)
I1212 14:08:48.270282 15749 sgd_solver.cpp:116] Iteration 48700, lr = 0.0001
I1212 14:12:18.808809 15749 solver.cpp:218] Iteration 48800 (0.474972 iter/s, 210.539s/100 iters), loss = 2.04953
I1212 14:12:18.808924 15749 solver.cpp:237]     Train net output #0: label = 13
I1212 14:12:18.808950 15749 solver.cpp:237]     Train net output #1: label_phocs = 13
I1212 14:12:18.808962 15749 solver.cpp:237]     Train net output #2: loss = 124.639 (* 1 = 124.639 loss)
I1212 14:12:18.808972 15749 sgd_solver.cpp:116] Iteration 48800, lr = 0.0001
I1212 14:15:56.858242 15749 solver.cpp:218] Iteration 48900 (0.458628 iter/s, 218.042s/100 iters), loss = 1.96208
I1212 14:15:56.858359 15749 solver.cpp:237]     Train net output #0: label = 902
I1212 14:15:56.858387 15749 solver.cpp:237]     Train net output #1: label_phocs = 902
I1212 14:15:56.858403 15749 solver.cpp:237]     Train net output #2: loss = 0.0571926 (* 1 = 0.0571926 loss)
I1212 14:15:56.858413 15749 sgd_solver.cpp:116] Iteration 48900, lr = 0.0001
[2017-12-12 14:19:27,250, PHOCNetTrainer] Running test evaluation
[2017-12-12 14:19:27,250, PHOCNetTrainer] Evaluating CNN after 48500 steps:
I1212 14:20:44.415879 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:20:44.416024 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 14:20:49,283, PHOCNetTrainer] mAP: 0.912499
I1212 14:20:49.285274 15749 solver.cpp:330] Iteration 49000, Testing net (#0)
I1212 14:20:49.285519 15749 net.cpp:676] Ignoring source layer drop6
I1212 14:20:49.285529 15749 net.cpp:676] Ignoring source layer drop7
I1212 14:22:02.480018 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:22:02.480201 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:22:03.628717 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 14:22:03.629134 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 14:22:03.629158 15749 solver.cpp:397]     Test net output #2: loss = 17.0286 (* 1 = 17.0286 loss)
I1212 14:22:05.800631 15749 solver.cpp:218] Iteration 49000 (0.271073 iter/s, 368.904s/100 iters), loss = 1.1041
I1212 14:22:05.801362 15749 solver.cpp:237]     Train net output #0: label = 182
I1212 14:22:05.801429 15749 solver.cpp:237]     Train net output #1: label_phocs = 182
I1212 14:22:05.801445 15749 solver.cpp:237]     Train net output #2: loss = 0.382769 (* 1 = 0.382769 loss)
I1212 14:22:05.801455 15749 sgd_solver.cpp:116] Iteration 49000, lr = 0.0001
I1212 14:25:47.350205 15749 solver.cpp:218] Iteration 49100 (0.451367 iter/s, 221.549s/100 iters), loss = 1.83032
I1212 14:25:47.350275 15749 solver.cpp:237]     Train net output #0: label = 499
I1212 14:25:47.350294 15749 solver.cpp:237]     Train net output #1: label_phocs = 499
I1212 14:25:47.350302 15749 solver.cpp:237]     Train net output #2: loss = 0.941495 (* 1 = 0.941495 loss)
I1212 14:25:47.350309 15749 sgd_solver.cpp:116] Iteration 49100, lr = 0.0001
I1212 14:29:03.111794 15749 solver.cpp:218] Iteration 49200 (0.51098 iter/s, 195.702s/100 iters), loss = 1.80294
I1212 14:29:03.111881 15749 solver.cpp:237]     Train net output #0: label = 106
I1212 14:29:03.111907 15749 solver.cpp:237]     Train net output #1: label_phocs = 106
I1212 14:29:03.111918 15749 solver.cpp:237]     Train net output #2: loss = 4.32808 (* 1 = 4.32808 loss)
I1212 14:29:03.111927 15749 sgd_solver.cpp:116] Iteration 49200, lr = 0.0001
I1212 14:32:41.491703 15749 solver.cpp:218] Iteration 49300 (0.457972 iter/s, 218.354s/100 iters), loss = 1.70347
I1212 14:32:41.491806 15749 solver.cpp:237]     Train net output #0: label = 298
I1212 14:32:41.491838 15749 solver.cpp:237]     Train net output #1: label_phocs = 298
I1212 14:32:41.491852 15749 solver.cpp:237]     Train net output #2: loss = 2.35294 (* 1 = 2.35294 loss)
I1212 14:32:41.491861 15749 sgd_solver.cpp:116] Iteration 49300, lr = 0.0001
I1212 14:35:24.846297 15749 solver.cpp:218] Iteration 49400 (0.612165 iter/s, 163.355s/100 iters), loss = 1.93288
I1212 14:35:24.846426 15749 solver.cpp:237]     Train net output #0: label = 433
I1212 14:35:24.846460 15749 solver.cpp:237]     Train net output #1: label_phocs = 433
I1212 14:35:24.846478 15749 solver.cpp:237]     Train net output #2: loss = 1.48825 (* 1 = 1.48825 loss)
I1212 14:35:24.846491 15749 sgd_solver.cpp:116] Iteration 49400, lr = 0.0001
[2017-12-12 14:39:33,012, PHOCNetTrainer] Running test evaluation
[2017-12-12 14:39:33,012, PHOCNetTrainer] Evaluating CNN after 49000 steps:
I1212 14:40:44.587852 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:40:44.588016 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 14:40:46,949, PHOCNetTrainer] mAP: 0.918692
I1212 14:40:46.951341 15749 solver.cpp:330] Iteration 49500, Testing net (#0)
I1212 14:40:46.951638 15749 net.cpp:676] Ignoring source layer drop6
I1212 14:40:46.951659 15749 net.cpp:676] Ignoring source layer drop7
I1212 14:41:44.851873 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:41:44.852016 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:41:46.319034 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 14:41:46.319110 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 14:41:46.319129 15749 solver.cpp:397]     Test net output #2: loss = 16.6188 (* 1 = 16.6188 loss)
I1212 14:41:47.784863 15749 solver.cpp:218] Iteration 49500 (0.261158 iter/s, 382.91s/100 iters), loss = 0.870671
I1212 14:41:47.784963 15749 solver.cpp:237]     Train net output #0: label = 865
I1212 14:41:47.784988 15749 solver.cpp:237]     Train net output #1: label_phocs = 865
I1212 14:41:47.785001 15749 solver.cpp:237]     Train net output #2: loss = 1.89272 (* 1 = 1.89272 loss)
I1212 14:41:47.785012 15749 sgd_solver.cpp:116] Iteration 49500, lr = 0.0001
I1212 14:45:11.449098 15749 solver.cpp:218] Iteration 49600 (0.491082 iter/s, 203.632s/100 iters), loss = 1.82292
I1212 14:45:11.449205 15749 solver.cpp:237]     Train net output #0: label = 796
I1212 14:45:11.449231 15749 solver.cpp:237]     Train net output #1: label_phocs = 796
I1212 14:45:11.449244 15749 solver.cpp:237]     Train net output #2: loss = 2.45401 (* 1 = 2.45401 loss)
I1212 14:45:11.449254 15749 sgd_solver.cpp:116] Iteration 49600, lr = 0.0001
I1212 14:48:09.832623 15749 solver.cpp:218] Iteration 49700 (0.560696 iter/s, 178.35s/100 iters), loss = 1.71994
I1212 14:48:09.832723 15749 solver.cpp:237]     Train net output #0: label = 131
I1212 14:48:09.832749 15749 solver.cpp:237]     Train net output #1: label_phocs = 131
I1212 14:48:09.832762 15749 solver.cpp:237]     Train net output #2: loss = 0.617517 (* 1 = 0.617517 loss)
I1212 14:48:09.832769 15749 sgd_solver.cpp:116] Iteration 49700, lr = 0.0001
I1212 14:51:02.418284 15749 solver.cpp:218] Iteration 49800 (0.579493 iter/s, 172.565s/100 iters), loss = 1.79308
I1212 14:51:02.418401 15749 solver.cpp:237]     Train net output #0: label = 428
I1212 14:51:02.418428 15749 solver.cpp:237]     Train net output #1: label_phocs = 428
I1212 14:51:02.418443 15749 solver.cpp:237]     Train net output #2: loss = 0.259165 (* 1 = 0.259165 loss)
I1212 14:51:02.418453 15749 sgd_solver.cpp:116] Iteration 49800, lr = 0.0001
I1212 14:54:04.175511 15749 solver.cpp:218] Iteration 49900 (0.550274 iter/s, 181.728s/100 iters), loss = 1.76009
I1212 14:54:04.175613 15749 solver.cpp:237]     Train net output #0: label = 972
I1212 14:54:04.175642 15749 solver.cpp:237]     Train net output #1: label_phocs = 972
I1212 14:54:04.175657 15749 solver.cpp:237]     Train net output #2: loss = 0.0792222 (* 1 = 0.0792222 loss)
I1212 14:54:04.175668 15749 sgd_solver.cpp:116] Iteration 49900, lr = 0.0001
[2017-12-12 14:56:53,420, PHOCNetTrainer] Running test evaluation
[2017-12-12 14:56:53,420, PHOCNetTrainer] Evaluating CNN after 49500 steps:
I1212 14:57:46.758775 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:57:46.758949 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 14:57:50,686, PHOCNetTrainer] mAP: 0.919912
I1212 14:57:50.687978 15749 solver.cpp:330] Iteration 50000, Testing net (#0)
I1212 14:57:50.688266 15749 net.cpp:676] Ignoring source layer drop6
I1212 14:57:50.688292 15749 net.cpp:676] Ignoring source layer drop7
I1212 14:58:51.195852 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:58:51.196012 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:58:51.540560 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 14:58:51.540622 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 14:58:51.540639 15749 solver.cpp:397]     Test net output #2: loss = 15.9657 (* 1 = 15.9657 loss)
I1212 14:58:52.762424 15749 solver.cpp:218] Iteration 50000 (0.34653 iter/s, 288.575s/100 iters), loss = 0.983896
I1212 14:58:52.762528 15749 solver.cpp:237]     Train net output #0: label = 1049
I1212 14:58:52.762555 15749 solver.cpp:237]     Train net output #1: label_phocs = 1049
I1212 14:58:52.762567 15749 solver.cpp:237]     Train net output #2: loss = 5.14588 (* 1 = 5.14588 loss)
I1212 14:58:52.762576 15749 sgd_solver.cpp:116] Iteration 50000, lr = 0.0001
I1212 14:59:48.156312 15774 data_layer.cpp:72] Restarting data prefetching from start.
I1212 14:59:48.156498 15775 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:01:38.816242 15749 solver.cpp:218] Iteration 50100 (0.602214 iter/s, 166.054s/100 iters), loss = 1.71982
I1212 15:01:38.816447 15749 solver.cpp:237]     Train net output #0: label = 1016
I1212 15:01:38.816486 15749 solver.cpp:237]     Train net output #1: label_phocs = 1016
I1212 15:01:38.816501 15749 solver.cpp:237]     Train net output #2: loss = 2.31394 (* 1 = 2.31394 loss)
I1212 15:01:38.816514 15749 sgd_solver.cpp:116] Iteration 50100, lr = 0.0001
I1212 15:04:24.859792 15749 solver.cpp:218] Iteration 50200 (0.602339 iter/s, 166.019s/100 iters), loss = 1.64649
I1212 15:04:24.859889 15749 solver.cpp:237]     Train net output #0: label = 698
I1212 15:04:24.859915 15749 solver.cpp:237]     Train net output #1: label_phocs = 698
I1212 15:04:24.859928 15749 solver.cpp:237]     Train net output #2: loss = 0.042828 (* 1 = 0.042828 loss)
I1212 15:04:24.859939 15749 sgd_solver.cpp:116] Iteration 50200, lr = 0.0001
I1212 15:07:23.251368 15749 solver.cpp:218] Iteration 50300 (0.560565 iter/s, 178.392s/100 iters), loss = 1.85201
I1212 15:07:23.251469 15749 solver.cpp:237]     Train net output #0: label = 916
I1212 15:07:23.251497 15749 solver.cpp:237]     Train net output #1: label_phocs = 916
I1212 15:07:23.251512 15749 solver.cpp:237]     Train net output #2: loss = 1.11691 (* 1 = 1.11691 loss)
I1212 15:07:23.251523 15749 sgd_solver.cpp:116] Iteration 50300, lr = 0.0001
I1212 15:10:16.202306 15749 solver.cpp:218] Iteration 50400 (0.578199 iter/s, 172.951s/100 iters), loss = 1.57965
I1212 15:10:16.202410 15749 solver.cpp:237]     Train net output #0: label = 439
I1212 15:10:16.202440 15749 solver.cpp:237]     Train net output #1: label_phocs = 439
I1212 15:10:16.202455 15749 solver.cpp:237]     Train net output #2: loss = 0.836687 (* 1 = 0.836687 loss)
I1212 15:10:16.202467 15749 sgd_solver.cpp:116] Iteration 50400, lr = 0.0001
[2017-12-12 15:13:13,601, PHOCNetTrainer] Running test evaluation
[2017-12-12 15:13:13,601, PHOCNetTrainer] Evaluating CNN after 50000 steps:
I1212 15:14:19.443883 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:14:19.444031 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 15:14:22,953, PHOCNetTrainer] mAP: 0.898776
I1212 15:14:22.955453 15749 solver.cpp:330] Iteration 50500, Testing net (#0)
I1212 15:14:22.955698 15749 net.cpp:676] Ignoring source layer drop6
I1212 15:14:22.955708 15749 net.cpp:676] Ignoring source layer drop7
I1212 15:15:17.492027 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:15:17.538848 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:15:18.521674 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 15:15:18.521725 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 15:15:18.521734 15749 solver.cpp:397]     Test net output #2: loss = 19.1964 (* 1 = 19.1964 loss)
I1212 15:15:20.374127 15749 solver.cpp:218] Iteration 50500 (0.328777 iter/s, 304.157s/100 iters), loss = 2.44181
I1212 15:15:20.374227 15749 solver.cpp:237]     Train net output #0: label = 393
I1212 15:15:20.374251 15749 solver.cpp:237]     Train net output #1: label_phocs = 393
I1212 15:15:20.374265 15749 solver.cpp:237]     Train net output #2: loss = 0.0480938 (* 1 = 0.0480938 loss)
I1212 15:15:20.374275 15749 sgd_solver.cpp:116] Iteration 50500, lr = 0.0001
I1212 15:18:14.437268 15749 solver.cpp:218] Iteration 50600 (0.574549 iter/s, 174.049s/100 iters), loss = 1.73986
I1212 15:18:14.437415 15749 solver.cpp:237]     Train net output #0: label = 686
I1212 15:18:14.437458 15749 solver.cpp:237]     Train net output #1: label_phocs = 686
I1212 15:18:14.437479 15749 solver.cpp:237]     Train net output #2: loss = 8.61333 (* 1 = 8.61333 loss)
I1212 15:18:14.437494 15749 sgd_solver.cpp:116] Iteration 50600, lr = 0.0001
I1212 15:21:18.370432 15749 solver.cpp:218] Iteration 50700 (0.543759 iter/s, 183.905s/100 iters), loss = 1.69686
I1212 15:21:18.370528 15749 solver.cpp:237]     Train net output #0: label = 321
I1212 15:21:18.370553 15749 solver.cpp:237]     Train net output #1: label_phocs = 321
I1212 15:21:18.370564 15749 solver.cpp:237]     Train net output #2: loss = 0.924285 (* 1 = 0.924285 loss)
I1212 15:21:18.370574 15749 sgd_solver.cpp:116] Iteration 50700, lr = 0.0001
I1212 15:24:16.129199 15749 solver.cpp:218] Iteration 50800 (0.56256 iter/s, 177.759s/100 iters), loss = 1.73442
I1212 15:24:16.129298 15749 solver.cpp:237]     Train net output #0: label = 706
I1212 15:24:16.129324 15749 solver.cpp:237]     Train net output #1: label_phocs = 706
I1212 15:24:16.129336 15749 solver.cpp:237]     Train net output #2: loss = 0.147569 (* 1 = 0.147569 loss)
I1212 15:24:16.129354 15749 sgd_solver.cpp:116] Iteration 50800, lr = 0.0001
I1212 15:27:20.328254 15749 solver.cpp:218] Iteration 50900 (0.542891 iter/s, 184.199s/100 iters), loss = 1.94905
I1212 15:27:20.328377 15749 solver.cpp:237]     Train net output #0: label = 55
I1212 15:27:20.328403 15749 solver.cpp:237]     Train net output #1: label_phocs = 55
I1212 15:27:20.328418 15749 solver.cpp:237]     Train net output #2: loss = 5.99234 (* 1 = 5.99234 loss)
I1212 15:27:20.328428 15749 sgd_solver.cpp:116] Iteration 50900, lr = 0.0001
[2017-12-12 15:30:17,657, PHOCNetTrainer] Running test evaluation
[2017-12-12 15:30:17,657, PHOCNetTrainer] Evaluating CNN after 50500 steps:
I1212 15:31:30.199977 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:31:30.200125 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 15:31:32,887, PHOCNetTrainer] mAP: 0.912989
I1212 15:31:32.929548 15749 solver.cpp:330] Iteration 51000, Testing net (#0)
I1212 15:31:32.929821 15749 net.cpp:676] Ignoring source layer drop6
I1212 15:31:32.929846 15749 net.cpp:676] Ignoring source layer drop7
I1212 15:32:34.207887 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:32:34.208048 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:32:34.924042 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 15:32:34.924098 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 15:32:34.924113 15749 solver.cpp:397]     Test net output #2: loss = 17.3735 (* 1 = 17.3735 loss)
I1212 15:32:36.354779 15749 solver.cpp:218] Iteration 51000 (0.31646 iter/s, 315.996s/100 iters), loss = 0.709218
I1212 15:32:36.354878 15749 solver.cpp:237]     Train net output #0: label = 384
I1212 15:32:36.354904 15749 solver.cpp:237]     Train net output #1: label_phocs = 384
I1212 15:32:36.354917 15749 solver.cpp:237]     Train net output #2: loss = 0.0861721 (* 1 = 0.0861721 loss)
I1212 15:32:36.354928 15749 sgd_solver.cpp:116] Iteration 51000, lr = 0.0001
I1212 15:35:32.310973 15749 solver.cpp:218] Iteration 51100 (0.568323 iter/s, 175.956s/100 iters), loss = 1.69628
I1212 15:35:32.311077 15749 solver.cpp:237]     Train net output #0: label = 728
I1212 15:35:32.311105 15749 solver.cpp:237]     Train net output #1: label_phocs = 728
I1212 15:35:32.311120 15749 solver.cpp:237]     Train net output #2: loss = 1.87167 (* 1 = 1.87167 loss)
I1212 15:35:32.311131 15749 sgd_solver.cpp:116] Iteration 51100, lr = 0.0001
I1212 15:38:24.796767 15749 solver.cpp:218] Iteration 51200 (0.579794 iter/s, 172.475s/100 iters), loss = 1.73834
I1212 15:38:24.796872 15749 solver.cpp:237]     Train net output #0: label = 734
I1212 15:38:24.796898 15749 solver.cpp:237]     Train net output #1: label_phocs = 734
I1212 15:38:24.796911 15749 solver.cpp:237]     Train net output #2: loss = 0.242957 (* 1 = 0.242957 loss)
I1212 15:38:24.796921 15749 sgd_solver.cpp:116] Iteration 51200, lr = 0.0001
I1212 15:41:18.795797 15749 solver.cpp:218] Iteration 51300 (0.574856 iter/s, 173.956s/100 iters), loss = 1.82827
I1212 15:41:18.795899 15749 solver.cpp:237]     Train net output #0: label = 524
I1212 15:41:18.795923 15749 solver.cpp:237]     Train net output #1: label_phocs = 524
I1212 15:41:18.795935 15749 solver.cpp:237]     Train net output #2: loss = 1.58371 (* 1 = 1.58371 loss)
I1212 15:41:18.795944 15749 sgd_solver.cpp:116] Iteration 51300, lr = 0.0001
I1212 15:44:05.214642 15749 solver.cpp:218] Iteration 51400 (0.60099 iter/s, 166.392s/100 iters), loss = 1.86647
I1212 15:44:05.214756 15749 solver.cpp:237]     Train net output #0: label = 1046
I1212 15:44:05.214784 15749 solver.cpp:237]     Train net output #1: label_phocs = 1046
I1212 15:44:05.214799 15749 solver.cpp:237]     Train net output #2: loss = 0.194516 (* 1 = 0.194516 loss)
I1212 15:44:05.214810 15749 sgd_solver.cpp:116] Iteration 51400, lr = 0.0001
[2017-12-12 15:46:58,372, PHOCNetTrainer] Running test evaluation
[2017-12-12 15:46:58,372, PHOCNetTrainer] Evaluating CNN after 51000 steps:
I1212 15:47:58.013411 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:47:58.013583 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 15:48:01,538, PHOCNetTrainer] mAP: 0.926010
I1212 15:48:01.540307 15749 solver.cpp:330] Iteration 51500, Testing net (#0)
I1212 15:48:01.540560 15749 net.cpp:676] Ignoring source layer drop6
I1212 15:48:01.540571 15749 net.cpp:676] Ignoring source layer drop7
I1212 15:49:05.003845 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:49:05.004065 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 15:49:05.686434 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 15:49:05.686489 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 15:49:05.686506 15749 solver.cpp:397]     Test net output #2: loss = 15.8829 (* 1 = 15.8829 loss)
I1212 15:49:06.977989 15749 solver.cpp:218] Iteration 51500 (0.331388 iter/s, 301.761s/100 iters), loss = 2.40269
I1212 15:49:06.978097 15749 solver.cpp:237]     Train net output #0: label = 898
I1212 15:49:06.978127 15749 solver.cpp:237]     Train net output #1: label_phocs = 898
I1212 15:49:06.978142 15749 solver.cpp:237]     Train net output #2: loss = 2.38232 (* 1 = 2.38232 loss)
I1212 15:49:06.978152 15749 sgd_solver.cpp:116] Iteration 51500, lr = 0.0001
I1212 15:52:02.129503 15749 solver.cpp:218] Iteration 51600 (0.571068 iter/s, 175.111s/100 iters), loss = 1.70788
I1212 15:52:02.129602 15749 solver.cpp:237]     Train net output #0: label = 469
I1212 15:52:02.129627 15749 solver.cpp:237]     Train net output #1: label_phocs = 469
I1212 15:52:02.129640 15749 solver.cpp:237]     Train net output #2: loss = 0.10299 (* 1 = 0.10299 loss)
I1212 15:52:02.129649 15749 sgd_solver.cpp:116] Iteration 51600, lr = 0.0001
I1212 15:54:55.705427 15749 solver.cpp:218] Iteration 51700 (0.576118 iter/s, 173.576s/100 iters), loss = 1.71187
I1212 15:54:55.705515 15749 solver.cpp:237]     Train net output #0: label = 493
I1212 15:54:55.705540 15749 solver.cpp:237]     Train net output #1: label_phocs = 493
I1212 15:54:55.705554 15749 solver.cpp:237]     Train net output #2: loss = 0.495947 (* 1 = 0.495947 loss)
I1212 15:54:55.705564 15749 sgd_solver.cpp:116] Iteration 51700, lr = 0.0001
I1212 15:57:42.404021 15749 solver.cpp:218] Iteration 51800 (0.599905 iter/s, 166.693s/100 iters), loss = 1.61351
I1212 15:57:42.404109 15749 solver.cpp:237]     Train net output #0: label = 503
I1212 15:57:42.404134 15749 solver.cpp:237]     Train net output #1: label_phocs = 503
I1212 15:57:42.404150 15749 solver.cpp:237]     Train net output #2: loss = 0.666025 (* 1 = 0.666025 loss)
I1212 15:57:42.404160 15749 sgd_solver.cpp:116] Iteration 51800, lr = 0.0001
I1212 16:00:26.975522 15749 solver.cpp:218] Iteration 51900 (0.607813 iter/s, 164.524s/100 iters), loss = 1.73724
I1212 16:00:26.975608 15749 solver.cpp:237]     Train net output #0: label = 906
I1212 16:00:26.975631 15749 solver.cpp:237]     Train net output #1: label_phocs = 906
I1212 16:00:26.975643 15749 solver.cpp:237]     Train net output #2: loss = 0.0431624 (* 1 = 0.0431624 loss)
I1212 16:00:26.975652 15749 sgd_solver.cpp:116] Iteration 51900, lr = 0.0001
[2017-12-12 16:03:11,025, PHOCNetTrainer] Running test evaluation
[2017-12-12 16:03:11,025, PHOCNetTrainer] Evaluating CNN after 51500 steps:
I1212 16:03:57.615837 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:03:57.615871 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 16:03:59,909, PHOCNetTrainer] mAP: 0.907544
I1212 16:03:59.911146 15749 solver.cpp:330] Iteration 52000, Testing net (#0)
I1212 16:03:59.911378 15749 net.cpp:676] Ignoring source layer drop6
I1212 16:03:59.911389 15749 net.cpp:676] Ignoring source layer drop7
I1212 16:04:39.487870 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:04:39.488236 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:04:39.785243 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 16:04:39.785289 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 16:04:39.785308 15749 solver.cpp:397]     Test net output #2: loss = 17.3204 (* 1 = 17.3204 loss)
I1212 16:04:41.155812 15749 solver.cpp:218] Iteration 52000 (0.393421 iter/s, 254.18s/100 iters), loss = 2.74925
I1212 16:04:41.155892 15749 solver.cpp:237]     Train net output #0: label = 277
I1212 16:04:41.155915 15749 solver.cpp:237]     Train net output #1: label_phocs = 277
I1212 16:04:41.155927 15749 solver.cpp:237]     Train net output #2: loss = 7.03364 (* 1 = 7.03364 loss)
I1212 16:04:41.155936 15749 sgd_solver.cpp:116] Iteration 52000, lr = 0.0001
I1212 16:07:18.604481 15749 solver.cpp:218] Iteration 52100 (0.635128 iter/s, 157.449s/100 iters), loss = 1.9514
I1212 16:07:18.604575 15749 solver.cpp:237]     Train net output #0: label = 835
I1212 16:07:18.604599 15749 solver.cpp:237]     Train net output #1: label_phocs = 835
I1212 16:07:18.604610 15749 solver.cpp:237]     Train net output #2: loss = 0.675557 (* 1 = 0.675557 loss)
I1212 16:07:18.604619 15749 sgd_solver.cpp:116] Iteration 52100, lr = 0.0001
I1212 16:10:30.406492 15749 solver.cpp:218] Iteration 52200 (0.521371 iter/s, 191.802s/100 iters), loss = 1.58971
I1212 16:10:30.406603 15749 solver.cpp:237]     Train net output #0: label = 453
I1212 16:10:30.406633 15749 solver.cpp:237]     Train net output #1: label_phocs = 453
I1212 16:10:30.406648 15749 solver.cpp:237]     Train net output #2: loss = 0.235753 (* 1 = 0.235753 loss)
I1212 16:10:30.406659 15749 sgd_solver.cpp:116] Iteration 52200, lr = 0.0001
I1212 16:13:57.276978 15749 solver.cpp:218] Iteration 52300 (0.483394 iter/s, 206.871s/100 iters), loss = 2.03163
I1212 16:13:57.277127 15749 solver.cpp:237]     Train net output #0: label = 669
I1212 16:13:57.277163 15749 solver.cpp:237]     Train net output #1: label_phocs = 669
I1212 16:13:57.277180 15749 solver.cpp:237]     Train net output #2: loss = 5.35548 (* 1 = 5.35548 loss)
I1212 16:13:57.277192 15749 sgd_solver.cpp:116] Iteration 52300, lr = 0.0001
I1212 16:17:29.897387 15749 solver.cpp:218] Iteration 52400 (0.470405 iter/s, 212.583s/100 iters), loss = 1.47436
I1212 16:17:29.898025 15749 solver.cpp:237]     Train net output #0: label = 1019
I1212 16:17:29.898068 15749 solver.cpp:237]     Train net output #1: label_phocs = 1019
I1212 16:17:29.898082 15749 solver.cpp:237]     Train net output #2: loss = 0.419803 (* 1 = 0.419803 loss)
I1212 16:17:29.898092 15749 sgd_solver.cpp:116] Iteration 52400, lr = 0.0001
[2017-12-12 16:20:53,145, PHOCNetTrainer] Running test evaluation
[2017-12-12 16:20:53,146, PHOCNetTrainer] Evaluating CNN after 52000 steps:
I1212 16:22:12.547931 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:22:12.548061 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 16:22:15,122, PHOCNetTrainer] mAP: 0.910816
I1212 16:22:15.124681 15749 solver.cpp:330] Iteration 52500, Testing net (#0)
I1212 16:22:15.125013 15749 net.cpp:676] Ignoring source layer drop6
I1212 16:22:15.125049 15749 net.cpp:676] Ignoring source layer drop7
I1212 16:23:32.345830 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:23:32.346096 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:23:33.688725 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 16:23:33.688776 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 16:23:33.688791 15749 solver.cpp:397]     Test net output #2: loss = 16.4424 (* 1 = 16.4424 loss)
I1212 16:23:36.559433 15749 solver.cpp:218] Iteration 52500 (0.272731 iter/s, 366.662s/100 iters), loss = 1.99806
I1212 16:23:36.559530 15749 solver.cpp:237]     Train net output #0: label = 1082
I1212 16:23:36.559556 15749 solver.cpp:237]     Train net output #1: label_phocs = 1082
I1212 16:23:36.559568 15749 solver.cpp:237]     Train net output #2: loss = 0.254538 (* 1 = 0.254538 loss)
I1212 16:23:36.559578 15749 sgd_solver.cpp:116] Iteration 52500, lr = 0.0001
I1212 16:27:12.302973 15749 solver.cpp:218] Iteration 52600 (0.463649 iter/s, 215.68s/100 iters), loss = 1.72368
I1212 16:27:12.303123 15749 solver.cpp:237]     Train net output #0: label = 450
I1212 16:27:12.303171 15749 solver.cpp:237]     Train net output #1: label_phocs = 450
I1212 16:27:12.303192 15749 solver.cpp:237]     Train net output #2: loss = 1.02177 (* 1 = 1.02177 loss)
I1212 16:27:12.303206 15749 sgd_solver.cpp:116] Iteration 52600, lr = 0.0001
I1212 16:30:28.141906 15749 solver.cpp:218] Iteration 52700 (0.510624 iter/s, 195.839s/100 iters), loss = 1.54071
I1212 16:30:28.142030 15749 solver.cpp:237]     Train net output #0: label = 933
I1212 16:30:28.142058 15749 solver.cpp:237]     Train net output #1: label_phocs = 933
I1212 16:30:28.142072 15749 solver.cpp:237]     Train net output #2: loss = 0.491431 (* 1 = 0.491431 loss)
I1212 16:30:28.142084 15749 sgd_solver.cpp:116] Iteration 52700, lr = 0.0001
I1212 16:33:46.619786 15749 solver.cpp:218] Iteration 52800 (0.503835 iter/s, 198.478s/100 iters), loss = 1.77426
I1212 16:33:46.621023 15749 solver.cpp:237]     Train net output #0: label = 564
I1212 16:33:46.621116 15749 solver.cpp:237]     Train net output #1: label_phocs = 564
I1212 16:33:46.621136 15749 solver.cpp:237]     Train net output #2: loss = 0.197128 (* 1 = 0.197128 loss)
I1212 16:33:46.621150 15749 sgd_solver.cpp:116] Iteration 52800, lr = 0.0001
I1212 16:37:11.408272 15749 solver.cpp:218] Iteration 52900 (0.488311 iter/s, 204.787s/100 iters), loss = 1.75129
I1212 16:37:11.408363 15749 solver.cpp:237]     Train net output #0: label = 1065
I1212 16:37:11.408387 15749 solver.cpp:237]     Train net output #1: label_phocs = 1065
I1212 16:37:11.408399 15749 solver.cpp:237]     Train net output #2: loss = 0.0601408 (* 1 = 0.0601408 loss)
I1212 16:37:11.408409 15749 sgd_solver.cpp:116] Iteration 52900, lr = 0.0001
[2017-12-12 16:40:54,832, PHOCNetTrainer] Running test evaluation
[2017-12-12 16:40:54,832, PHOCNetTrainer] Evaluating CNN after 52500 steps:
I1212 16:42:25.056180 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:42:25.056336 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 16:42:28,535, PHOCNetTrainer] mAP: 0.901138
I1212 16:42:28.536862 15749 solver.cpp:330] Iteration 53000, Testing net (#0)
I1212 16:42:28.537173 15749 net.cpp:676] Ignoring source layer drop6
I1212 16:42:28.537202 15749 net.cpp:676] Ignoring source layer drop7
I1212 16:43:43.351876 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:43:43.352025 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 16:43:44.058976 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 16:43:44.059034 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 16:43:44.059049 15749 solver.cpp:397]     Test net output #2: loss = 18.6031 (* 1 = 18.6031 loss)
I1212 16:43:45.648317 15749 solver.cpp:218] Iteration 53000 (0.253653 iter/s, 394.24s/100 iters), loss = 1.53024
I1212 16:43:45.648422 15749 solver.cpp:237]     Train net output #0: label = 480
I1212 16:43:45.648445 15749 solver.cpp:237]     Train net output #1: label_phocs = 480
I1212 16:43:45.648458 15749 solver.cpp:237]     Train net output #2: loss = 2.58626 (* 1 = 2.58626 loss)
I1212 16:43:45.648466 15749 sgd_solver.cpp:116] Iteration 53000, lr = 0.0001
I1212 16:46:48.795861 15749 solver.cpp:218] Iteration 53100 (0.546027 iter/s, 183.141s/100 iters), loss = 1.53857
I1212 16:46:48.795999 15749 solver.cpp:237]     Train net output #0: label = 816
I1212 16:46:48.796030 15749 solver.cpp:237]     Train net output #1: label_phocs = 816
I1212 16:46:48.796046 15749 solver.cpp:237]     Train net output #2: loss = 0.121522 (* 1 = 0.121522 loss)
I1212 16:46:48.796056 15749 sgd_solver.cpp:116] Iteration 53100, lr = 0.0001
I1212 16:50:28.795274 15749 solver.cpp:218] Iteration 53200 (0.454558 iter/s, 219.994s/100 iters), loss = 1.62739
I1212 16:50:28.795403 15749 solver.cpp:237]     Train net output #0: label = 433
I1212 16:50:28.795433 15749 solver.cpp:237]     Train net output #1: label_phocs = 433
I1212 16:50:28.795449 15749 solver.cpp:237]     Train net output #2: loss = 1.30616 (* 1 = 1.30616 loss)
I1212 16:50:28.795467 15749 sgd_solver.cpp:116] Iteration 53200, lr = 0.0001
I1212 16:54:06.005425 15749 solver.cpp:218] Iteration 53300 (0.460384 iter/s, 217.21s/100 iters), loss = 1.62033
I1212 16:54:06.005551 15749 solver.cpp:237]     Train net output #0: label = 398
I1212 16:54:06.005581 15749 solver.cpp:237]     Train net output #1: label_phocs = 398
I1212 16:54:06.005599 15749 solver.cpp:237]     Train net output #2: loss = 0.0544211 (* 1 = 0.0544211 loss)
I1212 16:54:06.005610 15749 sgd_solver.cpp:116] Iteration 53300, lr = 0.0001
I1212 16:56:57.742547 15749 solver.cpp:218] Iteration 53400 (0.582286 iter/s, 171.737s/100 iters), loss = 1.69931
I1212 16:56:57.742642 15749 solver.cpp:237]     Train net output #0: label = 119
I1212 16:56:57.742666 15749 solver.cpp:237]     Train net output #1: label_phocs = 119
I1212 16:56:57.742678 15749 solver.cpp:237]     Train net output #2: loss = 0.801736 (* 1 = 0.801736 loss)
I1212 16:56:57.742687 15749 sgd_solver.cpp:116] Iteration 53400, lr = 0.0001
[2017-12-12 17:00:36,839, PHOCNetTrainer] Running test evaluation
[2017-12-12 17:00:36,839, PHOCNetTrainer] Evaluating CNN after 53000 steps:
I1212 17:02:03.251919 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:02:03.252120 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 17:02:05,383, PHOCNetTrainer] mAP: 0.924498
I1212 17:02:05.385659 15749 solver.cpp:330] Iteration 53500, Testing net (#0)
I1212 17:02:05.385946 15749 net.cpp:676] Ignoring source layer drop6
I1212 17:02:05.385977 15749 net.cpp:676] Ignoring source layer drop7
I1212 17:03:15.459895 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:03:15.460295 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:03:16.061038 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 17:03:16.061094 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 17:03:16.061106 15749 solver.cpp:397]     Test net output #2: loss = 16.0497 (* 1 = 16.0497 loss)
I1212 17:03:18.255781 15749 solver.cpp:218] Iteration 53500 (0.262829 iter/s, 380.476s/100 iters), loss = 2.5257
I1212 17:03:18.255878 15749 solver.cpp:237]     Train net output #0: label = 159
I1212 17:03:18.255906 15749 solver.cpp:237]     Train net output #1: label_phocs = 159
I1212 17:03:18.255920 15749 solver.cpp:237]     Train net output #2: loss = 6.75133 (* 1 = 6.75133 loss)
I1212 17:03:18.255930 15749 sgd_solver.cpp:116] Iteration 53500, lr = 0.0001
I1212 17:06:38.959393 15749 solver.cpp:218] Iteration 53600 (0.498247 iter/s, 200.704s/100 iters), loss = 1.75323
I1212 17:06:38.959503 15749 solver.cpp:237]     Train net output #0: label = 432
I1212 17:06:38.959532 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1212 17:06:38.959545 15749 solver.cpp:237]     Train net output #2: loss = 2.53968 (* 1 = 2.53968 loss)
I1212 17:06:38.959555 15749 sgd_solver.cpp:116] Iteration 53600, lr = 0.0001
I1212 17:10:08.799798 15749 solver.cpp:218] Iteration 53700 (0.476699 iter/s, 209.776s/100 iters), loss = 1.7463
I1212 17:10:08.800870 15749 solver.cpp:237]     Train net output #0: label = 108
I1212 17:10:08.800922 15749 solver.cpp:237]     Train net output #1: label_phocs = 108
I1212 17:10:08.800936 15749 solver.cpp:237]     Train net output #2: loss = 1.7283 (* 1 = 1.7283 loss)
I1212 17:10:08.800946 15749 sgd_solver.cpp:116] Iteration 53700, lr = 0.0001
I1212 17:13:20.804553 15749 solver.cpp:218] Iteration 53800 (0.52085 iter/s, 191.994s/100 iters), loss = 1.68962
I1212 17:13:20.804661 15749 solver.cpp:237]     Train net output #0: label = 340
I1212 17:13:20.804690 15749 solver.cpp:237]     Train net output #1: label_phocs = 340
I1212 17:13:20.804704 15749 solver.cpp:237]     Train net output #2: loss = 2.31057 (* 1 = 2.31057 loss)
I1212 17:13:20.804715 15749 sgd_solver.cpp:116] Iteration 53800, lr = 0.0001
I1212 17:16:52.523936 15749 solver.cpp:218] Iteration 53900 (0.472344 iter/s, 211.71s/100 iters), loss = 1.45547
I1212 17:16:52.524057 15749 solver.cpp:237]     Train net output #0: label = 963
I1212 17:16:52.524093 15749 solver.cpp:237]     Train net output #1: label_phocs = 963
I1212 17:16:52.524111 15749 solver.cpp:237]     Train net output #2: loss = 2.78011 (* 1 = 2.78011 loss)
I1212 17:16:52.524121 15749 sgd_solver.cpp:116] Iteration 53900, lr = 0.0001
[2017-12-12 17:20:19,293, PHOCNetTrainer] Running test evaluation
[2017-12-12 17:20:19,293, PHOCNetTrainer] Evaluating CNN after 53500 steps:
I1212 17:21:41.699841 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:21:41.699998 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 17:21:44,619, PHOCNetTrainer] mAP: 0.918526
I1212 17:21:44.620692 15749 solver.cpp:330] Iteration 54000, Testing net (#0)
I1212 17:21:44.620942 15749 net.cpp:676] Ignoring source layer drop6
I1212 17:21:44.620952 15749 net.cpp:676] Ignoring source layer drop7
I1212 17:22:52.096146 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:22:52.098193 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:22:53.240308 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 17:22:53.240377 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 17:22:53.240393 15749 solver.cpp:397]     Test net output #2: loss = 16.5716 (* 1 = 16.5716 loss)
I1212 17:22:55.191802 15749 solver.cpp:218] Iteration 54000 (0.275772 iter/s, 362.618s/100 iters), loss = 0.195204
I1212 17:22:55.191927 15749 solver.cpp:237]     Train net output #0: label = 901
I1212 17:22:55.191952 15749 solver.cpp:237]     Train net output #1: label_phocs = 901
I1212 17:22:55.191965 15749 solver.cpp:237]     Train net output #2: loss = 0.335493 (* 1 = 0.335493 loss)
I1212 17:22:55.191975 15749 sgd_solver.cpp:116] Iteration 54000, lr = 0.0001
I1212 17:26:16.522693 15749 solver.cpp:218] Iteration 54100 (0.496695 iter/s, 201.331s/100 iters), loss = 1.47366
I1212 17:26:16.522860 15749 solver.cpp:237]     Train net output #0: label = 1087
I1212 17:26:16.522902 15749 solver.cpp:237]     Train net output #1: label_phocs = 1087
I1212 17:26:16.522924 15749 solver.cpp:237]     Train net output #2: loss = 1.08068 (* 1 = 1.08068 loss)
I1212 17:26:16.522940 15749 sgd_solver.cpp:116] Iteration 54100, lr = 0.0001
I1212 17:29:23.618178 15749 solver.cpp:218] Iteration 54200 (0.53451 iter/s, 187.087s/100 iters), loss = 1.72521
I1212 17:29:23.618302 15749 solver.cpp:237]     Train net output #0: label = 705
I1212 17:29:23.618331 15749 solver.cpp:237]     Train net output #1: label_phocs = 705
I1212 17:29:23.618345 15749 solver.cpp:237]     Train net output #2: loss = 0.346833 (* 1 = 0.346833 loss)
I1212 17:29:23.618355 15749 sgd_solver.cpp:116] Iteration 54200, lr = 0.0001
I1212 17:32:56.409895 15749 solver.cpp:218] Iteration 54300 (0.469943 iter/s, 212.792s/100 iters), loss = 1.62316
I1212 17:32:56.410001 15749 solver.cpp:237]     Train net output #0: label = 624
I1212 17:32:56.410025 15749 solver.cpp:237]     Train net output #1: label_phocs = 624
I1212 17:32:56.410038 15749 solver.cpp:237]     Train net output #2: loss = 0.694133 (* 1 = 0.694133 loss)
I1212 17:32:56.410048 15749 sgd_solver.cpp:116] Iteration 54300, lr = 0.0001
I1212 17:36:31.275940 15749 solver.cpp:218] Iteration 54400 (0.465417 iter/s, 214.861s/100 iters), loss = 1.50773
I1212 17:36:31.276049 15749 solver.cpp:237]     Train net output #0: label = 34
I1212 17:36:31.276074 15749 solver.cpp:237]     Train net output #1: label_phocs = 34
I1212 17:36:31.276087 15749 solver.cpp:237]     Train net output #2: loss = 1.25261 (* 1 = 1.25261 loss)
I1212 17:36:31.276096 15749 sgd_solver.cpp:116] Iteration 54400, lr = 0.0001
[2017-12-12 17:39:55,118, PHOCNetTrainer] Running test evaluation
[2017-12-12 17:39:55,118, PHOCNetTrainer] Evaluating CNN after 54000 steps:
I1212 17:41:17.819952 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:41:17.820232 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 17:41:21,520, PHOCNetTrainer] mAP: 0.920988
I1212 17:41:21.521745 15749 solver.cpp:330] Iteration 54500, Testing net (#0)
I1212 17:41:21.522001 15749 net.cpp:676] Ignoring source layer drop6
I1212 17:41:21.522029 15749 net.cpp:676] Ignoring source layer drop7
I1212 17:42:33.103904 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:42:33.104101 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:42:33.949198 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 17:42:33.949251 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 17:42:33.949265 15749 solver.cpp:397]     Test net output #2: loss = 16.8136 (* 1 = 16.8136 loss)
I1212 17:42:35.902125 15749 solver.cpp:218] Iteration 54500 (0.274253 iter/s, 364.626s/100 iters), loss = 2.48474
I1212 17:42:35.902259 15749 solver.cpp:237]     Train net output #0: label = 761
I1212 17:42:35.902289 15749 solver.cpp:237]     Train net output #1: label_phocs = 761
I1212 17:42:35.902307 15749 solver.cpp:237]     Train net output #2: loss = 3.35517 (* 1 = 3.35517 loss)
I1212 17:42:35.902319 15749 sgd_solver.cpp:116] Iteration 54500, lr = 0.0001
I1212 17:46:02.923058 15749 solver.cpp:218] Iteration 54600 (0.483043 iter/s, 207.021s/100 iters), loss = 1.44769
I1212 17:46:02.923172 15749 solver.cpp:237]     Train net output #0: label = 1002
I1212 17:46:02.923202 15749 solver.cpp:237]     Train net output #1: label_phocs = 1002
I1212 17:46:02.923218 15749 solver.cpp:237]     Train net output #2: loss = 2.40725 (* 1 = 2.40725 loss)
I1212 17:46:02.923228 15749 sgd_solver.cpp:116] Iteration 54600, lr = 0.0001
I1212 17:49:25.711964 15749 solver.cpp:218] Iteration 54700 (0.49322 iter/s, 202.749s/100 iters), loss = 1.39243
I1212 17:49:25.712083 15749 solver.cpp:237]     Train net output #0: label = 794
I1212 17:49:25.712108 15749 solver.cpp:237]     Train net output #1: label_phocs = 794
I1212 17:49:25.712122 15749 solver.cpp:237]     Train net output #2: loss = 1.44604 (* 1 = 1.44604 loss)
I1212 17:49:25.712133 15749 sgd_solver.cpp:116] Iteration 54700, lr = 0.0001
I1212 17:52:35.176722 15749 solver.cpp:218] Iteration 54800 (0.527803 iter/s, 189.465s/100 iters), loss = 1.59917
I1212 17:52:35.176820 15749 solver.cpp:237]     Train net output #0: label = 612
I1212 17:52:35.176841 15749 solver.cpp:237]     Train net output #1: label_phocs = 612
I1212 17:52:35.176849 15749 solver.cpp:237]     Train net output #2: loss = 0.234989 (* 1 = 0.234989 loss)
I1212 17:52:35.176857 15749 sgd_solver.cpp:116] Iteration 54800, lr = 0.0001
I1212 17:55:32.055259 15749 solver.cpp:218] Iteration 54900 (0.565368 iter/s, 176.876s/100 iters), loss = 1.48665
I1212 17:55:32.055366 15749 solver.cpp:237]     Train net output #0: label = 475
I1212 17:55:32.055393 15749 solver.cpp:237]     Train net output #1: label_phocs = 475
I1212 17:55:32.055408 15749 solver.cpp:237]     Train net output #2: loss = 0.298222 (* 1 = 0.298222 loss)
I1212 17:55:32.055418 15749 sgd_solver.cpp:116] Iteration 54900, lr = 0.0001
[2017-12-12 17:58:29,589, PHOCNetTrainer] Running test evaluation
[2017-12-12 17:58:29,589, PHOCNetTrainer] Evaluating CNN after 54500 steps:
I1212 17:59:41.895922 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 17:59:41.896118 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 17:59:44,966, PHOCNetTrainer] mAP: 0.916457
I1212 17:59:44.968019 15749 solver.cpp:330] Iteration 55000, Testing net (#0)
I1212 17:59:44.968286 15749 net.cpp:676] Ignoring source layer drop6
I1212 17:59:44.968297 15749 net.cpp:676] Ignoring source layer drop7
I1212 18:00:48.803884 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:00:48.804147 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:00:49.572593 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 18:00:49.572644 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 18:00:49.572656 15749 solver.cpp:397]     Test net output #2: loss = 16.4978 (* 1 = 16.4978 loss)
I1212 18:00:51.632401 15749 solver.cpp:218] Iteration 55000 (0.312914 iter/s, 319.577s/100 iters), loss = 1.52892
I1212 18:00:51.632506 15749 solver.cpp:237]     Train net output #0: label = 433
I1212 18:00:51.632541 15749 solver.cpp:237]     Train net output #1: label_phocs = 433
I1212 18:00:51.632555 15749 solver.cpp:237]     Train net output #2: loss = 6.80856 (* 1 = 6.80856 loss)
I1212 18:00:51.632565 15749 sgd_solver.cpp:116] Iteration 55000, lr = 0.0001
I1212 18:03:47.819780 15749 solver.cpp:218] Iteration 55100 (0.567647 iter/s, 176.166s/100 iters), loss = 1.30882
I1212 18:03:47.819880 15749 solver.cpp:237]     Train net output #0: label = 556
I1212 18:03:47.819905 15749 solver.cpp:237]     Train net output #1: label_phocs = 556
I1212 18:03:47.819917 15749 solver.cpp:237]     Train net output #2: loss = 0.820275 (* 1 = 0.820275 loss)
I1212 18:03:47.819926 15749 sgd_solver.cpp:116] Iteration 55100, lr = 0.0001
I1212 18:06:46.133769 15749 solver.cpp:218] Iteration 55200 (0.560809 iter/s, 178.314s/100 iters), loss = 1.43999
I1212 18:06:46.133888 15749 solver.cpp:237]     Train net output #0: label = 642
I1212 18:06:46.133919 15749 solver.cpp:237]     Train net output #1: label_phocs = 642
I1212 18:06:46.133934 15749 solver.cpp:237]     Train net output #2: loss = 0.0464562 (* 1 = 0.0464562 loss)
I1212 18:06:46.133945 15749 sgd_solver.cpp:116] Iteration 55200, lr = 0.0001
I1212 18:09:35.710485 15749 solver.cpp:218] Iteration 55300 (0.589709 iter/s, 169.575s/100 iters), loss = 1.48335
I1212 18:09:35.710618 15749 solver.cpp:237]     Train net output #0: label = 943
I1212 18:09:35.710645 15749 solver.cpp:237]     Train net output #1: label_phocs = 943
I1212 18:09:35.710659 15749 solver.cpp:237]     Train net output #2: loss = 0.449196 (* 1 = 0.449196 loss)
I1212 18:09:35.710669 15749 sgd_solver.cpp:116] Iteration 55300, lr = 0.0001
I1212 18:12:34.447096 15749 solver.cpp:218] Iteration 55400 (0.559606 iter/s, 178.697s/100 iters), loss = 1.36875
I1212 18:12:34.447194 15749 solver.cpp:237]     Train net output #0: label = 1073
I1212 18:12:34.447221 15749 solver.cpp:237]     Train net output #1: label_phocs = 1073
I1212 18:12:34.447237 15749 solver.cpp:237]     Train net output #2: loss = 0.0294689 (* 1 = 0.0294689 loss)
I1212 18:12:34.447247 15749 sgd_solver.cpp:116] Iteration 55400, lr = 0.0001
[2017-12-12 18:15:27,880, PHOCNetTrainer] Running test evaluation
[2017-12-12 18:15:27,880, PHOCNetTrainer] Evaluating CNN after 55000 steps:
I1212 18:16:38.059911 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:16:38.060107 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 18:16:41,082, PHOCNetTrainer] mAP: 0.920018
I1212 18:16:41.084756 15749 solver.cpp:330] Iteration 55500, Testing net (#0)
I1212 18:16:41.085048 15749 net.cpp:676] Ignoring source layer drop6
I1212 18:16:41.085077 15749 net.cpp:676] Ignoring source layer drop7
I1212 18:17:24.488150 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:17:24.488396 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:17:25.351968 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 18:17:25.352030 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 18:17:25.352051 15749 solver.cpp:397]     Test net output #2: loss = 16.8271 (* 1 = 16.8271 loss)
I1212 18:17:26.963021 15749 solver.cpp:218] Iteration 55500 (0.341927 iter/s, 292.46s/100 iters), loss = 1.2869
I1212 18:17:26.963124 15749 solver.cpp:237]     Train net output #0: label = 542
I1212 18:17:26.963152 15749 solver.cpp:237]     Train net output #1: label_phocs = 542
I1212 18:17:26.963167 15749 solver.cpp:237]     Train net output #2: loss = 0.564306 (* 1 = 0.564306 loss)
I1212 18:17:26.963178 15749 sgd_solver.cpp:116] Iteration 55500, lr = 0.0001
I1212 18:20:24.667927 15749 solver.cpp:218] Iteration 55600 (0.562731 iter/s, 177.705s/100 iters), loss = 1.64776
I1212 18:20:24.668035 15749 solver.cpp:237]     Train net output #0: label = 823
I1212 18:20:24.668063 15749 solver.cpp:237]     Train net output #1: label_phocs = 823
I1212 18:20:24.668081 15749 solver.cpp:237]     Train net output #2: loss = 0.066126 (* 1 = 0.066126 loss)
I1212 18:20:24.668092 15749 sgd_solver.cpp:116] Iteration 55600, lr = 0.0001
I1212 18:23:20.512171 15749 solver.cpp:218] Iteration 55700 (0.568685 iter/s, 175.844s/100 iters), loss = 1.27311
I1212 18:23:20.512284 15749 solver.cpp:237]     Train net output #0: label = 534
I1212 18:23:20.512311 15749 solver.cpp:237]     Train net output #1: label_phocs = 534
I1212 18:23:20.512326 15749 solver.cpp:237]     Train net output #2: loss = 2.15022 (* 1 = 2.15022 loss)
I1212 18:23:20.512336 15749 sgd_solver.cpp:116] Iteration 55700, lr = 0.0001
I1212 18:26:16.672655 15749 solver.cpp:218] Iteration 55800 (0.567753 iter/s, 176.133s/100 iters), loss = 1.51017
I1212 18:26:16.672766 15749 solver.cpp:237]     Train net output #0: label = 1051
I1212 18:26:16.672793 15749 solver.cpp:237]     Train net output #1: label_phocs = 1051
I1212 18:26:16.672807 15749 solver.cpp:237]     Train net output #2: loss = 0.0408962 (* 1 = 0.0408962 loss)
I1212 18:26:16.672817 15749 sgd_solver.cpp:116] Iteration 55800, lr = 0.0001
I1212 18:29:03.557859 15749 solver.cpp:218] Iteration 55900 (0.599331 iter/s, 166.853s/100 iters), loss = 1.56524
I1212 18:29:03.557960 15749 solver.cpp:237]     Train net output #0: label = 283
I1212 18:29:03.557984 15749 solver.cpp:237]     Train net output #1: label_phocs = 283
I1212 18:29:03.557996 15749 solver.cpp:237]     Train net output #2: loss = 3.77084 (* 1 = 3.77084 loss)
I1212 18:29:03.558006 15749 sgd_solver.cpp:116] Iteration 55900, lr = 0.0001
[2017-12-12 18:31:57,676, PHOCNetTrainer] Running test evaluation
[2017-12-12 18:31:57,676, PHOCNetTrainer] Evaluating CNN after 55500 steps:
I1212 18:32:54.686141 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:32:54.686470 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 18:32:57,704, PHOCNetTrainer] mAP: 0.913398
I1212 18:32:57.706712 15749 solver.cpp:330] Iteration 56000, Testing net (#0)
I1212 18:32:57.707000 15749 net.cpp:676] Ignoring source layer drop6
I1212 18:32:57.707013 15749 net.cpp:676] Ignoring source layer drop7
I1212 18:33:54.263885 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:33:54.264034 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:33:54.604655 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 18:33:54.604708 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 18:33:54.604724 15749 solver.cpp:397]     Test net output #2: loss = 16.8443 (* 1 = 16.8443 loss)
I1212 18:33:55.480249 15749 solver.cpp:218] Iteration 56000 (0.342557 iter/s, 291.922s/100 iters), loss = 0.628058
I1212 18:33:55.480343 15749 solver.cpp:237]     Train net output #0: label = 254
I1212 18:33:55.480370 15749 solver.cpp:237]     Train net output #1: label_phocs = 254
I1212 18:33:55.480386 15749 solver.cpp:237]     Train net output #2: loss = 0.712415 (* 1 = 0.712415 loss)
I1212 18:33:55.480396 15749 sgd_solver.cpp:116] Iteration 56000, lr = 0.0001
I1212 18:36:37.027796 15749 solver.cpp:218] Iteration 56100 (0.619123 iter/s, 161.519s/100 iters), loss = 1.42476
I1212 18:36:37.027892 15749 solver.cpp:237]     Train net output #0: label = 390
I1212 18:36:37.027916 15749 solver.cpp:237]     Train net output #1: label_phocs = 390
I1212 18:36:37.027928 15749 solver.cpp:237]     Train net output #2: loss = 0.0306397 (* 1 = 0.0306397 loss)
I1212 18:36:37.027938 15749 sgd_solver.cpp:116] Iteration 56100, lr = 0.0001
I1212 18:39:30.755224 15749 solver.cpp:218] Iteration 56200 (0.575874 iter/s, 173.649s/100 iters), loss = 1.45863
I1212 18:39:30.755340 15749 solver.cpp:237]     Train net output #0: label = 1123
I1212 18:39:30.755373 15749 solver.cpp:237]     Train net output #1: label_phocs = 1123
I1212 18:39:30.755389 15749 solver.cpp:237]     Train net output #2: loss = 0.0845596 (* 1 = 0.0845596 loss)
I1212 18:39:30.755401 15749 sgd_solver.cpp:116] Iteration 56200, lr = 0.0001
I1212 18:42:14.453367 15749 solver.cpp:218] Iteration 56300 (0.610939 iter/s, 163.682s/100 iters), loss = 1.32863
I1212 18:42:14.453481 15749 solver.cpp:237]     Train net output #0: label = 411
I1212 18:42:14.453521 15749 solver.cpp:237]     Train net output #1: label_phocs = 411
I1212 18:42:14.453536 15749 solver.cpp:237]     Train net output #2: loss = 0.122288 (* 1 = 0.122288 loss)
I1212 18:42:14.453547 15749 sgd_solver.cpp:116] Iteration 56300, lr = 0.0001
I1212 18:45:02.849158 15749 solver.cpp:218] Iteration 56400 (0.593839 iter/s, 168.396s/100 iters), loss = 1.32718
I1212 18:45:02.849277 15749 solver.cpp:237]     Train net output #0: label = 432
I1212 18:45:02.849304 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1212 18:45:02.849316 15749 solver.cpp:237]     Train net output #2: loss = 0.241919 (* 1 = 0.241919 loss)
I1212 18:45:02.849326 15749 sgd_solver.cpp:116] Iteration 56400, lr = 0.0001
[2017-12-12 18:47:58,771, PHOCNetTrainer] Running test evaluation
[2017-12-12 18:47:58,771, PHOCNetTrainer] Evaluating CNN after 56000 steps:
I1212 18:49:02.868170 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:49:02.868377 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 18:49:05,206, PHOCNetTrainer] mAP: 0.922027
I1212 18:49:05.208582 15749 solver.cpp:330] Iteration 56500, Testing net (#0)
I1212 18:49:05.208829 15749 net.cpp:676] Ignoring source layer drop6
I1212 18:49:05.208842 15749 net.cpp:676] Ignoring source layer drop7
I1212 18:50:08.851990 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:50:08.852156 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 18:50:09.511922 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 18:50:09.511972 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 18:50:09.511983 15749 solver.cpp:397]     Test net output #2: loss = 15.9898 (* 1 = 15.9898 loss)
I1212 18:50:11.196588 15749 solver.cpp:218] Iteration 56500 (0.324319 iter/s, 308.338s/100 iters), loss = 1.26747
I1212 18:50:11.196689 15749 solver.cpp:237]     Train net output #0: label = 105
I1212 18:50:11.196715 15749 solver.cpp:237]     Train net output #1: label_phocs = 105
I1212 18:50:11.196728 15749 solver.cpp:237]     Train net output #2: loss = 0.459459 (* 1 = 0.459459 loss)
I1212 18:50:11.196738 15749 sgd_solver.cpp:116] Iteration 56500, lr = 0.0001
I1212 18:52:56.327801 15749 solver.cpp:218] Iteration 56600 (0.606 iter/s, 165.017s/100 iters), loss = 1.41693
I1212 18:52:56.327904 15749 solver.cpp:237]     Train net output #0: label = 738
I1212 18:52:56.327929 15749 solver.cpp:237]     Train net output #1: label_phocs = 738
I1212 18:52:56.327941 15749 solver.cpp:237]     Train net output #2: loss = 1.29103 (* 1 = 1.29103 loss)
I1212 18:52:56.327951 15749 sgd_solver.cpp:116] Iteration 56600, lr = 0.0001
I1212 18:55:48.228355 15749 solver.cpp:218] Iteration 56700 (0.581779 iter/s, 171.887s/100 iters), loss = 1.33622
I1212 18:55:48.228477 15749 solver.cpp:237]     Train net output #0: label = 72
I1212 18:55:48.228507 15749 solver.cpp:237]     Train net output #1: label_phocs = 72
I1212 18:55:48.228520 15749 solver.cpp:237]     Train net output #2: loss = 0.064213 (* 1 = 0.064213 loss)
I1212 18:55:48.228533 15749 sgd_solver.cpp:116] Iteration 56700, lr = 0.0001
I1212 18:58:19.595691 15749 solver.cpp:218] Iteration 56800 (0.660645 iter/s, 151.367s/100 iters), loss = 1.25489
I1212 18:58:19.595780 15749 solver.cpp:237]     Train net output #0: label = 157
I1212 18:58:19.595804 15749 solver.cpp:237]     Train net output #1: label_phocs = 157
I1212 18:58:19.595816 15749 solver.cpp:237]     Train net output #2: loss = 0.210573 (* 1 = 0.210573 loss)
I1212 18:58:19.595824 15749 sgd_solver.cpp:116] Iteration 56800, lr = 0.0001
I1212 19:00:49.959166 15749 solver.cpp:218] Iteration 56900 (0.665055 iter/s, 150.363s/100 iters), loss = 1.55951
I1212 19:00:49.959249 15749 solver.cpp:237]     Train net output #0: label = 1076
I1212 19:00:49.959272 15749 solver.cpp:237]     Train net output #1: label_phocs = 1076
I1212 19:00:49.959285 15749 solver.cpp:237]     Train net output #2: loss = 0.197841 (* 1 = 0.197841 loss)
I1212 19:00:49.959295 15749 sgd_solver.cpp:116] Iteration 56900, lr = 0.0001
[2017-12-12 19:03:47,518, PHOCNetTrainer] Running test evaluation
[2017-12-12 19:03:47,518, PHOCNetTrainer] Evaluating CNN after 56500 steps:
I1212 19:04:53.199905 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:04:53.200088 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 19:04:56,389, PHOCNetTrainer] mAP: 0.922006
I1212 19:04:56.391854 15749 solver.cpp:330] Iteration 57000, Testing net (#0)
I1212 19:04:56.392185 15749 net.cpp:676] Ignoring source layer drop6
I1212 19:04:56.392200 15749 net.cpp:676] Ignoring source layer drop7
I1212 19:05:54.707892 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:05:54.708385 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:05:55.570868 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 19:05:55.570935 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 19:05:55.570950 15749 solver.cpp:397]     Test net output #2: loss = 16.5665 (* 1 = 16.5665 loss)
I1212 19:05:57.165597 15749 solver.cpp:218] Iteration 57000 (0.32554 iter/s, 307.182s/100 iters), loss = 0.319046
I1212 19:05:57.165710 15749 solver.cpp:237]     Train net output #0: label = 1050
I1212 19:05:57.165741 15749 solver.cpp:237]     Train net output #1: label_phocs = 1050
I1212 19:05:57.165757 15749 solver.cpp:237]     Train net output #2: loss = 0.0266193 (* 1 = 0.0266193 loss)
I1212 19:05:57.165769 15749 sgd_solver.cpp:116] Iteration 57000, lr = 0.0001
I1212 19:09:13.775807 15749 solver.cpp:218] Iteration 57100 (0.508664 iter/s, 196.593s/100 iters), loss = 1.17476
I1212 19:09:13.775913 15749 solver.cpp:237]     Train net output #0: label = 387
I1212 19:09:13.775941 15749 solver.cpp:237]     Train net output #1: label_phocs = 387
I1212 19:09:13.775956 15749 solver.cpp:237]     Train net output #2: loss = 0.0331927 (* 1 = 0.0331927 loss)
I1212 19:09:13.775967 15749 sgd_solver.cpp:116] Iteration 57100, lr = 0.0001
I1212 19:12:36.347796 15749 solver.cpp:218] Iteration 57200 (0.493654 iter/s, 202.571s/100 iters), loss = 1.54021
I1212 19:12:36.347894 15749 solver.cpp:237]     Train net output #0: label = 55
I1212 19:12:36.347919 15749 solver.cpp:237]     Train net output #1: label_phocs = 55
I1212 19:12:36.347931 15749 solver.cpp:237]     Train net output #2: loss = 0.510989 (* 1 = 0.510989 loss)
I1212 19:12:36.347940 15749 sgd_solver.cpp:116] Iteration 57200, lr = 0.0001
I1212 19:16:16.973928 15749 solver.cpp:218] Iteration 57300 (0.453256 iter/s, 220.626s/100 iters), loss = 1.37995
I1212 19:16:16.974017 15749 solver.cpp:237]     Train net output #0: label = 12
I1212 19:16:16.974045 15749 solver.cpp:237]     Train net output #1: label_phocs = 12
I1212 19:16:16.974059 15749 solver.cpp:237]     Train net output #2: loss = 3.29137 (* 1 = 3.29137 loss)
I1212 19:16:16.974069 15749 sgd_solver.cpp:116] Iteration 57300, lr = 0.0001
I1212 19:19:03.547430 15749 solver.cpp:218] Iteration 57400 (0.600336 iter/s, 166.574s/100 iters), loss = 1.48619
I1212 19:19:03.547544 15749 solver.cpp:237]     Train net output #0: label = 881
I1212 19:19:03.547575 15749 solver.cpp:237]     Train net output #1: label_phocs = 881
I1212 19:19:03.547591 15749 solver.cpp:237]     Train net output #2: loss = 0.00314058 (* 1 = 0.00314058 loss)
I1212 19:19:03.547601 15749 sgd_solver.cpp:116] Iteration 57400, lr = 0.0001
[2017-12-12 19:21:58,361, PHOCNetTrainer] Running test evaluation
[2017-12-12 19:21:58,361, PHOCNetTrainer] Evaluating CNN after 57000 steps:
I1212 19:23:08.415896 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:23:08.416074 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 19:23:11,126, PHOCNetTrainer] mAP: 0.923078
I1212 19:23:11.148761 15749 solver.cpp:330] Iteration 57500, Testing net (#0)
I1212 19:23:11.149011 15749 net.cpp:676] Ignoring source layer drop6
I1212 19:23:11.149022 15749 net.cpp:676] Ignoring source layer drop7
I1212 19:24:14.917527 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:24:14.917552 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:24:15.876736 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 19:24:15.876791 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 19:24:15.876803 15749 solver.cpp:397]     Test net output #2: loss = 15.858 (* 1 = 15.858 loss)
I1212 19:24:17.736165 15749 solver.cpp:218] Iteration 57500 (0.3183 iter/s, 314.169s/100 iters), loss = 0.680999
I1212 19:24:17.736270 15749 solver.cpp:237]     Train net output #0: label = 919
I1212 19:24:17.736294 15749 solver.cpp:237]     Train net output #1: label_phocs = 919
I1212 19:24:17.736307 15749 solver.cpp:237]     Train net output #2: loss = 0.909407 (* 1 = 0.909407 loss)
I1212 19:24:17.736316 15749 sgd_solver.cpp:116] Iteration 57500, lr = 0.0001
I1212 19:27:13.949281 15749 solver.cpp:218] Iteration 57600 (0.567495 iter/s, 176.213s/100 iters), loss = 1.24357
I1212 19:27:13.949847 15749 solver.cpp:237]     Train net output #0: label = 673
I1212 19:27:13.949889 15749 solver.cpp:237]     Train net output #1: label_phocs = 673
I1212 19:27:13.949905 15749 solver.cpp:237]     Train net output #2: loss = 0.634183 (* 1 = 0.634183 loss)
I1212 19:27:13.949915 15749 sgd_solver.cpp:116] Iteration 57600, lr = 0.0001
I1212 19:30:13.591533 15749 solver.cpp:218] Iteration 57700 (0.556706 iter/s, 179.628s/100 iters), loss = 1.25567
I1212 19:30:13.591639 15749 solver.cpp:237]     Train net output #0: label = 241
I1212 19:30:13.591667 15749 solver.cpp:237]     Train net output #1: label_phocs = 241
I1212 19:30:13.591684 15749 solver.cpp:237]     Train net output #2: loss = 1.82729 (* 1 = 1.82729 loss)
I1212 19:30:13.591696 15749 sgd_solver.cpp:116] Iteration 57700, lr = 0.0001
I1212 19:33:08.776973 15749 solver.cpp:218] Iteration 57800 (0.57093 iter/s, 175.153s/100 iters), loss = 1.74397
I1212 19:33:08.777076 15749 solver.cpp:237]     Train net output #0: label = 193
I1212 19:33:08.777107 15749 solver.cpp:237]     Train net output #1: label_phocs = 193
I1212 19:33:08.777122 15749 solver.cpp:237]     Train net output #2: loss = 9.85178 (* 1 = 9.85178 loss)
I1212 19:33:08.777133 15749 sgd_solver.cpp:116] Iteration 57800, lr = 0.0001
I1212 19:35:41.764657 15749 solver.cpp:218] Iteration 57900 (0.653709 iter/s, 152.973s/100 iters), loss = 1.14905
I1212 19:35:41.764755 15749 solver.cpp:237]     Train net output #0: label = 578
I1212 19:35:41.764781 15749 solver.cpp:237]     Train net output #1: label_phocs = 578
I1212 19:35:41.764792 15749 solver.cpp:237]     Train net output #2: loss = 5.78853 (* 1 = 5.78853 loss)
I1212 19:35:41.764802 15749 sgd_solver.cpp:116] Iteration 57900, lr = 0.0001
[2017-12-12 19:37:59,244, PHOCNetTrainer] Running test evaluation
[2017-12-12 19:37:59,244, PHOCNetTrainer] Evaluating CNN after 57500 steps:
I1212 19:38:56.083667 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:38:56.083834 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 19:38:58,260, PHOCNetTrainer] mAP: 0.920295
I1212 19:38:58.262109 15749 solver.cpp:330] Iteration 58000, Testing net (#0)
I1212 19:38:58.262404 15749 net.cpp:676] Ignoring source layer drop6
I1212 19:38:58.262428 15749 net.cpp:676] Ignoring source layer drop7
I1212 19:39:41.027889 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:39:41.028039 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:39:41.763185 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 19:39:41.763247 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 19:39:41.763263 15749 solver.cpp:397]     Test net output #2: loss = 16.5653 (* 1 = 16.5653 loss)
I1212 19:39:43.443758 15749 solver.cpp:218] Iteration 58000 (0.413785 iter/s, 241.671s/100 iters), loss = 0.863257
I1212 19:39:43.443850 15749 solver.cpp:237]     Train net output #0: label = 1054
I1212 19:39:43.443881 15749 solver.cpp:237]     Train net output #1: label_phocs = 1054
I1212 19:39:43.443898 15749 solver.cpp:237]     Train net output #2: loss = 1.53431 (* 1 = 1.53431 loss)
I1212 19:39:43.443912 15749 sgd_solver.cpp:116] Iteration 58000, lr = 0.0001
I1212 19:41:53.342214 15749 solver.cpp:218] Iteration 58100 (0.769832 iter/s, 129.898s/100 iters), loss = 1.26783
I1212 19:41:53.369313 15749 solver.cpp:237]     Train net output #0: label = 848
I1212 19:41:53.369385 15749 solver.cpp:237]     Train net output #1: label_phocs = 848
I1212 19:41:53.369401 15749 solver.cpp:237]     Train net output #2: loss = 3.32711 (* 1 = 3.32711 loss)
I1212 19:41:53.369412 15749 sgd_solver.cpp:116] Iteration 58100, lr = 0.0001
I1212 19:44:18.939937 15749 solver.cpp:218] Iteration 58200 (0.686967 iter/s, 145.567s/100 iters), loss = 1.31737
I1212 19:44:18.940043 15749 solver.cpp:237]     Train net output #0: label = 1105
I1212 19:44:18.940068 15749 solver.cpp:237]     Train net output #1: label_phocs = 1105
I1212 19:44:18.940080 15749 solver.cpp:237]     Train net output #2: loss = 0.38362 (* 1 = 0.38362 loss)
I1212 19:44:18.940091 15749 sgd_solver.cpp:116] Iteration 58200, lr = 0.0001
I1212 19:46:34.811799 15749 solver.cpp:218] Iteration 58300 (0.736085 iter/s, 135.854s/100 iters), loss = 1.43977
I1212 19:46:34.811908 15749 solver.cpp:237]     Train net output #0: label = 1004
I1212 19:46:34.811933 15749 solver.cpp:237]     Train net output #1: label_phocs = 1004
I1212 19:46:34.811945 15749 solver.cpp:237]     Train net output #2: loss = 0.209626 (* 1 = 0.209626 loss)
I1212 19:46:34.811954 15749 sgd_solver.cpp:116] Iteration 58300, lr = 0.0001
I1212 19:49:00.829334 15749 solver.cpp:218] Iteration 58400 (0.684995 iter/s, 145.987s/100 iters), loss = 1.29545
I1212 19:49:00.829442 15749 solver.cpp:237]     Train net output #0: label = 1065
I1212 19:49:00.829468 15749 solver.cpp:237]     Train net output #1: label_phocs = 1065
I1212 19:49:00.829481 15749 solver.cpp:237]     Train net output #2: loss = 3.38909 (* 1 = 3.38909 loss)
I1212 19:49:00.829490 15749 sgd_solver.cpp:116] Iteration 58400, lr = 0.0001
[2017-12-12 19:51:18,512, PHOCNetTrainer] Running test evaluation
[2017-12-12 19:51:18,513, PHOCNetTrainer] Evaluating CNN after 58000 steps:
I1212 19:52:06.039894 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:52:06.040175 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 19:52:08,927, PHOCNetTrainer] mAP: 0.923467
I1212 19:52:08.928800 15749 solver.cpp:330] Iteration 58500, Testing net (#0)
I1212 19:52:08.929049 15749 net.cpp:676] Ignoring source layer drop6
I1212 19:52:08.929060 15749 net.cpp:676] Ignoring source layer drop7
I1212 19:53:04.107882 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:53:04.108036 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 19:53:05.045192 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 19:53:05.045253 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 19:53:05.045267 15749 solver.cpp:397]     Test net output #2: loss = 16.1304 (* 1 = 16.1304 loss)
I1212 19:53:06.368069 15749 solver.cpp:218] Iteration 58500 (0.407268 iter/s, 245.539s/100 iters), loss = 0.661525
I1212 19:53:06.368185 15749 solver.cpp:237]     Train net output #0: label = 33
I1212 19:53:06.368216 15749 solver.cpp:237]     Train net output #1: label_phocs = 33
I1212 19:53:06.368230 15749 solver.cpp:237]     Train net output #2: loss = 0.0568736 (* 1 = 0.0568736 loss)
I1212 19:53:06.368242 15749 sgd_solver.cpp:116] Iteration 58500, lr = 0.0001
I1212 19:55:14.322401 15749 solver.cpp:218] Iteration 58600 (0.781559 iter/s, 127.949s/100 iters), loss = 1.21685
I1212 19:55:14.322518 15749 solver.cpp:237]     Train net output #0: label = 1107
I1212 19:55:14.322547 15749 solver.cpp:237]     Train net output #1: label_phocs = 1107
I1212 19:55:14.322563 15749 solver.cpp:237]     Train net output #2: loss = 0.615396 (* 1 = 0.615396 loss)
I1212 19:55:14.322574 15749 sgd_solver.cpp:116] Iteration 58600, lr = 0.0001
I1212 19:57:32.457953 15749 solver.cpp:218] Iteration 58700 (0.723927 iter/s, 138.136s/100 iters), loss = 1.2414
I1212 19:57:32.458075 15749 solver.cpp:237]     Train net output #0: label = 206
I1212 19:57:32.458104 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1212 19:57:32.458125 15749 solver.cpp:237]     Train net output #2: loss = 0.120639 (* 1 = 0.120639 loss)
I1212 19:57:32.458137 15749 sgd_solver.cpp:116] Iteration 58700, lr = 0.0001
I1212 19:59:49.603801 15749 solver.cpp:218] Iteration 58800 (0.729246 iter/s, 137.128s/100 iters), loss = 1.14228
I1212 19:59:49.603907 15749 solver.cpp:237]     Train net output #0: label = 1073
I1212 19:59:49.603931 15749 solver.cpp:237]     Train net output #1: label_phocs = 1073
I1212 19:59:49.603943 15749 solver.cpp:237]     Train net output #2: loss = 0.304114 (* 1 = 0.304114 loss)
I1212 19:59:49.603953 15749 sgd_solver.cpp:116] Iteration 58800, lr = 0.0001
I1212 20:02:10.415722 15749 solver.cpp:218] Iteration 58900 (0.710167 iter/s, 140.812s/100 iters), loss = 1.47151
I1212 20:02:10.415812 15749 solver.cpp:237]     Train net output #0: label = 7
I1212 20:02:10.415832 15749 solver.cpp:237]     Train net output #1: label_phocs = 7
I1212 20:02:10.415840 15749 solver.cpp:237]     Train net output #2: loss = 0.524818 (* 1 = 0.524818 loss)
I1212 20:02:10.415848 15749 sgd_solver.cpp:116] Iteration 58900, lr = 0.0001
[2017-12-12 20:04:30,375, PHOCNetTrainer] Running test evaluation
[2017-12-12 20:04:30,375, PHOCNetTrainer] Evaluating CNN after 58500 steps:
I1212 20:05:22.487855 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:05:22.488076 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 20:05:23,649, PHOCNetTrainer] mAP: 0.912255
I1212 20:05:23.651314 15749 solver.cpp:330] Iteration 59000, Testing net (#0)
I1212 20:05:23.651576 15749 net.cpp:676] Ignoring source layer drop6
I1212 20:05:23.651587 15749 net.cpp:676] Ignoring source layer drop7
I1212 20:06:09.115886 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:06:09.116104 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:06:09.995043 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 20:06:09.995101 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 20:06:09.995116 15749 solver.cpp:397]     Test net output #2: loss = 17.2106 (* 1 = 17.2106 loss)
I1212 20:06:11.981822 15749 solver.cpp:218] Iteration 59000 (0.413966 iter/s, 241.566s/100 iters), loss = 1.40649
I1212 20:06:11.981904 15749 solver.cpp:237]     Train net output #0: label = 1026
I1212 20:06:11.981930 15749 solver.cpp:237]     Train net output #1: label_phocs = 1026
I1212 20:06:11.981942 15749 solver.cpp:237]     Train net output #2: loss = 1.90481 (* 1 = 1.90481 loss)
I1212 20:06:11.981953 15749 sgd_solver.cpp:116] Iteration 59000, lr = 0.0001
I1212 20:08:41.862920 15749 solver.cpp:218] Iteration 59100 (0.667196 iter/s, 149.881s/100 iters), loss = 1.32433
I1212 20:08:41.863037 15749 solver.cpp:237]     Train net output #0: label = 613
I1212 20:08:41.863075 15749 solver.cpp:237]     Train net output #1: label_phocs = 613
I1212 20:08:41.863093 15749 solver.cpp:237]     Train net output #2: loss = 0.00109985 (* 1 = 0.00109985 loss)
I1212 20:08:41.863106 15749 sgd_solver.cpp:116] Iteration 59100, lr = 0.0001
I1212 20:11:06.803066 15749 solver.cpp:218] Iteration 59200 (0.690054 iter/s, 144.916s/100 iters), loss = 1.21402
I1212 20:11:06.803189 15749 solver.cpp:237]     Train net output #0: label = 933
I1212 20:11:06.803217 15749 solver.cpp:237]     Train net output #1: label_phocs = 933
I1212 20:11:06.803234 15749 solver.cpp:237]     Train net output #2: loss = 0.150121 (* 1 = 0.150121 loss)
I1212 20:11:06.803246 15749 sgd_solver.cpp:116] Iteration 59200, lr = 0.0001
I1212 20:13:27.553325 15749 solver.cpp:218] Iteration 59300 (0.710479 iter/s, 140.75s/100 iters), loss = 1.0982
I1212 20:13:27.553452 15749 solver.cpp:237]     Train net output #0: label = 338
I1212 20:13:27.553483 15749 solver.cpp:237]     Train net output #1: label_phocs = 338
I1212 20:13:27.553498 15749 solver.cpp:237]     Train net output #2: loss = 0.0350825 (* 1 = 0.0350825 loss)
I1212 20:13:27.553511 15749 sgd_solver.cpp:116] Iteration 59300, lr = 0.0001
I1212 20:15:45.150969 15749 solver.cpp:218] Iteration 59400 (0.726757 iter/s, 137.598s/100 iters), loss = 1.23486
I1212 20:15:45.151088 15749 solver.cpp:237]     Train net output #0: label = 481
I1212 20:15:45.151119 15749 solver.cpp:237]     Train net output #1: label_phocs = 481
I1212 20:15:45.151134 15749 solver.cpp:237]     Train net output #2: loss = 0.517002 (* 1 = 0.517002 loss)
I1212 20:15:45.151145 15749 sgd_solver.cpp:116] Iteration 59400, lr = 0.0001
[2017-12-12 20:17:54,778, PHOCNetTrainer] Running test evaluation
[2017-12-12 20:17:54,778, PHOCNetTrainer] Evaluating CNN after 59000 steps:
I1212 20:18:36.967909 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:18:36.968051 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 20:18:39,996, PHOCNetTrainer] mAP: 0.917619
I1212 20:18:39.998329 15749 solver.cpp:330] Iteration 59500, Testing net (#0)
I1212 20:18:39.998598 15749 net.cpp:676] Ignoring source layer drop6
I1212 20:18:39.998620 15749 net.cpp:676] Ignoring source layer drop7
I1212 20:19:35.440579 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:19:35.440814 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:19:35.788322 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 20:19:35.788380 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 20:19:35.788396 15749 solver.cpp:397]     Test net output #2: loss = 16.4469 (* 1 = 16.4469 loss)
I1212 20:19:36.554510 15749 solver.cpp:218] Iteration 59500 (0.432146 iter/s, 231.403s/100 iters), loss = 0.902979
I1212 20:19:36.554605 15749 solver.cpp:237]     Train net output #0: label = 302
I1212 20:19:36.554633 15749 solver.cpp:237]     Train net output #1: label_phocs = 302
I1212 20:19:36.554647 15749 solver.cpp:237]     Train net output #2: loss = 0.593685 (* 1 = 0.593685 loss)
I1212 20:19:36.554658 15749 sgd_solver.cpp:116] Iteration 59500, lr = 0.0001
I1212 20:21:54.693766 15749 solver.cpp:218] Iteration 59600 (0.723907 iter/s, 138.139s/100 iters), loss = 1.19219
I1212 20:21:54.693888 15749 solver.cpp:237]     Train net output #0: label = 275
I1212 20:21:54.693920 15749 solver.cpp:237]     Train net output #1: label_phocs = 275
I1212 20:21:54.693935 15749 solver.cpp:237]     Train net output #2: loss = 0.0324574 (* 1 = 0.0324574 loss)
I1212 20:21:54.693945 15749 sgd_solver.cpp:116] Iteration 59600, lr = 0.0001
I1212 20:24:15.887761 15749 solver.cpp:218] Iteration 59700 (0.708246 iter/s, 141.194s/100 iters), loss = 1.19733
I1212 20:24:15.887868 15749 solver.cpp:237]     Train net output #0: label = 640
I1212 20:24:15.887897 15749 solver.cpp:237]     Train net output #1: label_phocs = 640
I1212 20:24:15.887912 15749 solver.cpp:237]     Train net output #2: loss = 0.0710287 (* 1 = 0.0710287 loss)
I1212 20:24:15.887923 15749 sgd_solver.cpp:116] Iteration 59700, lr = 0.0001
I1212 20:26:04.307490 15749 solver.cpp:218] Iteration 59800 (0.922342 iter/s, 108.42s/100 iters), loss = 1.45639
I1212 20:26:04.307552 15749 solver.cpp:237]     Train net output #0: label = 798
I1212 20:26:04.307572 15749 solver.cpp:237]     Train net output #1: label_phocs = 798
I1212 20:26:04.307579 15749 solver.cpp:237]     Train net output #2: loss = 0.347035 (* 1 = 0.347035 loss)
I1212 20:26:04.307585 15749 sgd_solver.cpp:116] Iteration 59800, lr = 0.0001
I1212 20:27:47.457178 15749 solver.cpp:218] Iteration 59900 (0.969465 iter/s, 103.15s/100 iters), loss = 1.39935
I1212 20:27:47.457247 15749 solver.cpp:237]     Train net output #0: label = 365
I1212 20:27:47.457268 15749 solver.cpp:237]     Train net output #1: label_phocs = 365
I1212 20:27:47.457280 15749 solver.cpp:237]     Train net output #2: loss = 0.00962561 (* 1 = 0.00962561 loss)
I1212 20:27:47.457288 15749 sgd_solver.cpp:116] Iteration 59900, lr = 0.0001
[2017-12-12 20:29:28,622, PHOCNetTrainer] Running test evaluation
[2017-12-12 20:29:28,622, PHOCNetTrainer] Evaluating CNN after 59500 steps:
I1212 20:29:53.659858 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:29:53.659974 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 20:29:54,694, PHOCNetTrainer] mAP: 0.914273
I1212 20:29:54.696296 15749 solver.cpp:330] Iteration 60000, Testing net (#0)
I1212 20:29:54.696494 15749 net.cpp:676] Ignoring source layer drop6
I1212 20:29:54.696503 15749 net.cpp:676] Ignoring source layer drop7
I1212 20:30:19.335853 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:30:19.335983 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:30:19.704136 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 20:30:19.704181 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 20:30:19.704191 15749 solver.cpp:397]     Test net output #2: loss = 17.8667 (* 1 = 17.8667 loss)
I1212 20:30:20.751021 15749 solver.cpp:218] Iteration 60000 (0.652342 iter/s, 153.294s/100 iters), loss = 0.448463
I1212 20:30:20.751103 15749 solver.cpp:237]     Train net output #0: label = 739
I1212 20:30:20.751127 15749 solver.cpp:237]     Train net output #1: label_phocs = 739
I1212 20:30:20.751138 15749 solver.cpp:237]     Train net output #2: loss = 0.242774 (* 1 = 0.242774 loss)
I1212 20:30:20.751147 15749 sgd_solver.cpp:116] Iteration 60000, lr = 0.0001
I1212 20:32:02.555467 15749 solver.cpp:218] Iteration 60100 (0.982275 iter/s, 101.804s/100 iters), loss = 1.22616
I1212 20:32:02.555550 15749 solver.cpp:237]     Train net output #0: label = 427
I1212 20:32:02.555573 15749 solver.cpp:237]     Train net output #1: label_phocs = 427
I1212 20:32:02.555584 15749 solver.cpp:237]     Train net output #2: loss = 0.0690138 (* 1 = 0.0690138 loss)
I1212 20:32:02.555593 15749 sgd_solver.cpp:116] Iteration 60100, lr = 0.0001
I1212 20:33:51.924259 15749 solver.cpp:218] Iteration 60200 (0.914338 iter/s, 109.369s/100 iters), loss = 1.22077
I1212 20:33:51.924345 15749 solver.cpp:237]     Train net output #0: label = 1123
I1212 20:33:51.924367 15749 solver.cpp:237]     Train net output #1: label_phocs = 1123
I1212 20:33:51.924379 15749 solver.cpp:237]     Train net output #2: loss = 1.13087 (* 1 = 1.13087 loss)
I1212 20:33:51.924387 15749 sgd_solver.cpp:116] Iteration 60200, lr = 0.0001
I1212 20:35:49.597437 15749 solver.cpp:218] Iteration 60300 (0.85012 iter/s, 117.63s/100 iters), loss = 1.23662
I1212 20:35:49.597519 15749 solver.cpp:237]     Train net output #0: label = 884
I1212 20:35:49.597539 15749 solver.cpp:237]     Train net output #1: label_phocs = 884
I1212 20:35:49.597548 15749 solver.cpp:237]     Train net output #2: loss = 0.377843 (* 1 = 0.377843 loss)
I1212 20:35:49.597554 15749 sgd_solver.cpp:116] Iteration 60300, lr = 0.0001
I1212 20:37:38.039790 15749 solver.cpp:218] Iteration 60400 (0.922149 iter/s, 108.442s/100 iters), loss = 1.3554
I1212 20:37:38.039881 15749 solver.cpp:237]     Train net output #0: label = 552
I1212 20:37:38.039904 15749 solver.cpp:237]     Train net output #1: label_phocs = 552
I1212 20:37:38.039916 15749 solver.cpp:237]     Train net output #2: loss = 0.894111 (* 1 = 0.894111 loss)
I1212 20:37:38.039924 15749 sgd_solver.cpp:116] Iteration 60400, lr = 0.0001
[2017-12-12 20:39:25,905, PHOCNetTrainer] Running test evaluation
[2017-12-12 20:39:25,905, PHOCNetTrainer] Evaluating CNN after 60000 steps:
I1212 20:39:55.842862 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:39:55.842999 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 20:39:56,873, PHOCNetTrainer] mAP: 0.918972
I1212 20:39:56.874541 15749 solver.cpp:330] Iteration 60500, Testing net (#0)
I1212 20:39:56.874735 15749 net.cpp:676] Ignoring source layer drop6
I1212 20:39:56.874744 15749 net.cpp:676] Ignoring source layer drop7
I1212 20:40:22.919878 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:40:22.920120 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:40:23.234633 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 20:40:23.234675 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 20:40:23.234686 15749 solver.cpp:397]     Test net output #2: loss = 16.9149 (* 1 = 16.9149 loss)
I1212 20:40:24.545037 15749 solver.cpp:218] Iteration 60500 (0.600582 iter/s, 166.505s/100 iters), loss = 1.19601
I1212 20:40:24.545116 15749 solver.cpp:237]     Train net output #0: label = 1081
I1212 20:40:24.545140 15749 solver.cpp:237]     Train net output #1: label_phocs = 1081
I1212 20:40:24.545151 15749 solver.cpp:237]     Train net output #2: loss = 3.77069 (* 1 = 3.77069 loss)
I1212 20:40:24.545159 15749 sgd_solver.cpp:116] Iteration 60500, lr = 0.0001
I1212 20:42:06.452571 15749 solver.cpp:218] Iteration 60600 (0.981282 iter/s, 101.908s/100 iters), loss = 1.23683
I1212 20:42:06.452649 15749 solver.cpp:237]     Train net output #0: label = 380
I1212 20:42:06.452673 15749 solver.cpp:237]     Train net output #1: label_phocs = 380
I1212 20:42:06.452684 15749 solver.cpp:237]     Train net output #2: loss = 2.15646 (* 1 = 2.15646 loss)
I1212 20:42:06.452692 15749 sgd_solver.cpp:116] Iteration 60600, lr = 0.0001
I1212 20:43:50.969861 15749 solver.cpp:218] Iteration 60700 (0.95678 iter/s, 104.517s/100 iters), loss = 1.07352
I1212 20:43:50.969939 15749 solver.cpp:237]     Train net output #0: label = 932
I1212 20:43:50.969962 15749 solver.cpp:237]     Train net output #1: label_phocs = 932
I1212 20:43:50.969974 15749 solver.cpp:237]     Train net output #2: loss = 0.762095 (* 1 = 0.762095 loss)
I1212 20:43:50.969982 15749 sgd_solver.cpp:116] Iteration 60700, lr = 0.0001
I1212 20:45:37.289752 15749 solver.cpp:218] Iteration 60800 (0.940558 iter/s, 106.32s/100 iters), loss = 1.31241
I1212 20:45:37.289829 15749 solver.cpp:237]     Train net output #0: label = 318
I1212 20:45:37.289855 15749 solver.cpp:237]     Train net output #1: label_phocs = 318
I1212 20:45:37.289866 15749 solver.cpp:237]     Train net output #2: loss = 1.80623 (* 1 = 1.80623 loss)
I1212 20:45:37.289875 15749 sgd_solver.cpp:116] Iteration 60800, lr = 0.0001
I1212 20:47:25.648231 15749 solver.cpp:218] Iteration 60900 (0.922863 iter/s, 108.358s/100 iters), loss = 1.12102
I1212 20:47:25.648314 15749 solver.cpp:237]     Train net output #0: label = 863
I1212 20:47:25.648340 15749 solver.cpp:237]     Train net output #1: label_phocs = 863
I1212 20:47:25.648352 15749 solver.cpp:237]     Train net output #2: loss = 0.758788 (* 1 = 0.758788 loss)
I1212 20:47:25.648361 15749 sgd_solver.cpp:116] Iteration 60900, lr = 0.0001
[2017-12-12 20:49:41,368, PHOCNetTrainer] Running test evaluation
[2017-12-12 20:49:41,368, PHOCNetTrainer] Evaluating CNN after 60500 steps:
I1212 20:50:21.833480 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:50:21.833638 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 20:50:25,050, PHOCNetTrainer] mAP: 0.914696
I1212 20:50:25.052628 15749 solver.cpp:330] Iteration 61000, Testing net (#0)
I1212 20:50:25.052919 15749 net.cpp:676] Ignoring source layer drop6
I1212 20:50:25.052940 15749 net.cpp:676] Ignoring source layer drop7
I1212 20:51:11.459995 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:51:11.460047 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 20:51:11.811245 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 20:51:11.811296 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 20:51:11.811313 15749 solver.cpp:397]     Test net output #2: loss = 17.5392 (* 1 = 17.5392 loss)
I1212 20:51:12.745908 15749 solver.cpp:218] Iteration 61000 (0.440339 iter/s, 227.098s/100 iters), loss = 1.28968
I1212 20:51:12.746021 15749 solver.cpp:237]     Train net output #0: label = 1050
I1212 20:51:12.746052 15749 solver.cpp:237]     Train net output #1: label_phocs = 1050
I1212 20:51:12.746068 15749 solver.cpp:237]     Train net output #2: loss = 0.165452 (* 1 = 0.165452 loss)
I1212 20:51:12.746078 15749 sgd_solver.cpp:116] Iteration 61000, lr = 0.0001
I1212 20:53:34.969142 15749 solver.cpp:218] Iteration 61100 (0.70312 iter/s, 142.223s/100 iters), loss = 1.12293
I1212 20:53:34.969250 15749 solver.cpp:237]     Train net output #0: label = 119
I1212 20:53:34.969280 15749 solver.cpp:237]     Train net output #1: label_phocs = 119
I1212 20:53:34.969301 15749 solver.cpp:237]     Train net output #2: loss = 0.573824 (* 1 = 0.573824 loss)
I1212 20:53:34.969314 15749 sgd_solver.cpp:116] Iteration 61100, lr = 0.0001
I1212 20:55:58.462492 15749 solver.cpp:218] Iteration 61200 (0.696897 iter/s, 143.493s/100 iters), loss = 1.12924
I1212 20:55:58.462611 15749 solver.cpp:237]     Train net output #0: label = 963
I1212 20:55:58.462641 15749 solver.cpp:237]     Train net output #1: label_phocs = 963
I1212 20:55:58.462657 15749 solver.cpp:237]     Train net output #2: loss = 0.322691 (* 1 = 0.322691 loss)
I1212 20:55:58.462667 15749 sgd_solver.cpp:116] Iteration 61200, lr = 0.0001
I1212 20:58:21.367197 15749 solver.cpp:218] Iteration 61300 (0.699767 iter/s, 142.905s/100 iters), loss = 1.28322
I1212 20:58:21.367297 15749 solver.cpp:237]     Train net output #0: label = 653
I1212 20:58:21.367326 15749 solver.cpp:237]     Train net output #1: label_phocs = 653
I1212 20:58:21.367339 15749 solver.cpp:237]     Train net output #2: loss = 0.0114441 (* 1 = 0.0114441 loss)
I1212 20:58:21.367350 15749 sgd_solver.cpp:116] Iteration 61300, lr = 0.0001
I1212 21:00:38.960031 15749 solver.cpp:218] Iteration 61400 (0.726782 iter/s, 137.593s/100 iters), loss = 1.19126
I1212 21:00:38.960137 15749 solver.cpp:237]     Train net output #0: label = 1059
I1212 21:00:38.960167 15749 solver.cpp:237]     Train net output #1: label_phocs = 1059
I1212 21:00:38.960182 15749 solver.cpp:237]     Train net output #2: loss = 0.0270172 (* 1 = 0.0270172 loss)
I1212 21:00:38.960194 15749 sgd_solver.cpp:116] Iteration 61400, lr = 0.0001
[2017-12-12 21:02:39,729, PHOCNetTrainer] Running test evaluation
[2017-12-12 21:02:39,729, PHOCNetTrainer] Evaluating CNN after 61000 steps:
I1212 21:03:21.415029 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:03:21.415201 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 21:03:22,568, PHOCNetTrainer] mAP: 0.913353
I1212 21:03:22.570365 15749 solver.cpp:330] Iteration 61500, Testing net (#0)
I1212 21:03:22.570626 15749 net.cpp:676] Ignoring source layer drop6
I1212 21:03:22.570638 15749 net.cpp:676] Ignoring source layer drop7
I1212 21:04:00.251968 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:04:00.252115 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:04:00.738970 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 21:04:00.739027 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 21:04:00.739037 15749 solver.cpp:397]     Test net output #2: loss = 17.0546 (* 1 = 17.0546 loss)
I1212 21:04:01.886426 15749 solver.cpp:218] Iteration 61500 (0.492857 iter/s, 202.898s/100 iters), loss = 0.60597
I1212 21:04:01.886521 15749 solver.cpp:237]     Train net output #0: label = 541
I1212 21:04:01.886548 15749 solver.cpp:237]     Train net output #1: label_phocs = 541
I1212 21:04:01.886560 15749 solver.cpp:237]     Train net output #2: loss = 0.00228097 (* 1 = 0.00228097 loss)
I1212 21:04:01.886571 15749 sgd_solver.cpp:116] Iteration 61500, lr = 0.0001
I1212 21:06:26.109868 15749 solver.cpp:218] Iteration 61600 (0.69337 iter/s, 144.223s/100 iters), loss = 1.46463
I1212 21:06:26.109956 15749 solver.cpp:237]     Train net output #0: label = 1104
I1212 21:06:26.109983 15749 solver.cpp:237]     Train net output #1: label_phocs = 1104
I1212 21:06:26.109998 15749 solver.cpp:237]     Train net output #2: loss = 0.215772 (* 1 = 0.215772 loss)
I1212 21:06:26.110009 15749 sgd_solver.cpp:116] Iteration 61600, lr = 0.0001
I1212 21:08:44.124222 15749 solver.cpp:218] Iteration 61700 (0.724648 iter/s, 137.998s/100 iters), loss = 1.32297
I1212 21:08:44.124323 15749 solver.cpp:237]     Train net output #0: label = 421
I1212 21:08:44.124352 15749 solver.cpp:237]     Train net output #1: label_phocs = 421
I1212 21:08:44.124367 15749 solver.cpp:237]     Train net output #2: loss = 3.39654 (* 1 = 3.39654 loss)
I1212 21:08:44.124377 15749 sgd_solver.cpp:116] Iteration 61700, lr = 0.0001
I1212 21:11:01.197662 15749 solver.cpp:218] Iteration 61800 (0.729536 iter/s, 137.073s/100 iters), loss = 1.43273
I1212 21:11:01.197770 15749 solver.cpp:237]     Train net output #0: label = 812
I1212 21:11:01.197800 15749 solver.cpp:237]     Train net output #1: label_phocs = 812
I1212 21:11:01.197815 15749 solver.cpp:237]     Train net output #2: loss = 0.0220646 (* 1 = 0.0220646 loss)
I1212 21:11:01.197827 15749 sgd_solver.cpp:116] Iteration 61800, lr = 0.0001
I1212 21:13:16.972007 15749 solver.cpp:218] Iteration 61900 (0.736592 iter/s, 135.76s/100 iters), loss = 1.16188
I1212 21:13:16.972122 15749 solver.cpp:237]     Train net output #0: label = 824
I1212 21:13:16.972146 15749 solver.cpp:237]     Train net output #1: label_phocs = 824
I1212 21:13:16.972159 15749 solver.cpp:237]     Train net output #2: loss = 0.0417704 (* 1 = 0.0417704 loss)
I1212 21:13:16.972169 15749 sgd_solver.cpp:116] Iteration 61900, lr = 0.0001
[2017-12-12 21:15:31,745, PHOCNetTrainer] Running test evaluation
[2017-12-12 21:15:31,745, PHOCNetTrainer] Evaluating CNN after 61500 steps:
I1212 21:16:20.836580 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:16:20.836666 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 21:16:22,934, PHOCNetTrainer] mAP: 0.914400
I1212 21:16:22.935909 15749 solver.cpp:330] Iteration 62000, Testing net (#0)
I1212 21:16:22.936141 15749 net.cpp:676] Ignoring source layer drop6
I1212 21:16:22.936151 15749 net.cpp:676] Ignoring source layer drop7
I1212 21:17:04.839884 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:17:04.840039 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:17:05.195417 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 21:17:05.195477 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 21:17:05.195493 15749 solver.cpp:397]     Test net output #2: loss = 17.5251 (* 1 = 17.5251 loss)
I1212 21:17:06.107560 15749 solver.cpp:218] Iteration 62000 (0.436423 iter/s, 229.136s/100 iters), loss = 3.4415
I1212 21:17:06.107669 15749 solver.cpp:237]     Train net output #0: label = 859
I1212 21:17:06.107698 15749 solver.cpp:237]     Train net output #1: label_phocs = 859
I1212 21:17:06.107714 15749 solver.cpp:237]     Train net output #2: loss = 1.47145 (* 1 = 1.47145 loss)
I1212 21:17:06.107726 15749 sgd_solver.cpp:116] Iteration 62000, lr = 0.0001
I1212 21:19:17.464298 15749 solver.cpp:218] Iteration 62100 (0.761286 iter/s, 131.357s/100 iters), loss = 1.25997
I1212 21:19:17.464407 15749 solver.cpp:237]     Train net output #0: label = 927
I1212 21:19:17.464437 15749 solver.cpp:237]     Train net output #1: label_phocs = 927
I1212 21:19:17.464452 15749 solver.cpp:237]     Train net output #2: loss = 0.227313 (* 1 = 0.227313 loss)
I1212 21:19:17.464463 15749 sgd_solver.cpp:116] Iteration 62100, lr = 0.0001
I1212 21:21:37.768613 15749 solver.cpp:218] Iteration 62200 (0.712927 iter/s, 140.267s/100 iters), loss = 1.15397
I1212 21:21:37.768725 15749 solver.cpp:237]     Train net output #0: label = 624
I1212 21:21:37.768750 15749 solver.cpp:237]     Train net output #1: label_phocs = 624
I1212 21:21:37.768762 15749 solver.cpp:237]     Train net output #2: loss = 0.88175 (* 1 = 0.88175 loss)
I1212 21:21:37.768774 15749 sgd_solver.cpp:116] Iteration 62200, lr = 0.0001
I1212 21:23:59.330016 15749 solver.cpp:218] Iteration 62300 (0.706573 iter/s, 141.528s/100 iters), loss = 1.22803
I1212 21:23:59.330129 15749 solver.cpp:237]     Train net output #0: label = 1008
I1212 21:23:59.330158 15749 solver.cpp:237]     Train net output #1: label_phocs = 1008
I1212 21:23:59.330174 15749 solver.cpp:237]     Train net output #2: loss = 1.62945 (* 1 = 1.62945 loss)
I1212 21:23:59.330185 15749 sgd_solver.cpp:116] Iteration 62300, lr = 0.0001
I1212 21:26:20.754654 15749 solver.cpp:218] Iteration 62400 (0.707101 iter/s, 141.423s/100 iters), loss = 1.13825
I1212 21:26:20.754745 15749 solver.cpp:237]     Train net output #0: label = 156
I1212 21:26:20.754765 15749 solver.cpp:237]     Train net output #1: label_phocs = 156
I1212 21:26:20.754779 15749 solver.cpp:237]     Train net output #2: loss = 0.958503 (* 1 = 0.958503 loss)
I1212 21:26:20.754787 15749 sgd_solver.cpp:116] Iteration 62400, lr = 0.0001
[2017-12-12 21:28:30,334, PHOCNetTrainer] Running test evaluation
[2017-12-12 21:28:30,334, PHOCNetTrainer] Evaluating CNN after 62000 steps:
I1212 21:29:16.443125 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:29:16.443274 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 21:29:18,113, PHOCNetTrainer] mAP: 0.909330
I1212 21:29:18.171942 15749 solver.cpp:330] Iteration 62500, Testing net (#0)
I1212 21:29:18.172219 15749 net.cpp:676] Ignoring source layer drop6
I1212 21:29:18.172230 15749 net.cpp:676] Ignoring source layer drop7
I1212 21:30:07.789605 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:30:07.789742 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:30:08.631433 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 21:30:08.631494 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 21:30:08.631507 15749 solver.cpp:397]     Test net output #2: loss = 17.7322 (* 1 = 17.7322 loss)
I1212 21:30:09.880780 15749 solver.cpp:218] Iteration 62500 (0.436441 iter/s, 229.126s/100 iters), loss = 0.679498
I1212 21:30:09.880873 15749 solver.cpp:237]     Train net output #0: label = 381
I1212 21:30:09.880893 15749 solver.cpp:237]     Train net output #1: label_phocs = 381
I1212 21:30:09.880903 15749 solver.cpp:237]     Train net output #2: loss = 0.15731 (* 1 = 0.15731 loss)
I1212 21:30:09.880910 15749 sgd_solver.cpp:116] Iteration 62500, lr = 0.0001
I1212 21:32:26.924840 15749 solver.cpp:218] Iteration 62600 (0.729692 iter/s, 137.044s/100 iters), loss = 1.21546
I1212 21:32:26.924954 15749 solver.cpp:237]     Train net output #0: label = 432
I1212 21:32:26.924983 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1212 21:32:26.924998 15749 solver.cpp:237]     Train net output #2: loss = 0.0505937 (* 1 = 0.0505937 loss)
I1212 21:32:26.925010 15749 sgd_solver.cpp:116] Iteration 62600, lr = 0.0001
I1212 21:34:40.300437 15749 solver.cpp:218] Iteration 62700 (0.749801 iter/s, 133.369s/100 iters), loss = 1.37964
I1212 21:34:40.300551 15749 solver.cpp:237]     Train net output #0: label = 141
I1212 21:34:40.300577 15749 solver.cpp:237]     Train net output #1: label_phocs = 141
I1212 21:34:40.300590 15749 solver.cpp:237]     Train net output #2: loss = 3.21935 (* 1 = 3.21935 loss)
I1212 21:34:40.300601 15749 sgd_solver.cpp:116] Iteration 62700, lr = 0.0001
I1212 21:36:53.363571 15749 solver.cpp:218] Iteration 62800 (0.751523 iter/s, 133.063s/100 iters), loss = 1.14641
I1212 21:36:53.363682 15749 solver.cpp:237]     Train net output #0: label = 94
I1212 21:36:53.363710 15749 solver.cpp:237]     Train net output #1: label_phocs = 94
I1212 21:36:53.363725 15749 solver.cpp:237]     Train net output #2: loss = 0.901952 (* 1 = 0.901952 loss)
I1212 21:36:53.363737 15749 sgd_solver.cpp:116] Iteration 62800, lr = 0.0001
I1212 21:39:13.792935 15749 solver.cpp:218] Iteration 62900 (0.712241 iter/s, 140.402s/100 iters), loss = 1.16282
I1212 21:39:13.793056 15749 solver.cpp:237]     Train net output #0: label = 669
I1212 21:39:13.793090 15749 solver.cpp:237]     Train net output #1: label_phocs = 669
I1212 21:39:13.793107 15749 solver.cpp:237]     Train net output #2: loss = 0.073487 (* 1 = 0.073487 loss)
I1212 21:39:13.793119 15749 sgd_solver.cpp:116] Iteration 62900, lr = 0.0001
[2017-12-12 21:41:31,869, PHOCNetTrainer] Running test evaluation
[2017-12-12 21:41:31,869, PHOCNetTrainer] Evaluating CNN after 62500 steps:
I1212 21:42:24.631898 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:42:24.632048 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 21:42:27,491, PHOCNetTrainer] mAP: 0.918207
I1212 21:42:27.493247 15749 solver.cpp:330] Iteration 63000, Testing net (#0)
I1212 21:42:27.493505 15749 net.cpp:676] Ignoring source layer drop6
I1212 21:42:27.493526 15749 net.cpp:676] Ignoring source layer drop7
I1212 21:43:04.339282 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:43:04.339395 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:43:04.685904 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 21:43:04.685968 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 21:43:04.685984 15749 solver.cpp:397]     Test net output #2: loss = 17.5464 (* 1 = 17.5464 loss)
I1212 21:43:05.637591 15749 solver.cpp:218] Iteration 63000 (0.431324 iter/s, 231.844s/100 iters), loss = 1.21909
I1212 21:43:05.637673 15749 solver.cpp:237]     Train net output #0: label = 289
I1212 21:43:05.637701 15749 solver.cpp:237]     Train net output #1: label_phocs = 289
I1212 21:43:05.637717 15749 solver.cpp:237]     Train net output #2: loss = 0.276204 (* 1 = 0.276204 loss)
I1212 21:43:05.637727 15749 sgd_solver.cpp:116] Iteration 63000, lr = 0.0001
I1212 21:45:21.715149 15749 solver.cpp:218] Iteration 63100 (0.734875 iter/s, 136.078s/100 iters), loss = 1.20219
I1212 21:45:21.715273 15749 solver.cpp:237]     Train net output #0: label = 449
I1212 21:45:21.715301 15749 solver.cpp:237]     Train net output #1: label_phocs = 449
I1212 21:45:21.715315 15749 solver.cpp:237]     Train net output #2: loss = 0.055233 (* 1 = 0.055233 loss)
I1212 21:45:21.715327 15749 sgd_solver.cpp:116] Iteration 63100, lr = 0.0001
I1212 21:47:42.889493 15749 solver.cpp:218] Iteration 63200 (0.708344 iter/s, 141.174s/100 iters), loss = 1.09523
I1212 21:47:42.889621 15749 solver.cpp:237]     Train net output #0: label = 150
I1212 21:47:42.889653 15749 solver.cpp:237]     Train net output #1: label_phocs = 150
I1212 21:47:42.889669 15749 solver.cpp:237]     Train net output #2: loss = 0.357468 (* 1 = 0.357468 loss)
I1212 21:47:42.889683 15749 sgd_solver.cpp:116] Iteration 63200, lr = 0.0001
I1212 21:50:05.944150 15749 solver.cpp:218] Iteration 63300 (0.699035 iter/s, 143.054s/100 iters), loss = 1.10024
I1212 21:50:05.944236 15749 solver.cpp:237]     Train net output #0: label = 637
I1212 21:50:05.944259 15749 solver.cpp:237]     Train net output #1: label_phocs = 637
I1212 21:50:05.944272 15749 solver.cpp:237]     Train net output #2: loss = 0.00545915 (* 1 = 0.00545915 loss)
I1212 21:50:05.944281 15749 sgd_solver.cpp:116] Iteration 63300, lr = 0.0001
I1212 21:52:23.083245 15749 solver.cpp:218] Iteration 63400 (0.729189 iter/s, 137.139s/100 iters), loss = 1.00857
I1212 21:52:23.083358 15749 solver.cpp:237]     Train net output #0: label = 669
I1212 21:52:23.083382 15749 solver.cpp:237]     Train net output #1: label_phocs = 669
I1212 21:52:23.083395 15749 solver.cpp:237]     Train net output #2: loss = 0.792995 (* 1 = 0.792995 loss)
I1212 21:52:23.083406 15749 sgd_solver.cpp:116] Iteration 63400, lr = 0.0001
[2017-12-12 21:54:41,886, PHOCNetTrainer] Running test evaluation
[2017-12-12 21:54:41,887, PHOCNetTrainer] Evaluating CNN after 63000 steps:
I1212 21:55:30.055441 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:55:30.055644 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 21:55:32,031, PHOCNetTrainer] mAP: 0.916670
I1212 21:55:32.033476 15749 solver.cpp:330] Iteration 63500, Testing net (#0)
I1212 21:55:32.033752 15749 net.cpp:676] Ignoring source layer drop6
I1212 21:55:32.033778 15749 net.cpp:676] Ignoring source layer drop7
I1212 21:56:24.893813 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:56:24.894078 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 21:56:25.606041 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 21:56:25.606091 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 21:56:25.606101 15749 solver.cpp:397]     Test net output #2: loss = 16.656 (* 1 = 16.656 loss)
I1212 21:56:27.600463 15749 solver.cpp:218] Iteration 63500 (0.409051 iter/s, 244.468s/100 iters), loss = 0.906965
I1212 21:56:27.600546 15749 solver.cpp:237]     Train net output #0: label = 208
I1212 21:56:27.600574 15749 solver.cpp:237]     Train net output #1: label_phocs = 208
I1212 21:56:27.600584 15749 solver.cpp:237]     Train net output #2: loss = 0.0054082 (* 1 = 0.0054082 loss)
I1212 21:56:27.600590 15749 sgd_solver.cpp:116] Iteration 63500, lr = 0.0001
I1212 21:58:43.999264 15749 solver.cpp:218] Iteration 63600 (0.733412 iter/s, 136.349s/100 iters), loss = 1.17586
I1212 21:58:43.999379 15749 solver.cpp:237]     Train net output #0: label = 659
I1212 21:58:43.999403 15749 solver.cpp:237]     Train net output #1: label_phocs = 659
I1212 21:58:43.999415 15749 solver.cpp:237]     Train net output #2: loss = 0.383545 (* 1 = 0.383545 loss)
I1212 21:58:43.999425 15749 sgd_solver.cpp:116] Iteration 63600, lr = 0.0001
I1212 22:01:01.358597 15749 solver.cpp:218] Iteration 63700 (0.728018 iter/s, 137.359s/100 iters), loss = 1.40469
I1212 22:01:01.358708 15749 solver.cpp:237]     Train net output #0: label = 1082
I1212 22:01:01.358732 15749 solver.cpp:237]     Train net output #1: label_phocs = 1082
I1212 22:01:01.358745 15749 solver.cpp:237]     Train net output #2: loss = 1.31174 (* 1 = 1.31174 loss)
I1212 22:01:01.358755 15749 sgd_solver.cpp:116] Iteration 63700, lr = 0.0001
I1212 22:03:20.638857 15749 solver.cpp:218] Iteration 63800 (0.717977 iter/s, 139.28s/100 iters), loss = 1.27472
I1212 22:03:20.638972 15749 solver.cpp:237]     Train net output #0: label = 120
I1212 22:03:20.638998 15749 solver.cpp:237]     Train net output #1: label_phocs = 120
I1212 22:03:20.639010 15749 solver.cpp:237]     Train net output #2: loss = 0.0875528 (* 1 = 0.0875528 loss)
I1212 22:03:20.639020 15749 sgd_solver.cpp:116] Iteration 63800, lr = 0.0001
I1212 22:05:40.257740 15749 solver.cpp:218] Iteration 63900 (0.716236 iter/s, 139.619s/100 iters), loss = 1.15746
I1212 22:05:40.257858 15749 solver.cpp:237]     Train net output #0: label = 339
I1212 22:05:40.257882 15749 solver.cpp:237]     Train net output #1: label_phocs = 339
I1212 22:05:40.257895 15749 solver.cpp:237]     Train net output #2: loss = 0.341886 (* 1 = 0.341886 loss)
I1212 22:05:40.257906 15749 sgd_solver.cpp:116] Iteration 63900, lr = 0.0001
[2017-12-12 22:07:58,123, PHOCNetTrainer] Running test evaluation
[2017-12-12 22:07:58,123, PHOCNetTrainer] Evaluating CNN after 63500 steps:
I1212 22:08:45.579613 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:08:45.579804 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 22:08:47,051, PHOCNetTrainer] mAP: 0.922076
I1212 22:08:47.052640 15749 solver.cpp:330] Iteration 64000, Testing net (#0)
I1212 22:08:47.052901 15749 net.cpp:676] Ignoring source layer drop6
I1212 22:08:47.052911 15749 net.cpp:676] Ignoring source layer drop7
I1212 22:09:35.331858 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:09:35.332083 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:09:36.031118 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 22:09:36.031175 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 22:09:36.031193 15749 solver.cpp:397]     Test net output #2: loss = 16.2672 (* 1 = 16.2672 loss)
I1212 22:09:37.296954 15749 solver.cpp:218] Iteration 64000 (0.421871 iter/s, 237.039s/100 iters), loss = 0.886849
I1212 22:09:37.297065 15749 solver.cpp:237]     Train net output #0: label = 112
I1212 22:09:37.297093 15749 solver.cpp:237]     Train net output #1: label_phocs = 112
I1212 22:09:37.297108 15749 solver.cpp:237]     Train net output #2: loss = 0.170593 (* 1 = 0.170593 loss)
I1212 22:09:37.297118 15749 sgd_solver.cpp:116] Iteration 64000, lr = 0.0001
I1212 22:11:56.923794 15749 solver.cpp:218] Iteration 64100 (0.716267 iter/s, 139.613s/100 iters), loss = 0.961747
I1212 22:11:56.923888 15749 solver.cpp:237]     Train net output #0: label = 737
I1212 22:11:56.923913 15749 solver.cpp:237]     Train net output #1: label_phocs = 737
I1212 22:11:56.923925 15749 solver.cpp:237]     Train net output #2: loss = 0.0490076 (* 1 = 0.0490076 loss)
I1212 22:11:56.923934 15749 sgd_solver.cpp:116] Iteration 64100, lr = 0.0001
I1212 22:14:15.160382 15749 solver.cpp:218] Iteration 64200 (0.723502 iter/s, 138.217s/100 iters), loss = 1.021
I1212 22:14:15.160492 15749 solver.cpp:237]     Train net output #0: label = 452
I1212 22:14:15.160517 15749 solver.cpp:237]     Train net output #1: label_phocs = 452
I1212 22:14:15.160529 15749 solver.cpp:237]     Train net output #2: loss = 0.0193765 (* 1 = 0.0193765 loss)
I1212 22:14:15.160539 15749 sgd_solver.cpp:116] Iteration 64200, lr = 0.0001
I1212 22:16:29.307590 15749 solver.cpp:218] Iteration 64300 (0.74545 iter/s, 134.147s/100 iters), loss = 1.14857
I1212 22:16:29.307723 15749 solver.cpp:237]     Train net output #0: label = 1026
I1212 22:16:29.307757 15749 solver.cpp:237]     Train net output #1: label_phocs = 1026
I1212 22:16:29.307773 15749 solver.cpp:237]     Train net output #2: loss = 0.0914771 (* 1 = 0.0914771 loss)
I1212 22:16:29.307785 15749 sgd_solver.cpp:116] Iteration 64300, lr = 0.0001
I1212 22:18:46.412941 15749 solver.cpp:218] Iteration 64400 (0.729366 iter/s, 137.105s/100 iters), loss = 1.16831
I1212 22:18:46.413058 15749 solver.cpp:237]     Train net output #0: label = 932
I1212 22:18:46.413082 15749 solver.cpp:237]     Train net output #1: label_phocs = 932
I1212 22:18:46.413094 15749 solver.cpp:237]     Train net output #2: loss = 0.587921 (* 1 = 0.587921 loss)
I1212 22:18:46.413105 15749 sgd_solver.cpp:116] Iteration 64400, lr = 0.0001
[2017-12-12 22:20:58,983, PHOCNetTrainer] Running test evaluation
[2017-12-12 22:20:58,983, PHOCNetTrainer] Evaluating CNN after 64000 steps:
I1212 22:21:37.523087 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:21:37.523404 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 22:21:39,710, PHOCNetTrainer] mAP: 0.910864
I1212 22:21:39.712759 15749 solver.cpp:330] Iteration 64500, Testing net (#0)
I1212 22:21:39.713022 15749 net.cpp:676] Ignoring source layer drop6
I1212 22:21:39.713034 15749 net.cpp:676] Ignoring source layer drop7
I1212 22:22:27.269502 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:22:27.269728 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:22:27.613744 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 22:22:27.613818 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 22:22:27.613837 15749 solver.cpp:397]     Test net output #2: loss = 17.7453 (* 1 = 17.7453 loss)
I1212 22:22:28.406532 15749 solver.cpp:218] Iteration 64500 (0.450463 iter/s, 221.994s/100 iters), loss = 0.985617
I1212 22:22:28.406641 15749 solver.cpp:237]     Train net output #0: label = 746
I1212 22:22:28.406669 15749 solver.cpp:237]     Train net output #1: label_phocs = 746
I1212 22:22:28.406684 15749 solver.cpp:237]     Train net output #2: loss = 1.18183 (* 1 = 1.18183 loss)
I1212 22:22:28.406697 15749 sgd_solver.cpp:116] Iteration 64500, lr = 0.0001
I1212 22:24:37.930274 15749 solver.cpp:218] Iteration 64600 (0.772293 iter/s, 129.485s/100 iters), loss = 1.12236
I1212 22:24:37.930389 15749 solver.cpp:237]     Train net output #0: label = 204
I1212 22:24:37.930415 15749 solver.cpp:237]     Train net output #1: label_phocs = 204
I1212 22:24:37.930428 15749 solver.cpp:237]     Train net output #2: loss = 1.36012 (* 1 = 1.36012 loss)
I1212 22:24:37.930438 15749 sgd_solver.cpp:116] Iteration 64600, lr = 0.0001
I1212 22:26:58.687268 15749 solver.cpp:218] Iteration 64700 (0.710649 iter/s, 140.717s/100 iters), loss = 0.890924
I1212 22:26:58.687391 15749 solver.cpp:237]     Train net output #0: label = 711
I1212 22:26:58.687422 15749 solver.cpp:237]     Train net output #1: label_phocs = 711
I1212 22:26:58.687438 15749 solver.cpp:237]     Train net output #2: loss = 0.882044 (* 1 = 0.882044 loss)
I1212 22:26:58.687449 15749 sgd_solver.cpp:116] Iteration 64700, lr = 0.0001
I1212 22:29:18.507269 15749 solver.cpp:218] Iteration 64800 (0.715205 iter/s, 139.82s/100 iters), loss = 1.01871
I1212 22:29:18.507385 15749 solver.cpp:237]     Train net output #0: label = 542
I1212 22:29:18.507407 15749 solver.cpp:237]     Train net output #1: label_phocs = 542
I1212 22:29:18.507422 15749 solver.cpp:237]     Train net output #2: loss = 0.0296187 (* 1 = 0.0296187 loss)
I1212 22:29:18.507431 15749 sgd_solver.cpp:116] Iteration 64800, lr = 0.0001
I1212 22:31:35.345021 15749 solver.cpp:218] Iteration 64900 (0.730793 iter/s, 136.838s/100 iters), loss = 1.05815
I1212 22:31:35.345144 15749 solver.cpp:237]     Train net output #0: label = 168
I1212 22:31:35.345171 15749 solver.cpp:237]     Train net output #1: label_phocs = 168
I1212 22:31:35.345186 15749 solver.cpp:237]     Train net output #2: loss = 0.143214 (* 1 = 0.143214 loss)
I1212 22:31:35.345198 15749 sgd_solver.cpp:116] Iteration 64900, lr = 0.0001
[2017-12-12 22:33:50,421, PHOCNetTrainer] Running test evaluation
[2017-12-12 22:33:50,422, PHOCNetTrainer] Evaluating CNN after 64500 steps:
I1212 22:34:36.719902 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:34:36.719902 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 22:34:38,011, PHOCNetTrainer] mAP: 0.920837
I1212 22:34:38.012540 15749 solver.cpp:330] Iteration 65000, Testing net (#0)
I1212 22:34:38.012786 15749 net.cpp:676] Ignoring source layer drop6
I1212 22:34:38.012802 15749 net.cpp:676] Ignoring source layer drop7
I1212 22:35:27.346832 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:35:27.346837 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:35:28.366925 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 22:35:28.366981 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 22:35:28.366994 15749 solver.cpp:397]     Test net output #2: loss = 17.3069 (* 1 = 17.3069 loss)
I1212 22:35:29.660233 15749 solver.cpp:218] Iteration 65000 (0.426799 iter/s, 234.302s/100 iters), loss = 0.760164
I1212 22:35:29.660332 15749 solver.cpp:237]     Train net output #0: label = 919
I1212 22:35:29.660358 15749 solver.cpp:237]     Train net output #1: label_phocs = 919
I1212 22:35:29.660372 15749 solver.cpp:237]     Train net output #2: loss = 0.0355505 (* 1 = 0.0355505 loss)
I1212 22:35:29.660383 15749 sgd_solver.cpp:116] Iteration 65000, lr = 0.0001
I1212 22:37:49.753890 15749 solver.cpp:218] Iteration 65100 (0.713808 iter/s, 140.094s/100 iters), loss = 1.26334
I1212 22:37:49.754006 15749 solver.cpp:237]     Train net output #0: label = 413
I1212 22:37:49.754032 15749 solver.cpp:237]     Train net output #1: label_phocs = 413
I1212 22:37:49.754046 15749 solver.cpp:237]     Train net output #2: loss = 0.00125891 (* 1 = 0.00125891 loss)
I1212 22:37:49.754056 15749 sgd_solver.cpp:116] Iteration 65100, lr = 0.0001
I1212 22:40:05.151547 15749 solver.cpp:218] Iteration 65200 (0.738565 iter/s, 135.398s/100 iters), loss = 1.09228
I1212 22:40:05.151684 15749 solver.cpp:237]     Train net output #0: label = 1005
I1212 22:40:05.151715 15749 solver.cpp:237]     Train net output #1: label_phocs = 1005
I1212 22:40:05.151732 15749 solver.cpp:237]     Train net output #2: loss = 0.162465 (* 1 = 0.162465 loss)
I1212 22:40:05.151746 15749 sgd_solver.cpp:116] Iteration 65200, lr = 0.0001
I1212 22:42:24.131866 15749 solver.cpp:218] Iteration 65300 (0.719584 iter/s, 138.969s/100 iters), loss = 1.05673
I1212 22:42:24.131997 15749 solver.cpp:237]     Train net output #0: label = 982
I1212 22:42:24.132026 15749 solver.cpp:237]     Train net output #1: label_phocs = 982
I1212 22:42:24.132042 15749 solver.cpp:237]     Train net output #2: loss = 0.0152602 (* 1 = 0.0152602 loss)
I1212 22:42:24.132053 15749 sgd_solver.cpp:116] Iteration 65300, lr = 0.0001
I1212 22:45:29.711601 15749 solver.cpp:218] Iteration 65400 (0.538873 iter/s, 185.572s/100 iters), loss = 1.11724
I1212 22:45:29.711711 15749 solver.cpp:237]     Train net output #0: label = 454
I1212 22:45:29.711737 15749 solver.cpp:237]     Train net output #1: label_phocs = 454
I1212 22:45:29.711762 15749 solver.cpp:237]     Train net output #2: loss = 0.176059 (* 1 = 0.176059 loss)
I1212 22:45:29.711773 15749 sgd_solver.cpp:116] Iteration 65400, lr = 0.0001
[2017-12-12 22:48:01,135, PHOCNetTrainer] Running test evaluation
[2017-12-12 22:48:01,135, PHOCNetTrainer] Evaluating CNN after 65000 steps:
I1212 22:49:46.992292 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:49:46.992463 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 22:49:49,274, PHOCNetTrainer] mAP: 0.926163
I1212 22:49:49.276031 15749 solver.cpp:330] Iteration 65500, Testing net (#0)
I1212 22:49:49.276293 15749 net.cpp:676] Ignoring source layer drop6
I1212 22:49:49.276304 15749 net.cpp:676] Ignoring source layer drop7
I1212 22:51:42.481256 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:51:42.481487 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 22:51:44.798676 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 22:51:44.798740 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 22:51:44.798753 15749 solver.cpp:397]     Test net output #2: loss = 15.9805 (* 1 = 15.9805 loss)
I1212 22:51:47.218487 15749 solver.cpp:218] Iteration 65500 (0.264912 iter/s, 377.484s/100 iters), loss = 0.897104
I1212 22:51:47.218631 15749 solver.cpp:237]     Train net output #0: label = 140
I1212 22:51:47.218654 15749 solver.cpp:237]     Train net output #1: label_phocs = 140
I1212 22:51:47.218667 15749 solver.cpp:237]     Train net output #2: loss = 0.34462 (* 1 = 0.34462 loss)
I1212 22:51:47.218675 15749 sgd_solver.cpp:116] Iteration 65500, lr = 0.0001
I1212 22:56:00.719061 15749 solver.cpp:218] Iteration 65600 (0.394482 iter/s, 253.497s/100 iters), loss = 0.94664
I1212 22:56:00.719173 15749 solver.cpp:237]     Train net output #0: label = 908
I1212 22:56:00.719202 15749 solver.cpp:237]     Train net output #1: label_phocs = 908
I1212 22:56:00.719216 15749 solver.cpp:237]     Train net output #2: loss = 5.37689 (* 1 = 5.37689 loss)
I1212 22:56:00.719228 15749 sgd_solver.cpp:116] Iteration 65600, lr = 0.0001
I1212 23:00:04.935729 15749 solver.cpp:218] Iteration 65700 (0.409478 iter/s, 244.214s/100 iters), loss = 1.00356
I1212 23:00:04.935835 15749 solver.cpp:237]     Train net output #0: label = 55
I1212 23:00:04.935865 15749 solver.cpp:237]     Train net output #1: label_phocs = 55
I1212 23:00:04.935880 15749 solver.cpp:237]     Train net output #2: loss = 3.19307 (* 1 = 3.19307 loss)
I1212 23:00:04.935890 15749 sgd_solver.cpp:116] Iteration 65700, lr = 0.0001
I1212 23:03:44.483769 15749 solver.cpp:218] Iteration 65800 (0.455481 iter/s, 219.548s/100 iters), loss = 0.964075
I1212 23:03:44.484905 15749 solver.cpp:237]     Train net output #0: label = 906
I1212 23:03:44.484989 15749 solver.cpp:237]     Train net output #1: label_phocs = 906
I1212 23:03:44.485005 15749 solver.cpp:237]     Train net output #2: loss = 0.137378 (* 1 = 0.137378 loss)
I1212 23:03:44.485016 15749 sgd_solver.cpp:116] Iteration 65800, lr = 0.0001
I1212 23:07:52.328204 15749 solver.cpp:218] Iteration 65900 (0.403498 iter/s, 247.833s/100 iters), loss = 1.26791
I1212 23:07:52.328976 15749 solver.cpp:237]     Train net output #0: label = 856
I1212 23:07:52.329025 15749 solver.cpp:237]     Train net output #1: label_phocs = 856
I1212 23:07:52.329046 15749 solver.cpp:237]     Train net output #2: loss = 0.0432846 (* 1 = 0.0432846 loss)
I1212 23:07:52.329066 15749 sgd_solver.cpp:116] Iteration 65900, lr = 0.0001
[2017-12-12 23:11:47,033, PHOCNetTrainer] Running test evaluation
[2017-12-12 23:11:47,033, PHOCNetTrainer] Evaluating CNN after 65500 steps:
I1212 23:13:40.423856 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:13:40.424033 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 23:13:44,406, PHOCNetTrainer] mAP: 0.922152
I1212 23:13:44.407861 15749 solver.cpp:330] Iteration 66000, Testing net (#0)
I1212 23:13:44.408152 15749 net.cpp:676] Ignoring source layer drop6
I1212 23:13:44.408166 15749 net.cpp:676] Ignoring source layer drop7
I1212 23:15:11.250663 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:15:11.251860 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:15:12.799957 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 23:15:12.800016 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 23:15:12.800031 15749 solver.cpp:397]     Test net output #2: loss = 16.7456 (* 1 = 16.7456 loss)
I1212 23:15:15.400990 15749 solver.cpp:218] Iteration 66000 (0.225709 iter/s, 443.049s/100 iters), loss = 1.02996
I1212 23:15:15.401649 15749 solver.cpp:237]     Train net output #0: label = 819
I1212 23:15:15.401696 15749 solver.cpp:237]     Train net output #1: label_phocs = 819
I1212 23:15:15.401710 15749 solver.cpp:237]     Train net output #2: loss = 2.35336 (* 1 = 2.35336 loss)
I1212 23:15:15.401721 15749 sgd_solver.cpp:116] Iteration 66000, lr = 0.0001
I1212 23:18:30.569492 15749 solver.cpp:218] Iteration 66100 (0.51241 iter/s, 195.156s/100 iters), loss = 0.977211
I1212 23:18:30.570683 15749 solver.cpp:237]     Train net output #0: label = 243
I1212 23:18:30.570713 15749 solver.cpp:237]     Train net output #1: label_phocs = 243
I1212 23:18:30.570724 15749 solver.cpp:237]     Train net output #2: loss = 0.103385 (* 1 = 0.103385 loss)
I1212 23:18:30.570734 15749 sgd_solver.cpp:116] Iteration 66100, lr = 0.0001
I1212 23:21:37.555840 15749 solver.cpp:218] Iteration 66200 (0.534801 iter/s, 186.985s/100 iters), loss = 1.10501
I1212 23:21:37.557024 15749 solver.cpp:237]     Train net output #0: label = 805
I1212 23:21:37.557056 15749 solver.cpp:237]     Train net output #1: label_phocs = 805
I1212 23:21:37.557070 15749 solver.cpp:237]     Train net output #2: loss = 0.257564 (* 1 = 0.257564 loss)
I1212 23:21:37.557078 15749 sgd_solver.cpp:116] Iteration 66200, lr = 0.0001
I1212 23:24:28.792742 15749 solver.cpp:218] Iteration 66300 (0.58399 iter/s, 171.236s/100 iters), loss = 1.05366
I1212 23:24:28.793056 15749 solver.cpp:237]     Train net output #0: label = 206
I1212 23:24:28.793079 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1212 23:24:28.793090 15749 solver.cpp:237]     Train net output #2: loss = 2.59821 (* 1 = 2.59821 loss)
I1212 23:24:28.793099 15749 sgd_solver.cpp:116] Iteration 66300, lr = 0.0001
I1212 23:27:39.740007 15749 solver.cpp:218] Iteration 66400 (0.523705 iter/s, 190.947s/100 iters), loss = 1.2683
I1212 23:27:39.741139 15749 solver.cpp:237]     Train net output #0: label = 938
I1212 23:27:39.741194 15749 solver.cpp:237]     Train net output #1: label_phocs = 938
I1212 23:27:39.741212 15749 solver.cpp:237]     Train net output #2: loss = 0.113315 (* 1 = 0.113315 loss)
I1212 23:27:39.741224 15749 sgd_solver.cpp:116] Iteration 66400, lr = 0.0001
[2017-12-12 23:31:18,915, PHOCNetTrainer] Running test evaluation
[2017-12-12 23:31:18,915, PHOCNetTrainer] Evaluating CNN after 66000 steps:
I1212 23:33:07.204751 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:33:07.205963 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 23:33:10,024, PHOCNetTrainer] mAP: 0.914628
I1212 23:33:10.026362 15749 solver.cpp:330] Iteration 66500, Testing net (#0)
I1212 23:33:10.026618 15749 net.cpp:676] Ignoring source layer drop6
I1212 23:33:10.026629 15749 net.cpp:676] Ignoring source layer drop7
I1212 23:34:42.083887 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:34:42.084041 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:34:42.755169 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 23:34:42.755231 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 23:34:42.755244 15749 solver.cpp:397]     Test net output #2: loss = 17.4021 (* 1 = 17.4021 loss)
I1212 23:34:44.842677 15749 solver.cpp:218] Iteration 66500 (0.235238 iter/s, 425.102s/100 iters), loss = 1.05853
I1212 23:34:44.842793 15749 solver.cpp:237]     Train net output #0: label = 348
I1212 23:34:44.842818 15749 solver.cpp:237]     Train net output #1: label_phocs = 348
I1212 23:34:44.842830 15749 solver.cpp:237]     Train net output #2: loss = 1.29885 (* 1 = 1.29885 loss)
I1212 23:34:44.842840 15749 sgd_solver.cpp:116] Iteration 66500, lr = 0.0001
I1212 23:38:19.796643 15749 solver.cpp:218] Iteration 66600 (0.465216 iter/s, 214.954s/100 iters), loss = 1.2134
I1212 23:38:19.797818 15749 solver.cpp:237]     Train net output #0: label = 1058
I1212 23:38:19.797901 15749 solver.cpp:237]     Train net output #1: label_phocs = 1058
I1212 23:38:19.797919 15749 solver.cpp:237]     Train net output #2: loss = 0.0639444 (* 1 = 0.0639444 loss)
I1212 23:38:19.797931 15749 sgd_solver.cpp:116] Iteration 66600, lr = 0.0001
I1212 23:42:23.781697 15749 solver.cpp:218] Iteration 66700 (0.40992 iter/s, 243.95s/100 iters), loss = 1.0519
I1212 23:42:23.782462 15749 solver.cpp:237]     Train net output #0: label = 659
I1212 23:42:23.782522 15749 solver.cpp:237]     Train net output #1: label_phocs = 659
I1212 23:42:23.782537 15749 solver.cpp:237]     Train net output #2: loss = 0.0132284 (* 1 = 0.0132284 loss)
I1212 23:42:23.782549 15749 sgd_solver.cpp:116] Iteration 66700, lr = 0.0001
I1212 23:46:37.235795 15749 solver.cpp:218] Iteration 66800 (0.394567 iter/s, 253.442s/100 iters), loss = 0.964764
I1212 23:46:37.235901 15749 solver.cpp:237]     Train net output #0: label = 498
I1212 23:46:37.235925 15749 solver.cpp:237]     Train net output #1: label_phocs = 498
I1212 23:46:37.235939 15749 solver.cpp:237]     Train net output #2: loss = 0.0360059 (* 1 = 0.0360059 loss)
I1212 23:46:37.235947 15749 sgd_solver.cpp:116] Iteration 66800, lr = 0.0001
I1212 23:50:03.526398 15749 solver.cpp:218] Iteration 66900 (0.484784 iter/s, 206.278s/100 iters), loss = 0.935216
I1212 23:50:03.527001 15749 solver.cpp:237]     Train net output #0: label = 1107
I1212 23:50:03.527038 15749 solver.cpp:237]     Train net output #1: label_phocs = 1107
I1212 23:50:03.527052 15749 solver.cpp:237]     Train net output #2: loss = 0.134585 (* 1 = 0.134585 loss)
I1212 23:50:03.527063 15749 sgd_solver.cpp:116] Iteration 66900, lr = 0.0001
[2017-12-12 23:54:04,201, PHOCNetTrainer] Running test evaluation
[2017-12-12 23:54:04,201, PHOCNetTrainer] Evaluating CNN after 66500 steps:
I1212 23:55:48.692950 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:55:48.693140 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-12 23:55:51,468, PHOCNetTrainer] mAP: 0.925806
I1212 23:55:51.470459 15749 solver.cpp:330] Iteration 67000, Testing net (#0)
I1212 23:55:51.470700 15749 net.cpp:676] Ignoring source layer drop6
I1212 23:55:51.470710 15749 net.cpp:676] Ignoring source layer drop7
I1212 23:57:29.027876 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:57:29.028126 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1212 23:57:31.171710 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1212 23:57:31.179797 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1212 23:57:31.179839 15749 solver.cpp:397]     Test net output #2: loss = 15.8763 (* 1 = 15.8763 loss)
I1212 23:57:33.252470 15749 solver.cpp:218] Iteration 67000 (0.222369 iter/s, 449.703s/100 iters), loss = 1.2738
I1212 23:57:33.252609 15749 solver.cpp:237]     Train net output #0: label = 279
I1212 23:57:33.252637 15749 solver.cpp:237]     Train net output #1: label_phocs = 279
I1212 23:57:33.252652 15749 solver.cpp:237]     Train net output #2: loss = 0.0988281 (* 1 = 0.0988281 loss)
I1212 23:57:33.252663 15749 sgd_solver.cpp:116] Iteration 67000, lr = 0.0001
I1213 00:01:29.952510 15749 solver.cpp:218] Iteration 67100 (0.422514 iter/s, 236.679s/100 iters), loss = 1.03117
I1213 00:01:29.952627 15749 solver.cpp:237]     Train net output #0: label = 158
I1213 00:01:29.952656 15749 solver.cpp:237]     Train net output #1: label_phocs = 158
I1213 00:01:29.952672 15749 solver.cpp:237]     Train net output #2: loss = 2.51578 (* 1 = 2.51578 loss)
I1213 00:01:29.952682 15749 sgd_solver.cpp:116] Iteration 67100, lr = 0.0001
I1213 00:05:12.017155 15749 solver.cpp:218] Iteration 67200 (0.450446 iter/s, 222.002s/100 iters), loss = 0.980036
I1213 00:05:12.017258 15749 solver.cpp:237]     Train net output #0: label = 103
I1213 00:05:12.017287 15749 solver.cpp:237]     Train net output #1: label_phocs = 103
I1213 00:05:12.017307 15749 solver.cpp:237]     Train net output #2: loss = 0.1414 (* 1 = 0.1414 loss)
I1213 00:05:12.017318 15749 sgd_solver.cpp:116] Iteration 67200, lr = 0.0001
I1213 00:09:14.630573 15749 solver.cpp:218] Iteration 67300 (0.412275 iter/s, 242.557s/100 iters), loss = 0.973343
I1213 00:09:14.630709 15749 solver.cpp:237]     Train net output #0: label = 469
I1213 00:09:14.630739 15749 solver.cpp:237]     Train net output #1: label_phocs = 469
I1213 00:09:14.630755 15749 solver.cpp:237]     Train net output #2: loss = 0.120939 (* 1 = 0.120939 loss)
I1213 00:09:14.630766 15749 sgd_solver.cpp:116] Iteration 67300, lr = 0.0001
I1213 00:13:30.560252 15749 solver.cpp:218] Iteration 67400 (0.390733 iter/s, 255.929s/100 iters), loss = 1.04911
I1213 00:13:30.560356 15749 solver.cpp:237]     Train net output #0: label = 799
I1213 00:13:30.560384 15749 solver.cpp:237]     Train net output #1: label_phocs = 799
I1213 00:13:30.560398 15749 solver.cpp:237]     Train net output #2: loss = 0.456218 (* 1 = 0.456218 loss)
I1213 00:13:30.560408 15749 sgd_solver.cpp:116] Iteration 67400, lr = 0.0001
[2017-12-13 00:16:53,759, PHOCNetTrainer] Running test evaluation
[2017-12-13 00:16:53,760, PHOCNetTrainer] Evaluating CNN after 67000 steps:
I1213 00:18:57.475879 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:18:57.476027 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 00:18:59,098, PHOCNetTrainer] mAP: 0.922557
I1213 00:18:59.100610 15749 solver.cpp:330] Iteration 67500, Testing net (#0)
I1213 00:18:59.100888 15749 net.cpp:676] Ignoring source layer drop6
I1213 00:18:59.100914 15749 net.cpp:676] Ignoring source layer drop7
I1213 00:20:44.399889 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:20:44.400137 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:20:46.931794 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 00:20:46.931869 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 00:20:46.931892 15749 solver.cpp:397]     Test net output #2: loss = 16.61 (* 1 = 16.61 loss)
I1213 00:20:49.395864 15749 solver.cpp:218] Iteration 67500 (0.227882 iter/s, 438.824s/100 iters), loss = 0.437709
I1213 00:20:49.395992 15749 solver.cpp:237]     Train net output #0: label = 536
I1213 00:20:49.396023 15749 solver.cpp:237]     Train net output #1: label_phocs = 536
I1213 00:20:49.396039 15749 solver.cpp:237]     Train net output #2: loss = 0.0352488 (* 1 = 0.0352488 loss)
I1213 00:20:49.396049 15749 sgd_solver.cpp:116] Iteration 67500, lr = 0.0001
I1213 00:24:51.622468 15749 solver.cpp:218] Iteration 67600 (0.412854 iter/s, 242.216s/100 iters), loss = 1.02201
I1213 00:24:51.623697 15749 solver.cpp:237]     Train net output #0: label = 1015
I1213 00:24:51.623785 15749 solver.cpp:237]     Train net output #1: label_phocs = 1015
I1213 00:24:51.623805 15749 solver.cpp:237]     Train net output #2: loss = 0.130295 (* 1 = 0.130295 loss)
I1213 00:24:51.623816 15749 sgd_solver.cpp:116] Iteration 67600, lr = 0.0001
I1213 00:28:39.435084 15749 solver.cpp:218] Iteration 67700 (0.438959 iter/s, 227.812s/100 iters), loss = 1.00695
I1213 00:28:39.488281 15749 solver.cpp:237]     Train net output #0: label = 270
I1213 00:28:39.488366 15749 solver.cpp:237]     Train net output #1: label_phocs = 270
I1213 00:28:39.488384 15749 solver.cpp:237]     Train net output #2: loss = 1.51968 (* 1 = 1.51968 loss)
I1213 00:28:39.488394 15749 sgd_solver.cpp:116] Iteration 67700, lr = 0.0001
I1213 00:32:36.387112 15749 solver.cpp:218] Iteration 67800 (0.422027 iter/s, 236.951s/100 iters), loss = 1.109
I1213 00:32:36.387225 15749 solver.cpp:237]     Train net output #0: label = 323
I1213 00:32:36.387250 15749 solver.cpp:237]     Train net output #1: label_phocs = 323
I1213 00:32:36.387264 15749 solver.cpp:237]     Train net output #2: loss = 0.198165 (* 1 = 0.198165 loss)
I1213 00:32:36.387274 15749 sgd_solver.cpp:116] Iteration 67800, lr = 0.0001
I1213 00:36:49.253609 15749 solver.cpp:218] Iteration 67900 (0.395503 iter/s, 252.843s/100 iters), loss = 1.26055
I1213 00:36:49.253726 15749 solver.cpp:237]     Train net output #0: label = 85
I1213 00:36:49.253754 15749 solver.cpp:237]     Train net output #1: label_phocs = 85
I1213 00:36:49.253769 15749 solver.cpp:237]     Train net output #2: loss = 0.565106 (* 1 = 0.565106 loss)
I1213 00:36:49.253780 15749 sgd_solver.cpp:116] Iteration 67900, lr = 0.0001
[2017-12-13 00:40:48,129, PHOCNetTrainer] Running test evaluation
[2017-12-13 00:40:48,129, PHOCNetTrainer] Evaluating CNN after 67500 steps:
I1213 00:42:12.456656 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:42:12.456835 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 00:42:14,037, PHOCNetTrainer] mAP: 0.922640
I1213 00:42:14.039013 15749 solver.cpp:330] Iteration 68000, Testing net (#0)
I1213 00:42:14.039266 15749 net.cpp:676] Ignoring source layer drop6
I1213 00:42:14.039278 15749 net.cpp:676] Ignoring source layer drop7
I1213 00:44:08.636008 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:44:08.636185 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 00:44:10.491523 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 00:44:10.491581 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 00:44:10.491595 15749 solver.cpp:397]     Test net output #2: loss = 16.0747 (* 1 = 16.0747 loss)
I1213 00:44:12.215766 15749 solver.cpp:218] Iteration 68000 (0.22576 iter/s, 442.948s/100 iters), loss = 0.875154
I1213 00:44:12.215996 15749 solver.cpp:237]     Train net output #0: label = 157
I1213 00:44:12.216033 15749 solver.cpp:237]     Train net output #1: label_phocs = 157
I1213 00:44:12.216050 15749 solver.cpp:237]     Train net output #2: loss = 0.0467503 (* 1 = 0.0467503 loss)
I1213 00:44:12.216063 15749 sgd_solver.cpp:116] Iteration 68000, lr = 0.0001
I1213 00:48:20.351905 15749 solver.cpp:218] Iteration 68100 (0.40305 iter/s, 248.108s/100 iters), loss = 0.911428
I1213 00:48:20.352041 15749 solver.cpp:237]     Train net output #0: label = 776
I1213 00:48:20.352069 15749 solver.cpp:237]     Train net output #1: label_phocs = 776
I1213 00:48:20.352084 15749 solver.cpp:237]     Train net output #2: loss = 0.457232 (* 1 = 0.457232 loss)
I1213 00:48:20.352095 15749 sgd_solver.cpp:116] Iteration 68100, lr = 0.0001
I1213 00:52:22.058033 15749 solver.cpp:218] Iteration 68200 (0.413726 iter/s, 241.706s/100 iters), loss = 0.942733
I1213 00:52:22.058152 15749 solver.cpp:237]     Train net output #0: label = 206
I1213 00:52:22.058179 15749 solver.cpp:237]     Train net output #1: label_phocs = 206
I1213 00:52:22.058194 15749 solver.cpp:237]     Train net output #2: loss = 0.00837231 (* 1 = 0.00837231 loss)
I1213 00:52:22.058204 15749 sgd_solver.cpp:116] Iteration 68200, lr = 0.0001
I1213 00:55:45.855821 15749 solver.cpp:218] Iteration 68300 (0.490729 iter/s, 203.778s/100 iters), loss = 1.03155
I1213 00:55:45.855959 15749 solver.cpp:237]     Train net output #0: label = 365
I1213 00:55:45.855989 15749 solver.cpp:237]     Train net output #1: label_phocs = 365
I1213 00:55:45.856005 15749 solver.cpp:237]     Train net output #2: loss = 0.0572914 (* 1 = 0.0572914 loss)
I1213 00:55:45.856016 15749 sgd_solver.cpp:116] Iteration 68300, lr = 0.0001
I1213 00:59:55.879808 15749 solver.cpp:218] Iteration 68400 (0.399978 iter/s, 250.014s/100 iters), loss = 1.07449
I1213 00:59:55.879945 15749 solver.cpp:237]     Train net output #0: label = 965
I1213 00:59:55.879976 15749 solver.cpp:237]     Train net output #1: label_phocs = 965
I1213 00:59:55.879992 15749 solver.cpp:237]     Train net output #2: loss = 0.8222 (* 1 = 0.8222 loss)
I1213 00:59:55.880002 15749 sgd_solver.cpp:116] Iteration 68400, lr = 0.0001
[2017-12-13 01:04:00,078, PHOCNetTrainer] Running test evaluation
[2017-12-13 01:04:00,078, PHOCNetTrainer] Evaluating CNN after 68000 steps:
I1213 01:05:41.576699 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:05:41.577245 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 01:05:44,655, PHOCNetTrainer] mAP: 0.920304
I1213 01:05:44.708123 15749 solver.cpp:330] Iteration 68500, Testing net (#0)
I1213 01:05:44.708374 15749 net.cpp:676] Ignoring source layer drop6
I1213 01:05:44.708386 15749 net.cpp:676] Ignoring source layer drop7
I1213 01:06:58.875958 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:06:58.875958 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:07:00.468277 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 01:07:00.468338 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 01:07:00.468351 15749 solver.cpp:397]     Test net output #2: loss = 17.1972 (* 1 = 17.1972 loss)
I1213 01:07:02.819797 15749 solver.cpp:218] Iteration 68500 (0.234237 iter/s, 426.918s/100 iters), loss = 1.34647
I1213 01:07:02.819955 15749 solver.cpp:237]     Train net output #0: label = 303
I1213 01:07:02.819980 15749 solver.cpp:237]     Train net output #1: label_phocs = 303
I1213 01:07:02.819993 15749 solver.cpp:237]     Train net output #2: loss = 0.0588474 (* 1 = 0.0588474 loss)
I1213 01:07:02.820003 15749 sgd_solver.cpp:116] Iteration 68500, lr = 0.0001
I1213 01:10:58.755581 15749 solver.cpp:218] Iteration 68600 (0.42393 iter/s, 235.888s/100 iters), loss = 1.00769
I1213 01:10:58.755975 15749 solver.cpp:237]     Train net output #0: label = 454
I1213 01:10:58.756036 15749 solver.cpp:237]     Train net output #1: label_phocs = 454
I1213 01:10:58.756054 15749 solver.cpp:237]     Train net output #2: loss = 0.00330905 (* 1 = 0.00330905 loss)
I1213 01:10:58.756067 15749 sgd_solver.cpp:116] Iteration 68600, lr = 0.0001
I1213 01:15:12.341398 15749 solver.cpp:218] Iteration 68700 (0.394344 iter/s, 253.586s/100 iters), loss = 0.937533
I1213 01:15:12.342542 15749 solver.cpp:237]     Train net output #0: label = 299
I1213 01:15:12.342627 15749 solver.cpp:237]     Train net output #1: label_phocs = 299
I1213 01:15:12.342644 15749 solver.cpp:237]     Train net output #2: loss = 0.00751216 (* 1 = 0.00751216 loss)
I1213 01:15:12.342658 15749 sgd_solver.cpp:116] Iteration 68700, lr = 0.0001
I1213 01:19:19.297062 15749 solver.cpp:218] Iteration 68800 (0.404933 iter/s, 246.955s/100 iters), loss = 0.884485
I1213 01:19:19.297420 15749 solver.cpp:237]     Train net output #0: label = 687
I1213 01:19:19.297452 15749 solver.cpp:237]     Train net output #1: label_phocs = 687
I1213 01:19:19.297468 15749 solver.cpp:237]     Train net output #2: loss = 4.68194 (* 1 = 4.68194 loss)
I1213 01:19:19.297479 15749 sgd_solver.cpp:116] Iteration 68800, lr = 0.0001
I1213 01:22:48.478862 15749 solver.cpp:218] Iteration 68900 (0.478115 iter/s, 209.155s/100 iters), loss = 0.909985
I1213 01:22:48.479001 15749 solver.cpp:237]     Train net output #0: label = 209
I1213 01:22:48.479030 15749 solver.cpp:237]     Train net output #1: label_phocs = 209
I1213 01:22:48.479045 15749 solver.cpp:237]     Train net output #2: loss = 0.666816 (* 1 = 0.666816 loss)
I1213 01:22:48.479055 15749 sgd_solver.cpp:116] Iteration 68900, lr = 0.0001
[2017-12-13 01:26:56,582, PHOCNetTrainer] Running test evaluation
[2017-12-13 01:26:56,582, PHOCNetTrainer] Evaluating CNN after 68500 steps:
I1213 01:28:58.692872 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:28:58.693070 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 01:29:01,645, PHOCNetTrainer] mAP: 0.923768
I1213 01:29:01.647513 15749 solver.cpp:330] Iteration 69000, Testing net (#0)
I1213 01:29:01.647831 15749 net.cpp:676] Ignoring source layer drop6
I1213 01:29:01.647857 15749 net.cpp:676] Ignoring source layer drop7
I1213 01:30:32.147876 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:30:32.148020 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:30:33.386607 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 01:30:33.386665 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 01:30:33.386680 15749 solver.cpp:397]     Test net output #2: loss = 16.2978 (* 1 = 16.2978 loss)
I1213 01:30:35.758749 15749 solver.cpp:218] Iteration 69000 (0.214004 iter/s, 467.28s/100 iters), loss = 0.937438
I1213 01:30:35.760144 15749 solver.cpp:237]     Train net output #0: label = 246
I1213 01:30:35.760198 15749 solver.cpp:237]     Train net output #1: label_phocs = 246
I1213 01:30:35.760208 15749 solver.cpp:237]     Train net output #2: loss = 0.0499834 (* 1 = 0.0499834 loss)
I1213 01:30:35.760216 15749 sgd_solver.cpp:116] Iteration 69000, lr = 0.0001
I1213 01:34:07.555454 15749 solver.cpp:218] Iteration 69100 (0.472154 iter/s, 211.795s/100 iters), loss = 0.955305
I1213 01:34:07.556607 15749 solver.cpp:237]     Train net output #0: label = 1060
I1213 01:34:07.556658 15749 solver.cpp:237]     Train net output #1: label_phocs = 1060
I1213 01:34:07.556670 15749 solver.cpp:237]     Train net output #2: loss = 0.0189271 (* 1 = 0.0189271 loss)
I1213 01:34:07.556681 15749 sgd_solver.cpp:116] Iteration 69100, lr = 0.0001
I1213 01:38:07.603077 15749 solver.cpp:218] Iteration 69200 (0.416637 iter/s, 240.017s/100 iters), loss = 0.901838
I1213 01:38:07.604120 15749 solver.cpp:237]     Train net output #0: label = 858
I1213 01:38:07.604202 15749 solver.cpp:237]     Train net output #1: label_phocs = 858
I1213 01:38:07.604218 15749 solver.cpp:237]     Train net output #2: loss = 0.0312171 (* 1 = 0.0312171 loss)
I1213 01:38:07.604228 15749 sgd_solver.cpp:116] Iteration 69200, lr = 0.0001
I1213 01:42:07.471168 15749 solver.cpp:218] Iteration 69300 (0.416938 iter/s, 239.844s/100 iters), loss = 0.830735
I1213 01:42:07.472291 15749 solver.cpp:237]     Train net output #0: label = 975
I1213 01:42:07.472352 15749 solver.cpp:237]     Train net output #1: label_phocs = 975
I1213 01:42:07.472367 15749 solver.cpp:237]     Train net output #2: loss = 2.75487 (* 1 = 2.75487 loss)
I1213 01:42:07.472376 15749 sgd_solver.cpp:116] Iteration 69300, lr = 0.0001
I1213 01:45:58.227802 15749 solver.cpp:218] Iteration 69400 (0.433407 iter/s, 230.73s/100 iters), loss = 0.927007
I1213 01:45:58.227915 15749 solver.cpp:237]     Train net output #0: label = 704
I1213 01:45:58.227939 15749 solver.cpp:237]     Train net output #1: label_phocs = 704
I1213 01:45:58.227952 15749 solver.cpp:237]     Train net output #2: loss = 0.57672 (* 1 = 0.57672 loss)
I1213 01:45:58.227962 15749 sgd_solver.cpp:116] Iteration 69400, lr = 0.0001
[2017-12-13 01:49:51,336, PHOCNetTrainer] Running test evaluation
[2017-12-13 01:49:51,336, PHOCNetTrainer] Evaluating CNN after 69000 steps:
I1213 01:52:01.751854 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:52:01.752030 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 01:52:04,713, PHOCNetTrainer] mAP: 0.923507
I1213 01:52:04.715387 15749 solver.cpp:330] Iteration 69500, Testing net (#0)
I1213 01:52:04.715682 15749 net.cpp:676] Ignoring source layer drop6
I1213 01:52:04.715710 15749 net.cpp:676] Ignoring source layer drop7
I1213 01:53:48.939860 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:53:48.940032 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 01:53:50.817133 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 01:53:50.817181 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 01:53:50.817190 15749 solver.cpp:397]     Test net output #2: loss = 16.1719 (* 1 = 16.1719 loss)
I1213 01:53:52.998868 15749 solver.cpp:218] Iteration 69500 (0.210643 iter/s, 474.738s/100 iters), loss = 0.156072
I1213 01:53:52.998996 15749 solver.cpp:237]     Train net output #0: label = 708
I1213 01:53:52.999025 15749 solver.cpp:237]     Train net output #1: label_phocs = 708
I1213 01:53:52.999040 15749 solver.cpp:237]     Train net output #2: loss = 0.99383 (* 1 = 0.99383 loss)
I1213 01:53:52.999053 15749 sgd_solver.cpp:116] Iteration 69500, lr = 0.0001
I1213 01:57:54.055456 15749 solver.cpp:218] Iteration 69600 (0.41484 iter/s, 241.057s/100 iters), loss = 0.844132
I1213 01:57:54.056054 15749 solver.cpp:237]     Train net output #0: label = 119
I1213 01:57:54.056123 15749 solver.cpp:237]     Train net output #1: label_phocs = 119
I1213 01:57:54.056149 15749 solver.cpp:237]     Train net output #2: loss = 1.55265 (* 1 = 1.55265 loss)
I1213 01:57:54.056160 15749 sgd_solver.cpp:116] Iteration 69600, lr = 0.0001
I1213 02:01:37.111641 15749 solver.cpp:218] Iteration 69700 (0.448318 iter/s, 223.056s/100 iters), loss = 0.970357
I1213 02:01:37.113013 15749 solver.cpp:237]     Train net output #0: label = 669
I1213 02:01:37.113097 15749 solver.cpp:237]     Train net output #1: label_phocs = 669
I1213 02:01:37.113114 15749 solver.cpp:237]     Train net output #2: loss = 0.00407359 (* 1 = 0.00407359 loss)
I1213 02:01:37.113126 15749 sgd_solver.cpp:116] Iteration 69700, lr = 0.0001
I1213 02:05:47.335646 15749 solver.cpp:218] Iteration 69800 (0.399671 iter/s, 250.206s/100 iters), loss = 0.827068
I1213 02:05:47.335791 15749 solver.cpp:237]     Train net output #0: label = 515
I1213 02:05:47.335820 15749 solver.cpp:237]     Train net output #1: label_phocs = 515
I1213 02:05:47.335834 15749 solver.cpp:237]     Train net output #2: loss = 0.00307192 (* 1 = 0.00307192 loss)
I1213 02:05:47.335844 15749 sgd_solver.cpp:116] Iteration 69800, lr = 0.0001
I1213 02:09:50.028872 15749 solver.cpp:218] Iteration 69900 (0.412045 iter/s, 242.692s/100 iters), loss = 0.797465
I1213 02:09:50.028986 15749 solver.cpp:237]     Train net output #0: label = 457
I1213 02:09:50.029016 15749 solver.cpp:237]     Train net output #1: label_phocs = 457
I1213 02:09:50.029032 15749 solver.cpp:237]     Train net output #2: loss = 0.403907 (* 1 = 0.403907 loss)
I1213 02:09:50.029043 15749 sgd_solver.cpp:116] Iteration 69900, lr = 0.0001
[2017-12-13 02:13:22,755, PHOCNetTrainer] Running test evaluation
[2017-12-13 02:13:22,755, PHOCNetTrainer] Evaluating CNN after 69500 steps:
I1213 02:15:15.132866 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:15:15.133134 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 02:15:19,513, PHOCNetTrainer] mAP: 0.928073
I1213 02:15:19.540639 15749 solver.cpp:330] Iteration 70000, Testing net (#0)
I1213 02:15:19.540892 15749 net.cpp:676] Ignoring source layer drop6
I1213 02:15:19.540910 15749 net.cpp:676] Ignoring source layer drop7
I1213 02:17:00.680891 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:17:00.681105 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:17:03.060540 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 02:17:03.060600 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 02:17:03.060616 15749 solver.cpp:397]     Test net output #2: loss = 16.2529 (* 1 = 16.2529 loss)
I1213 02:17:05.572310 15749 solver.cpp:218] Iteration 70000 (0.2296 iter/s, 435.539s/100 iters), loss = 0.182344
I1213 02:17:05.573285 15749 solver.cpp:237]     Train net output #0: label = 576
I1213 02:17:05.573355 15749 solver.cpp:237]     Train net output #1: label_phocs = 576
I1213 02:17:05.573370 15749 solver.cpp:237]     Train net output #2: loss = 0.00898932 (* 1 = 0.00898932 loss)
I1213 02:17:05.573381 15749 sgd_solver.cpp:116] Iteration 70000, lr = 1e-05
I1213 02:21:06.028426 15749 solver.cpp:218] Iteration 70100 (0.415878 iter/s, 240.455s/100 iters), loss = 0.902327
I1213 02:21:06.029657 15749 solver.cpp:237]     Train net output #0: label = 142
I1213 02:21:06.029743 15749 solver.cpp:237]     Train net output #1: label_phocs = 142
I1213 02:21:06.029759 15749 solver.cpp:237]     Train net output #2: loss = 0.00839981 (* 1 = 0.00839981 loss)
I1213 02:21:06.029770 15749 sgd_solver.cpp:116] Iteration 70100, lr = 1e-05
I1213 02:24:42.754253 15749 solver.cpp:218] Iteration 70200 (0.461415 iter/s, 216.725s/100 iters), loss = 0.779714
I1213 02:24:42.754590 15749 solver.cpp:237]     Train net output #0: label = 102
I1213 02:24:42.754618 15749 solver.cpp:237]     Train net output #1: label_phocs = 102
I1213 02:24:42.754631 15749 solver.cpp:237]     Train net output #2: loss = 2.13343 (* 1 = 2.13343 loss)
I1213 02:24:42.754642 15749 sgd_solver.cpp:116] Iteration 70200, lr = 1e-05
I1213 02:28:42.077431 15749 solver.cpp:218] Iteration 70300 (0.417889 iter/s, 239.298s/100 iters), loss = 0.910752
I1213 02:28:42.077607 15749 solver.cpp:237]     Train net output #0: label = 297
I1213 02:28:42.077636 15749 solver.cpp:237]     Train net output #1: label_phocs = 297
I1213 02:28:42.077648 15749 solver.cpp:237]     Train net output #2: loss = 0.364736 (* 1 = 0.364736 loss)
I1213 02:28:42.077659 15749 sgd_solver.cpp:116] Iteration 70300, lr = 1e-05
I1213 02:32:43.020647 15749 solver.cpp:218] Iteration 70400 (0.415054 iter/s, 240.933s/100 iters), loss = 0.976795
I1213 02:32:43.021836 15749 solver.cpp:237]     Train net output #0: label = 230
I1213 02:32:43.021916 15749 solver.cpp:237]     Train net output #1: label_phocs = 230
I1213 02:32:43.021932 15749 solver.cpp:237]     Train net output #2: loss = 0.410566 (* 1 = 0.410566 loss)
I1213 02:32:43.021944 15749 sgd_solver.cpp:116] Iteration 70400, lr = 1e-05
[2017-12-13 02:36:38,462, PHOCNetTrainer] Running test evaluation
[2017-12-13 02:36:38,462, PHOCNetTrainer] Evaluating CNN after 70000 steps:
I1213 02:37:58.601282 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:37:58.601478 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 02:38:01,660, PHOCNetTrainer] mAP: 0.927948
I1213 02:38:01.662199 15749 solver.cpp:330] Iteration 70500, Testing net (#0)
I1213 02:38:01.662443 15749 net.cpp:676] Ignoring source layer drop6
I1213 02:38:01.662453 15749 net.cpp:676] Ignoring source layer drop7
I1213 02:39:40.462302 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:39:40.462487 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 02:39:42.648912 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 02:39:42.648972 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 02:39:42.648986 15749 solver.cpp:397]     Test net output #2: loss = 16.275 (* 1 = 16.275 loss)
I1213 02:39:45.004688 15749 solver.cpp:218] Iteration 70500 (0.236976 iter/s, 421.983s/100 iters), loss = 0.680208
I1213 02:39:45.004793 15749 solver.cpp:237]     Train net output #0: label = 190
I1213 02:39:45.004822 15749 solver.cpp:237]     Train net output #1: label_phocs = 190
I1213 02:39:45.004837 15749 solver.cpp:237]     Train net output #2: loss = 0.495582 (* 1 = 0.495582 loss)
I1213 02:39:45.004848 15749 sgd_solver.cpp:116] Iteration 70500, lr = 1e-05
I1213 02:43:47.187913 15749 solver.cpp:218] Iteration 70600 (0.41291 iter/s, 242.183s/100 iters), loss = 0.846145
I1213 02:43:47.188540 15749 solver.cpp:237]     Train net output #0: label = 279
I1213 02:43:47.188594 15749 solver.cpp:237]     Train net output #1: label_phocs = 279
I1213 02:43:47.188609 15749 solver.cpp:237]     Train net output #2: loss = 0.0865214 (* 1 = 0.0865214 loss)
I1213 02:43:47.188621 15749 sgd_solver.cpp:116] Iteration 70600, lr = 1e-05
I1213 02:47:53.435971 15749 solver.cpp:218] Iteration 70700 (0.406121 iter/s, 246.232s/100 iters), loss = 0.855328
I1213 02:47:53.436110 15749 solver.cpp:237]     Train net output #0: label = 532
I1213 02:47:53.436136 15749 solver.cpp:237]     Train net output #1: label_phocs = 532
I1213 02:47:53.436148 15749 solver.cpp:237]     Train net output #2: loss = 4.86488 (* 1 = 4.86488 loss)
I1213 02:47:53.436157 15749 sgd_solver.cpp:116] Iteration 70700, lr = 1e-05
I1213 02:51:29.023960 15749 solver.cpp:218] Iteration 70800 (0.463848 iter/s, 215.588s/100 iters), loss = 0.88682
I1213 02:51:29.024557 15749 solver.cpp:237]     Train net output #0: label = 524
I1213 02:51:29.024600 15749 solver.cpp:237]     Train net output #1: label_phocs = 524
I1213 02:51:29.024615 15749 solver.cpp:237]     Train net output #2: loss = 0.178524 (* 1 = 0.178524 loss)
I1213 02:51:29.024624 15749 sgd_solver.cpp:116] Iteration 70800, lr = 1e-05
I1213 02:55:24.009347 15749 solver.cpp:218] Iteration 70900 (0.42566 iter/s, 234.929s/100 iters), loss = 0.855626
I1213 02:55:24.009462 15749 solver.cpp:237]     Train net output #0: label = 308
I1213 02:55:24.009493 15749 solver.cpp:237]     Train net output #1: label_phocs = 308
I1213 02:55:24.009517 15749 solver.cpp:237]     Train net output #2: loss = 0.637143 (* 1 = 0.637143 loss)
I1213 02:55:24.009531 15749 sgd_solver.cpp:116] Iteration 70900, lr = 1e-05
[2017-12-13 02:59:26,315, PHOCNetTrainer] Running test evaluation
[2017-12-13 02:59:26,315, PHOCNetTrainer] Evaluating CNN after 70500 steps:
I1213 03:01:08.463907 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:01:08.464073 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 03:01:12,515, PHOCNetTrainer] mAP: 0.927453
I1213 03:01:12.545987 15749 solver.cpp:330] Iteration 71000, Testing net (#0)
I1213 03:01:12.546257 15749 net.cpp:676] Ignoring source layer drop6
I1213 03:01:12.546270 15749 net.cpp:676] Ignoring source layer drop7
I1213 03:02:47.267856 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:02:47.267917 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:02:48.691709 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 03:02:48.691772 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 03:02:48.691789 15749 solver.cpp:397]     Test net output #2: loss = 16.2588 (* 1 = 16.2588 loss)
I1213 03:02:50.232213 15749 solver.cpp:218] Iteration 71000 (0.22412 iter/s, 446.189s/100 iters), loss = 2.13984
I1213 03:02:50.232316 15749 solver.cpp:237]     Train net output #0: label = 775
I1213 03:02:50.232342 15749 solver.cpp:237]     Train net output #1: label_phocs = 775
I1213 03:02:50.232357 15749 solver.cpp:237]     Train net output #2: loss = 10.0332 (* 1 = 10.0332 loss)
I1213 03:02:50.232367 15749 sgd_solver.cpp:116] Iteration 71000, lr = 1e-05
I1213 03:06:31.676540 15749 solver.cpp:218] Iteration 71100 (0.451581 iter/s, 221.444s/100 iters), loss = 1.03834
I1213 03:06:31.677680 15749 solver.cpp:237]     Train net output #0: label = 626
I1213 03:06:31.677754 15749 solver.cpp:237]     Train net output #1: label_phocs = 626
I1213 03:06:31.677769 15749 solver.cpp:237]     Train net output #2: loss = 0.015734 (* 1 = 0.015734 loss)
I1213 03:06:31.677780 15749 sgd_solver.cpp:116] Iteration 71100, lr = 1e-05
I1213 03:10:35.542932 15749 solver.cpp:218] Iteration 71200 (0.410062 iter/s, 243.865s/100 iters), loss = 0.913077
I1213 03:10:35.544072 15749 solver.cpp:237]     Train net output #0: label = 961
I1213 03:10:35.544157 15749 solver.cpp:237]     Train net output #1: label_phocs = 961
I1213 03:10:35.544173 15749 solver.cpp:237]     Train net output #2: loss = 1.90239 (* 1 = 1.90239 loss)
I1213 03:10:35.544185 15749 sgd_solver.cpp:116] Iteration 71200, lr = 1e-05
I1213 03:14:51.921596 15749 solver.cpp:218] Iteration 71300 (0.390087 iter/s, 256.353s/100 iters), loss = 0.875137
I1213 03:14:51.934432 15749 solver.cpp:237]     Train net output #0: label = 968
I1213 03:14:51.934499 15749 solver.cpp:237]     Train net output #1: label_phocs = 968
I1213 03:14:51.934514 15749 solver.cpp:237]     Train net output #2: loss = 1.89196 (* 1 = 1.89196 loss)
I1213 03:14:51.934523 15749 sgd_solver.cpp:116] Iteration 71300, lr = 1e-05
I1213 03:18:20.648520 15749 solver.cpp:218] Iteration 71400 (0.479124 iter/s, 208.714s/100 iters), loss = 0.884966
I1213 03:18:20.649667 15749 solver.cpp:237]     Train net output #0: label = 298
I1213 03:18:20.649760 15749 solver.cpp:237]     Train net output #1: label_phocs = 298
I1213 03:18:20.649776 15749 solver.cpp:237]     Train net output #2: loss = 0.00745819 (* 1 = 0.00745819 loss)
I1213 03:18:20.649788 15749 sgd_solver.cpp:116] Iteration 71400, lr = 1e-05
[2017-12-13 03:22:32,165, PHOCNetTrainer] Running test evaluation
[2017-12-13 03:22:32,166, PHOCNetTrainer] Evaluating CNN after 71000 steps:
I1213 03:24:20.731896 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:24:20.732172 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 03:24:23,020, PHOCNetTrainer] mAP: 0.928054
I1213 03:24:23.022783 15749 solver.cpp:330] Iteration 71500, Testing net (#0)
I1213 03:24:23.023078 15749 net.cpp:676] Ignoring source layer drop6
I1213 03:24:23.023092 15749 net.cpp:676] Ignoring source layer drop7
I1213 03:26:13.932351 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:26:13.932535 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:26:16.358098 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 03:26:16.358155 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 03:26:16.358168 15749 solver.cpp:397]     Test net output #2: loss = 16.2284 (* 1 = 16.2284 loss)
I1213 03:26:19.886715 15749 solver.cpp:218] Iteration 71500 (0.208672 iter/s, 479.22s/100 iters), loss = 0.763853
I1213 03:26:19.887171 15749 solver.cpp:237]     Train net output #0: label = 1009
I1213 03:26:19.887207 15749 solver.cpp:237]     Train net output #1: label_phocs = 1009
I1213 03:26:19.887223 15749 solver.cpp:237]     Train net output #2: loss = 0.195224 (* 1 = 0.195224 loss)
I1213 03:26:19.887233 15749 sgd_solver.cpp:116] Iteration 71500, lr = 1e-05
I1213 03:29:55.386010 15749 solver.cpp:218] Iteration 71600 (0.464039 iter/s, 215.499s/100 iters), loss = 0.856529
I1213 03:29:55.387150 15749 solver.cpp:237]     Train net output #0: label = 489
I1213 03:29:55.387233 15749 solver.cpp:237]     Train net output #1: label_phocs = 489
I1213 03:29:55.387248 15749 solver.cpp:237]     Train net output #2: loss = 0.0615963 (* 1 = 0.0615963 loss)
I1213 03:29:55.387259 15749 sgd_solver.cpp:116] Iteration 71600, lr = 1e-05
I1213 03:33:58.673130 15749 solver.cpp:218] Iteration 71700 (0.411052 iter/s, 243.278s/100 iters), loss = 0.729276
I1213 03:33:58.673274 15749 solver.cpp:237]     Train net output #0: label = 612
I1213 03:33:58.673305 15749 solver.cpp:237]     Train net output #1: label_phocs = 612
I1213 03:33:58.673321 15749 solver.cpp:237]     Train net output #2: loss = 0.792576 (* 1 = 0.792576 loss)
I1213 03:33:58.673331 15749 sgd_solver.cpp:116] Iteration 71700, lr = 1e-05
I1213 03:37:22.662344 15749 solver.cpp:218] Iteration 71800 (0.490222 iter/s, 203.989s/100 iters), loss = 0.895791
I1213 03:37:22.663426 15749 solver.cpp:237]     Train net output #0: label = 497
I1213 03:37:22.663445 15749 solver.cpp:237]     Train net output #1: label_phocs = 497
I1213 03:37:22.663453 15749 solver.cpp:237]     Train net output #2: loss = 0.0151871 (* 1 = 0.0151871 loss)
I1213 03:37:22.663460 15749 sgd_solver.cpp:116] Iteration 71800, lr = 1e-05
I1213 03:40:26.867781 15749 solver.cpp:218] Iteration 71900 (0.542875 iter/s, 184.205s/100 iters), loss = 0.879209
I1213 03:40:26.867900 15749 solver.cpp:237]     Train net output #0: label = 1090
I1213 03:40:26.867924 15749 solver.cpp:237]     Train net output #1: label_phocs = 1090
I1213 03:40:26.867936 15749 solver.cpp:237]     Train net output #2: loss = 4.88372 (* 1 = 4.88372 loss)
I1213 03:40:26.867944 15749 sgd_solver.cpp:116] Iteration 71900, lr = 1e-05
[2017-12-13 03:43:30,045, PHOCNetTrainer] Running test evaluation
[2017-12-13 03:43:30,045, PHOCNetTrainer] Evaluating CNN after 71500 steps:
I1213 03:44:41.031543 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:44:41.034422 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 03:44:42,454, PHOCNetTrainer] mAP: 0.928648
I1213 03:44:42.455217 15749 solver.cpp:330] Iteration 72000, Testing net (#0)
I1213 03:44:42.455395 15749 net.cpp:676] Ignoring source layer drop6
I1213 03:44:42.455402 15749 net.cpp:676] Ignoring source layer drop7
I1213 03:45:53.255295 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:45:53.255290 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 03:45:54.429628 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 03:45:54.429677 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 03:45:54.429689 15749 solver.cpp:397]     Test net output #2: loss = 16.2057 (* 1 = 16.2057 loss)
I1213 03:45:55.903872 15749 solver.cpp:218] Iteration 72000 (0.303918 iter/s, 329.036s/100 iters), loss = 0.271269
I1213 03:45:55.904201 15749 solver.cpp:237]     Train net output #0: label = 45
I1213 03:45:55.904227 15749 solver.cpp:237]     Train net output #1: label_phocs = 45
I1213 03:45:55.904245 15749 solver.cpp:237]     Train net output #2: loss = 0.504946 (* 1 = 0.504946 loss)
I1213 03:45:55.904255 15749 sgd_solver.cpp:116] Iteration 72000, lr = 1e-05
I1213 03:49:07.759637 15749 solver.cpp:218] Iteration 72100 (0.521225 iter/s, 191.856s/100 iters), loss = 0.876748
I1213 03:49:07.761240 15749 solver.cpp:237]     Train net output #0: label = 153
I1213 03:49:07.761267 15749 solver.cpp:237]     Train net output #1: label_phocs = 153
I1213 03:49:07.761279 15749 solver.cpp:237]     Train net output #2: loss = 0.158953 (* 1 = 0.158953 loss)
I1213 03:49:07.761288 15749 sgd_solver.cpp:116] Iteration 72100, lr = 1e-05
I1213 03:51:55.807497 15749 solver.cpp:218] Iteration 72200 (0.595074 iter/s, 168.046s/100 iters), loss = 0.911034
I1213 03:51:55.808645 15749 solver.cpp:237]     Train net output #0: label = 813
I1213 03:51:55.808672 15749 solver.cpp:237]     Train net output #1: label_phocs = 813
I1213 03:51:55.808684 15749 solver.cpp:237]     Train net output #2: loss = 0.0192449 (* 1 = 0.0192449 loss)
I1213 03:51:55.808693 15749 sgd_solver.cpp:116] Iteration 72200, lr = 1e-05
I1213 03:55:08.877857 15749 solver.cpp:218] Iteration 72300 (0.517948 iter/s, 193.069s/100 iters), loss = 0.824189
I1213 03:55:08.878543 15749 solver.cpp:237]     Train net output #0: label = 1064
I1213 03:55:08.878577 15749 solver.cpp:237]     Train net output #1: label_phocs = 1064
I1213 03:55:08.878593 15749 solver.cpp:237]     Train net output #2: loss = 0.176901 (* 1 = 0.176901 loss)
I1213 03:55:08.878603 15749 sgd_solver.cpp:116] Iteration 72300, lr = 1e-05
I1213 03:58:25.673650 15749 solver.cpp:218] Iteration 72400 (0.508142 iter/s, 196.795s/100 iters), loss = 0.884367
I1213 03:58:25.673766 15749 solver.cpp:237]     Train net output #0: label = 867
I1213 03:58:25.673789 15749 solver.cpp:237]     Train net output #1: label_phocs = 867
I1213 03:58:25.673800 15749 solver.cpp:237]     Train net output #2: loss = 0.205544 (* 1 = 0.205544 loss)
I1213 03:58:25.673810 15749 sgd_solver.cpp:116] Iteration 72400, lr = 1e-05
[2017-12-13 04:01:13,401, PHOCNetTrainer] Running test evaluation
[2017-12-13 04:01:13,401, PHOCNetTrainer] Evaluating CNN after 72000 steps:
I1213 04:02:21.891845 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:02:21.891968 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 04:02:23,834, PHOCNetTrainer] mAP: 0.929798
I1213 04:02:23.835178 15749 solver.cpp:330] Iteration 72500, Testing net (#0)
I1213 04:02:23.835356 15749 net.cpp:676] Ignoring source layer drop6
I1213 04:02:23.835364 15749 net.cpp:676] Ignoring source layer drop7
I1213 04:03:28.619428 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:03:28.619647 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:03:29.530310 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 04:03:29.530357 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 04:03:29.530369 15749 solver.cpp:397]     Test net output #2: loss = 16.1026 (* 1 = 16.1026 loss)
I1213 04:03:31.206640 15749 solver.cpp:218] Iteration 72500 (0.327297 iter/s, 305.533s/100 iters), loss = 0.608682
I1213 04:03:31.207798 15749 solver.cpp:237]     Train net output #0: label = 269
I1213 04:03:31.207824 15749 solver.cpp:237]     Train net output #1: label_phocs = 269
I1213 04:03:31.207836 15749 solver.cpp:237]     Train net output #2: loss = 0.0992057 (* 1 = 0.0992057 loss)
I1213 04:03:31.207845 15749 sgd_solver.cpp:116] Iteration 72500, lr = 1e-05
I1213 04:06:44.813333 15749 solver.cpp:218] Iteration 72600 (0.516514 iter/s, 193.606s/100 iters), loss = 0.759512
I1213 04:06:44.814474 15749 solver.cpp:237]     Train net output #0: label = 502
I1213 04:06:44.814499 15749 solver.cpp:237]     Train net output #1: label_phocs = 502
I1213 04:06:44.814512 15749 solver.cpp:237]     Train net output #2: loss = 0.00293385 (* 1 = 0.00293385 loss)
I1213 04:06:44.814519 15749 sgd_solver.cpp:116] Iteration 72600, lr = 1e-05
I1213 04:10:01.517026 15749 solver.cpp:218] Iteration 72700 (0.508451 iter/s, 196.676s/100 iters), loss = 0.740386
I1213 04:10:01.517144 15749 solver.cpp:237]     Train net output #0: label = 113
I1213 04:10:01.517168 15749 solver.cpp:237]     Train net output #1: label_phocs = 113
I1213 04:10:01.517179 15749 solver.cpp:237]     Train net output #2: loss = 0.475278 (* 1 = 0.475278 loss)
I1213 04:10:01.517189 15749 sgd_solver.cpp:116] Iteration 72700, lr = 1e-05
I1213 04:12:56.233139 15749 solver.cpp:218] Iteration 72800 (0.572357 iter/s, 174.716s/100 iters), loss = 0.804163
I1213 04:12:56.233695 15749 solver.cpp:237]     Train net output #0: label = 989
I1213 04:12:56.233721 15749 solver.cpp:237]     Train net output #1: label_phocs = 989
I1213 04:12:56.233731 15749 solver.cpp:237]     Train net output #2: loss = 0.0818167 (* 1 = 0.0818167 loss)
I1213 04:12:56.233741 15749 sgd_solver.cpp:116] Iteration 72800, lr = 1e-05
I1213 04:16:16.859387 15749 solver.cpp:218] Iteration 72900 (0.49844 iter/s, 200.626s/100 iters), loss = 0.893937
I1213 04:16:16.860534 15749 solver.cpp:237]     Train net output #0: label = 802
I1213 04:16:16.860558 15749 solver.cpp:237]     Train net output #1: label_phocs = 802
I1213 04:16:16.860566 15749 solver.cpp:237]     Train net output #2: loss = 0.0146678 (* 1 = 0.0146678 loss)
I1213 04:16:16.860572 15749 sgd_solver.cpp:116] Iteration 72900, lr = 1e-05
[2017-12-13 04:19:38,825, PHOCNetTrainer] Running test evaluation
[2017-12-13 04:19:38,825, PHOCNetTrainer] Evaluating CNN after 72500 steps:
I1213 04:20:35.221326 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:20:35.225319 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 04:20:36,501, PHOCNetTrainer] mAP: 0.929107
I1213 04:20:36.503355 15749 solver.cpp:330] Iteration 73000, Testing net (#0)
I1213 04:20:36.503556 15749 net.cpp:676] Ignoring source layer drop6
I1213 04:20:36.503566 15749 net.cpp:676] Ignoring source layer drop7
I1213 04:21:35.386204 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:21:35.386785 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:21:36.118810 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 04:21:36.118854 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 04:21:36.118865 15749 solver.cpp:397]     Test net output #2: loss = 16.2111 (* 1 = 16.2111 loss)
I1213 04:21:37.653041 15749 solver.cpp:218] Iteration 73000 (0.311742 iter/s, 320.778s/100 iters), loss = 1.03524
I1213 04:21:37.653295 15749 solver.cpp:237]     Train net output #0: label = 693
I1213 04:21:37.653316 15749 solver.cpp:237]     Train net output #1: label_phocs = 693
I1213 04:21:37.653327 15749 solver.cpp:237]     Train net output #2: loss = 1.17798 (* 1 = 1.17798 loss)
I1213 04:21:37.653337 15749 sgd_solver.cpp:116] Iteration 73000, lr = 1e-05
I1213 04:24:52.742575 15749 solver.cpp:218] Iteration 73100 (0.512585 iter/s, 195.089s/100 iters), loss = 0.829835
I1213 04:24:52.742774 15749 solver.cpp:237]     Train net output #0: label = 386
I1213 04:24:52.742799 15749 solver.cpp:237]     Train net output #1: label_phocs = 386
I1213 04:24:52.742810 15749 solver.cpp:237]     Train net output #2: loss = 0.326289 (* 1 = 0.326289 loss)
I1213 04:24:52.742820 15749 sgd_solver.cpp:116] Iteration 73100, lr = 1e-05
I1213 04:28:12.197041 15749 solver.cpp:218] Iteration 73200 (0.501368 iter/s, 199.454s/100 iters), loss = 0.825078
I1213 04:28:12.197574 15749 solver.cpp:237]     Train net output #0: label = 1077
I1213 04:28:12.197592 15749 solver.cpp:237]     Train net output #1: label_phocs = 1077
I1213 04:28:12.197600 15749 solver.cpp:237]     Train net output #2: loss = 0.0300773 (* 1 = 0.0300773 loss)
I1213 04:28:12.197607 15749 sgd_solver.cpp:116] Iteration 73200, lr = 1e-05
I1213 04:31:06.569394 15749 solver.cpp:218] Iteration 73300 (0.573558 iter/s, 174.35s/100 iters), loss = 0.764134
I1213 04:31:06.569802 15749 solver.cpp:237]     Train net output #0: label = 1008
I1213 04:31:06.569825 15749 solver.cpp:237]     Train net output #1: label_phocs = 1008
I1213 04:31:06.569841 15749 solver.cpp:237]     Train net output #2: loss = 0.247034 (* 1 = 0.247034 loss)
I1213 04:31:06.569850 15749 sgd_solver.cpp:116] Iteration 73300, lr = 1e-05
I1213 04:34:25.617012 15749 solver.cpp:218] Iteration 73400 (0.502393 iter/s, 199.047s/100 iters), loss = 0.79812
I1213 04:34:25.617099 15749 solver.cpp:237]     Train net output #0: label = 541
I1213 04:34:25.617122 15749 solver.cpp:237]     Train net output #1: label_phocs = 541
I1213 04:34:25.617133 15749 solver.cpp:237]     Train net output #2: loss = 1.62705 (* 1 = 1.62705 loss)
I1213 04:34:25.617142 15749 sgd_solver.cpp:116] Iteration 73400, lr = 1e-05
[2017-12-13 04:37:46,787, PHOCNetTrainer] Running test evaluation
[2017-12-13 04:37:46,788, PHOCNetTrainer] Evaluating CNN after 73000 steps:
I1213 04:39:00.253330 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:39:00.254639 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 04:39:02,111, PHOCNetTrainer] mAP: 0.928894
I1213 04:39:02.112937 15749 solver.cpp:330] Iteration 73500, Testing net (#0)
I1213 04:39:02.113117 15749 net.cpp:676] Ignoring source layer drop6
I1213 04:39:02.113124 15749 net.cpp:676] Ignoring source layer drop7
I1213 04:40:04.967974 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:40:04.968128 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:40:05.748945 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 04:40:05.748991 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 04:40:05.749001 15749 solver.cpp:397]     Test net output #2: loss = 16.0786 (* 1 = 16.0786 loss)
I1213 04:40:07.149260 15749 solver.cpp:218] Iteration 73500 (0.292798 iter/s, 341.533s/100 iters), loss = 0.554009
I1213 04:40:07.149349 15749 solver.cpp:237]     Train net output #0: label = 324
I1213 04:40:07.149379 15749 solver.cpp:237]     Train net output #1: label_phocs = 324
I1213 04:40:07.149396 15749 solver.cpp:237]     Train net output #2: loss = 0.147784 (* 1 = 0.147784 loss)
I1213 04:40:07.149408 15749 sgd_solver.cpp:116] Iteration 73500, lr = 1e-05
I1213 04:43:05.939508 15749 solver.cpp:218] Iteration 73600 (0.559314 iter/s, 178.79s/100 iters), loss = 0.746383
I1213 04:43:05.940742 15749 solver.cpp:237]     Train net output #0: label = 191
I1213 04:43:05.940768 15749 solver.cpp:237]     Train net output #1: label_phocs = 191
I1213 04:43:05.940778 15749 solver.cpp:237]     Train net output #2: loss = 0.406026 (* 1 = 0.406026 loss)
I1213 04:43:05.940788 15749 sgd_solver.cpp:116] Iteration 73600, lr = 1e-05
I1213 04:46:18.884420 15749 solver.cpp:218] Iteration 73700 (0.518285 iter/s, 192.944s/100 iters), loss = 0.744144
I1213 04:46:18.885242 15749 solver.cpp:237]     Train net output #0: label = 398
I1213 04:46:18.885267 15749 solver.cpp:237]     Train net output #1: label_phocs = 398
I1213 04:46:18.885277 15749 solver.cpp:237]     Train net output #2: loss = 0.331749 (* 1 = 0.331749 loss)
I1213 04:46:18.885282 15749 sgd_solver.cpp:116] Iteration 73700, lr = 1e-05
I1213 04:49:34.616950 15749 solver.cpp:218] Iteration 73800 (0.510903 iter/s, 195.732s/100 iters), loss = 0.797971
I1213 04:49:34.617033 15749 solver.cpp:237]     Train net output #0: label = 967
I1213 04:49:34.617056 15749 solver.cpp:237]     Train net output #1: label_phocs = 967
I1213 04:49:34.617069 15749 solver.cpp:237]     Train net output #2: loss = 0.03059 (* 1 = 0.03059 loss)
I1213 04:49:34.617077 15749 sgd_solver.cpp:116] Iteration 73800, lr = 1e-05
I1213 04:52:25.930901 15749 solver.cpp:218] Iteration 73900 (0.583723 iter/s, 171.314s/100 iters), loss = 0.726634
I1213 04:52:25.930989 15749 solver.cpp:237]     Train net output #0: label = 6
I1213 04:52:25.931012 15749 solver.cpp:237]     Train net output #1: label_phocs = 6
I1213 04:52:25.931023 15749 solver.cpp:237]     Train net output #2: loss = 0.405489 (* 1 = 0.405489 loss)
I1213 04:52:25.931032 15749 sgd_solver.cpp:116] Iteration 73900, lr = 1e-05
[2017-12-13 04:55:43,344, PHOCNetTrainer] Running test evaluation
[2017-12-13 04:55:43,344, PHOCNetTrainer] Evaluating CNN after 73500 steps:
I1213 04:56:56.047926 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:56:56.048048 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 04:56:58,036, PHOCNetTrainer] mAP: 0.928313
I1213 04:56:58.038300 15749 solver.cpp:330] Iteration 74000, Testing net (#0)
I1213 04:56:58.038491 15749 net.cpp:676] Ignoring source layer drop6
I1213 04:56:58.038499 15749 net.cpp:676] Ignoring source layer drop7
I1213 04:58:05.373905 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:58:05.374039 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 04:58:06.308362 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 04:58:06.308399 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 04:58:06.308408 15749 solver.cpp:397]     Test net output #2: loss = 16.0296 (* 1 = 16.0296 loss)
I1213 04:58:08.266975 15749 solver.cpp:218] Iteration 74000 (0.29211 iter/s, 342.336s/100 iters), loss = 0.75545
I1213 04:58:08.267253 15749 solver.cpp:237]     Train net output #0: label = 416
I1213 04:58:08.267277 15749 solver.cpp:237]     Train net output #1: label_phocs = 416
I1213 04:58:08.267288 15749 solver.cpp:237]     Train net output #2: loss = 0.0617196 (* 1 = 0.0617196 loss)
I1213 04:58:08.267297 15749 sgd_solver.cpp:116] Iteration 74000, lr = 1e-05
I1213 05:00:58.366976 15749 solver.cpp:218] Iteration 74100 (0.58789 iter/s, 170.1s/100 iters), loss = 0.894357
I1213 05:00:58.368110 15749 solver.cpp:237]     Train net output #0: label = 451
I1213 05:00:58.368139 15749 solver.cpp:237]     Train net output #1: label_phocs = 451
I1213 05:00:58.368150 15749 solver.cpp:237]     Train net output #2: loss = 1.72018 (* 1 = 1.72018 loss)
I1213 05:00:58.368160 15749 sgd_solver.cpp:116] Iteration 74100, lr = 1e-05
I1213 05:04:21.123844 15749 solver.cpp:218] Iteration 74200 (0.493204 iter/s, 202.756s/100 iters), loss = 0.719485
I1213 05:04:21.125030 15749 solver.cpp:237]     Train net output #0: label = 276
I1213 05:04:21.125051 15749 solver.cpp:237]     Train net output #1: label_phocs = 276
I1213 05:04:21.125058 15749 solver.cpp:237]     Train net output #2: loss = 1.281 (* 1 = 1.281 loss)
I1213 05:04:21.125066 15749 sgd_solver.cpp:116] Iteration 74200, lr = 1e-05
I1213 05:07:39.393230 15749 solver.cpp:218] Iteration 74300 (0.504378 iter/s, 198.264s/100 iters), loss = 0.819058
I1213 05:07:39.394183 15749 solver.cpp:237]     Train net output #0: label = 28
I1213 05:07:39.394210 15749 solver.cpp:237]     Train net output #1: label_phocs = 28
I1213 05:07:39.394222 15749 solver.cpp:237]     Train net output #2: loss = 0.1893 (* 1 = 0.1893 loss)
I1213 05:07:39.394230 15749 sgd_solver.cpp:116] Iteration 74300, lr = 1e-05
I1213 05:10:48.914599 15749 solver.cpp:218] Iteration 74400 (0.527647 iter/s, 189.521s/100 iters), loss = 0.768648
I1213 05:10:48.915012 15749 solver.cpp:237]     Train net output #0: label = 553
I1213 05:10:48.915031 15749 solver.cpp:237]     Train net output #1: label_phocs = 553
I1213 05:10:48.915040 15749 solver.cpp:237]     Train net output #2: loss = 0.00181248 (* 1 = 0.00181248 loss)
I1213 05:10:48.915045 15749 sgd_solver.cpp:116] Iteration 74400, lr = 1e-05
[2017-12-13 05:13:51,176, PHOCNetTrainer] Running test evaluation
[2017-12-13 05:13:51,176, PHOCNetTrainer] Evaluating CNN after 74000 steps:
I1213 05:15:03.008862 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:15:03.009305 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 05:15:04,930, PHOCNetTrainer] mAP: 0.927824
I1213 05:15:04.932458 15749 solver.cpp:330] Iteration 74500, Testing net (#0)
I1213 05:15:04.932644 15749 net.cpp:676] Ignoring source layer drop6
I1213 05:15:04.932653 15749 net.cpp:676] Ignoring source layer drop7
I1213 05:16:14.059954 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:16:14.060144 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:16:15.469244 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 05:16:15.469296 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 05:16:15.469307 15749 solver.cpp:397]     Test net output #2: loss = 16.2788 (* 1 = 16.2788 loss)
I1213 05:16:17.021214 15749 solver.cpp:218] Iteration 74500 (0.304779 iter/s, 328.107s/100 iters), loss = 1.1196
I1213 05:16:17.021327 15749 solver.cpp:237]     Train net output #0: label = 1055
I1213 05:16:17.021345 15749 solver.cpp:237]     Train net output #1: label_phocs = 1055
I1213 05:16:17.021353 15749 solver.cpp:237]     Train net output #2: loss = 0.132158 (* 1 = 0.132158 loss)
I1213 05:16:17.021359 15749 sgd_solver.cpp:116] Iteration 74500, lr = 1e-05
I1213 05:19:28.813383 15749 solver.cpp:218] Iteration 74600 (0.521397 iter/s, 191.792s/100 iters), loss = 0.816341
I1213 05:19:28.813470 15749 solver.cpp:237]     Train net output #0: label = 1069
I1213 05:19:28.813493 15749 solver.cpp:237]     Train net output #1: label_phocs = 1069
I1213 05:19:28.813504 15749 solver.cpp:237]     Train net output #2: loss = 1.39775 (* 1 = 1.39775 loss)
I1213 05:19:28.813513 15749 sgd_solver.cpp:116] Iteration 74600, lr = 1e-05
I1213 05:22:20.758193 15749 solver.cpp:218] Iteration 74700 (0.581582 iter/s, 171.945s/100 iters), loss = 0.902547
I1213 05:22:20.758314 15749 solver.cpp:237]     Train net output #0: label = 705
I1213 05:22:20.758337 15749 solver.cpp:237]     Train net output #1: label_phocs = 705
I1213 05:22:20.758350 15749 solver.cpp:237]     Train net output #2: loss = 0.0341196 (* 1 = 0.0341196 loss)
I1213 05:22:20.758358 15749 sgd_solver.cpp:116] Iteration 74700, lr = 1e-05
I1213 05:25:36.387205 15749 solver.cpp:218] Iteration 74800 (0.511171 iter/s, 195.629s/100 iters), loss = 0.785651
I1213 05:25:36.387287 15749 solver.cpp:237]     Train net output #0: label = 239
I1213 05:25:36.387310 15749 solver.cpp:237]     Train net output #1: label_phocs = 239
I1213 05:25:36.387322 15749 solver.cpp:237]     Train net output #2: loss = 0.0227143 (* 1 = 0.0227143 loss)
I1213 05:25:36.387331 15749 sgd_solver.cpp:116] Iteration 74800, lr = 1e-05
I1213 05:28:52.623108 15749 solver.cpp:218] Iteration 74900 (0.50959 iter/s, 196.236s/100 iters), loss = 0.697343
I1213 05:28:52.623544 15749 solver.cpp:237]     Train net output #0: label = 1
I1213 05:28:52.623569 15749 solver.cpp:237]     Train net output #1: label_phocs = 1
I1213 05:28:52.623579 15749 solver.cpp:237]     Train net output #2: loss = 1.0808 (* 1 = 1.0808 loss)
I1213 05:28:52.623586 15749 sgd_solver.cpp:116] Iteration 74900, lr = 1e-05
[2017-12-13 05:31:42,008, PHOCNetTrainer] Running test evaluation
[2017-12-13 05:31:42,009, PHOCNetTrainer] Evaluating CNN after 74500 steps:
I1213 05:32:54.401774 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:32:54.402247 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 05:32:55,889, PHOCNetTrainer] mAP: 0.927957
I1213 05:32:55.890892 15749 solver.cpp:330] Iteration 75000, Testing net (#0)
I1213 05:32:55.891083 15749 net.cpp:676] Ignoring source layer drop6
I1213 05:32:55.891091 15749 net.cpp:676] Ignoring source layer drop7
I1213 05:34:05.539873 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:34:05.540005 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:34:06.589848 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 05:34:06.589890 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 05:34:06.589901 15749 solver.cpp:397]     Test net output #2: loss = 16.1452 (* 1 = 16.1452 loss)
I1213 05:34:08.200846 15749 solver.cpp:218] Iteration 75000 (0.316879 iter/s, 315.578s/100 iters), loss = 1.07036
I1213 05:34:08.201990 15749 solver.cpp:237]     Train net output #0: label = 94
I1213 05:34:08.202013 15749 solver.cpp:237]     Train net output #1: label_phocs = 94
I1213 05:34:08.202025 15749 solver.cpp:237]     Train net output #2: loss = 0.374611 (* 1 = 0.374611 loss)
I1213 05:34:08.202034 15749 sgd_solver.cpp:116] Iteration 75000, lr = 1e-05
I1213 05:37:24.300102 15749 solver.cpp:218] Iteration 75100 (0.509948 iter/s, 196.098s/100 iters), loss = 0.836538
I1213 05:37:24.300215 15749 solver.cpp:237]     Train net output #0: label = 58
I1213 05:37:24.300235 15749 solver.cpp:237]     Train net output #1: label_phocs = 58
I1213 05:37:24.300243 15749 solver.cpp:237]     Train net output #2: loss = 0.444712 (* 1 = 0.444712 loss)
I1213 05:37:24.300249 15749 sgd_solver.cpp:116] Iteration 75100, lr = 1e-05
I1213 05:40:33.106953 15749 solver.cpp:218] Iteration 75200 (0.529642 iter/s, 188.807s/100 iters), loss = 0.737764
I1213 05:40:33.107277 15749 solver.cpp:237]     Train net output #0: label = 182
I1213 05:40:33.107300 15749 solver.cpp:237]     Train net output #1: label_phocs = 182
I1213 05:40:33.107312 15749 solver.cpp:237]     Train net output #2: loss = 0.181769 (* 1 = 0.181769 loss)
I1213 05:40:33.107321 15749 sgd_solver.cpp:116] Iteration 75200, lr = 1e-05
I1213 05:43:35.258384 15749 solver.cpp:218] Iteration 75300 (0.548994 iter/s, 182.151s/100 iters), loss = 0.786037
I1213 05:43:35.259827 15749 solver.cpp:237]     Train net output #0: label = 265
I1213 05:43:35.259856 15749 solver.cpp:237]     Train net output #1: label_phocs = 265
I1213 05:43:35.259869 15749 solver.cpp:237]     Train net output #2: loss = 0.00672378 (* 1 = 0.00672378 loss)
I1213 05:43:35.259878 15749 sgd_solver.cpp:116] Iteration 75300, lr = 1e-05
I1213 05:46:53.195281 15749 solver.cpp:218] Iteration 75400 (0.505215 iter/s, 197.936s/100 iters), loss = 0.748688
I1213 05:46:53.196419 15749 solver.cpp:237]     Train net output #0: label = 68
I1213 05:46:53.196444 15749 solver.cpp:237]     Train net output #1: label_phocs = 68
I1213 05:46:53.196452 15749 solver.cpp:237]     Train net output #2: loss = 0.073606 (* 1 = 0.073606 loss)
I1213 05:46:53.196460 15749 sgd_solver.cpp:116] Iteration 75400, lr = 1e-05
[2017-12-13 05:50:11,341, PHOCNetTrainer] Running test evaluation
[2017-12-13 05:50:11,342, PHOCNetTrainer] Evaluating CNN after 75000 steps:
I1213 05:51:03.557296 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:51:03.557597 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 05:51:04,875, PHOCNetTrainer] mAP: 0.926828
I1213 05:51:04.877266 15749 solver.cpp:330] Iteration 75500, Testing net (#0)
I1213 05:51:04.877468 15749 net.cpp:676] Ignoring source layer drop6
I1213 05:51:04.877478 15749 net.cpp:676] Ignoring source layer drop7
I1213 05:52:04.167706 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:52:04.167971 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 05:52:05.069658 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 05:52:05.069699 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 05:52:05.069710 15749 solver.cpp:397]     Test net output #2: loss = 16.2727 (* 1 = 16.2727 loss)
I1213 05:52:06.769381 15749 solver.cpp:218] Iteration 75500 (0.318905 iter/s, 313.573s/100 iters), loss = 0.344937
I1213 05:52:06.769459 15749 solver.cpp:237]     Train net output #0: label = 516
I1213 05:52:06.769484 15749 solver.cpp:237]     Train net output #1: label_phocs = 516
I1213 05:52:06.769495 15749 solver.cpp:237]     Train net output #2: loss = 1.38836 (* 1 = 1.38836 loss)
I1213 05:52:06.769503 15749 sgd_solver.cpp:116] Iteration 75500, lr = 1e-05
I1213 05:55:19.808640 15749 solver.cpp:218] Iteration 75600 (0.518029 iter/s, 193.039s/100 iters), loss = 0.80711
I1213 05:55:19.809461 15749 solver.cpp:237]     Train net output #0: label = 14
I1213 05:55:19.809489 15749 solver.cpp:237]     Train net output #1: label_phocs = 14
I1213 05:55:19.809500 15749 solver.cpp:237]     Train net output #2: loss = 0.649183 (* 1 = 0.649183 loss)
I1213 05:55:19.809509 15749 sgd_solver.cpp:116] Iteration 75600, lr = 1e-05
I1213 05:58:36.947790 15749 solver.cpp:218] Iteration 75700 (0.507346 iter/s, 197.104s/100 iters), loss = 0.720831
I1213 05:58:36.948843 15749 solver.cpp:237]     Train net output #0: label = 396
I1213 05:58:36.948887 15749 solver.cpp:237]     Train net output #1: label_phocs = 396
I1213 05:58:36.948911 15749 solver.cpp:237]     Train net output #2: loss = 0.089137 (* 1 = 0.089137 loss)
I1213 05:58:36.948921 15749 sgd_solver.cpp:116] Iteration 75700, lr = 1e-05
I1213 06:01:31.003727 15749 solver.cpp:218] Iteration 75800 (0.574531 iter/s, 174.055s/100 iters), loss = 0.719533
I1213 06:01:31.026451 15749 solver.cpp:237]     Train net output #0: label = 66
I1213 06:01:31.026479 15749 solver.cpp:237]     Train net output #1: label_phocs = 66
I1213 06:01:31.026490 15749 solver.cpp:237]     Train net output #2: loss = 0.50795 (* 1 = 0.50795 loss)
I1213 06:01:31.026499 15749 sgd_solver.cpp:116] Iteration 75800, lr = 1e-05
I1213 06:04:41.373018 15749 solver.cpp:218] Iteration 75900 (0.525397 iter/s, 190.332s/100 iters), loss = 0.671142
I1213 06:04:41.373453 15749 solver.cpp:237]     Train net output #0: label = 65
I1213 06:04:41.373477 15749 solver.cpp:237]     Train net output #1: label_phocs = 65
I1213 06:04:41.373489 15749 solver.cpp:237]     Train net output #2: loss = 0.0229267 (* 1 = 0.0229267 loss)
I1213 06:04:41.373497 15749 sgd_solver.cpp:116] Iteration 75900, lr = 1e-05
[2017-12-13 06:07:55,363, PHOCNetTrainer] Running test evaluation
[2017-12-13 06:07:55,363, PHOCNetTrainer] Evaluating CNN after 75500 steps:
I1213 06:09:09.252146 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:09:09.252146 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 06:09:10,729, PHOCNetTrainer] mAP: 0.926448
I1213 06:09:10.730618 15749 solver.cpp:330] Iteration 76000, Testing net (#0)
I1213 06:09:10.730813 15749 net.cpp:676] Ignoring source layer drop6
I1213 06:09:10.730823 15749 net.cpp:676] Ignoring source layer drop7
I1213 06:10:15.427801 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:10:15.427796 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:10:16.121320 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 06:10:16.121362 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 06:10:16.121373 15749 solver.cpp:397]     Test net output #2: loss = 16.1464 (* 1 = 16.1464 loss)
I1213 06:10:17.387449 15749 solver.cpp:218] Iteration 76000 (0.297606 iter/s, 336.014s/100 iters), loss = 0.4316
I1213 06:10:17.387548 15749 solver.cpp:237]     Train net output #0: label = 392
I1213 06:10:17.387579 15749 solver.cpp:237]     Train net output #1: label_phocs = 392
I1213 06:10:17.387593 15749 solver.cpp:237]     Train net output #2: loss = 1.87271 (* 1 = 1.87271 loss)
I1213 06:10:17.387603 15749 sgd_solver.cpp:116] Iteration 76000, lr = 1e-05
I1213 06:13:11.821867 15749 solver.cpp:218] Iteration 76100 (0.573281 iter/s, 174.435s/100 iters), loss = 0.8279
I1213 06:13:11.821951 15749 solver.cpp:237]     Train net output #0: label = 1010
I1213 06:13:11.821975 15749 solver.cpp:237]     Train net output #1: label_phocs = 1010
I1213 06:13:11.821987 15749 solver.cpp:237]     Train net output #2: loss = 0.00881402 (* 1 = 0.00881402 loss)
I1213 06:13:11.821995 15749 sgd_solver.cpp:116] Iteration 76100, lr = 1e-05
I1213 06:16:20.088474 15749 solver.cpp:218] Iteration 76200 (0.531161 iter/s, 188.267s/100 iters), loss = 0.726021
I1213 06:16:20.089606 15749 solver.cpp:237]     Train net output #0: label = 135
I1213 06:16:20.089629 15749 solver.cpp:237]     Train net output #1: label_phocs = 135
I1213 06:16:20.089640 15749 solver.cpp:237]     Train net output #2: loss = 0.278108 (* 1 = 0.278108 loss)
I1213 06:16:20.089648 15749 sgd_solver.cpp:116] Iteration 76200, lr = 1e-05
I1213 06:19:32.141736 15749 solver.cpp:218] Iteration 76300 (0.520691 iter/s, 192.052s/100 iters), loss = 0.838902
I1213 06:19:32.142506 15749 solver.cpp:237]     Train net output #0: label = 823
I1213 06:19:32.142532 15749 solver.cpp:237]     Train net output #1: label_phocs = 823
I1213 06:19:32.142544 15749 solver.cpp:237]     Train net output #2: loss = 0.0640393 (* 1 = 0.0640393 loss)
I1213 06:19:32.142552 15749 sgd_solver.cpp:116] Iteration 76300, lr = 1e-05
I1213 06:22:24.625020 15749 solver.cpp:218] Iteration 76400 (0.579768 iter/s, 172.483s/100 iters), loss = 0.694555
I1213 06:22:24.626157 15749 solver.cpp:237]     Train net output #0: label = 258
I1213 06:22:24.626206 15749 solver.cpp:237]     Train net output #1: label_phocs = 258
I1213 06:22:24.626219 15749 solver.cpp:237]     Train net output #2: loss = 0.820201 (* 1 = 0.820201 loss)
I1213 06:22:24.626230 15749 sgd_solver.cpp:116] Iteration 76400, lr = 1e-05
[2017-12-13 06:25:33,687, PHOCNetTrainer] Running test evaluation
[2017-12-13 06:25:33,687, PHOCNetTrainer] Evaluating CNN after 76000 steps:
I1213 06:26:46.860191 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:26:46.862092 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 06:26:48,470, PHOCNetTrainer] mAP: 0.927868
I1213 06:26:48.471905 15749 solver.cpp:330] Iteration 76500, Testing net (#0)
I1213 06:26:48.472084 15749 net.cpp:676] Ignoring source layer drop6
I1213 06:26:48.472091 15749 net.cpp:676] Ignoring source layer drop7
I1213 06:27:58.344611 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:27:58.345909 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:27:58.903954 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 06:27:58.904001 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 06:27:58.904012 15749 solver.cpp:397]     Test net output #2: loss = 16.088 (* 1 = 16.088 loss)
I1213 06:28:00.808495 15749 solver.cpp:218] Iteration 76500 (0.297457 iter/s, 336.183s/100 iters), loss = 0.514427
I1213 06:28:00.808578 15749 solver.cpp:237]     Train net output #0: label = 434
I1213 06:28:00.808601 15749 solver.cpp:237]     Train net output #1: label_phocs = 434
I1213 06:28:00.808614 15749 solver.cpp:237]     Train net output #2: loss = 0.001959 (* 1 = 0.001959 loss)
I1213 06:28:00.808622 15749 sgd_solver.cpp:116] Iteration 76500, lr = 1e-05
I1213 06:31:09.355469 15749 solver.cpp:218] Iteration 76600 (0.530371 iter/s, 188.547s/100 iters), loss = 0.762131
I1213 06:31:09.355556 15749 solver.cpp:237]     Train net output #0: label = 316
I1213 06:31:09.355581 15749 solver.cpp:237]     Train net output #1: label_phocs = 316
I1213 06:31:09.355592 15749 solver.cpp:237]     Train net output #2: loss = 0.0936338 (* 1 = 0.0936338 loss)
I1213 06:31:09.355600 15749 sgd_solver.cpp:116] Iteration 76600, lr = 1e-05
I1213 06:34:32.001332 15749 solver.cpp:218] Iteration 76700 (0.493472 iter/s, 202.646s/100 iters), loss = 0.798141
I1213 06:34:32.001492 15749 solver.cpp:237]     Train net output #0: label = 262
I1213 06:34:32.001518 15749 solver.cpp:237]     Train net output #1: label_phocs = 262
I1213 06:34:32.001530 15749 solver.cpp:237]     Train net output #2: loss = 0.00678997 (* 1 = 0.00678997 loss)
I1213 06:34:32.001540 15749 sgd_solver.cpp:116] Iteration 76700, lr = 1e-05
I1213 06:38:40.973392 15749 solver.cpp:218] Iteration 76800 (0.401652 iter/s, 248.972s/100 iters), loss = 0.783364
I1213 06:38:40.973762 15749 solver.cpp:237]     Train net output #0: label = 667
I1213 06:38:40.973796 15749 solver.cpp:237]     Train net output #1: label_phocs = 667
I1213 06:38:40.973811 15749 solver.cpp:237]     Train net output #2: loss = 3.02452 (* 1 = 3.02452 loss)
I1213 06:38:40.973824 15749 sgd_solver.cpp:116] Iteration 76800, lr = 1e-05
I1213 06:42:45.963697 15749 solver.cpp:218] Iteration 76900 (0.408256 iter/s, 244.944s/100 iters), loss = 0.722127
I1213 06:42:45.963826 15749 solver.cpp:237]     Train net output #0: label = 270
I1213 06:42:45.963855 15749 solver.cpp:237]     Train net output #1: label_phocs = 270
I1213 06:42:45.963867 15749 solver.cpp:237]     Train net output #2: loss = 0.0768573 (* 1 = 0.0768573 loss)
I1213 06:42:45.963879 15749 sgd_solver.cpp:116] Iteration 76900, lr = 1e-05
[2017-12-13 06:46:10,123, PHOCNetTrainer] Running test evaluation
[2017-12-13 06:46:10,124, PHOCNetTrainer] Evaluating CNN after 76500 steps:
I1213 06:48:08.008582 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:48:08.008896 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 06:48:11,276, PHOCNetTrainer] mAP: 0.927422
I1213 06:48:11.278101 15749 solver.cpp:330] Iteration 77000, Testing net (#0)
I1213 06:48:11.278357 15749 net.cpp:676] Ignoring source layer drop6
I1213 06:48:11.278369 15749 net.cpp:676] Ignoring source layer drop7
I1213 06:50:01.881999 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:50:01.892478 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 06:50:03.125829 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 06:50:03.125891 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 06:50:03.125906 15749 solver.cpp:397]     Test net output #2: loss = 16.1568 (* 1 = 16.1568 loss)
I1213 06:50:04.983119 15749 solver.cpp:218] Iteration 77000 (0.22778 iter/s, 439.02s/100 iters), loss = 2.07675
I1213 06:50:04.983252 15749 solver.cpp:237]     Train net output #0: label = 438
I1213 06:50:04.983280 15749 solver.cpp:237]     Train net output #1: label_phocs = 438
I1213 06:50:04.983295 15749 solver.cpp:237]     Train net output #2: loss = 0.272528 (* 1 = 0.272528 loss)
I1213 06:50:04.983306 15749 sgd_solver.cpp:116] Iteration 77000, lr = 1e-05
I1213 06:54:02.522665 15749 solver.cpp:218] Iteration 77100 (0.421007 iter/s, 237.526s/100 iters), loss = 0.787901
I1213 06:54:02.522778 15749 solver.cpp:237]     Train net output #0: label = 96
I1213 06:54:02.522804 15749 solver.cpp:237]     Train net output #1: label_phocs = 96
I1213 06:54:02.522816 15749 solver.cpp:237]     Train net output #2: loss = 1.13897 (* 1 = 1.13897 loss)
I1213 06:54:02.522826 15749 sgd_solver.cpp:116] Iteration 77100, lr = 1e-05
I1213 06:57:38.511910 15749 solver.cpp:218] Iteration 77200 (0.463007 iter/s, 215.979s/100 iters), loss = 0.753424
I1213 06:57:38.512038 15749 solver.cpp:237]     Train net output #0: label = 117
I1213 06:57:38.512064 15749 solver.cpp:237]     Train net output #1: label_phocs = 117
I1213 06:57:38.512076 15749 solver.cpp:237]     Train net output #2: loss = 2.08487 (* 1 = 2.08487 loss)
I1213 06:57:38.512085 15749 sgd_solver.cpp:116] Iteration 77200, lr = 1e-05
I1213 07:01:40.815726 15749 solver.cpp:218] Iteration 77300 (0.412711 iter/s, 242.3s/100 iters), loss = 0.704371
I1213 07:01:40.816499 15749 solver.cpp:237]     Train net output #0: label = 924
I1213 07:01:40.816577 15749 solver.cpp:237]     Train net output #1: label_phocs = 924
I1213 07:01:40.816593 15749 solver.cpp:237]     Train net output #2: loss = 0.741503 (* 1 = 0.741503 loss)
I1213 07:01:40.816604 15749 sgd_solver.cpp:116] Iteration 77300, lr = 1e-05
I1213 07:05:55.444439 15749 solver.cpp:218] Iteration 77400 (0.392737 iter/s, 254.623s/100 iters), loss = 0.83724
I1213 07:05:55.445549 15749 solver.cpp:237]     Train net output #0: label = 788
I1213 07:05:55.445614 15749 solver.cpp:237]     Train net output #1: label_phocs = 788
I1213 07:05:55.445628 15749 solver.cpp:237]     Train net output #2: loss = 0.00636226 (* 1 = 0.00636226 loss)
I1213 07:05:55.445638 15749 sgd_solver.cpp:116] Iteration 77400, lr = 1e-05
[2017-12-13 07:09:39,518, PHOCNetTrainer] Running test evaluation
[2017-12-13 07:09:39,519, PHOCNetTrainer] Evaluating CNN after 77000 steps:
I1213 07:11:04.375906 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:11:04.376068 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 07:11:08,430, PHOCNetTrainer] mAP: 0.925609
I1213 07:11:08.431890 15749 solver.cpp:330] Iteration 77500, Testing net (#0)
I1213 07:11:08.432150 15749 net.cpp:676] Ignoring source layer drop6
I1213 07:11:08.432163 15749 net.cpp:676] Ignoring source layer drop7
I1213 07:12:45.251873 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:12:45.252025 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:12:47.487912 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 07:12:47.487972 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 07:12:47.487988 15749 solver.cpp:397]     Test net output #2: loss = 16.2603 (* 1 = 16.2603 loss)
I1213 07:12:49.319072 15749 solver.cpp:218] Iteration 77500 (0.24162 iter/s, 413.874s/100 iters), loss = 2.10206
I1213 07:12:49.319432 15749 solver.cpp:237]     Train net output #0: label = 71
I1213 07:12:49.319479 15749 solver.cpp:237]     Train net output #1: label_phocs = 71
I1213 07:12:49.319495 15749 solver.cpp:237]     Train net output #2: loss = 0.0236832 (* 1 = 0.0236832 loss)
I1213 07:12:49.319505 15749 sgd_solver.cpp:116] Iteration 77500, lr = 1e-05
I1213 07:16:53.476213 15749 solver.cpp:218] Iteration 77600 (0.409607 iter/s, 244.136s/100 iters), loss = 0.714721
I1213 07:16:53.476312 15749 solver.cpp:237]     Train net output #0: label = 255
I1213 07:16:53.476343 15749 solver.cpp:237]     Train net output #1: label_phocs = 255
I1213 07:16:53.476359 15749 solver.cpp:237]     Train net output #2: loss = 0.06345 (* 1 = 0.06345 loss)
I1213 07:16:53.476369 15749 sgd_solver.cpp:116] Iteration 77600, lr = 1e-05
I1213 07:21:06.694965 15749 solver.cpp:218] Iteration 77700 (0.394937 iter/s, 253.205s/100 iters), loss = 0.723081
I1213 07:21:06.695220 15749 solver.cpp:237]     Train net output #0: label = 805
I1213 07:21:06.695250 15749 solver.cpp:237]     Train net output #1: label_phocs = 805
I1213 07:21:06.695264 15749 solver.cpp:237]     Train net output #2: loss = 0.00109858 (* 1 = 0.00109858 loss)
I1213 07:21:06.695276 15749 sgd_solver.cpp:116] Iteration 77700, lr = 1e-05
I1213 07:24:41.881245 15749 solver.cpp:218] Iteration 77800 (0.464714 iter/s, 215.186s/100 iters), loss = 0.870952
I1213 07:24:41.882403 15749 solver.cpp:237]     Train net output #0: label = 675
I1213 07:24:41.882503 15749 solver.cpp:237]     Train net output #1: label_phocs = 675
I1213 07:24:41.882521 15749 solver.cpp:237]     Train net output #2: loss = 0.00188511 (* 1 = 0.00188511 loss)
I1213 07:24:41.882534 15749 sgd_solver.cpp:116] Iteration 77800, lr = 1e-05
I1213 07:28:37.546345 15749 solver.cpp:218] Iteration 77900 (0.424333 iter/s, 235.664s/100 iters), loss = 0.813096
I1213 07:28:37.546449 15749 solver.cpp:237]     Train net output #0: label = 909
I1213 07:28:37.546473 15749 solver.cpp:237]     Train net output #1: label_phocs = 909
I1213 07:28:37.546485 15749 solver.cpp:237]     Train net output #2: loss = 0.630654 (* 1 = 0.630654 loss)
I1213 07:28:37.546495 15749 sgd_solver.cpp:116] Iteration 77900, lr = 1e-05
[2017-12-13 07:32:41,934, PHOCNetTrainer] Running test evaluation
[2017-12-13 07:32:41,934, PHOCNetTrainer] Evaluating CNN after 77500 steps:
I1213 07:34:34.271877 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:34:34.272019 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 07:34:38,715, PHOCNetTrainer] mAP: 0.924681
I1213 07:34:38.716845 15749 solver.cpp:330] Iteration 78000, Testing net (#0)
I1213 07:34:38.717089 15749 net.cpp:676] Ignoring source layer drop6
I1213 07:34:38.717104 15749 net.cpp:676] Ignoring source layer drop7
I1213 07:35:45.996218 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:35:46.057546 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:35:47.804126 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 07:35:47.804181 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 07:35:47.804194 15749 solver.cpp:397]     Test net output #2: loss = 16.255 (* 1 = 16.255 loss)
I1213 07:35:49.926765 15749 solver.cpp:218] Iteration 78000 (0.231278 iter/s, 432.381s/100 iters), loss = 0.613307
I1213 07:35:49.927072 15749 solver.cpp:237]     Train net output #0: label = 829
I1213 07:35:49.927112 15749 solver.cpp:237]     Train net output #1: label_phocs = 829
I1213 07:35:49.927132 15749 solver.cpp:237]     Train net output #2: loss = 0.91224 (* 1 = 0.91224 loss)
I1213 07:35:49.927150 15749 sgd_solver.cpp:116] Iteration 78000, lr = 1e-05
I1213 07:39:50.483829 15749 solver.cpp:218] Iteration 78100 (0.41574 iter/s, 240.535s/100 iters), loss = 0.7097
I1213 07:39:50.484983 15749 solver.cpp:237]     Train net output #0: label = 1020
I1213 07:39:50.485072 15749 solver.cpp:237]     Train net output #1: label_phocs = 1020
I1213 07:39:50.485093 15749 solver.cpp:237]     Train net output #2: loss = 0.36091 (* 1 = 0.36091 loss)
I1213 07:39:50.485113 15749 sgd_solver.cpp:116] Iteration 78100, lr = 1e-05
I1213 07:44:00.343824 15749 solver.cpp:218] Iteration 78200 (0.400231 iter/s, 249.856s/100 iters), loss = 0.730151
I1213 07:44:00.344481 15749 solver.cpp:237]     Train net output #0: label = 592
I1213 07:44:00.344552 15749 solver.cpp:237]     Train net output #1: label_phocs = 592
I1213 07:44:00.344568 15749 solver.cpp:237]     Train net output #2: loss = 0.0334188 (* 1 = 0.0334188 loss)
I1213 07:44:00.344580 15749 sgd_solver.cpp:116] Iteration 78200, lr = 1e-05
I1213 07:48:04.878566 15749 solver.cpp:218] Iteration 78300 (0.408941 iter/s, 244.534s/100 iters), loss = 0.707961
I1213 07:48:04.879139 15749 solver.cpp:237]     Train net output #0: label = 479
I1213 07:48:04.879185 15749 solver.cpp:237]     Train net output #1: label_phocs = 479
I1213 07:48:04.879201 15749 solver.cpp:237]     Train net output #2: loss = 0.212942 (* 1 = 0.212942 loss)
I1213 07:48:04.879212 15749 sgd_solver.cpp:116] Iteration 78300, lr = 1e-05
I1213 07:51:42.682088 15749 solver.cpp:218] Iteration 78400 (0.45913 iter/s, 217.803s/100 iters), loss = 0.76319
I1213 07:51:42.682358 15749 solver.cpp:237]     Train net output #0: label = 979
I1213 07:51:42.682387 15749 solver.cpp:237]     Train net output #1: label_phocs = 979
I1213 07:51:42.682404 15749 solver.cpp:237]     Train net output #2: loss = 0.00308251 (* 1 = 0.00308251 loss)
I1213 07:51:42.682415 15749 sgd_solver.cpp:116] Iteration 78400, lr = 1e-05
[2017-12-13 07:55:53,487, PHOCNetTrainer] Running test evaluation
[2017-12-13 07:55:53,488, PHOCNetTrainer] Evaluating CNN after 78000 steps:
I1213 07:57:45.617036 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:57:45.617214 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 07:57:50,055, PHOCNetTrainer] mAP: 0.927027
I1213 07:57:50.056697 15749 solver.cpp:330] Iteration 78500, Testing net (#0)
I1213 07:57:50.056954 15749 net.cpp:676] Ignoring source layer drop6
I1213 07:57:50.056965 15749 net.cpp:676] Ignoring source layer drop7
I1213 07:59:47.292915 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:59:47.293149 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 07:59:49.119886 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 07:59:49.119945 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 07:59:49.119959 15749 solver.cpp:397]     Test net output #2: loss = 16.125 (* 1 = 16.125 loss)
I1213 07:59:50.733131 15749 solver.cpp:218] Iteration 78500 (0.204897 iter/s, 488.051s/100 iters), loss = 0.521568
I1213 07:59:50.733914 15749 solver.cpp:237]     Train net output #0: label = 312
I1213 07:59:50.733989 15749 solver.cpp:237]     Train net output #1: label_phocs = 312
I1213 07:59:50.734005 15749 solver.cpp:237]     Train net output #2: loss = 0.149152 (* 1 = 0.149152 loss)
I1213 07:59:50.734016 15749 sgd_solver.cpp:116] Iteration 78500, lr = 1e-05
I1213 08:03:35.003180 15749 solver.cpp:218] Iteration 78600 (0.445892 iter/s, 224.269s/100 iters), loss = 0.711564
I1213 08:03:35.031913 15749 solver.cpp:237]     Train net output #0: label = 153
I1213 08:03:35.032023 15749 solver.cpp:237]     Train net output #1: label_phocs = 153
I1213 08:03:35.032044 15749 solver.cpp:237]     Train net output #2: loss = 0.56052 (* 1 = 0.56052 loss)
I1213 08:03:35.032057 15749 sgd_solver.cpp:116] Iteration 78600, lr = 1e-05
I1213 08:07:42.273001 15749 solver.cpp:218] Iteration 78700 (0.404418 iter/s, 247.269s/100 iters), loss = 0.775939
I1213 08:07:42.274137 15749 solver.cpp:237]     Train net output #0: label = 576
I1213 08:07:42.274233 15749 solver.cpp:237]     Train net output #1: label_phocs = 576
I1213 08:07:42.274252 15749 solver.cpp:237]     Train net output #2: loss = 0.119866 (* 1 = 0.119866 loss)
I1213 08:07:42.274266 15749 sgd_solver.cpp:116] Iteration 78700, lr = 1e-05
I1213 08:11:47.068138 15749 solver.cpp:218] Iteration 78800 (0.408506 iter/s, 244.794s/100 iters), loss = 0.746467
I1213 08:11:47.068258 15749 solver.cpp:237]     Train net output #0: label = 37
I1213 08:11:47.068286 15749 solver.cpp:237]     Train net output #1: label_phocs = 37
I1213 08:11:47.068301 15749 solver.cpp:237]     Train net output #2: loss = 0.0215088 (* 1 = 0.0215088 loss)
I1213 08:11:47.068312 15749 sgd_solver.cpp:116] Iteration 78800, lr = 1e-05
I1213 08:15:33.832707 15749 solver.cpp:218] Iteration 78900 (0.441029 iter/s, 226.742s/100 iters), loss = 0.801956
I1213 08:15:33.833184 15749 solver.cpp:237]     Train net output #0: label = 609
I1213 08:15:33.833217 15749 solver.cpp:237]     Train net output #1: label_phocs = 609
I1213 08:15:33.833233 15749 solver.cpp:237]     Train net output #2: loss = 0.00970583 (* 1 = 0.00970583 loss)
I1213 08:15:33.833243 15749 sgd_solver.cpp:116] Iteration 78900, lr = 1e-05
[2017-12-13 08:19:30,203, PHOCNetTrainer] Running test evaluation
[2017-12-13 08:19:30,203, PHOCNetTrainer] Evaluating CNN after 78500 steps:
I1213 08:21:41.319880 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:21:41.320055 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 08:21:42,641, PHOCNetTrainer] mAP: 0.925353
I1213 08:21:42.642700 15749 solver.cpp:330] Iteration 79000, Testing net (#0)
I1213 08:21:42.642933 15749 net.cpp:676] Ignoring source layer drop6
I1213 08:21:42.642946 15749 net.cpp:676] Ignoring source layer drop7
I1213 08:23:38.333462 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:23:38.380251 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:23:39.601824 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 08:23:39.601881 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 08:23:39.601892 15749 solver.cpp:397]     Test net output #2: loss = 16.5016 (* 1 = 16.5016 loss)
I1213 08:23:42.575603 15749 solver.cpp:218] Iteration 79000 (0.204607 iter/s, 488.743s/100 iters), loss = 0.403782
I1213 08:23:42.576747 15749 solver.cpp:237]     Train net output #0: label = 145
I1213 08:23:42.576831 15749 solver.cpp:237]     Train net output #1: label_phocs = 145
I1213 08:23:42.576848 15749 solver.cpp:237]     Train net output #2: loss = 0.048784 (* 1 = 0.048784 loss)
I1213 08:23:42.576860 15749 sgd_solver.cpp:116] Iteration 79000, lr = 1e-05
I1213 08:27:23.032253 15749 solver.cpp:218] Iteration 79100 (0.453612 iter/s, 220.453s/100 iters), loss = 0.750316
I1213 08:27:23.032377 15749 solver.cpp:237]     Train net output #0: label = 662
I1213 08:27:23.032408 15749 solver.cpp:237]     Train net output #1: label_phocs = 662
I1213 08:27:23.032425 15749 solver.cpp:237]     Train net output #2: loss = 0.011183 (* 1 = 0.011183 loss)
I1213 08:27:23.032438 15749 sgd_solver.cpp:116] Iteration 79100, lr = 1e-05
I1213 08:31:04.859176 15749 solver.cpp:218] Iteration 79200 (0.450802 iter/s, 221.827s/100 iters), loss = 0.740601
I1213 08:31:04.860325 15749 solver.cpp:237]     Train net output #0: label = 20
I1213 08:31:04.860430 15749 solver.cpp:237]     Train net output #1: label_phocs = 20
I1213 08:31:04.860455 15749 solver.cpp:237]     Train net output #2: loss = 0.107092 (* 1 = 0.107092 loss)
I1213 08:31:04.860471 15749 sgd_solver.cpp:116] Iteration 79200, lr = 1e-05
I1213 08:35:08.358074 15749 solver.cpp:218] Iteration 79300 (0.410731 iter/s, 243.469s/100 iters), loss = 0.778125
I1213 08:35:08.358224 15749 solver.cpp:237]     Train net output #0: label = 338
I1213 08:35:08.358256 15749 solver.cpp:237]     Train net output #1: label_phocs = 338
I1213 08:35:08.358273 15749 solver.cpp:237]     Train net output #2: loss = 0.527805 (* 1 = 0.527805 loss)
I1213 08:35:08.358283 15749 sgd_solver.cpp:116] Iteration 79300, lr = 1e-05
I1213 08:39:17.977139 15749 solver.cpp:218] Iteration 79400 (0.40061 iter/s, 249.619s/100 iters), loss = 0.844503
I1213 08:39:17.977978 15749 solver.cpp:237]     Train net output #0: label = 227
I1213 08:39:17.978027 15749 solver.cpp:237]     Train net output #1: label_phocs = 227
I1213 08:39:17.978042 15749 solver.cpp:237]     Train net output #2: loss = 0.0153877 (* 1 = 0.0153877 loss)
I1213 08:39:17.978058 15749 sgd_solver.cpp:116] Iteration 79400, lr = 1e-05
[2017-12-13 08:42:55,242, PHOCNetTrainer] Running test evaluation
[2017-12-13 08:42:55,242, PHOCNetTrainer] Evaluating CNN after 79000 steps:
I1213 08:45:05.919888 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:45:05.920043 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 08:45:10,753, PHOCNetTrainer] mAP: 0.926832
I1213 08:45:10.755589 15749 solver.cpp:330] Iteration 79500, Testing net (#0)
I1213 08:45:10.768157 15749 net.cpp:676] Ignoring source layer drop6
I1213 08:45:10.768189 15749 net.cpp:676] Ignoring source layer drop7
I1213 08:47:00.615243 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:47:00.654800 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 08:47:01.657601 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 08:47:01.657660 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 08:47:01.657673 15749 solver.cpp:397]     Test net output #2: loss = 16.4351 (* 1 = 16.4351 loss)
I1213 08:47:05.023696 15749 solver.cpp:218] Iteration 79500 (0.214123 iter/s, 467.021s/100 iters), loss = 0.617145
I1213 08:47:05.023835 15749 solver.cpp:237]     Train net output #0: label = 311
I1213 08:47:05.023860 15749 solver.cpp:237]     Train net output #1: label_phocs = 311
I1213 08:47:05.023872 15749 solver.cpp:237]     Train net output #2: loss = 0.210984 (* 1 = 0.210984 loss)
I1213 08:47:05.023882 15749 sgd_solver.cpp:116] Iteration 79500, lr = 1e-05
I1213 08:51:06.390419 15749 solver.cpp:218] Iteration 79600 (0.414329 iter/s, 241.354s/100 iters), loss = 0.80958
I1213 08:51:06.390563 15749 solver.cpp:237]     Train net output #0: label = 347
I1213 08:51:06.390591 15749 solver.cpp:237]     Train net output #1: label_phocs = 347
I1213 08:51:06.390606 15749 solver.cpp:237]     Train net output #2: loss = 1.59857 (* 1 = 1.59857 loss)
I1213 08:51:06.390617 15749 sgd_solver.cpp:116] Iteration 79600, lr = 1e-05
I1213 08:54:42.033298 15749 solver.cpp:218] Iteration 79700 (0.463824 iter/s, 215.599s/100 iters), loss = 0.691566
I1213 08:54:42.033849 15749 solver.cpp:237]     Train net output #0: label = 501
I1213 08:54:42.033900 15749 solver.cpp:237]     Train net output #1: label_phocs = 501
I1213 08:54:42.033916 15749 solver.cpp:237]     Train net output #2: loss = 0.0624674 (* 1 = 0.0624674 loss)
I1213 08:54:42.033928 15749 sgd_solver.cpp:116] Iteration 79700, lr = 1e-05
I1213 08:58:51.668802 15749 solver.cpp:218] Iteration 79800 (0.400628 iter/s, 249.608s/100 iters), loss = 0.727614
I1213 08:58:51.668898 15749 solver.cpp:237]     Train net output #0: label = 987
I1213 08:58:51.668923 15749 solver.cpp:237]     Train net output #1: label_phocs = 987
I1213 08:58:51.668936 15749 solver.cpp:237]     Train net output #2: loss = 0.103923 (* 1 = 0.103923 loss)
I1213 08:58:51.668946 15749 sgd_solver.cpp:116] Iteration 79800, lr = 1e-05
I1213 09:03:02.703480 15749 solver.cpp:218] Iteration 79900 (0.398369 iter/s, 251.024s/100 iters), loss = 0.644008
I1213 09:03:02.704653 15749 solver.cpp:237]     Train net output #0: label = 382
I1213 09:03:02.704726 15749 solver.cpp:237]     Train net output #1: label_phocs = 382
I1213 09:03:02.704740 15749 solver.cpp:237]     Train net output #2: loss = 0.0101807 (* 1 = 0.0101807 loss)
I1213 09:03:02.704751 15749 sgd_solver.cpp:116] Iteration 79900, lr = 1e-05
[2017-12-13 09:06:48,932, PHOCNetTrainer] Running test evaluation
[2017-12-13 09:06:48,932, PHOCNetTrainer] Evaluating CNN after 79500 steps:
I1213 09:08:29.884040 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:08:29.884205 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 09:08:34,400, PHOCNetTrainer] mAP: 0.927073
I1213 09:08:34.401741 15749 solver.cpp:330] Iteration 80000, Testing net (#0)
I1213 09:08:34.402005 15749 net.cpp:676] Ignoring source layer drop6
I1213 09:08:34.402021 15749 net.cpp:676] Ignoring source layer drop7
I1213 09:10:26.107933 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:10:26.108239 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:10:27.951743 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 09:10:27.951795 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 09:10:27.951804 15749 solver.cpp:397]     Test net output #2: loss = 16.3291 (* 1 = 16.3291 loss)
I1213 09:10:30.661747 15749 solver.cpp:218] Iteration 80000 (0.223236 iter/s, 447.957s/100 iters), loss = 0.507414
I1213 09:10:30.661839 15749 solver.cpp:237]     Train net output #0: label = 362
I1213 09:10:30.661865 15749 solver.cpp:237]     Train net output #1: label_phocs = 362
I1213 09:10:30.661880 15749 solver.cpp:237]     Train net output #2: loss = 0.693139 (* 1 = 0.693139 loss)
I1213 09:10:30.661890 15749 sgd_solver.cpp:116] Iteration 80000, lr = 1e-05
I1213 09:14:33.569850 15749 solver.cpp:218] Iteration 80100 (0.41172 iter/s, 242.883s/100 iters), loss = 0.708008
I1213 09:14:33.569970 15749 solver.cpp:237]     Train net output #0: label = 747
I1213 09:14:33.570000 15749 solver.cpp:237]     Train net output #1: label_phocs = 747
I1213 09:14:33.570015 15749 solver.cpp:237]     Train net output #2: loss = 0.137488 (* 1 = 0.137488 loss)
I1213 09:14:33.570026 15749 sgd_solver.cpp:116] Iteration 80100, lr = 1e-05
I1213 09:18:22.792987 15749 solver.cpp:218] Iteration 80200 (0.436325 iter/s, 229.187s/100 iters), loss = 0.798916
I1213 09:18:22.793093 15749 solver.cpp:237]     Train net output #0: label = 709
I1213 09:18:22.793121 15749 solver.cpp:237]     Train net output #1: label_phocs = 709
I1213 09:18:22.793136 15749 solver.cpp:237]     Train net output #2: loss = 0.815426 (* 1 = 0.815426 loss)
I1213 09:18:22.793148 15749 sgd_solver.cpp:116] Iteration 80200, lr = 1e-05
I1213 09:21:54.964123 15749 solver.cpp:218] Iteration 80300 (0.471367 iter/s, 212.149s/100 iters), loss = 0.634451
I1213 09:21:54.964310 15749 solver.cpp:237]     Train net output #0: label = 748
I1213 09:21:54.964341 15749 solver.cpp:237]     Train net output #1: label_phocs = 748
I1213 09:21:54.964354 15749 solver.cpp:237]     Train net output #2: loss = 0.331358 (* 1 = 0.331358 loss)
I1213 09:21:54.964365 15749 sgd_solver.cpp:116] Iteration 80300, lr = 1e-05
I1213 09:26:00.516942 15749 solver.cpp:218] Iteration 80400 (0.407253 iter/s, 245.547s/100 iters), loss = 0.8
I1213 09:26:00.517083 15749 solver.cpp:237]     Train net output #0: label = 489
I1213 09:26:00.517112 15749 solver.cpp:237]     Train net output #1: label_phocs = 489
I1213 09:26:00.517124 15749 solver.cpp:237]     Train net output #2: loss = 0.39756 (* 1 = 0.39756 loss)
I1213 09:26:00.517135 15749 sgd_solver.cpp:116] Iteration 80400, lr = 1e-05
[2017-12-13 09:30:02,381, PHOCNetTrainer] Running test evaluation
[2017-12-13 09:30:02,381, PHOCNetTrainer] Evaluating CNN after 80000 steps:
I1213 09:31:58.351860 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:31:58.352025 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 09:31:59,923, PHOCNetTrainer] mAP: 0.926703
I1213 09:31:59.924821 15749 solver.cpp:330] Iteration 80500, Testing net (#0)
I1213 09:31:59.925118 15749 net.cpp:676] Ignoring source layer drop6
I1213 09:31:59.925146 15749 net.cpp:676] Ignoring source layer drop7
I1213 09:33:39.591892 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:33:39.592039 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:33:40.346164 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 09:33:40.346220 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 09:33:40.346227 15749 solver.cpp:397]     Test net output #2: loss = 16.2372 (* 1 = 16.2372 loss)
I1213 09:33:42.834879 15749 solver.cpp:218] Iteration 80500 (0.216313 iter/s, 462.294s/100 iters), loss = 1.65723
I1213 09:33:42.834980 15749 solver.cpp:237]     Train net output #0: label = 44
I1213 09:33:42.835006 15749 solver.cpp:237]     Train net output #1: label_phocs = 44
I1213 09:33:42.835019 15749 solver.cpp:237]     Train net output #2: loss = 4.17533 (* 1 = 4.17533 loss)
I1213 09:33:42.835037 15749 sgd_solver.cpp:116] Iteration 80500, lr = 1e-05
I1213 09:37:46.322319 15749 solver.cpp:218] Iteration 80600 (0.410699 iter/s, 243.488s/100 iters), loss = 0.703353
I1213 09:37:46.323452 15749 solver.cpp:237]     Train net output #0: label = 682
I1213 09:37:46.323535 15749 solver.cpp:237]     Train net output #1: label_phocs = 682
I1213 09:37:46.323552 15749 solver.cpp:237]     Train net output #2: loss = 0.0286917 (* 1 = 0.0286917 loss)
I1213 09:37:46.323563 15749 sgd_solver.cpp:116] Iteration 80600, lr = 1e-05
I1213 09:41:46.495296 15749 solver.cpp:218] Iteration 80700 (0.41641 iter/s, 240.148s/100 iters), loss = 0.677002
I1213 09:41:46.495398 15749 solver.cpp:237]     Train net output #0: label = 637
I1213 09:41:46.495425 15749 solver.cpp:237]     Train net output #1: label_phocs = 637
I1213 09:41:46.495440 15749 solver.cpp:237]     Train net output #2: loss = 0.227112 (* 1 = 0.227112 loss)
I1213 09:41:46.495450 15749 sgd_solver.cpp:116] Iteration 80700, lr = 1e-05
I1213 09:45:25.284112 15749 solver.cpp:218] Iteration 80800 (0.457062 iter/s, 218.789s/100 iters), loss = 0.700327
I1213 09:45:25.284220 15749 solver.cpp:237]     Train net output #0: label = 439
I1213 09:45:25.284246 15749 solver.cpp:237]     Train net output #1: label_phocs = 439
I1213 09:45:25.284260 15749 solver.cpp:237]     Train net output #2: loss = 0.0688894 (* 1 = 0.0688894 loss)
I1213 09:45:25.284270 15749 sgd_solver.cpp:116] Iteration 80800, lr = 1e-05
I1213 09:49:28.074584 15749 solver.cpp:218] Iteration 80900 (0.411899 iter/s, 242.778s/100 iters), loss = 0.665854
I1213 09:49:28.074702 15749 solver.cpp:237]     Train net output #0: label = 217
I1213 09:49:28.074730 15749 solver.cpp:237]     Train net output #1: label_phocs = 217
I1213 09:49:28.074745 15749 solver.cpp:237]     Train net output #2: loss = 0.00734239 (* 1 = 0.00734239 loss)
I1213 09:49:28.074756 15749 sgd_solver.cpp:116] Iteration 80900, lr = 1e-05
[2017-12-13 09:53:34,005, PHOCNetTrainer] Running test evaluation
[2017-12-13 09:53:34,005, PHOCNetTrainer] Evaluating CNN after 80500 steps:
I1213 09:55:34.896952 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:55:34.897141 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 09:55:36,939, PHOCNetTrainer] mAP: 0.927557
I1213 09:55:36.941491 15749 solver.cpp:330] Iteration 81000, Testing net (#0)
I1213 09:55:36.941753 15749 net.cpp:676] Ignoring source layer drop6
I1213 09:55:36.941767 15749 net.cpp:676] Ignoring source layer drop7
I1213 09:56:51.704900 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:56:51.705128 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 09:56:53.081408 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 09:56:53.081476 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 09:56:53.081499 15749 solver.cpp:397]     Test net output #2: loss = 16.2225 (* 1 = 16.2225 loss)
I1213 09:56:54.875254 15749 solver.cpp:218] Iteration 81000 (0.223813 iter/s, 446.801s/100 iters), loss = 0.353426
I1213 09:56:54.875530 15749 solver.cpp:237]     Train net output #0: label = 313
I1213 09:56:54.875560 15749 solver.cpp:237]     Train net output #1: label_phocs = 313
I1213 09:56:54.875576 15749 solver.cpp:237]     Train net output #2: loss = 1.45949 (* 1 = 1.45949 loss)
I1213 09:56:54.875586 15749 sgd_solver.cpp:116] Iteration 81000, lr = 1e-05
I1213 10:00:38.129992 15749 solver.cpp:218] Iteration 81100 (0.447919 iter/s, 223.255s/100 iters), loss = 0.648242
I1213 10:00:38.147764 15749 solver.cpp:237]     Train net output #0: label = 368
I1213 10:00:38.147827 15749 solver.cpp:237]     Train net output #1: label_phocs = 368
I1213 10:00:38.147841 15749 solver.cpp:237]     Train net output #2: loss = 0.0151637 (* 1 = 0.0151637 loss)
I1213 10:00:38.147851 15749 sgd_solver.cpp:116] Iteration 81100, lr = 1e-05
I1213 10:04:42.259016 15749 solver.cpp:218] Iteration 81200 (0.409649 iter/s, 244.111s/100 iters), loss = 0.759835
I1213 10:04:42.260159 15749 solver.cpp:237]     Train net output #0: label = 689
I1213 10:04:42.260263 15749 solver.cpp:237]     Train net output #1: label_phocs = 689
I1213 10:04:42.260280 15749 solver.cpp:237]     Train net output #2: loss = 0.00675261 (* 1 = 0.00675261 loss)
I1213 10:04:42.260293 15749 sgd_solver.cpp:116] Iteration 81200, lr = 1e-05
I1213 10:08:35.966655 15749 solver.cpp:218] Iteration 81300 (0.427922 iter/s, 233.687s/100 iters), loss = 0.84292
I1213 10:08:35.967778 15749 solver.cpp:237]     Train net output #0: label = 234
I1213 10:08:35.967856 15749 solver.cpp:237]     Train net output #1: label_phocs = 234
I1213 10:08:35.967871 15749 solver.cpp:237]     Train net output #2: loss = 0.189033 (* 1 = 0.189033 loss)
I1213 10:08:35.967881 15749 sgd_solver.cpp:116] Iteration 81300, lr = 1e-05
I1213 10:11:58.458616 15749 solver.cpp:218] Iteration 81400 (0.493867 iter/s, 202.484s/100 iters), loss = 0.723412
I1213 10:11:58.458730 15749 solver.cpp:237]     Train net output #0: label = 739
I1213 10:11:58.458760 15749 solver.cpp:237]     Train net output #1: label_phocs = 739
I1213 10:11:58.458775 15749 solver.cpp:237]     Train net output #2: loss = 2.8679 (* 1 = 2.8679 loss)
I1213 10:11:58.458784 15749 sgd_solver.cpp:116] Iteration 81400, lr = 1e-05
[2017-12-13 10:15:59,939, PHOCNetTrainer] Running test evaluation
[2017-12-13 10:15:59,939, PHOCNetTrainer] Evaluating CNN after 81000 steps:
I1213 10:17:51.061030 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:17:51.061326 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 10:17:54,988, PHOCNetTrainer] mAP: 0.926157
I1213 10:17:54.990423 15749 solver.cpp:330] Iteration 81500, Testing net (#0)
I1213 10:17:54.990716 15749 net.cpp:676] Ignoring source layer drop6
I1213 10:17:54.990742 15749 net.cpp:676] Ignoring source layer drop7
I1213 10:19:55.424880 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:19:55.425199 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:19:56.654675 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 10:19:56.654737 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 10:19:56.654749 15749 solver.cpp:397]     Test net output #2: loss = 16.3296 (* 1 = 16.3296 loss)
I1213 10:19:58.913252 15749 solver.cpp:218] Iteration 81500 (0.208136 iter/s, 480.455s/100 iters), loss = 0.301272
I1213 10:19:58.913363 15749 solver.cpp:237]     Train net output #0: label = 154
I1213 10:19:58.913393 15749 solver.cpp:237]     Train net output #1: label_phocs = 154
I1213 10:19:58.913408 15749 solver.cpp:237]     Train net output #2: loss = 0.0913175 (* 1 = 0.0913175 loss)
I1213 10:19:58.913419 15749 sgd_solver.cpp:116] Iteration 81500, lr = 1e-05
I1213 10:23:24.696884 15749 solver.cpp:218] Iteration 81600 (0.485947 iter/s, 205.784s/100 iters), loss = 0.783541
I1213 10:23:24.697007 15749 solver.cpp:237]     Train net output #0: label = 23
I1213 10:23:24.697036 15749 solver.cpp:237]     Train net output #1: label_phocs = 23
I1213 10:23:24.697052 15749 solver.cpp:237]     Train net output #2: loss = 1.15212 (* 1 = 1.15212 loss)
I1213 10:23:24.697063 15749 sgd_solver.cpp:116] Iteration 81600, lr = 1e-05
I1213 10:27:30.145593 15749 solver.cpp:218] Iteration 81700 (0.40744 iter/s, 245.435s/100 iters), loss = 0.733252
I1213 10:27:30.145709 15749 solver.cpp:237]     Train net output #0: label = 257
I1213 10:27:30.145737 15749 solver.cpp:237]     Train net output #1: label_phocs = 257
I1213 10:27:30.145752 15749 solver.cpp:237]     Train net output #2: loss = 1.1274 (* 1 = 1.1274 loss)
I1213 10:27:30.145763 15749 sgd_solver.cpp:116] Iteration 81700, lr = 1e-05
I1213 10:31:37.504333 15749 solver.cpp:218] Iteration 81800 (0.4043 iter/s, 247.341s/100 iters), loss = 0.730598
I1213 10:31:37.504462 15749 solver.cpp:237]     Train net output #0: label = 811
I1213 10:31:37.504492 15749 solver.cpp:237]     Train net output #1: label_phocs = 811
I1213 10:31:37.504508 15749 solver.cpp:237]     Train net output #2: loss = 0.024646 (* 1 = 0.024646 loss)
I1213 10:31:37.504525 15749 sgd_solver.cpp:116] Iteration 81800, lr = 1e-05
I1213 10:35:22.692037 15749 solver.cpp:218] Iteration 81900 (0.444074 iter/s, 225.188s/100 iters), loss = 0.659729
I1213 10:35:22.692531 15749 solver.cpp:237]     Train net output #0: label = 220
I1213 10:35:22.692564 15749 solver.cpp:237]     Train net output #1: label_phocs = 220
I1213 10:35:22.692577 15749 solver.cpp:237]     Train net output #2: loss = 0.205398 (* 1 = 0.205398 loss)
I1213 10:35:22.692587 15749 sgd_solver.cpp:116] Iteration 81900, lr = 1e-05
[2017-12-13 10:39:02,091, PHOCNetTrainer] Running test evaluation
[2017-12-13 10:39:02,091, PHOCNetTrainer] Evaluating CNN after 81500 steps:
I1213 10:40:49.851886 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:40:49.852028 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 10:40:51,857, PHOCNetTrainer] mAP: 0.924535
I1213 10:40:51.858794 15749 solver.cpp:330] Iteration 82000, Testing net (#0)
I1213 10:40:51.859072 15749 net.cpp:676] Ignoring source layer drop6
I1213 10:40:51.859096 15749 net.cpp:676] Ignoring source layer drop7
I1213 10:42:19.579852 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:42:19.580013 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 10:42:20.159083 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 10:42:20.159138 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 10:42:20.159153 15749 solver.cpp:397]     Test net output #2: loss = 16.6867 (* 1 = 16.6867 loss)
I1213 10:42:22.890291 15749 solver.cpp:218] Iteration 82000 (0.238013 iter/s, 420.145s/100 iters), loss = 1.05128
I1213 10:42:22.890424 15749 solver.cpp:237]     Train net output #0: label = 411
I1213 10:42:22.890453 15749 solver.cpp:237]     Train net output #1: label_phocs = 411
I1213 10:42:22.890468 15749 solver.cpp:237]     Train net output #2: loss = 2.78822 (* 1 = 2.78822 loss)
I1213 10:42:22.890480 15749 sgd_solver.cpp:116] Iteration 82000, lr = 1e-05
I1213 10:46:20.570636 15749 solver.cpp:218] Iteration 82100 (0.420733 iter/s, 237.68s/100 iters), loss = 0.678207
I1213 10:46:20.571779 15749 solver.cpp:237]     Train net output #0: label = 1040
I1213 10:46:20.571854 15749 solver.cpp:237]     Train net output #1: label_phocs = 1040
I1213 10:46:20.571871 15749 solver.cpp:237]     Train net output #2: loss = 0.00974292 (* 1 = 0.00974292 loss)
I1213 10:46:20.571882 15749 sgd_solver.cpp:116] Iteration 82100, lr = 1e-05
I1213 10:49:44.351245 15749 solver.cpp:218] Iteration 82200 (0.490769 iter/s, 203.762s/100 iters), loss = 0.657209
I1213 10:49:44.351377 15749 solver.cpp:237]     Train net output #0: label = 212
I1213 10:49:44.351400 15749 solver.cpp:237]     Train net output #1: label_phocs = 212
I1213 10:49:44.351413 15749 solver.cpp:237]     Train net output #2: loss = 0.0673141 (* 1 = 0.0673141 loss)
I1213 10:49:44.351423 15749 sgd_solver.cpp:116] Iteration 82200, lr = 1e-05
I1213 10:53:32.350899 15749 solver.cpp:218] Iteration 82300 (0.438597 iter/s, 228s/100 iters), loss = 0.648131
I1213 10:53:32.351033 15749 solver.cpp:237]     Train net output #0: label = 1112
I1213 10:53:32.351069 15749 solver.cpp:237]     Train net output #1: label_phocs = 1112
I1213 10:53:32.351085 15749 solver.cpp:237]     Train net output #2: loss = 0.115683 (* 1 = 0.115683 loss)
I1213 10:53:32.351095 15749 sgd_solver.cpp:116] Iteration 82300, lr = 1e-05
I1213 10:57:42.619382 15749 solver.cpp:218] Iteration 82400 (0.399585 iter/s, 250.26s/100 iters), loss = 0.744829
I1213 10:57:42.619483 15749 solver.cpp:237]     Train net output #0: label = 853
I1213 10:57:42.619513 15749 solver.cpp:237]     Train net output #1: label_phocs = 853
I1213 10:57:42.619527 15749 solver.cpp:237]     Train net output #2: loss = 0.0103024 (* 1 = 0.0103024 loss)
I1213 10:57:42.619537 15749 sgd_solver.cpp:116] Iteration 82400, lr = 1e-05
[2017-12-13 11:01:16,324, PHOCNetTrainer] Running test evaluation
[2017-12-13 11:01:16,324, PHOCNetTrainer] Evaluating CNN after 82000 steps:
I1213 11:03:08.191884 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:03:08.192045 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 11:03:11,819, PHOCNetTrainer] mAP: 0.926048
I1213 11:03:11.821842 15749 solver.cpp:330] Iteration 82500, Testing net (#0)
I1213 11:03:11.822162 15749 net.cpp:676] Ignoring source layer drop6
I1213 11:03:11.822178 15749 net.cpp:676] Ignoring source layer drop7
I1213 11:04:52.509690 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:04:52.509897 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:04:54.260399 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 11:04:54.260455 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 11:04:54.260468 15749 solver.cpp:397]     Test net output #2: loss = 16.6268 (* 1 = 16.6268 loss)
I1213 11:04:56.264539 15749 solver.cpp:218] Iteration 82500 (0.230603 iter/s, 433.645s/100 iters), loss = 0.868778
I1213 11:04:56.265671 15749 solver.cpp:237]     Train net output #0: label = 320
I1213 11:04:56.265748 15749 solver.cpp:237]     Train net output #1: label_phocs = 320
I1213 11:04:56.265765 15749 solver.cpp:237]     Train net output #2: loss = 0.627394 (* 1 = 0.627394 loss)
I1213 11:04:56.265777 15749 sgd_solver.cpp:116] Iteration 82500, lr = 1e-05
I1213 11:08:51.592829 15749 solver.cpp:218] Iteration 82600 (0.42494 iter/s, 235.327s/100 iters), loss = 0.764042
I1213 11:08:51.593894 15749 solver.cpp:237]     Train net output #0: label = 353
I1213 11:08:51.593963 15749 solver.cpp:237]     Train net output #1: label_phocs = 353
I1213 11:08:51.593977 15749 solver.cpp:237]     Train net output #2: loss = 0.135447 (* 1 = 0.135447 loss)
I1213 11:08:51.593987 15749 sgd_solver.cpp:116] Iteration 82600, lr = 1e-05
I1213 11:12:31.689226 15749 solver.cpp:218] Iteration 82700 (0.454383 iter/s, 220.079s/100 iters), loss = 0.749402
I1213 11:12:31.689333 15749 solver.cpp:237]     Train net output #0: label = 611
I1213 11:12:31.689358 15749 solver.cpp:237]     Train net output #1: label_phocs = 611
I1213 11:12:31.689371 15749 solver.cpp:237]     Train net output #2: loss = 0.505051 (* 1 = 0.505051 loss)
I1213 11:12:31.689380 15749 sgd_solver.cpp:116] Iteration 82700, lr = 1e-05
I1213 11:16:12.272575 15749 solver.cpp:218] Iteration 82800 (0.453442 iter/s, 220.535s/100 iters), loss = 0.707857
I1213 11:16:12.272686 15749 solver.cpp:237]     Train net output #0: label = 369
I1213 11:16:12.272716 15749 solver.cpp:237]     Train net output #1: label_phocs = 369
I1213 11:16:12.272730 15749 solver.cpp:237]     Train net output #2: loss = 0.991344 (* 1 = 0.991344 loss)
I1213 11:16:12.272742 15749 sgd_solver.cpp:116] Iteration 82800, lr = 1e-05
I1213 11:20:17.941268 15749 solver.cpp:218] Iteration 82900 (0.40714 iter/s, 245.616s/100 iters), loss = 0.760071
I1213 11:20:17.942466 15749 solver.cpp:237]     Train net output #0: label = 576
I1213 11:20:17.942536 15749 solver.cpp:237]     Train net output #1: label_phocs = 576
I1213 11:20:17.942553 15749 solver.cpp:237]     Train net output #2: loss = 0.0203955 (* 1 = 0.0203955 loss)
I1213 11:20:17.942564 15749 sgd_solver.cpp:116] Iteration 82900, lr = 1e-05
[2017-12-13 11:24:06,647, PHOCNetTrainer] Running test evaluation
[2017-12-13 11:24:06,647, PHOCNetTrainer] Evaluating CNN after 82500 steps:
I1213 11:25:32.938359 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:25:32.938467 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 11:25:34,486, PHOCNetTrainer] mAP: 0.925896
I1213 11:25:34.488159 15749 solver.cpp:330] Iteration 83000, Testing net (#0)
I1213 11:25:34.488428 15749 net.cpp:676] Ignoring source layer drop6
I1213 11:25:34.488441 15749 net.cpp:676] Ignoring source layer drop7
I1213 11:27:03.480263 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:27:03.503854 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:27:06.324906 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 11:27:06.324965 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 11:27:06.324991 15749 solver.cpp:397]     Test net output #2: loss = 16.4515 (* 1 = 16.4515 loss)
I1213 11:27:08.908850 15749 solver.cpp:218] Iteration 83000 (0.243332 iter/s, 410.961s/100 iters), loss = 1.50901
I1213 11:27:08.908990 15749 solver.cpp:237]     Train net output #0: label = 713
I1213 11:27:08.909023 15749 solver.cpp:237]     Train net output #1: label_phocs = 713
I1213 11:27:08.909039 15749 solver.cpp:237]     Train net output #2: loss = 0.0236439 (* 1 = 0.0236439 loss)
I1213 11:27:08.909050 15749 sgd_solver.cpp:116] Iteration 83000, lr = 1e-05
I1213 11:31:11.650511 15749 solver.cpp:218] Iteration 83100 (0.411993 iter/s, 242.723s/100 iters), loss = 0.65795
I1213 11:31:11.650665 15749 solver.cpp:237]     Train net output #0: label = 191
I1213 11:31:11.650698 15749 solver.cpp:237]     Train net output #1: label_phocs = 191
I1213 11:31:11.650715 15749 solver.cpp:237]     Train net output #2: loss = 0.0401241 (* 1 = 0.0401241 loss)
I1213 11:31:11.650727 15749 sgd_solver.cpp:116] Iteration 83100, lr = 1e-05
I1213 11:35:18.895937 15749 solver.cpp:218] Iteration 83200 (0.404456 iter/s, 247.245s/100 iters), loss = 0.669737
I1213 11:35:18.896073 15749 solver.cpp:237]     Train net output #0: label = 518
I1213 11:35:18.896101 15749 solver.cpp:237]     Train net output #1: label_phocs = 518
I1213 11:35:18.896117 15749 solver.cpp:237]     Train net output #2: loss = 1.304 (* 1 = 1.304 loss)
I1213 11:35:18.896127 15749 sgd_solver.cpp:116] Iteration 83200, lr = 1e-05
I1213 11:38:37.862776 15749 solver.cpp:218] Iteration 83300 (0.502597 iter/s, 198.967s/100 iters), loss = 0.775107
I1213 11:38:37.863919 15749 solver.cpp:237]     Train net output #0: label = 552
I1213 11:38:37.864013 15749 solver.cpp:237]     Train net output #1: label_phocs = 552
I1213 11:38:37.864033 15749 solver.cpp:237]     Train net output #2: loss = 0.0189031 (* 1 = 0.0189031 loss)
I1213 11:38:37.864047 15749 sgd_solver.cpp:116] Iteration 83300, lr = 1e-05
I1213 11:42:29.951323 15749 solver.cpp:218] Iteration 83400 (0.430872 iter/s, 232.087s/100 iters), loss = 0.742021
I1213 11:42:29.951833 15749 solver.cpp:237]     Train net output #0: label = 967
I1213 11:42:29.951880 15749 solver.cpp:237]     Train net output #1: label_phocs = 967
I1213 11:42:29.951897 15749 solver.cpp:237]     Train net output #2: loss = 2.18017 (* 1 = 2.18017 loss)
I1213 11:42:29.951910 15749 sgd_solver.cpp:116] Iteration 83400, lr = 1e-05
[2017-12-13 11:46:36,028, PHOCNetTrainer] Running test evaluation
[2017-12-13 11:46:36,028, PHOCNetTrainer] Evaluating CNN after 83000 steps:
I1213 11:48:34.663569 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:48:34.665413 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 11:48:36,905, PHOCNetTrainer] mAP: 0.927031
I1213 11:48:36.907071 15749 solver.cpp:330] Iteration 83500, Testing net (#0)
I1213 11:48:36.907340 15749 net.cpp:676] Ignoring source layer drop6
I1213 11:48:36.907351 15749 net.cpp:676] Ignoring source layer drop7
I1213 11:50:06.039880 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:50:06.040030 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 11:50:07.629276 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 11:50:07.629340 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 11:50:07.629356 15749 solver.cpp:397]     Test net output #2: loss = 16.2503 (* 1 = 16.2503 loss)
I1213 11:50:09.509707 15749 solver.cpp:218] Iteration 83500 (0.2176 iter/s, 459.558s/100 iters), loss = 0.430827
I1213 11:50:09.510782 15749 solver.cpp:237]     Train net output #0: label = 572
I1213 11:50:09.510833 15749 solver.cpp:237]     Train net output #1: label_phocs = 572
I1213 11:50:09.510848 15749 solver.cpp:237]     Train net output #2: loss = 0.0341466 (* 1 = 0.0341466 loss)
I1213 11:50:09.510859 15749 sgd_solver.cpp:116] Iteration 83500, lr = 1e-05
I1213 11:54:09.993185 15749 solver.cpp:218] Iteration 83600 (0.415836 iter/s, 240.48s/100 iters), loss = 0.775745
I1213 11:54:09.993342 15749 solver.cpp:237]     Train net output #0: label = 31
I1213 11:54:09.993372 15749 solver.cpp:237]     Train net output #1: label_phocs = 31
I1213 11:54:09.993386 15749 solver.cpp:237]     Train net output #2: loss = 1.89636 (* 1 = 1.89636 loss)
I1213 11:54:09.993396 15749 sgd_solver.cpp:116] Iteration 83600, lr = 1e-05
I1213 11:58:28.169225 15749 solver.cpp:218] Iteration 83700 (0.387333 iter/s, 258.176s/100 iters), loss = 0.702614
I1213 11:58:28.170362 15749 solver.cpp:237]     Train net output #0: label = 152
I1213 11:58:28.170449 15749 solver.cpp:237]     Train net output #1: label_phocs = 152
I1213 11:58:28.170464 15749 solver.cpp:237]     Train net output #2: loss = 0.0970488 (* 1 = 0.0970488 loss)
I1213 11:58:28.170475 15749 sgd_solver.cpp:116] Iteration 83700, lr = 1e-05
I1213 12:02:21.056701 15749 solver.cpp:218] Iteration 83800 (0.429394 iter/s, 232.886s/100 iters), loss = 0.794738
I1213 12:02:21.056849 15749 solver.cpp:237]     Train net output #0: label = 916
I1213 12:02:21.056876 15749 solver.cpp:237]     Train net output #1: label_phocs = 916
I1213 12:02:21.056888 15749 solver.cpp:237]     Train net output #2: loss = 2.5529 (* 1 = 2.5529 loss)
I1213 12:02:21.056898 15749 sgd_solver.cpp:116] Iteration 83800, lr = 1e-05
I1213 12:05:59.757719 15749 solver.cpp:218] Iteration 83900 (0.457263 iter/s, 218.693s/100 iters), loss = 0.795195
I1213 12:05:59.757942 15749 solver.cpp:237]     Train net output #0: label = 584
I1213 12:05:59.757972 15749 solver.cpp:237]     Train net output #1: label_phocs = 584
I1213 12:05:59.757987 15749 solver.cpp:237]     Train net output #2: loss = 0.198936 (* 1 = 0.198936 loss)
I1213 12:05:59.757997 15749 sgd_solver.cpp:116] Iteration 83900, lr = 1e-05
[2017-12-13 12:09:50,537, PHOCNetTrainer] Running test evaluation
[2017-12-13 12:09:50,537, PHOCNetTrainer] Evaluating CNN after 83500 steps:
I1213 12:11:32.759341 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:11:32.759537 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 12:11:37,915, PHOCNetTrainer] mAP: 0.924345
I1213 12:11:37.925256 15749 solver.cpp:330] Iteration 84000, Testing net (#0)
I1213 12:11:37.925510 15749 net.cpp:676] Ignoring source layer drop6
I1213 12:11:37.925521 15749 net.cpp:676] Ignoring source layer drop7
I1213 12:13:28.023977 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:13:28.024140 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:13:29.231741 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 12:13:29.231799 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 12:13:29.231815 15749 solver.cpp:397]     Test net output #2: loss = 16.5659 (* 1 = 16.5659 loss)
I1213 12:13:31.525781 15749 solver.cpp:218] Iteration 84000 (0.221353 iter/s, 451.768s/100 iters), loss = 0.634468
I1213 12:13:31.525900 15749 solver.cpp:237]     Train net output #0: label = 764
I1213 12:13:31.525930 15749 solver.cpp:237]     Train net output #1: label_phocs = 764
I1213 12:13:31.525945 15749 solver.cpp:237]     Train net output #2: loss = 0.692828 (* 1 = 0.692828 loss)
I1213 12:13:31.525955 15749 sgd_solver.cpp:116] Iteration 84000, lr = 1e-05
I1213 12:17:02.090145 15749 solver.cpp:218] Iteration 84100 (0.474914 iter/s, 210.564s/100 iters), loss = 0.689496
I1213 12:17:02.091290 15749 solver.cpp:237]     Train net output #0: label = 592
I1213 12:17:02.091367 15749 solver.cpp:237]     Train net output #1: label_phocs = 592
I1213 12:17:02.091382 15749 solver.cpp:237]     Train net output #2: loss = 8.44014 (* 1 = 8.44014 loss)
I1213 12:17:02.091392 15749 sgd_solver.cpp:116] Iteration 84100, lr = 1e-05
I1213 12:21:04.498469 15749 solver.cpp:218] Iteration 84200 (0.412529 iter/s, 242.407s/100 iters), loss = 0.75967
I1213 12:21:04.498594 15749 solver.cpp:237]     Train net output #0: label = 180
I1213 12:21:04.498621 15749 solver.cpp:237]     Train net output #1: label_phocs = 180
I1213 12:21:04.498636 15749 solver.cpp:237]     Train net output #2: loss = 0.219645 (* 1 = 0.219645 loss)
I1213 12:21:04.498652 15749 sgd_solver.cpp:116] Iteration 84200, lr = 1e-05
I1213 12:25:13.627310 15749 solver.cpp:218] Iteration 84300 (0.401399 iter/s, 249.129s/100 iters), loss = 0.706421
I1213 12:25:13.627424 15749 solver.cpp:237]     Train net output #0: label = 490
I1213 12:25:13.627451 15749 solver.cpp:237]     Train net output #1: label_phocs = 490
I1213 12:25:13.627465 15749 solver.cpp:237]     Train net output #2: loss = 1.60528 (* 1 = 1.60528 loss)
I1213 12:25:13.627475 15749 sgd_solver.cpp:116] Iteration 84300, lr = 1e-05
I1213 12:28:35.559347 15749 solver.cpp:218] Iteration 84400 (0.495216 iter/s, 201.932s/100 iters), loss = 0.700274
I1213 12:28:35.559455 15749 solver.cpp:237]     Train net output #0: label = 211
I1213 12:28:35.559480 15749 solver.cpp:237]     Train net output #1: label_phocs = 211
I1213 12:28:35.559492 15749 solver.cpp:237]     Train net output #2: loss = 0.168939 (* 1 = 0.168939 loss)
I1213 12:28:35.559501 15749 sgd_solver.cpp:116] Iteration 84400, lr = 1e-05
[2017-12-13 12:32:13,000, PHOCNetTrainer] Running test evaluation
[2017-12-13 12:32:13,000, PHOCNetTrainer] Evaluating CNN after 84000 steps:
I1213 12:33:58.295430 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:33:58.295555 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 12:34:02,683, PHOCNetTrainer] mAP: 0.925970
I1213 12:34:02.685611 15749 solver.cpp:330] Iteration 84500, Testing net (#0)
I1213 12:34:02.685883 15749 net.cpp:676] Ignoring source layer drop6
I1213 12:34:02.685902 15749 net.cpp:676] Ignoring source layer drop7
I1213 12:35:49.634289 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:35:49.634474 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:35:50.846906 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 12:35:50.846961 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 12:35:50.846974 15749 solver.cpp:397]     Test net output #2: loss = 16.3181 (* 1 = 16.3181 loss)
I1213 12:35:52.434214 15749 solver.cpp:218] Iteration 84500 (0.228907 iter/s, 436.859s/100 iters), loss = 0.811077
I1213 12:35:52.434339 15749 solver.cpp:237]     Train net output #0: label = 687
I1213 12:35:52.434363 15749 solver.cpp:237]     Train net output #1: label_phocs = 687
I1213 12:35:52.434376 15749 solver.cpp:237]     Train net output #2: loss = 0.154551 (* 1 = 0.154551 loss)
I1213 12:35:52.434386 15749 sgd_solver.cpp:116] Iteration 84500, lr = 1e-05
I1213 12:39:55.431692 15749 solver.cpp:218] Iteration 84600 (0.411527 iter/s, 242.997s/100 iters), loss = 0.714452
I1213 12:39:55.431803 15749 solver.cpp:237]     Train net output #0: label = 1087
I1213 12:39:55.431831 15749 solver.cpp:237]     Train net output #1: label_phocs = 1087
I1213 12:39:55.431848 15749 solver.cpp:237]     Train net output #2: loss = 0.0938365 (* 1 = 0.0938365 loss)
I1213 12:39:55.431859 15749 sgd_solver.cpp:116] Iteration 84600, lr = 1e-05
I1213 12:43:57.660768 15749 solver.cpp:218] Iteration 84700 (0.412832 iter/s, 242.229s/100 iters), loss = 0.712934
I1213 12:43:57.660953 15749 solver.cpp:237]     Train net output #0: label = 618
I1213 12:43:57.660982 15749 solver.cpp:237]     Train net output #1: label_phocs = 618
I1213 12:43:57.660995 15749 solver.cpp:237]     Train net output #2: loss = 1.77941 (* 1 = 1.77941 loss)
I1213 12:43:57.661005 15749 sgd_solver.cpp:116] Iteration 84700, lr = 1e-05
I1213 12:48:28.785454 15749 solver.cpp:218] Iteration 84800 (0.368834 iter/s, 271.125s/100 iters), loss = 0.740818
I1213 12:48:28.785739 15749 solver.cpp:237]     Train net output #0: label = 897
I1213 12:48:28.785773 15749 solver.cpp:237]     Train net output #1: label_phocs = 897
I1213 12:48:28.785785 15749 solver.cpp:237]     Train net output #2: loss = 0.149145 (* 1 = 0.149145 loss)
I1213 12:48:28.785794 15749 sgd_solver.cpp:116] Iteration 84800, lr = 1e-05
I1213 12:52:55.892536 15749 solver.cpp:218] Iteration 84900 (0.374422 iter/s, 267.078s/100 iters), loss = 0.683952
I1213 12:52:55.892647 15749 solver.cpp:237]     Train net output #0: label = 395
I1213 12:52:55.892685 15749 solver.cpp:237]     Train net output #1: label_phocs = 395
I1213 12:52:55.892701 15749 solver.cpp:237]     Train net output #2: loss = 0.0126543 (* 1 = 0.0126543 loss)
I1213 12:52:55.892712 15749 sgd_solver.cpp:116] Iteration 84900, lr = 1e-05
[2017-12-13 12:56:56,365, PHOCNetTrainer] Running test evaluation
[2017-12-13 12:56:56,365, PHOCNetTrainer] Evaluating CNN after 84500 steps:
I1213 12:59:10.947899 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 12:59:10.948077 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 12:59:14,609, PHOCNetTrainer] mAP: 0.925270
I1213 12:59:14.611436 15749 solver.cpp:330] Iteration 85000, Testing net (#0)
I1213 12:59:14.611791 15749 net.cpp:676] Ignoring source layer drop6
I1213 12:59:14.611825 15749 net.cpp:676] Ignoring source layer drop7
I1213 13:01:23.845170 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:01:23.845615 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:01:24.989714 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 13:01:24.989783 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 13:01:24.989799 15749 solver.cpp:397]     Test net output #2: loss = 16.4451 (* 1 = 16.4451 loss)
I1213 13:01:26.837101 15749 solver.cpp:218] Iteration 85000 (0.195716 iter/s, 510.945s/100 iters), loss = 0.396964
I1213 13:01:26.838243 15749 solver.cpp:237]     Train net output #0: label = 621
I1213 13:01:26.838317 15749 solver.cpp:237]     Train net output #1: label_phocs = 621
I1213 13:01:26.838335 15749 solver.cpp:237]     Train net output #2: loss = 0.00275042 (* 1 = 0.00275042 loss)
I1213 13:01:26.838347 15749 sgd_solver.cpp:116] Iteration 85000, lr = 1e-05
I1213 13:05:59.527554 15749 solver.cpp:218] Iteration 85100 (0.366718 iter/s, 272.689s/100 iters), loss = 0.637627
I1213 13:05:59.528692 15749 solver.cpp:237]     Train net output #0: label = 1107
I1213 13:05:59.528775 15749 solver.cpp:237]     Train net output #1: label_phocs = 1107
I1213 13:05:59.528791 15749 solver.cpp:237]     Train net output #2: loss = 0.130944 (* 1 = 0.130944 loss)
I1213 13:05:59.528802 15749 sgd_solver.cpp:116] Iteration 85100, lr = 1e-05
I1213 13:10:08.725596 15749 solver.cpp:218] Iteration 85200 (0.401289 iter/s, 249.197s/100 iters), loss = 0.746693
I1213 13:10:08.725972 15749 solver.cpp:237]     Train net output #0: label = 645
I1213 13:10:08.726016 15749 solver.cpp:237]     Train net output #1: label_phocs = 645
I1213 13:10:08.726032 15749 solver.cpp:237]     Train net output #2: loss = 0.587208 (* 1 = 0.587208 loss)
I1213 13:10:08.726042 15749 sgd_solver.cpp:116] Iteration 85200, lr = 1e-05
I1213 13:14:07.259794 15749 solver.cpp:218] Iteration 85300 (0.419288 iter/s, 238.499s/100 iters), loss = 0.881138
I1213 13:14:07.270169 15749 solver.cpp:237]     Train net output #0: label = 84
I1213 13:14:07.270238 15749 solver.cpp:237]     Train net output #1: label_phocs = 84
I1213 13:14:07.270256 15749 solver.cpp:237]     Train net output #2: loss = 0.175686 (* 1 = 0.175686 loss)
I1213 13:14:07.270268 15749 sgd_solver.cpp:116] Iteration 85300, lr = 1e-05
I1213 13:18:28.511575 15749 solver.cpp:218] Iteration 85400 (0.382787 iter/s, 261.242s/100 iters), loss = 0.706235
I1213 13:18:28.512061 15749 solver.cpp:237]     Train net output #0: label = 1062
I1213 13:18:28.512090 15749 solver.cpp:237]     Train net output #1: label_phocs = 1062
I1213 13:18:28.512102 15749 solver.cpp:237]     Train net output #2: loss = 0.875975 (* 1 = 0.875975 loss)
I1213 13:18:28.512112 15749 sgd_solver.cpp:116] Iteration 85400, lr = 1e-05
[2017-12-13 13:22:49,747, PHOCNetTrainer] Running test evaluation
[2017-12-13 13:22:49,747, PHOCNetTrainer] Evaluating CNN after 85000 steps:
I1213 13:24:45.321301 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:24:45.321691 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 13:24:50,106, PHOCNetTrainer] mAP: 0.925088
I1213 13:24:50.132803 15749 solver.cpp:330] Iteration 85500, Testing net (#0)
I1213 13:24:50.133057 15749 net.cpp:676] Ignoring source layer drop6
I1213 13:24:50.133069 15749 net.cpp:676] Ignoring source layer drop7
I1213 13:26:16.488744 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:26:16.489351 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:26:17.591328 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 13:26:17.591400 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 13:26:17.591418 15749 solver.cpp:397]     Test net output #2: loss = 16.5118 (* 1 = 16.5118 loss)
I1213 13:26:20.502496 15749 solver.cpp:218] Iteration 85500 (0.211869 iter/s, 471.991s/100 iters), loss = 0.35786
I1213 13:26:20.502607 15749 solver.cpp:237]     Train net output #0: label = 685
I1213 13:26:20.502634 15749 solver.cpp:237]     Train net output #1: label_phocs = 685
I1213 13:26:20.502647 15749 solver.cpp:237]     Train net output #2: loss = 0.0139677 (* 1 = 0.0139677 loss)
I1213 13:26:20.502658 15749 sgd_solver.cpp:116] Iteration 85500, lr = 1e-05
I1213 13:30:41.559209 15749 solver.cpp:218] Iteration 85600 (0.383058 iter/s, 261.057s/100 iters), loss = 0.704525
I1213 13:30:41.583799 15749 solver.cpp:237]     Train net output #0: label = 903
I1213 13:30:41.583891 15749 solver.cpp:237]     Train net output #1: label_phocs = 903
I1213 13:30:41.583905 15749 solver.cpp:237]     Train net output #2: loss = 0.0445544 (* 1 = 0.0445544 loss)
I1213 13:30:41.583916 15749 sgd_solver.cpp:116] Iteration 85600, lr = 1e-05
I1213 13:35:02.659799 15749 solver.cpp:218] Iteration 85700 (0.383022 iter/s, 261.082s/100 iters), loss = 0.821439
I1213 13:35:02.661227 15749 solver.cpp:237]     Train net output #0: label = 1016
I1213 13:35:02.661295 15749 solver.cpp:237]     Train net output #1: label_phocs = 1016
I1213 13:35:02.661312 15749 solver.cpp:237]     Train net output #2: loss = 0.0213525 (* 1 = 0.0213525 loss)
I1213 13:35:02.661324 15749 sgd_solver.cpp:116] Iteration 85700, lr = 1e-05
I1213 13:39:24.001891 15749 solver.cpp:218] Iteration 85800 (0.382642 iter/s, 261.341s/100 iters), loss = 0.630491
I1213 13:39:24.002022 15749 solver.cpp:237]     Train net output #0: label = 22
I1213 13:39:24.002053 15749 solver.cpp:237]     Train net output #1: label_phocs = 22
I1213 13:39:24.002068 15749 solver.cpp:237]     Train net output #2: loss = 0.210142 (* 1 = 0.210142 loss)
I1213 13:39:24.002079 15749 sgd_solver.cpp:116] Iteration 85800, lr = 1e-05
I1213 13:43:24.061868 15749 solver.cpp:218] Iteration 85900 (0.416563 iter/s, 240.06s/100 iters), loss = 0.773162
I1213 13:43:24.062816 15749 solver.cpp:237]     Train net output #0: label = 939
I1213 13:43:24.062888 15749 solver.cpp:237]     Train net output #1: label_phocs = 939
I1213 13:43:24.062906 15749 solver.cpp:237]     Train net output #2: loss = 0.0117799 (* 1 = 0.0117799 loss)
I1213 13:43:24.062916 15749 sgd_solver.cpp:116] Iteration 85900, lr = 1e-05
[2017-12-13 13:47:50,487, PHOCNetTrainer] Running test evaluation
[2017-12-13 13:47:50,487, PHOCNetTrainer] Evaluating CNN after 85500 steps:
I1213 13:50:01.311882 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:50:01.312041 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 13:50:04,214, PHOCNetTrainer] mAP: 0.926836
I1213 13:50:04.269707 15749 solver.cpp:330] Iteration 86000, Testing net (#0)
I1213 13:50:04.269953 15749 net.cpp:676] Ignoring source layer drop6
I1213 13:50:04.269965 15749 net.cpp:676] Ignoring source layer drop7
I1213 13:52:00.832983 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:52:00.833189 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 13:52:02.620728 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 13:52:02.620781 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 13:52:02.620793 15749 solver.cpp:397]     Test net output #2: loss = 16.4756 (* 1 = 16.4756 loss)
I1213 13:52:06.103951 15749 solver.cpp:218] Iteration 86000 (0.19157 iter/s, 522.002s/100 iters), loss = 0.695214
I1213 13:52:06.104055 15749 solver.cpp:237]     Train net output #0: label = 1100
I1213 13:52:06.104082 15749 solver.cpp:237]     Train net output #1: label_phocs = 1100
I1213 13:52:06.104099 15749 solver.cpp:237]     Train net output #2: loss = 0.00397701 (* 1 = 0.00397701 loss)
I1213 13:52:06.104109 15749 sgd_solver.cpp:116] Iteration 86000, lr = 1e-05
I1213 13:56:19.361984 15749 solver.cpp:218] Iteration 86100 (0.394854 iter/s, 253.258s/100 iters), loss = 0.724851
I1213 13:56:19.362323 15749 solver.cpp:237]     Train net output #0: label = 280
I1213 13:56:19.362370 15749 solver.cpp:237]     Train net output #1: label_phocs = 280
I1213 13:56:19.362386 15749 solver.cpp:237]     Train net output #2: loss = 0.0276986 (* 1 = 0.0276986 loss)
I1213 13:56:19.362397 15749 sgd_solver.cpp:116] Iteration 86100, lr = 1e-05
I1213 14:00:46.038761 15749 solver.cpp:218] Iteration 86200 (0.375006 iter/s, 266.662s/100 iters), loss = 0.743169
I1213 14:00:46.038866 15749 solver.cpp:237]     Train net output #0: label = 939
I1213 14:00:46.038895 15749 solver.cpp:237]     Train net output #1: label_phocs = 939
I1213 14:00:46.038910 15749 solver.cpp:237]     Train net output #2: loss = 2.46691 (* 1 = 2.46691 loss)
I1213 14:00:46.038920 15749 sgd_solver.cpp:116] Iteration 86200, lr = 1e-05
I1213 14:05:12.523895 15749 solver.cpp:218] Iteration 86300 (0.375313 iter/s, 266.444s/100 iters), loss = 0.68873
I1213 14:05:12.524375 15749 solver.cpp:237]     Train net output #0: label = 515
I1213 14:05:12.524425 15749 solver.cpp:237]     Train net output #1: label_phocs = 515
I1213 14:05:12.524440 15749 solver.cpp:237]     Train net output #2: loss = 0.0315955 (* 1 = 0.0315955 loss)
I1213 14:05:12.524449 15749 sgd_solver.cpp:116] Iteration 86300, lr = 1e-05
I1213 14:09:20.551342 15749 solver.cpp:218] Iteration 86400 (0.403182 iter/s, 248.027s/100 iters), loss = 0.742916
I1213 14:09:20.551687 15749 solver.cpp:237]     Train net output #0: label = 85
I1213 14:09:20.551733 15749 solver.cpp:237]     Train net output #1: label_phocs = 85
I1213 14:09:20.551779 15749 solver.cpp:237]     Train net output #2: loss = 1.3963 (* 1 = 1.3963 loss)
I1213 14:09:20.551796 15749 sgd_solver.cpp:116] Iteration 86400, lr = 1e-05
[2017-12-13 14:13:16,504, PHOCNetTrainer] Running test evaluation
[2017-12-13 14:13:16,504, PHOCNetTrainer] Evaluating CNN after 86000 steps:
I1213 14:15:24.079957 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:15:24.080005 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 14:15:29,670, PHOCNetTrainer] mAP: 0.924441
I1213 14:15:29.672266 15749 solver.cpp:330] Iteration 86500, Testing net (#0)
I1213 14:15:29.672570 15749 net.cpp:676] Ignoring source layer drop6
I1213 14:15:29.672595 15749 net.cpp:676] Ignoring source layer drop7
I1213 14:17:30.159998 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:17:30.160171 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:17:31.450933 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 14:17:31.450992 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 14:17:31.451005 15749 solver.cpp:397]     Test net output #2: loss = 16.5471 (* 1 = 16.5471 loss)
I1213 14:17:33.942355 15749 solver.cpp:218] Iteration 86500 (0.202688 iter/s, 493.37s/100 iters), loss = 0.751563
I1213 14:17:33.943526 15749 solver.cpp:237]     Train net output #0: label = 539
I1213 14:17:33.943599 15749 solver.cpp:237]     Train net output #1: label_phocs = 539
I1213 14:17:33.943614 15749 solver.cpp:237]     Train net output #2: loss = 0.218414 (* 1 = 0.218414 loss)
I1213 14:17:33.943625 15749 sgd_solver.cpp:116] Iteration 86500, lr = 1e-05
I1213 14:22:04.836441 15749 solver.cpp:218] Iteration 86600 (0.369215 iter/s, 270.845s/100 iters), loss = 0.669786
I1213 14:22:04.836573 15749 solver.cpp:237]     Train net output #0: label = 601
I1213 14:22:04.836597 15749 solver.cpp:237]     Train net output #1: label_phocs = 601
I1213 14:22:04.836609 15749 solver.cpp:237]     Train net output #2: loss = 1.41335 (* 1 = 1.41335 loss)
I1213 14:22:04.836624 15749 sgd_solver.cpp:116] Iteration 86600, lr = 1e-05
I1213 14:26:12.331759 15749 solver.cpp:218] Iteration 86700 (0.404113 iter/s, 247.456s/100 iters), loss = 0.620508
I1213 14:26:12.332238 15749 solver.cpp:237]     Train net output #0: label = 987
I1213 14:26:12.332301 15749 solver.cpp:237]     Train net output #1: label_phocs = 987
I1213 14:26:12.332316 15749 solver.cpp:237]     Train net output #2: loss = 0.0370557 (* 1 = 0.0370557 loss)
I1213 14:26:12.332327 15749 sgd_solver.cpp:116] Iteration 86700, lr = 1e-05
I1213 14:30:32.057219 15749 solver.cpp:218] Iteration 86800 (0.385056 iter/s, 259.703s/100 iters), loss = 0.69817
I1213 14:30:32.057520 15749 solver.cpp:237]     Train net output #0: label = 1050
I1213 14:30:32.057575 15749 solver.cpp:237]     Train net output #1: label_phocs = 1050
I1213 14:30:32.057590 15749 solver.cpp:237]     Train net output #2: loss = 0.0409512 (* 1 = 0.0409512 loss)
I1213 14:30:32.057601 15749 sgd_solver.cpp:116] Iteration 86800, lr = 1e-05
I1213 14:34:55.372910 15749 solver.cpp:218] Iteration 86900 (0.37982 iter/s, 263.282s/100 iters), loss = 0.676718
I1213 14:34:55.373023 15749 solver.cpp:237]     Train net output #0: label = 1053
I1213 14:34:55.373051 15749 solver.cpp:237]     Train net output #1: label_phocs = 1053
I1213 14:34:55.373066 15749 solver.cpp:237]     Train net output #2: loss = 0.026465 (* 1 = 0.026465 loss)
I1213 14:34:55.373077 15749 sgd_solver.cpp:116] Iteration 86900, lr = 1e-05
[2017-12-13 14:39:17,813, PHOCNetTrainer] Running test evaluation
[2017-12-13 14:39:17,813, PHOCNetTrainer] Evaluating CNN after 86500 steps:
I1213 14:41:05.947765 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:41:05.947896 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 14:41:09,584, PHOCNetTrainer] mAP: 0.926770
I1213 14:41:09.586233 15749 solver.cpp:330] Iteration 87000, Testing net (#0)
I1213 14:41:09.586490 15749 net.cpp:676] Ignoring source layer drop6
I1213 14:41:09.586503 15749 net.cpp:676] Ignoring source layer drop7
I1213 14:43:22.264560 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:43:22.264789 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 14:43:25.298702 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 14:43:25.298754 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 14:43:25.298765 15749 solver.cpp:397]     Test net output #2: loss = 16.4514 (* 1 = 16.4514 loss)
I1213 14:43:27.331816 15749 solver.cpp:218] Iteration 87000 (0.195328 iter/s, 511.959s/100 iters), loss = 0.416953
I1213 14:43:27.331964 15749 solver.cpp:237]     Train net output #0: label = 180
I1213 14:43:27.331998 15749 solver.cpp:237]     Train net output #1: label_phocs = 180
I1213 14:43:27.332018 15749 solver.cpp:237]     Train net output #2: loss = 0.270047 (* 1 = 0.270047 loss)
I1213 14:43:27.332031 15749 sgd_solver.cpp:116] Iteration 87000, lr = 1e-05
I1213 14:48:01.677402 15749 solver.cpp:218] Iteration 87100 (0.364504 iter/s, 274.345s/100 iters), loss = 0.655209
I1213 14:48:01.677520 15749 solver.cpp:237]     Train net output #0: label = 863
I1213 14:48:01.677551 15749 solver.cpp:237]     Train net output #1: label_phocs = 863
I1213 14:48:01.677568 15749 solver.cpp:237]     Train net output #2: loss = 1.91589 (* 1 = 1.91589 loss)
I1213 14:48:01.677579 15749 sgd_solver.cpp:116] Iteration 87100, lr = 1e-05
I1213 14:52:32.874796 15749 solver.cpp:218] Iteration 87200 (0.368735 iter/s, 271.197s/100 iters), loss = 0.756132
I1213 14:52:32.875368 15749 solver.cpp:237]     Train net output #0: label = 175
I1213 14:52:32.875425 15749 solver.cpp:237]     Train net output #1: label_phocs = 175
I1213 14:52:32.875439 15749 solver.cpp:237]     Train net output #2: loss = 0.00718742 (* 1 = 0.00718742 loss)
I1213 14:52:32.875450 15749 sgd_solver.cpp:116] Iteration 87200, lr = 1e-05
I1213 14:56:20.227550 15749 solver.cpp:218] Iteration 87300 (0.439963 iter/s, 227.292s/100 iters), loss = 0.623948
I1213 14:56:20.227676 15749 solver.cpp:237]     Train net output #0: label = 339
I1213 14:56:20.227707 15749 solver.cpp:237]     Train net output #1: label_phocs = 339
I1213 14:56:20.227720 15749 solver.cpp:237]     Train net output #2: loss = 0.287054 (* 1 = 0.287054 loss)
I1213 14:56:20.227728 15749 sgd_solver.cpp:116] Iteration 87300, lr = 1e-05
I1213 15:00:53.972898 15749 solver.cpp:218] Iteration 87400 (0.365303 iter/s, 273.745s/100 iters), loss = 0.717756
I1213 15:00:53.974074 15749 solver.cpp:237]     Train net output #0: label = 321
I1213 15:00:53.974143 15749 solver.cpp:237]     Train net output #1: label_phocs = 321
I1213 15:00:53.974158 15749 solver.cpp:237]     Train net output #2: loss = 0.615176 (* 1 = 0.615176 loss)
I1213 15:00:53.974169 15749 sgd_solver.cpp:116] Iteration 87400, lr = 1e-05
[2017-12-13 15:05:30,882, PHOCNetTrainer] Running test evaluation
[2017-12-13 15:05:30,882, PHOCNetTrainer] Evaluating CNN after 87000 steps:
I1213 15:07:45.516710 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:07:45.516877 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 15:07:49,633, PHOCNetTrainer] mAP: 0.925738
I1213 15:07:49.636869 15749 solver.cpp:330] Iteration 87500, Testing net (#0)
I1213 15:07:49.637151 15749 net.cpp:676] Ignoring source layer drop6
I1213 15:07:49.637183 15749 net.cpp:676] Ignoring source layer drop7
I1213 15:09:29.244748 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:09:29.244976 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:09:31.096843 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 15:09:31.096913 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 15:09:31.096930 15749 solver.cpp:397]     Test net output #2: loss = 16.5847 (* 1 = 16.5847 loss)
I1213 15:09:34.109526 15749 solver.cpp:218] Iteration 87500 (0.192261 iter/s, 520.126s/100 iters), loss = 0.409383
I1213 15:09:34.117858 15749 solver.cpp:237]     Train net output #0: label = 615
I1213 15:09:34.117930 15749 solver.cpp:237]     Train net output #1: label_phocs = 615
I1213 15:09:34.117949 15749 solver.cpp:237]     Train net output #2: loss = 0.37937 (* 1 = 0.37937 loss)
I1213 15:09:34.117960 15749 sgd_solver.cpp:116] Iteration 87500, lr = 1e-05
I1213 15:13:50.425480 15749 solver.cpp:218] Iteration 87600 (0.390156 iter/s, 256.308s/100 iters), loss = 0.667875
I1213 15:13:50.425755 15749 solver.cpp:237]     Train net output #0: label = 492
I1213 15:13:50.425786 15749 solver.cpp:237]     Train net output #1: label_phocs = 492
I1213 15:13:50.425797 15749 solver.cpp:237]     Train net output #2: loss = 1.57101 (* 1 = 1.57101 loss)
I1213 15:13:50.425806 15749 sgd_solver.cpp:116] Iteration 87600, lr = 1e-05
I1213 15:17:44.571949 15749 solver.cpp:218] Iteration 87700 (0.427083 iter/s, 234.147s/100 iters), loss = 0.729517
I1213 15:17:44.572042 15749 solver.cpp:237]     Train net output #0: label = 506
I1213 15:17:44.572067 15749 solver.cpp:237]     Train net output #1: label_phocs = 506
I1213 15:17:44.572078 15749 solver.cpp:237]     Train net output #2: loss = 0.051392 (* 1 = 0.051392 loss)
I1213 15:17:44.572088 15749 sgd_solver.cpp:116] Iteration 87700, lr = 1e-05
I1213 15:21:38.401244 15749 solver.cpp:218] Iteration 87800 (0.427663 iter/s, 233.829s/100 iters), loss = 0.572503
I1213 15:21:38.401319 15749 solver.cpp:237]     Train net output #0: label = 524
I1213 15:21:38.401342 15749 solver.cpp:237]     Train net output #1: label_phocs = 524
I1213 15:21:38.401355 15749 solver.cpp:237]     Train net output #2: loss = 0.331669 (* 1 = 0.331669 loss)
I1213 15:21:38.401365 15749 sgd_solver.cpp:116] Iteration 87800, lr = 1e-05
I1213 15:25:10.296015 15749 solver.cpp:218] Iteration 87900 (0.471932 iter/s, 211.895s/100 iters), loss = 0.673612
I1213 15:25:10.296092 15749 solver.cpp:237]     Train net output #0: label = 957
I1213 15:25:10.296114 15749 solver.cpp:237]     Train net output #1: label_phocs = 957
I1213 15:25:10.296126 15749 solver.cpp:237]     Train net output #2: loss = 0.0188712 (* 1 = 0.0188712 loss)
I1213 15:25:10.296134 15749 sgd_solver.cpp:116] Iteration 87900, lr = 1e-05
[2017-12-13 15:28:59,025, PHOCNetTrainer] Running test evaluation
[2017-12-13 15:28:59,025, PHOCNetTrainer] Evaluating CNN after 87500 steps:
I1213 15:30:35.653987 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:30:35.654104 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 15:30:38,800, PHOCNetTrainer] mAP: 0.927613
I1213 15:30:38.802465 15749 solver.cpp:330] Iteration 88000, Testing net (#0)
I1213 15:30:38.802661 15749 net.cpp:676] Ignoring source layer drop6
I1213 15:30:38.802670 15749 net.cpp:676] Ignoring source layer drop7
I1213 15:32:08.609190 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:32:08.609323 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:32:09.165621 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 15:32:09.165664 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 15:32:09.165675 15749 solver.cpp:397]     Test net output #2: loss = 16.3945 (* 1 = 16.3945 loss)
I1213 15:32:11.315935 15749 solver.cpp:218] Iteration 88000 (0.237518 iter/s, 421.02s/100 iters), loss = 0.47893
I1213 15:32:11.316012 15749 solver.cpp:237]     Train net output #0: label = 118
I1213 15:32:11.316035 15749 solver.cpp:237]     Train net output #1: label_phocs = 118
I1213 15:32:11.316047 15749 solver.cpp:237]     Train net output #2: loss = 0.0289788 (* 1 = 0.0289788 loss)
I1213 15:32:11.316056 15749 sgd_solver.cpp:116] Iteration 88000, lr = 1e-05
I1213 15:36:11.075189 15749 solver.cpp:218] Iteration 88100 (0.417085 iter/s, 239.759s/100 iters), loss = 0.621113
I1213 15:36:11.075958 15749 solver.cpp:237]     Train net output #0: label = 532
I1213 15:36:11.075983 15749 solver.cpp:237]     Train net output #1: label_phocs = 532
I1213 15:36:11.075994 15749 solver.cpp:237]     Train net output #2: loss = 0.92852 (* 1 = 0.92852 loss)
I1213 15:36:11.076001 15749 sgd_solver.cpp:116] Iteration 88100, lr = 1e-05
I1213 15:39:47.383702 15749 solver.cpp:218] Iteration 88200 (0.462324 iter/s, 216.299s/100 iters), loss = 0.741403
I1213 15:39:47.383797 15749 solver.cpp:237]     Train net output #0: label = 239
I1213 15:39:47.383822 15749 solver.cpp:237]     Train net output #1: label_phocs = 239
I1213 15:39:47.383836 15749 solver.cpp:237]     Train net output #2: loss = 0.00888028 (* 1 = 0.00888028 loss)
I1213 15:39:47.383844 15749 sgd_solver.cpp:116] Iteration 88200, lr = 1e-05
I1213 15:43:47.717043 15749 solver.cpp:218] Iteration 88300 (0.416089 iter/s, 240.333s/100 iters), loss = 0.634753
I1213 15:43:47.717126 15749 solver.cpp:237]     Train net output #0: label = 850
I1213 15:43:47.717152 15749 solver.cpp:237]     Train net output #1: label_phocs = 850
I1213 15:43:47.717165 15749 solver.cpp:237]     Train net output #2: loss = 0.966678 (* 1 = 0.966678 loss)
I1213 15:43:47.717172 15749 sgd_solver.cpp:116] Iteration 88300, lr = 1e-05
I1213 15:47:43.564123 15749 solver.cpp:218] Iteration 88400 (0.424078 iter/s, 235.806s/100 iters), loss = 0.723056
I1213 15:47:43.564257 15749 solver.cpp:237]     Train net output #0: label = 165
I1213 15:47:43.564281 15749 solver.cpp:237]     Train net output #1: label_phocs = 165
I1213 15:47:43.564293 15749 solver.cpp:237]     Train net output #2: loss = 0.0767441 (* 1 = 0.0767441 loss)
I1213 15:47:43.564302 15749 sgd_solver.cpp:116] Iteration 88400, lr = 1e-05
[2017-12-13 15:51:14,671, PHOCNetTrainer] Running test evaluation
[2017-12-13 15:51:14,671, PHOCNetTrainer] Evaluating CNN after 88000 steps:
I1213 15:52:45.503845 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:52:45.504075 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 15:52:46,621, PHOCNetTrainer] mAP: 0.924756
I1213 15:52:46.622879 15749 solver.cpp:330] Iteration 88500, Testing net (#0)
I1213 15:52:46.623073 15749 net.cpp:676] Ignoring source layer drop6
I1213 15:52:46.623082 15749 net.cpp:676] Ignoring source layer drop7
I1213 15:54:17.023860 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:54:17.024138 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 15:54:18.045521 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 15:54:18.045567 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 15:54:18.045578 15749 solver.cpp:397]     Test net output #2: loss = 16.4366 (* 1 = 16.4366 loss)
I1213 15:54:20.111639 15749 solver.cpp:218] Iteration 88500 (0.252176 iter/s, 396.548s/100 iters), loss = 0.380853
I1213 15:54:20.111735 15749 solver.cpp:237]     Train net output #0: label = 468
I1213 15:54:20.111804 15749 solver.cpp:237]     Train net output #1: label_phocs = 468
I1213 15:54:20.111819 15749 solver.cpp:237]     Train net output #2: loss = 0.184449 (* 1 = 0.184449 loss)
I1213 15:54:20.111829 15749 sgd_solver.cpp:116] Iteration 88500, lr = 1e-05
I1213 15:58:19.733129 15749 solver.cpp:218] Iteration 88600 (0.417374 iter/s, 239.593s/100 iters), loss = 0.794847
I1213 15:58:19.733402 15749 solver.cpp:237]     Train net output #0: label = 360
I1213 15:58:19.733428 15749 solver.cpp:237]     Train net output #1: label_phocs = 360
I1213 15:58:19.733440 15749 solver.cpp:237]     Train net output #2: loss = 0.0696171 (* 1 = 0.0696171 loss)
I1213 15:58:19.733449 15749 sgd_solver.cpp:116] Iteration 88600, lr = 1e-05
I1213 16:02:09.819478 15749 solver.cpp:218] Iteration 88700 (0.43462 iter/s, 230.086s/100 iters), loss = 0.606807
I1213 16:02:09.819563 15749 solver.cpp:237]     Train net output #0: label = 148
I1213 16:02:09.819586 15749 solver.cpp:237]     Train net output #1: label_phocs = 148
I1213 16:02:09.819597 15749 solver.cpp:237]     Train net output #2: loss = 0.00971176 (* 1 = 0.00971176 loss)
I1213 16:02:09.819607 15749 sgd_solver.cpp:116] Iteration 88700, lr = 1e-05
I1213 16:05:38.494617 15749 solver.cpp:218] Iteration 88800 (0.479214 iter/s, 208.675s/100 iters), loss = 0.746642
I1213 16:05:38.494704 15749 solver.cpp:237]     Train net output #0: label = 1028
I1213 16:05:38.494729 15749 solver.cpp:237]     Train net output #1: label_phocs = 1028
I1213 16:05:38.494740 15749 solver.cpp:237]     Train net output #2: loss = 2.04008 (* 1 = 2.04008 loss)
I1213 16:05:38.494750 15749 sgd_solver.cpp:116] Iteration 88800, lr = 1e-05
I1213 16:09:37.369818 15749 solver.cpp:218] Iteration 88900 (0.418644 iter/s, 238.866s/100 iters), loss = 0.737625
I1213 16:09:37.370309 15749 solver.cpp:237]     Train net output #0: label = 1045
I1213 16:09:37.370333 15749 solver.cpp:237]     Train net output #1: label_phocs = 1045
I1213 16:09:37.370344 15749 solver.cpp:237]     Train net output #2: loss = 0.0392943 (* 1 = 0.0392943 loss)
I1213 16:09:37.370353 15749 sgd_solver.cpp:116] Iteration 88900, lr = 1e-05
[2017-12-13 16:13:29,158, PHOCNetTrainer] Running test evaluation
[2017-12-13 16:13:29,158, PHOCNetTrainer] Evaluating CNN after 88500 steps:
I1213 16:15:09.151389 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:15:09.154364 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 16:15:10,693, PHOCNetTrainer] mAP: 0.924592
I1213 16:15:10.695550 15749 solver.cpp:330] Iteration 89000, Testing net (#0)
I1213 16:15:10.695786 15749 net.cpp:676] Ignoring source layer drop6
I1213 16:15:10.695796 15749 net.cpp:676] Ignoring source layer drop7
I1213 16:16:18.544363 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:16:18.544567 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:16:19.329093 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 16:16:19.329131 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 16:16:19.329140 15749 solver.cpp:397]     Test net output #2: loss = 16.7482 (* 1 = 16.7482 loss)
I1213 16:16:20.480765 15749 solver.cpp:218] Iteration 89000 (0.248071 iter/s, 403.111s/100 iters), loss = 0.17981
I1213 16:16:20.480844 15749 solver.cpp:237]     Train net output #0: label = 45
I1213 16:16:20.480865 15749 solver.cpp:237]     Train net output #1: label_phocs = 45
I1213 16:16:20.480875 15749 solver.cpp:237]     Train net output #2: loss = 0.0788953 (* 1 = 0.0788953 loss)
I1213 16:16:20.480890 15749 sgd_solver.cpp:116] Iteration 89000, lr = 1e-05
I1213 16:20:12.655544 15749 solver.cpp:218] Iteration 89100 (0.43071 iter/s, 232.175s/100 iters), loss = 0.62964
I1213 16:20:12.655622 15749 solver.cpp:237]     Train net output #0: label = 68
I1213 16:20:12.655645 15749 solver.cpp:237]     Train net output #1: label_phocs = 68
I1213 16:20:12.655656 15749 solver.cpp:237]     Train net output #2: loss = 2.84677 (* 1 = 2.84677 loss)
I1213 16:20:12.655665 15749 sgd_solver.cpp:116] Iteration 89100, lr = 1e-05
I1213 16:24:05.601560 15749 solver.cpp:218] Iteration 89200 (0.429344 iter/s, 232.914s/100 iters), loss = 0.763985
I1213 16:24:05.601649 15749 solver.cpp:237]     Train net output #0: label = 729
I1213 16:24:05.601675 15749 solver.cpp:237]     Train net output #1: label_phocs = 729
I1213 16:24:05.601686 15749 solver.cpp:237]     Train net output #2: loss = 5.28836 (* 1 = 5.28836 loss)
I1213 16:24:05.601696 15749 sgd_solver.cpp:116] Iteration 89200, lr = 1e-05
I1213 16:27:51.799789 15749 solver.cpp:218] Iteration 89300 (0.442195 iter/s, 226.145s/100 iters), loss = 0.682161
I1213 16:27:51.799896 15749 solver.cpp:237]     Train net output #0: label = 1052
I1213 16:27:51.799918 15749 solver.cpp:237]     Train net output #1: label_phocs = 1052
I1213 16:27:51.799929 15749 solver.cpp:237]     Train net output #2: loss = 0.00338079 (* 1 = 0.00338079 loss)
I1213 16:27:51.799938 15749 sgd_solver.cpp:116] Iteration 89300, lr = 1e-05
I1213 16:31:16.710271 15749 solver.cpp:218] Iteration 89400 (0.488027 iter/s, 204.907s/100 iters), loss = 0.64494
I1213 16:31:16.711911 15749 solver.cpp:237]     Train net output #0: label = 825
I1213 16:31:16.711964 15749 solver.cpp:237]     Train net output #1: label_phocs = 825
I1213 16:31:16.711978 15749 solver.cpp:237]     Train net output #2: loss = 0.0592943 (* 1 = 0.0592943 loss)
I1213 16:31:16.712000 15749 sgd_solver.cpp:116] Iteration 89400, lr = 1e-05
[2017-12-13 16:35:12,694, PHOCNetTrainer] Running test evaluation
[2017-12-13 16:35:12,694, PHOCNetTrainer] Evaluating CNN after 89000 steps:
I1213 16:36:48.835846 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:36:48.835959 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 16:36:50,296, PHOCNetTrainer] mAP: 0.925509
I1213 16:36:50.297957 15749 solver.cpp:330] Iteration 89500, Testing net (#0)
I1213 16:36:50.298146 15749 net.cpp:676] Ignoring source layer drop6
I1213 16:36:50.298154 15749 net.cpp:676] Ignoring source layer drop7
I1213 16:38:35.999828 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:38:36.000005 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:38:38.118329 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 16:38:38.118367 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 16:38:38.118378 15749 solver.cpp:397]     Test net output #2: loss = 16.642 (* 1 = 16.642 loss)
I1213 16:38:40.557629 15749 solver.cpp:218] Iteration 89500 (0.225307 iter/s, 443.84s/100 iters), loss = 0.220461
I1213 16:38:40.557715 15749 solver.cpp:237]     Train net output #0: label = 1032
I1213 16:38:40.557739 15749 solver.cpp:237]     Train net output #1: label_phocs = 1032
I1213 16:38:40.557750 15749 solver.cpp:237]     Train net output #2: loss = 0.0842707 (* 1 = 0.0842707 loss)
I1213 16:38:40.557760 15749 sgd_solver.cpp:116] Iteration 89500, lr = 1e-05
I1213 16:41:52.184855 15749 solver.cpp:218] Iteration 89600 (0.521847 iter/s, 191.627s/100 iters), loss = 0.679137
I1213 16:41:52.185214 15749 solver.cpp:237]     Train net output #0: label = 1066
I1213 16:41:52.185241 15749 solver.cpp:237]     Train net output #1: label_phocs = 1066
I1213 16:41:52.185253 15749 solver.cpp:237]     Train net output #2: loss = 0.366181 (* 1 = 0.366181 loss)
I1213 16:41:52.185261 15749 sgd_solver.cpp:116] Iteration 89600, lr = 1e-05
I1213 16:45:41.296459 15749 solver.cpp:218] Iteration 89700 (0.436469 iter/s, 229.111s/100 iters), loss = 0.68434
I1213 16:45:41.296537 15749 solver.cpp:237]     Train net output #0: label = 544
I1213 16:45:41.296566 15749 solver.cpp:237]     Train net output #1: label_phocs = 544
I1213 16:45:41.296578 15749 solver.cpp:237]     Train net output #2: loss = 0.00570193 (* 1 = 0.00570193 loss)
I1213 16:45:41.296587 15749 sgd_solver.cpp:116] Iteration 89700, lr = 1e-05
I1213 16:49:32.610388 15749 solver.cpp:218] Iteration 89800 (0.432313 iter/s, 231.314s/100 iters), loss = 0.722158
I1213 16:49:32.610467 15749 solver.cpp:237]     Train net output #0: label = 683
I1213 16:49:32.610491 15749 solver.cpp:237]     Train net output #1: label_phocs = 683
I1213 16:49:32.610502 15749 solver.cpp:237]     Train net output #2: loss = 0.01335 (* 1 = 0.01335 loss)
I1213 16:49:32.610510 15749 sgd_solver.cpp:116] Iteration 89800, lr = 1e-05
I1213 16:53:09.197041 15749 solver.cpp:218] Iteration 89900 (0.461755 iter/s, 216.565s/100 iters), loss = 0.630628
I1213 16:53:09.197124 15749 solver.cpp:237]     Train net output #0: label = 20
I1213 16:53:09.197146 15749 solver.cpp:237]     Train net output #1: label_phocs = 20
I1213 16:53:09.197157 15749 solver.cpp:237]     Train net output #2: loss = 0.0425712 (* 1 = 0.0425712 loss)
I1213 16:53:09.197166 15749 sgd_solver.cpp:116] Iteration 89900, lr = 1e-05
[2017-12-13 16:56:34,978, PHOCNetTrainer] Running test evaluation
[2017-12-13 16:56:34,978, PHOCNetTrainer] Evaluating CNN after 89500 steps:
I1213 16:58:17.915988 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:58:17.916110 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 16:58:21,486, PHOCNetTrainer] mAP: 0.926781
I1213 16:58:21.488205 15749 solver.cpp:330] Iteration 90000, Testing net (#0)
I1213 16:58:21.488396 15749 net.cpp:676] Ignoring source layer drop6
I1213 16:58:21.488405 15749 net.cpp:676] Ignoring source layer drop7
I1213 16:59:51.079838 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:59:51.079951 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 16:59:52.383720 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 16:59:52.383764 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 16:59:52.383779 15749 solver.cpp:397]     Test net output #2: loss = 16.4048 (* 1 = 16.4048 loss)
I1213 16:59:54.590909 15749 solver.cpp:218] Iteration 90000 (0.246693 iter/s, 405.362s/100 iters), loss = 1.01403
I1213 16:59:54.591699 15749 solver.cpp:237]     Train net output #0: label = 223
I1213 16:59:54.591722 15749 solver.cpp:237]     Train net output #1: label_phocs = 223
I1213 16:59:54.591734 15749 solver.cpp:237]     Train net output #2: loss = 5.64006 (* 1 = 5.64006 loss)
I1213 16:59:54.591742 15749 sgd_solver.cpp:116] Iteration 90000, lr = 1e-05
I1213 17:03:44.019624 15749 solver.cpp:218] Iteration 90100 (0.435905 iter/s, 229.408s/100 iters), loss = 0.651604
I1213 17:03:44.019757 15749 solver.cpp:237]     Train net output #0: label = 892
I1213 17:03:44.019788 15749 solver.cpp:237]     Train net output #1: label_phocs = 892
I1213 17:03:44.019801 15749 solver.cpp:237]     Train net output #2: loss = 0.15644 (* 1 = 0.15644 loss)
I1213 17:03:44.019810 15749 sgd_solver.cpp:116] Iteration 90100, lr = 1e-05
I1213 17:07:08.488533 15749 solver.cpp:218] Iteration 90200 (0.489072 iter/s, 204.469s/100 iters), loss = 0.683017
I1213 17:07:08.488610 15749 solver.cpp:237]     Train net output #0: label = 279
I1213 17:07:08.488633 15749 solver.cpp:237]     Train net output #1: label_phocs = 279
I1213 17:07:08.488646 15749 solver.cpp:237]     Train net output #2: loss = 3.32744 (* 1 = 3.32744 loss)
I1213 17:07:08.488653 15749 sgd_solver.cpp:116] Iteration 90200, lr = 1e-05
I1213 17:10:58.433079 15749 solver.cpp:218] Iteration 90300 (0.434913 iter/s, 229.931s/100 iters), loss = 0.598023
I1213 17:10:58.433202 15749 solver.cpp:237]     Train net output #0: label = 771
I1213 17:10:58.433225 15749 solver.cpp:237]     Train net output #1: label_phocs = 771
I1213 17:10:58.433236 15749 solver.cpp:237]     Train net output #2: loss = 0.148294 (* 1 = 0.148294 loss)
I1213 17:10:58.433245 15749 sgd_solver.cpp:116] Iteration 90300, lr = 1e-05
I1213 17:14:52.055059 15749 solver.cpp:218] Iteration 90400 (0.428141 iter/s, 233.568s/100 iters), loss = 0.804108
I1213 17:14:52.056053 15749 solver.cpp:237]     Train net output #0: label = 369
I1213 17:14:52.056107 15749 solver.cpp:237]     Train net output #1: label_phocs = 369
I1213 17:14:52.056119 15749 solver.cpp:237]     Train net output #2: loss = 1.159 (* 1 = 1.159 loss)
I1213 17:14:52.056129 15749 sgd_solver.cpp:116] Iteration 90400, lr = 1e-05
[2017-12-13 17:18:50,326, PHOCNetTrainer] Running test evaluation
[2017-12-13 17:18:50,326, PHOCNetTrainer] Evaluating CNN after 90000 steps:
I1213 17:19:54.895849 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:19:54.895967 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 17:19:57,353, PHOCNetTrainer] mAP: 0.925691
I1213 17:19:57.391057 15749 solver.cpp:330] Iteration 90500, Testing net (#0)
I1213 17:19:57.391264 15749 net.cpp:676] Ignoring source layer drop6
I1213 17:19:57.391274 15749 net.cpp:676] Ignoring source layer drop7
I1213 17:21:18.137158 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:21:18.141535 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:21:21.031939 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 17:21:21.031983 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 17:21:21.031991 15749 solver.cpp:397]     Test net output #2: loss = 16.5302 (* 1 = 16.5302 loss)
I1213 17:21:24.120309 15749 solver.cpp:218] Iteration 90500 (0.255079 iter/s, 392.035s/100 iters), loss = 0.533105
I1213 17:21:24.120427 15749 solver.cpp:237]     Train net output #0: label = 200
I1213 17:21:24.120452 15749 solver.cpp:237]     Train net output #1: label_phocs = 200
I1213 17:21:24.120465 15749 solver.cpp:237]     Train net output #2: loss = 0.174214 (* 1 = 0.174214 loss)
I1213 17:21:24.120473 15749 sgd_solver.cpp:116] Iteration 90500, lr = 1e-05
I1213 17:25:19.464735 15749 solver.cpp:218] Iteration 90600 (0.424945 iter/s, 235.325s/100 iters), loss = 0.678914
I1213 17:25:19.464818 15749 solver.cpp:237]     Train net output #0: label = 99
I1213 17:25:19.464841 15749 solver.cpp:237]     Train net output #1: label_phocs = 99
I1213 17:25:19.464854 15749 solver.cpp:237]     Train net output #2: loss = 0.0274583 (* 1 = 0.0274583 loss)
I1213 17:25:19.464861 15749 sgd_solver.cpp:116] Iteration 90600, lr = 1e-05
I1213 17:29:06.673913 15749 solver.cpp:218] Iteration 90700 (0.440123 iter/s, 227.209s/100 iters), loss = 0.726228
I1213 17:29:06.675045 15749 solver.cpp:237]     Train net output #0: label = 1104
I1213 17:29:06.675073 15749 solver.cpp:237]     Train net output #1: label_phocs = 1104
I1213 17:29:06.675086 15749 solver.cpp:237]     Train net output #2: loss = 0.106128 (* 1 = 0.106128 loss)
I1213 17:29:06.675096 15749 sgd_solver.cpp:116] Iteration 90700, lr = 1e-05
I1213 17:32:57.572289 15749 solver.cpp:218] Iteration 90800 (0.433093 iter/s, 230.897s/100 iters), loss = 0.890591
I1213 17:32:57.573199 15749 solver.cpp:237]     Train net output #0: label = 912
I1213 17:32:57.573248 15749 solver.cpp:237]     Train net output #1: label_phocs = 912
I1213 17:32:57.573262 15749 solver.cpp:237]     Train net output #2: loss = 0.0534414 (* 1 = 0.0534414 loss)
I1213 17:32:57.573271 15749 sgd_solver.cpp:116] Iteration 90800, lr = 1e-05
I1213 17:36:47.476850 15749 solver.cpp:218] Iteration 90900 (0.434965 iter/s, 229.904s/100 iters), loss = 0.756491
I1213 17:36:47.476927 15749 solver.cpp:237]     Train net output #0: label = 975
I1213 17:36:47.476953 15749 solver.cpp:237]     Train net output #1: label_phocs = 975
I1213 17:36:47.476964 15749 solver.cpp:237]     Train net output #2: loss = 0.0182667 (* 1 = 0.0182667 loss)
I1213 17:36:47.476974 15749 sgd_solver.cpp:116] Iteration 90900, lr = 1e-05
[2017-12-13 17:40:55,636, PHOCNetTrainer] Running test evaluation
[2017-12-13 17:40:55,636, PHOCNetTrainer] Evaluating CNN after 90500 steps:
I1213 17:42:43.535820 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:42:43.535960 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 17:42:47,379, PHOCNetTrainer] mAP: 0.927490
I1213 17:42:47.380996 15749 solver.cpp:330] Iteration 91000, Testing net (#0)
I1213 17:42:47.381199 15749 net.cpp:676] Ignoring source layer drop6
I1213 17:42:47.381209 15749 net.cpp:676] Ignoring source layer drop7
I1213 17:44:24.815855 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:44:24.815979 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 17:44:26.811482 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 17:44:26.811542 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 17:44:26.811556 15749 solver.cpp:397]     Test net output #2: loss = 16.3643 (* 1 = 16.3643 loss)
I1213 17:44:28.691082 15749 solver.cpp:218] Iteration 91000 (0.216819 iter/s, 461.214s/100 iters), loss = 1.1651
I1213 17:44:28.691506 15749 solver.cpp:237]     Train net output #0: label = 445
I1213 17:44:28.691532 15749 solver.cpp:237]     Train net output #1: label_phocs = 445
I1213 17:44:28.691545 15749 solver.cpp:237]     Train net output #2: loss = 5.05361 (* 1 = 5.05361 loss)
I1213 17:44:28.691553 15749 sgd_solver.cpp:116] Iteration 91000, lr = 1e-05
I1213 17:48:14.848600 15749 solver.cpp:218] Iteration 91100 (0.442203 iter/s, 226.14s/100 iters), loss = 0.673345
I1213 17:48:14.848708 15749 solver.cpp:237]     Train net output #0: label = 1095
I1213 17:48:14.848733 15749 solver.cpp:237]     Train net output #1: label_phocs = 1095
I1213 17:48:14.848745 15749 solver.cpp:237]     Train net output #2: loss = 0.322993 (* 1 = 0.322993 loss)
I1213 17:48:14.848754 15749 sgd_solver.cpp:116] Iteration 91100, lr = 1e-05
I1213 17:52:36.171936 15749 solver.cpp:218] Iteration 91200 (0.382732 iter/s, 261.28s/100 iters), loss = 0.711658
I1213 17:52:36.172026 15749 solver.cpp:237]     Train net output #0: label = 679
I1213 17:52:36.172049 15749 solver.cpp:237]     Train net output #1: label_phocs = 679
I1213 17:52:36.172061 15749 solver.cpp:237]     Train net output #2: loss = 0.757593 (* 1 = 0.757593 loss)
I1213 17:52:36.172070 15749 sgd_solver.cpp:116] Iteration 91200, lr = 1e-05
I1213 17:57:00.372509 15749 solver.cpp:218] Iteration 91300 (0.378633 iter/s, 264.108s/100 iters), loss = 0.708001
I1213 17:57:00.421372 15749 solver.cpp:237]     Train net output #0: label = 901
I1213 17:57:00.421481 15749 solver.cpp:237]     Train net output #1: label_phocs = 901
I1213 17:57:00.421499 15749 solver.cpp:237]     Train net output #2: loss = 0.0256226 (* 1 = 0.0256226 loss)
I1213 17:57:00.447769 15749 sgd_solver.cpp:116] Iteration 91300, lr = 1e-05
I1213 18:01:18.820883 15749 solver.cpp:218] Iteration 91400 (0.386997 iter/s, 258.4s/100 iters), loss = 0.658452
I1213 18:01:18.821182 15749 solver.cpp:237]     Train net output #0: label = 606
I1213 18:01:18.821238 15749 solver.cpp:237]     Train net output #1: label_phocs = 606
I1213 18:01:18.821257 15749 solver.cpp:237]     Train net output #2: loss = 1.76004 (* 1 = 1.76004 loss)
I1213 18:01:18.821269 15749 sgd_solver.cpp:116] Iteration 91400, lr = 1e-05
[2017-12-13 18:05:32,633, PHOCNetTrainer] Running test evaluation
[2017-12-13 18:05:32,814, PHOCNetTrainer] Evaluating CNN after 91000 steps:
I1213 18:08:01.516834 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:08:01.541434 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 18:08:07,043, PHOCNetTrainer] mAP: 0.927192
I1213 18:08:07.070196 15749 solver.cpp:330] Iteration 91500, Testing net (#0)
I1213 18:08:07.095938 15749 net.cpp:676] Ignoring source layer drop6
I1213 18:08:07.095984 15749 net.cpp:676] Ignoring source layer drop7
I1213 18:09:59.235875 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:09:59.236121 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:10:01.566234 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 18:10:01.566282 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 18:10:01.566305 15749 solver.cpp:397]     Test net output #2: loss = 16.5535 (* 1 = 16.5535 loss)
I1213 18:10:04.114681 15749 solver.cpp:218] Iteration 91500 (0.19037 iter/s, 525.294s/100 iters), loss = 0.369055
I1213 18:10:04.116536 15749 solver.cpp:237]     Train net output #0: label = 1019
I1213 18:10:04.116637 15749 solver.cpp:237]     Train net output #1: label_phocs = 1019
I1213 18:10:04.116658 15749 solver.cpp:237]     Train net output #2: loss = 0.00462151 (* 1 = 0.00462151 loss)
I1213 18:10:04.116672 15749 sgd_solver.cpp:116] Iteration 91500, lr = 1e-05
I1213 18:14:26.427691 15749 solver.cpp:218] Iteration 91600 (0.38132 iter/s, 262.247s/100 iters), loss = 0.657342
I1213 18:14:26.427809 15749 solver.cpp:237]     Train net output #0: label = 320
I1213 18:14:26.427839 15749 solver.cpp:237]     Train net output #1: label_phocs = 320
I1213 18:14:26.427853 15749 solver.cpp:237]     Train net output #2: loss = 0.186035 (* 1 = 0.186035 loss)
I1213 18:14:26.427865 15749 sgd_solver.cpp:116] Iteration 91600, lr = 1e-05
I1213 18:18:30.855077 15749 solver.cpp:218] Iteration 91700 (0.409124 iter/s, 244.424s/100 iters), loss = 0.685657
I1213 18:18:30.855186 15749 solver.cpp:237]     Train net output #0: label = 316
I1213 18:18:30.855217 15749 solver.cpp:237]     Train net output #1: label_phocs = 316
I1213 18:18:30.855234 15749 solver.cpp:237]     Train net output #2: loss = 0.039247 (* 1 = 0.039247 loss)
I1213 18:18:30.855248 15749 sgd_solver.cpp:116] Iteration 91700, lr = 1e-05
I1213 18:19:00.935662 15749 blocking_queue.cpp:49] Waiting for data
I1213 18:23:06.338521 15749 solver.cpp:218] Iteration 91800 (0.362998 iter/s, 275.483s/100 iters), loss = 0.719427
I1213 18:23:06.339126 15749 solver.cpp:237]     Train net output #0: label = 819
I1213 18:23:06.339193 15749 solver.cpp:237]     Train net output #1: label_phocs = 819
I1213 18:23:06.339210 15749 solver.cpp:237]     Train net output #2: loss = 1.67228 (* 1 = 1.67228 loss)
I1213 18:23:06.339220 15749 sgd_solver.cpp:116] Iteration 91800, lr = 1e-05
I1213 18:27:32.850164 15749 solver.cpp:218] Iteration 91900 (0.375241 iter/s, 266.495s/100 iters), loss = 0.66051
I1213 18:27:32.850267 15749 solver.cpp:237]     Train net output #0: label = 189
I1213 18:27:32.850294 15749 solver.cpp:237]     Train net output #1: label_phocs = 189
I1213 18:27:32.850308 15749 solver.cpp:237]     Train net output #2: loss = 0.101707 (* 1 = 0.101707 loss)
I1213 18:27:32.850318 15749 sgd_solver.cpp:116] Iteration 91900, lr = 1e-05
[2017-12-13 18:31:37,565, PHOCNetTrainer] Running test evaluation
[2017-12-13 18:31:37,566, PHOCNetTrainer] Evaluating CNN after 91500 steps:
I1213 18:33:33.844964 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:33:33.845160 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 18:33:37,324, PHOCNetTrainer] mAP: 0.926360
I1213 18:33:37.325927 15749 solver.cpp:330] Iteration 92000, Testing net (#0)
I1213 18:33:37.326182 15749 net.cpp:676] Ignoring source layer drop6
I1213 18:33:37.326195 15749 net.cpp:676] Ignoring source layer drop7
I1213 18:35:39.358283 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:35:39.358588 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:35:40.855842 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 18:35:40.855901 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 18:35:40.855913 15749 solver.cpp:397]     Test net output #2: loss = 16.3025 (* 1 = 16.3025 loss)
I1213 18:35:43.764227 15749 solver.cpp:218] Iteration 92000 (0.20372 iter/s, 490.869s/100 iters), loss = 0.119934
I1213 18:35:43.764360 15749 solver.cpp:237]     Train net output #0: label = 188
I1213 18:35:43.764394 15749 solver.cpp:237]     Train net output #1: label_phocs = 188
I1213 18:35:43.764410 15749 solver.cpp:237]     Train net output #2: loss = 0.00291928 (* 1 = 0.00291928 loss)
I1213 18:35:43.764421 15749 sgd_solver.cpp:116] Iteration 92000, lr = 1e-05
I1213 18:40:16.955338 15749 solver.cpp:218] Iteration 92100 (0.366044 iter/s, 273.191s/100 iters), loss = 0.665167
I1213 18:40:16.955451 15749 solver.cpp:237]     Train net output #0: label = 1070
I1213 18:40:16.955476 15749 solver.cpp:237]     Train net output #1: label_phocs = 1070
I1213 18:40:16.955488 15749 solver.cpp:237]     Train net output #2: loss = 0.0286362 (* 1 = 0.0286362 loss)
I1213 18:40:16.955498 15749 sgd_solver.cpp:116] Iteration 92100, lr = 1e-05
I1213 18:44:46.813539 15749 solver.cpp:218] Iteration 92200 (0.370593 iter/s, 269.838s/100 iters), loss = 0.629969
I1213 18:44:46.814607 15749 solver.cpp:237]     Train net output #0: label = 754
I1213 18:44:46.814668 15749 solver.cpp:237]     Train net output #1: label_phocs = 754
I1213 18:44:46.814682 15749 solver.cpp:237]     Train net output #2: loss = 0.155384 (* 1 = 0.155384 loss)
I1213 18:44:46.814694 15749 sgd_solver.cpp:116] Iteration 92200, lr = 1e-05
I1213 18:48:49.267182 15749 solver.cpp:218] Iteration 92300 (0.412496 iter/s, 242.426s/100 iters), loss = 0.652026
I1213 18:48:49.267987 15749 solver.cpp:237]     Train net output #0: label = 741
I1213 18:48:49.268026 15749 solver.cpp:237]     Train net output #1: label_phocs = 741
I1213 18:48:49.268043 15749 solver.cpp:237]     Train net output #2: loss = 0.0467257 (* 1 = 0.0467257 loss)
I1213 18:48:49.268052 15749 sgd_solver.cpp:116] Iteration 92300, lr = 1e-05
I1213 18:53:22.052840 15749 solver.cpp:218] Iteration 92400 (0.366589 iter/s, 272.785s/100 iters), loss = 0.625227
I1213 18:53:22.052928 15749 solver.cpp:237]     Train net output #0: label = 480
I1213 18:53:22.052954 15749 solver.cpp:237]     Train net output #1: label_phocs = 480
I1213 18:53:22.052968 15749 solver.cpp:237]     Train net output #2: loss = 0.0579141 (* 1 = 0.0579141 loss)
I1213 18:53:22.052978 15749 sgd_solver.cpp:116] Iteration 92400, lr = 1e-05
[2017-12-13 18:57:46,069, PHOCNetTrainer] Running test evaluation
[2017-12-13 18:57:46,069, PHOCNetTrainer] Evaluating CNN after 92000 steps:
I1213 18:59:56.183895 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 18:59:56.184036 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 18:59:58,724, PHOCNetTrainer] mAP: 0.927818
I1213 18:59:58.726158 15749 solver.cpp:330] Iteration 92500, Testing net (#0)
I1213 18:59:58.726441 15749 net.cpp:676] Ignoring source layer drop6
I1213 18:59:58.726454 15749 net.cpp:676] Ignoring source layer drop7
I1213 19:01:30.607929 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:01:30.608106 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:01:31.934919 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 19:01:31.934978 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 19:01:31.934990 15749 solver.cpp:397]     Test net output #2: loss = 16.4599 (* 1 = 16.4599 loss)
I1213 19:01:34.295673 15749 solver.cpp:218] Iteration 92500 (0.203152 iter/s, 492.243s/100 iters), loss = 0.774098
I1213 19:01:34.316314 15749 solver.cpp:237]     Train net output #0: label = 126
I1213 19:01:34.316370 15749 solver.cpp:237]     Train net output #1: label_phocs = 126
I1213 19:01:34.316385 15749 solver.cpp:237]     Train net output #2: loss = 1.23551 (* 1 = 1.23551 loss)
I1213 19:01:34.316393 15749 sgd_solver.cpp:116] Iteration 92500, lr = 1e-05
I1213 19:06:04.994401 15749 solver.cpp:218] Iteration 92600 (0.369442 iter/s, 270.678s/100 iters), loss = 0.745304
I1213 19:06:04.994513 15749 solver.cpp:237]     Train net output #0: label = 1083
I1213 19:06:04.994539 15749 solver.cpp:237]     Train net output #1: label_phocs = 1083
I1213 19:06:04.994554 15749 solver.cpp:237]     Train net output #2: loss = 0.0145705 (* 1 = 0.0145705 loss)
I1213 19:06:04.994565 15749 sgd_solver.cpp:116] Iteration 92600, lr = 1e-05
I1213 19:10:28.340605 15749 solver.cpp:218] Iteration 92700 (0.379743 iter/s, 263.336s/100 iters), loss = 0.689689
I1213 19:10:28.340781 15749 solver.cpp:237]     Train net output #0: label = 1061
I1213 19:10:28.340816 15749 solver.cpp:237]     Train net output #1: label_phocs = 1061
I1213 19:10:28.340832 15749 solver.cpp:237]     Train net output #2: loss = 1.05471 (* 1 = 1.05471 loss)
I1213 19:10:28.340849 15749 sgd_solver.cpp:116] Iteration 92700, lr = 1e-05
I1213 19:15:01.353150 15749 solver.cpp:218] Iteration 92800 (0.366333 iter/s, 272.975s/100 iters), loss = 0.718621
I1213 19:15:01.353278 15749 solver.cpp:237]     Train net output #0: label = 20
I1213 19:15:01.353305 15749 solver.cpp:237]     Train net output #1: label_phocs = 20
I1213 19:15:01.353318 15749 solver.cpp:237]     Train net output #2: loss = 1.78428 (* 1 = 1.78428 loss)
I1213 19:15:01.353328 15749 sgd_solver.cpp:116] Iteration 92800, lr = 1e-05
I1213 19:18:45.115228 15749 solver.cpp:218] Iteration 92900 (0.446979 iter/s, 223.724s/100 iters), loss = 0.657784
I1213 19:18:45.115604 15749 solver.cpp:237]     Train net output #0: label = 286
I1213 19:18:45.115635 15749 solver.cpp:237]     Train net output #1: label_phocs = 286
I1213 19:18:45.115649 15749 solver.cpp:237]     Train net output #2: loss = 0.226954 (* 1 = 0.226954 loss)
I1213 19:18:45.115659 15749 sgd_solver.cpp:116] Iteration 92900, lr = 1e-05
[2017-12-13 19:23:08,925, PHOCNetTrainer] Running test evaluation
[2017-12-13 19:23:08,925, PHOCNetTrainer] Evaluating CNN after 92500 steps:
I1213 19:25:14.347878 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:25:14.348019 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 19:25:17,301, PHOCNetTrainer] mAP: 0.927165
I1213 19:25:17.303172 15749 solver.cpp:330] Iteration 93000, Testing net (#0)
I1213 19:25:17.303452 15749 net.cpp:676] Ignoring source layer drop6
I1213 19:25:17.303464 15749 net.cpp:676] Ignoring source layer drop7
I1213 19:27:19.759853 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:27:19.760064 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:27:20.984346 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 19:27:20.984402 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 19:27:20.984416 15749 solver.cpp:397]     Test net output #2: loss = 16.6251 (* 1 = 16.6251 loss)
I1213 19:27:23.440124 15749 solver.cpp:218] Iteration 93000 (0.19293 iter/s, 518.324s/100 iters), loss = 0.215076
I1213 19:27:23.440213 15749 solver.cpp:237]     Train net output #0: label = 295
I1213 19:27:23.440235 15749 solver.cpp:237]     Train net output #1: label_phocs = 295
I1213 19:27:23.440248 15749 solver.cpp:237]     Train net output #2: loss = 0.0114543 (* 1 = 0.0114543 loss)
I1213 19:27:23.440255 15749 sgd_solver.cpp:116] Iteration 93000, lr = 1e-05
I1213 19:31:38.452664 15749 solver.cpp:218] Iteration 93100 (0.392138 iter/s, 255.012s/100 iters), loss = 0.704959
I1213 19:31:38.452744 15749 solver.cpp:237]     Train net output #0: label = 322
I1213 19:31:38.452769 15749 solver.cpp:237]     Train net output #1: label_phocs = 322
I1213 19:31:38.452783 15749 solver.cpp:237]     Train net output #2: loss = 0.362728 (* 1 = 0.362728 loss)
I1213 19:31:38.452792 15749 sgd_solver.cpp:116] Iteration 93100, lr = 1e-05
I1213 19:36:07.683684 15749 solver.cpp:218] Iteration 93200 (0.371442 iter/s, 269.221s/100 iters), loss = 0.704123
I1213 19:36:07.684085 15749 solver.cpp:237]     Train net output #0: label = 747
I1213 19:36:07.684137 15749 solver.cpp:237]     Train net output #1: label_phocs = 747
I1213 19:36:07.684152 15749 solver.cpp:237]     Train net output #2: loss = 5.03875 (* 1 = 5.03875 loss)
I1213 19:36:07.684162 15749 sgd_solver.cpp:116] Iteration 93200, lr = 1e-05
I1213 19:40:29.446475 15749 solver.cpp:218] Iteration 93300 (0.382026 iter/s, 261.762s/100 iters), loss = 0.670739
I1213 19:40:29.451831 15749 solver.cpp:237]     Train net output #0: label = 539
I1213 19:40:29.451908 15749 solver.cpp:237]     Train net output #1: label_phocs = 539
I1213 19:40:29.451925 15749 solver.cpp:237]     Train net output #2: loss = 0.00338101 (* 1 = 0.00338101 loss)
I1213 19:40:29.451936 15749 sgd_solver.cpp:116] Iteration 93300, lr = 1e-05
I1213 19:45:03.408826 15749 solver.cpp:218] Iteration 93400 (0.365021 iter/s, 273.957s/100 iters), loss = 0.645042
I1213 19:45:03.413290 15749 solver.cpp:237]     Train net output #0: label = 145
I1213 19:45:03.413373 15749 solver.cpp:237]     Train net output #1: label_phocs = 145
I1213 19:45:03.413391 15749 solver.cpp:237]     Train net output #2: loss = 0.139846 (* 1 = 0.139846 loss)
I1213 19:45:03.413403 15749 sgd_solver.cpp:116] Iteration 93400, lr = 1e-05
[2017-12-13 19:48:56,667, PHOCNetTrainer] Running test evaluation
[2017-12-13 19:48:56,667, PHOCNetTrainer] Evaluating CNN after 93000 steps:
I1213 19:51:01.087888 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:51:01.088035 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 19:51:05,471, PHOCNetTrainer] mAP: 0.927838
I1213 19:51:05.473127 15749 solver.cpp:330] Iteration 93500, Testing net (#0)
I1213 19:51:05.473398 15749 net.cpp:676] Ignoring source layer drop6
I1213 19:51:05.473418 15749 net.cpp:676] Ignoring source layer drop7
I1213 19:52:57.696269 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:52:57.696451 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 19:53:00.128655 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 19:53:00.128722 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 19:53:00.128736 15749 solver.cpp:397]     Test net output #2: loss = 16.4227 (* 1 = 16.4227 loss)
I1213 19:53:03.758903 15749 solver.cpp:218] Iteration 93500 (0.208183 iter/s, 480.346s/100 iters), loss = 0.44766
I1213 19:53:03.759009 15749 solver.cpp:237]     Train net output #0: label = 1033
I1213 19:53:03.759037 15749 solver.cpp:237]     Train net output #1: label_phocs = 1033
I1213 19:53:03.759052 15749 solver.cpp:237]     Train net output #2: loss = 0.0202537 (* 1 = 0.0202537 loss)
I1213 19:53:03.759063 15749 sgd_solver.cpp:116] Iteration 93500, lr = 1e-05
I1213 19:57:17.140002 15749 solver.cpp:218] Iteration 93600 (0.394674 iter/s, 253.373s/100 iters), loss = 0.743621
I1213 19:57:17.140782 15749 solver.cpp:237]     Train net output #0: label = 1013
I1213 19:57:17.140817 15749 solver.cpp:237]     Train net output #1: label_phocs = 1013
I1213 19:57:17.140831 15749 solver.cpp:237]     Train net output #2: loss = 0.107327 (* 1 = 0.107327 loss)
I1213 19:57:17.140841 15749 sgd_solver.cpp:116] Iteration 93600, lr = 1e-05
I1213 20:00:58.331010 15749 solver.cpp:218] Iteration 93700 (0.452099 iter/s, 221.19s/100 iters), loss = 0.782158
I1213 20:00:58.332065 15749 solver.cpp:237]     Train net output #0: label = 133
I1213 20:00:58.332087 15749 solver.cpp:237]     Train net output #1: label_phocs = 133
I1213 20:00:58.332094 15749 solver.cpp:237]     Train net output #2: loss = 5.43789 (* 1 = 5.43789 loss)
I1213 20:00:58.332101 15749 sgd_solver.cpp:116] Iteration 93700, lr = 1e-05
I1213 20:05:00.839262 15749 solver.cpp:218] Iteration 93800 (0.41237 iter/s, 242.501s/100 iters), loss = 0.711973
I1213 20:05:00.839342 15749 solver.cpp:237]     Train net output #0: label = 452
I1213 20:05:00.839366 15749 solver.cpp:237]     Train net output #1: label_phocs = 452
I1213 20:05:00.839378 15749 solver.cpp:237]     Train net output #2: loss = 0.0643938 (* 1 = 0.0643938 loss)
I1213 20:05:00.839387 15749 sgd_solver.cpp:116] Iteration 93800, lr = 1e-05
I1213 20:08:54.291247 15749 solver.cpp:218] Iteration 93900 (0.428385 iter/s, 233.435s/100 iters), loss = 0.735624
I1213 20:08:54.291363 15749 solver.cpp:237]     Train net output #0: label = 195
I1213 20:08:54.291386 15749 solver.cpp:237]     Train net output #1: label_phocs = 195
I1213 20:08:54.291399 15749 solver.cpp:237]     Train net output #2: loss = 0.19147 (* 1 = 0.19147 loss)
I1213 20:08:54.291407 15749 sgd_solver.cpp:116] Iteration 93900, lr = 1e-05
[2017-12-13 20:12:36,337, PHOCNetTrainer] Running test evaluation
[2017-12-13 20:12:36,337, PHOCNetTrainer] Evaluating CNN after 93500 steps:
I1213 20:13:56.835950 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:13:56.837462 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 20:13:59,885, PHOCNetTrainer] mAP: 0.926613
I1213 20:13:59.887102 15749 solver.cpp:330] Iteration 94000, Testing net (#0)
I1213 20:13:59.887311 15749 net.cpp:676] Ignoring source layer drop6
I1213 20:13:59.887321 15749 net.cpp:676] Ignoring source layer drop7
I1213 20:15:40.567945 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:15:40.568320 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:15:41.084241 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 20:15:41.084292 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 20:15:41.084306 15749 solver.cpp:397]     Test net output #2: loss = 16.4381 (* 1 = 16.4381 loss)
I1213 20:15:43.545941 15749 solver.cpp:218] Iteration 94000 (0.244359 iter/s, 409.234s/100 iters), loss = 0.214382
I1213 20:15:43.546052 15749 solver.cpp:237]     Train net output #0: label = 26
I1213 20:15:43.546077 15749 solver.cpp:237]     Train net output #1: label_phocs = 26
I1213 20:15:43.546089 15749 solver.cpp:237]     Train net output #2: loss = 0.30421 (* 1 = 0.30421 loss)
I1213 20:15:43.546097 15749 sgd_solver.cpp:116] Iteration 94000, lr = 1e-05
I1213 20:19:41.079859 15749 solver.cpp:218] Iteration 94100 (0.420992 iter/s, 237.534s/100 iters), loss = 0.667013
I1213 20:19:41.080132 15749 solver.cpp:237]     Train net output #0: label = 554
I1213 20:19:41.080158 15749 solver.cpp:237]     Train net output #1: label_phocs = 554
I1213 20:19:41.080171 15749 solver.cpp:237]     Train net output #2: loss = 0.00879914 (* 1 = 0.00879914 loss)
I1213 20:19:41.080180 15749 sgd_solver.cpp:116] Iteration 94100, lr = 1e-05
I1213 20:23:44.554388 15749 solver.cpp:218] Iteration 94200 (0.410721 iter/s, 243.474s/100 iters), loss = 0.618486
I1213 20:23:44.554469 15749 solver.cpp:237]     Train net output #0: label = 232
I1213 20:23:44.554493 15749 solver.cpp:237]     Train net output #1: label_phocs = 232
I1213 20:23:44.554505 15749 solver.cpp:237]     Train net output #2: loss = 0.0247382 (* 1 = 0.0247382 loss)
I1213 20:23:44.554514 15749 sgd_solver.cpp:116] Iteration 94200, lr = 1e-05
I1213 20:27:12.186758 15749 solver.cpp:218] Iteration 94300 (0.481669 iter/s, 207.611s/100 iters), loss = 0.636638
I1213 20:27:12.186842 15749 solver.cpp:237]     Train net output #0: label = 498
I1213 20:27:12.186867 15749 solver.cpp:237]     Train net output #1: label_phocs = 498
I1213 20:27:12.186878 15749 solver.cpp:237]     Train net output #2: loss = 0.88966 (* 1 = 0.88966 loss)
I1213 20:27:12.186887 15749 sgd_solver.cpp:116] Iteration 94300, lr = 1e-05
I1213 20:31:07.708814 15749 solver.cpp:218] Iteration 94400 (0.424688 iter/s, 235.467s/100 iters), loss = 0.67622
I1213 20:31:07.709936 15749 solver.cpp:237]     Train net output #0: label = 903
I1213 20:31:07.709960 15749 solver.cpp:237]     Train net output #1: label_phocs = 903
I1213 20:31:07.709971 15749 solver.cpp:237]     Train net output #2: loss = 0.0235133 (* 1 = 0.0235133 loss)
I1213 20:31:07.709980 15749 sgd_solver.cpp:116] Iteration 94400, lr = 1e-05
[2017-12-13 20:35:03,463, PHOCNetTrainer] Running test evaluation
[2017-12-13 20:35:03,463, PHOCNetTrainer] Evaluating CNN after 94000 steps:
I1213 20:36:34.426499 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:36:34.426492 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 20:36:37,233, PHOCNetTrainer] mAP: 0.927538
I1213 20:36:37.235050 15749 solver.cpp:330] Iteration 94500, Testing net (#0)
I1213 20:36:37.235231 15749 net.cpp:676] Ignoring source layer drop6
I1213 20:36:37.235239 15749 net.cpp:676] Ignoring source layer drop7
I1213 20:38:12.172971 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:38:12.173107 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:38:13.847645 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 20:38:13.847692 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 20:38:13.847703 15749 solver.cpp:397]     Test net output #2: loss = 16.3218 (* 1 = 16.3218 loss)
I1213 20:38:16.427325 15749 solver.cpp:218] Iteration 94500 (0.233254 iter/s, 428.718s/100 iters), loss = 0.404005
I1213 20:38:16.428452 15749 solver.cpp:237]     Train net output #0: label = 411
I1213 20:38:16.428472 15749 solver.cpp:237]     Train net output #1: label_phocs = 411
I1213 20:38:16.428479 15749 solver.cpp:237]     Train net output #2: loss = 1.00344 (* 1 = 1.00344 loss)
I1213 20:38:16.428485 15749 sgd_solver.cpp:116] Iteration 94500, lr = 1e-05
I1213 20:41:45.495445 15749 solver.cpp:218] Iteration 94600 (0.478315 iter/s, 209.067s/100 iters), loss = 0.601804
I1213 20:41:45.496570 15749 solver.cpp:237]     Train net output #0: label = 235
I1213 20:41:45.496594 15749 solver.cpp:237]     Train net output #1: label_phocs = 235
I1213 20:41:45.496603 15749 solver.cpp:237]     Train net output #2: loss = 0.0250867 (* 1 = 0.0250867 loss)
I1213 20:41:45.496609 15749 sgd_solver.cpp:116] Iteration 94600, lr = 1e-05
I1213 20:45:45.137531 15749 solver.cpp:218] Iteration 94700 (0.417396 iter/s, 239.581s/100 iters), loss = 0.663925
I1213 20:45:45.138068 15749 solver.cpp:237]     Train net output #0: label = 246
I1213 20:45:45.138104 15749 solver.cpp:237]     Train net output #1: label_phocs = 246
I1213 20:45:45.138116 15749 solver.cpp:237]     Train net output #2: loss = 0.0562287 (* 1 = 0.0562287 loss)
I1213 20:45:45.138126 15749 sgd_solver.cpp:116] Iteration 94700, lr = 1e-05
I1213 20:49:33.279772 15749 solver.cpp:218] Iteration 94800 (0.438339 iter/s, 228.134s/100 iters), loss = 0.585604
I1213 20:49:33.279867 15749 solver.cpp:237]     Train net output #0: label = 953
I1213 20:49:33.279891 15749 solver.cpp:237]     Train net output #1: label_phocs = 953
I1213 20:49:33.279903 15749 solver.cpp:237]     Train net output #2: loss = 0.00399708 (* 1 = 0.00399708 loss)
I1213 20:49:33.279912 15749 sgd_solver.cpp:116] Iteration 94800, lr = 1e-05
I1213 20:53:09.967797 15749 solver.cpp:218] Iteration 94900 (0.461568 iter/s, 216.653s/100 iters), loss = 0.703029
I1213 20:53:09.967911 15749 solver.cpp:237]     Train net output #0: label = 677
I1213 20:53:09.967936 15749 solver.cpp:237]     Train net output #1: label_phocs = 677
I1213 20:53:09.967948 15749 solver.cpp:237]     Train net output #2: loss = 0.351749 (* 1 = 0.351749 loss)
I1213 20:53:09.967957 15749 sgd_solver.cpp:116] Iteration 94900, lr = 1e-05
[2017-12-13 20:56:47,722, PHOCNetTrainer] Running test evaluation
[2017-12-13 20:56:47,722, PHOCNetTrainer] Evaluating CNN after 94500 steps:
I1213 20:58:22.462878 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 20:58:22.496760 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 20:58:25,146, PHOCNetTrainer] mAP: 0.926447
I1213 20:58:25.148332 15749 solver.cpp:330] Iteration 95000, Testing net (#0)
I1213 20:58:25.148535 15749 net.cpp:676] Ignoring source layer drop6
I1213 20:58:25.148545 15749 net.cpp:676] Ignoring source layer drop7
I1213 21:00:06.415854 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:00:06.415988 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:00:07.597772 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 21:00:07.597815 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 21:00:07.597825 15749 solver.cpp:397]     Test net output #2: loss = 16.3665 (* 1 = 16.3665 loss)
I1213 21:00:09.496938 15749 solver.cpp:218] Iteration 95000 (0.238381 iter/s, 419.497s/100 iters), loss = 0.355904
I1213 21:00:09.498149 15749 solver.cpp:237]     Train net output #0: label = 386
I1213 21:00:09.498201 15749 solver.cpp:237]     Train net output #1: label_phocs = 386
I1213 21:00:09.498219 15749 solver.cpp:237]     Train net output #2: loss = 0.0225639 (* 1 = 0.0225639 loss)
I1213 21:00:09.498230 15749 sgd_solver.cpp:116] Iteration 95000, lr = 1e-05
I1213 21:04:12.040531 15749 solver.cpp:218] Iteration 95100 (0.412378 iter/s, 242.496s/100 iters), loss = 0.684316
I1213 21:04:12.040613 15749 solver.cpp:237]     Train net output #0: label = 827
I1213 21:04:12.040637 15749 solver.cpp:237]     Train net output #1: label_phocs = 827
I1213 21:04:12.040649 15749 solver.cpp:237]     Train net output #2: loss = 0.0863455 (* 1 = 0.0863455 loss)
I1213 21:04:12.040663 15749 sgd_solver.cpp:116] Iteration 95100, lr = 1e-05
I1213 21:07:46.285542 15749 solver.cpp:218] Iteration 95200 (0.466755 iter/s, 214.245s/100 iters), loss = 0.60044
I1213 21:07:46.286665 15749 solver.cpp:237]     Train net output #0: label = 694
I1213 21:07:46.286720 15749 solver.cpp:237]     Train net output #1: label_phocs = 694
I1213 21:07:46.286736 15749 solver.cpp:237]     Train net output #2: loss = 1.37871 (* 1 = 1.37871 loss)
I1213 21:07:46.286746 15749 sgd_solver.cpp:116] Iteration 95200, lr = 1e-05
I1213 21:11:37.973520 15749 solver.cpp:218] Iteration 95300 (0.431699 iter/s, 231.643s/100 iters), loss = 0.710056
I1213 21:11:37.974007 15749 solver.cpp:237]     Train net output #0: label = 852
I1213 21:11:37.974033 15749 solver.cpp:237]     Train net output #1: label_phocs = 852
I1213 21:11:37.974045 15749 solver.cpp:237]     Train net output #2: loss = 0.37235 (* 1 = 0.37235 loss)
I1213 21:11:37.974054 15749 sgd_solver.cpp:116] Iteration 95300, lr = 1e-05
I1213 21:15:36.489418 15749 solver.cpp:218] Iteration 95400 (0.419331 iter/s, 238.475s/100 iters), loss = 0.715091
I1213 21:15:36.489539 15749 solver.cpp:237]     Train net output #0: label = 923
I1213 21:15:36.489563 15749 solver.cpp:237]     Train net output #1: label_phocs = 923
I1213 21:15:36.489575 15749 solver.cpp:237]     Train net output #2: loss = 0.0370945 (* 1 = 0.0370945 loss)
I1213 21:15:36.489584 15749 sgd_solver.cpp:116] Iteration 95400, lr = 1e-05
[2017-12-13 21:19:28,180, PHOCNetTrainer] Running test evaluation
[2017-12-13 21:19:28,180, PHOCNetTrainer] Evaluating CNN after 95000 steps:
I1213 21:20:42.722668 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:20:42.723868 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 21:20:47,097, PHOCNetTrainer] mAP: 0.926981
I1213 21:20:47.099061 15749 solver.cpp:330] Iteration 95500, Testing net (#0)
I1213 21:20:47.099261 15749 net.cpp:676] Ignoring source layer drop6
I1213 21:20:47.099270 15749 net.cpp:676] Ignoring source layer drop7
I1213 21:22:32.704073 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:22:32.704077 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:22:34.062402 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 21:22:34.062448 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 21:22:34.062458 15749 solver.cpp:397]     Test net output #2: loss = 16.5693 (* 1 = 16.5693 loss)
I1213 21:22:35.986039 15749 solver.cpp:218] Iteration 95500 (0.238381 iter/s, 419.497s/100 iters), loss = 0.399903
I1213 21:22:35.999977 15749 solver.cpp:237]     Train net output #0: label = 833
I1213 21:22:36.000123 15749 solver.cpp:237]     Train net output #1: label_phocs = 833
I1213 21:22:36.000136 15749 solver.cpp:237]     Train net output #2: loss = 0.225615 (* 1 = 0.225615 loss)
I1213 21:22:36.000145 15749 sgd_solver.cpp:116] Iteration 95500, lr = 1e-05
I1213 21:26:31.585924 15749 solver.cpp:218] Iteration 95600 (0.424473 iter/s, 235.586s/100 iters), loss = 0.570354
I1213 21:26:31.587240 15749 solver.cpp:237]     Train net output #0: label = 626
I1213 21:26:31.587270 15749 solver.cpp:237]     Train net output #1: label_phocs = 626
I1213 21:26:31.587282 15749 solver.cpp:237]     Train net output #2: loss = 0.0345449 (* 1 = 0.0345449 loss)
I1213 21:26:31.587291 15749 sgd_solver.cpp:116] Iteration 95600, lr = 1e-05
I1213 21:30:22.197382 15749 solver.cpp:218] Iteration 95700 (0.433646 iter/s, 230.603s/100 iters), loss = 0.724548
I1213 21:30:22.198220 15749 solver.cpp:237]     Train net output #0: label = 604
I1213 21:30:22.198247 15749 solver.cpp:237]     Train net output #1: label_phocs = 604
I1213 21:30:22.198259 15749 solver.cpp:237]     Train net output #2: loss = 0.0795878 (* 1 = 0.0795878 loss)
I1213 21:30:22.198268 15749 sgd_solver.cpp:116] Iteration 95700, lr = 1e-05
I1213 21:33:55.171135 15749 solver.cpp:218] Iteration 95800 (0.469579 iter/s, 212.957s/100 iters), loss = 0.650681
I1213 21:33:55.171223 15749 solver.cpp:237]     Train net output #0: label = 496
I1213 21:33:55.171247 15749 solver.cpp:237]     Train net output #1: label_phocs = 496
I1213 21:33:55.171259 15749 solver.cpp:237]     Train net output #2: loss = 0.0168954 (* 1 = 0.0168954 loss)
I1213 21:33:55.171267 15749 sgd_solver.cpp:116] Iteration 95800, lr = 1e-05
I1213 21:37:43.356379 15749 solver.cpp:218] Iteration 95900 (0.43824 iter/s, 228.185s/100 iters), loss = 0.735621
I1213 21:37:43.357586 15749 solver.cpp:237]     Train net output #0: label = 425
I1213 21:37:43.357609 15749 solver.cpp:237]     Train net output #1: label_phocs = 425
I1213 21:37:43.357621 15749 solver.cpp:237]     Train net output #2: loss = 0.00506812 (* 1 = 0.00506812 loss)
I1213 21:37:43.357630 15749 sgd_solver.cpp:116] Iteration 95900, lr = 1e-05
[2017-12-13 21:41:47,509, PHOCNetTrainer] Running test evaluation
[2017-12-13 21:41:47,509, PHOCNetTrainer] Evaluating CNN after 95500 steps:
I1213 21:43:18.240345 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:43:18.242627 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 21:43:21,379, PHOCNetTrainer] mAP: 0.925517
I1213 21:43:21.385247 15749 solver.cpp:330] Iteration 96000, Testing net (#0)
I1213 21:43:21.385440 15749 net.cpp:676] Ignoring source layer drop6
I1213 21:43:21.385449 15749 net.cpp:676] Ignoring source layer drop7
I1213 21:45:02.404104 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:45:02.404320 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 21:45:04.322314 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 21:45:04.322358 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 21:45:04.322369 15749 solver.cpp:397]     Test net output #2: loss = 16.6592 (* 1 = 16.6592 loss)
I1213 21:45:06.402916 15749 solver.cpp:218] Iteration 96000 (0.225718 iter/s, 443.03s/100 iters), loss = 1.45318
I1213 21:45:06.402997 15749 solver.cpp:237]     Train net output #0: label = 624
I1213 21:45:06.403020 15749 solver.cpp:237]     Train net output #1: label_phocs = 624
I1213 21:45:06.403033 15749 solver.cpp:237]     Train net output #2: loss = 8.81873 (* 1 = 8.81873 loss)
I1213 21:45:06.403041 15749 sgd_solver.cpp:116] Iteration 96000, lr = 1e-05
I1213 21:48:39.983163 15749 solver.cpp:218] Iteration 96100 (0.468248 iter/s, 213.562s/100 iters), loss = 0.714834
I1213 21:48:39.983247 15749 solver.cpp:237]     Train net output #0: label = 533
I1213 21:48:39.983273 15749 solver.cpp:237]     Train net output #1: label_phocs = 533
I1213 21:48:39.983285 15749 solver.cpp:237]     Train net output #2: loss = 0.288009 (* 1 = 0.288009 loss)
I1213 21:48:39.983294 15749 sgd_solver.cpp:116] Iteration 96100, lr = 1e-05
I1213 21:52:55.329509 15749 solver.cpp:218] Iteration 96200 (0.391641 iter/s, 255.336s/100 iters), loss = 0.707851
I1213 21:52:55.330181 15749 solver.cpp:237]     Train net output #0: label = 963
I1213 21:52:55.330209 15749 solver.cpp:237]     Train net output #1: label_phocs = 963
I1213 21:52:55.330220 15749 solver.cpp:237]     Train net output #2: loss = 0.179379 (* 1 = 0.179379 loss)
I1213 21:52:55.330229 15749 sgd_solver.cpp:116] Iteration 96200, lr = 1e-05
I1213 21:57:03.062083 15749 solver.cpp:218] Iteration 96300 (0.403662 iter/s, 247.732s/100 iters), loss = 0.785235
I1213 21:57:03.062180 15749 solver.cpp:237]     Train net output #0: label = 811
I1213 21:57:03.062203 15749 solver.cpp:237]     Train net output #1: label_phocs = 811
I1213 21:57:03.062216 15749 solver.cpp:237]     Train net output #2: loss = 0.467736 (* 1 = 0.467736 loss)
I1213 21:57:03.062225 15749 sgd_solver.cpp:116] Iteration 96300, lr = 1e-05
I1213 22:00:50.736222 15749 solver.cpp:218] Iteration 96400 (0.439238 iter/s, 227.667s/100 iters), loss = 0.679626
I1213 22:00:50.736305 15749 solver.cpp:237]     Train net output #0: label = 747
I1213 22:00:50.736328 15749 solver.cpp:237]     Train net output #1: label_phocs = 747
I1213 22:00:50.736340 15749 solver.cpp:237]     Train net output #2: loss = 0.21131 (* 1 = 0.21131 loss)
I1213 22:00:50.736353 15749 sgd_solver.cpp:116] Iteration 96400, lr = 1e-05
[2017-12-13 22:04:43,551, PHOCNetTrainer] Running test evaluation
[2017-12-13 22:04:43,551, PHOCNetTrainer] Evaluating CNN after 96000 steps:
I1213 22:06:22.093027 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:06:22.093160 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 22:06:25,033, PHOCNetTrainer] mAP: 0.927397
I1213 22:06:25.034682 15749 solver.cpp:330] Iteration 96500, Testing net (#0)
I1213 22:06:25.034864 15749 net.cpp:676] Ignoring source layer drop6
I1213 22:06:25.034871 15749 net.cpp:676] Ignoring source layer drop7
I1213 22:08:03.598682 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:08:03.598811 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:08:05.202360 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 22:08:05.202402 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 22:08:05.202414 15749 solver.cpp:397]     Test net output #2: loss = 16.4294 (* 1 = 16.4294 loss)
I1213 22:08:07.333801 15749 solver.cpp:218] Iteration 96500 (0.229045 iter/s, 436.595s/100 iters), loss = 0.217963
I1213 22:08:07.333878 15749 solver.cpp:237]     Train net output #0: label = 299
I1213 22:08:07.333901 15749 solver.cpp:237]     Train net output #1: label_phocs = 299
I1213 22:08:07.333914 15749 solver.cpp:237]     Train net output #2: loss = 0.0187941 (* 1 = 0.0187941 loss)
I1213 22:08:07.333922 15749 sgd_solver.cpp:116] Iteration 96500, lr = 1e-05
I1213 22:12:14.579900 15749 solver.cpp:218] Iteration 96600 (0.404455 iter/s, 247.246s/100 iters), loss = 0.620847
I1213 22:12:14.580018 15749 solver.cpp:237]     Train net output #0: label = 676
I1213 22:12:14.580049 15749 solver.cpp:237]     Train net output #1: label_phocs = 676
I1213 22:12:14.580063 15749 solver.cpp:237]     Train net output #2: loss = 1.68974 (* 1 = 1.68974 loss)
I1213 22:12:14.580072 15749 sgd_solver.cpp:116] Iteration 96600, lr = 1e-05
I1213 22:15:50.675858 15749 solver.cpp:218] Iteration 96700 (0.462942 iter/s, 216.01s/100 iters), loss = 0.611941
I1213 22:15:50.676995 15749 solver.cpp:237]     Train net output #0: label = 448
I1213 22:15:50.677045 15749 solver.cpp:237]     Train net output #1: label_phocs = 448
I1213 22:15:50.677059 15749 solver.cpp:237]     Train net output #2: loss = 0.117639 (* 1 = 0.117639 loss)
I1213 22:15:50.677068 15749 sgd_solver.cpp:116] Iteration 96700, lr = 1e-05
I1213 22:19:47.094796 15749 solver.cpp:218] Iteration 96800 (0.423023 iter/s, 236.394s/100 iters), loss = 0.629969
I1213 22:19:47.095371 15749 solver.cpp:237]     Train net output #0: label = 593
I1213 22:19:47.095397 15749 solver.cpp:237]     Train net output #1: label_phocs = 593
I1213 22:19:47.095407 15749 solver.cpp:237]     Train net output #2: loss = 0.0620501 (* 1 = 0.0620501 loss)
I1213 22:19:47.095414 15749 sgd_solver.cpp:116] Iteration 96800, lr = 1e-05
I1213 22:23:45.337172 15749 solver.cpp:218] Iteration 96900 (0.419741 iter/s, 238.242s/100 iters), loss = 0.622787
I1213 22:23:45.337255 15749 solver.cpp:237]     Train net output #0: label = 156
I1213 22:23:45.337280 15749 solver.cpp:237]     Train net output #1: label_phocs = 156
I1213 22:23:45.337291 15749 solver.cpp:237]     Train net output #2: loss = 0.0235332 (* 1 = 0.0235332 loss)
I1213 22:23:45.337301 15749 sgd_solver.cpp:116] Iteration 96900, lr = 1e-05
[2017-12-13 22:27:21,016, PHOCNetTrainer] Running test evaluation
[2017-12-13 22:27:21,016, PHOCNetTrainer] Evaluating CNN after 96500 steps:
I1213 22:28:54.641571 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:28:54.643853 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 22:28:57,884, PHOCNetTrainer] mAP: 0.926773
I1213 22:28:57.885679 15749 solver.cpp:330] Iteration 97000, Testing net (#0)
I1213 22:28:57.885875 15749 net.cpp:676] Ignoring source layer drop6
I1213 22:28:57.885885 15749 net.cpp:676] Ignoring source layer drop7
I1213 22:30:39.522915 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:30:39.523182 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:30:40.243377 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 22:30:40.243422 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 22:30:40.243433 15749 solver.cpp:397]     Test net output #2: loss = 16.5299 (* 1 = 16.5299 loss)
I1213 22:30:42.085391 15749 solver.cpp:218] Iteration 97000 (0.239964 iter/s, 416.73s/100 iters), loss = 0.239152
I1213 22:30:42.086268 15749 solver.cpp:237]     Train net output #0: label = 3
I1213 22:30:42.086292 15749 solver.cpp:237]     Train net output #1: label_phocs = 3
I1213 22:30:42.086304 15749 solver.cpp:237]     Train net output #2: loss = 0.0535614 (* 1 = 0.0535614 loss)
I1213 22:30:42.086313 15749 sgd_solver.cpp:116] Iteration 97000, lr = 1e-05
I1213 22:34:46.116397 15749 solver.cpp:218] Iteration 97100 (0.409785 iter/s, 244.03s/100 iters), loss = 0.740926
I1213 22:34:46.116487 15749 solver.cpp:237]     Train net output #0: label = 633
I1213 22:34:46.116510 15749 solver.cpp:237]     Train net output #1: label_phocs = 633
I1213 22:34:46.116523 15749 solver.cpp:237]     Train net output #2: loss = 0.0113631 (* 1 = 0.0113631 loss)
I1213 22:34:46.116531 15749 sgd_solver.cpp:116] Iteration 97100, lr = 1e-05
I1213 22:38:49.671835 15749 solver.cpp:218] Iteration 97200 (0.410584 iter/s, 243.555s/100 iters), loss = 0.64808
I1213 22:38:49.671921 15749 solver.cpp:237]     Train net output #0: label = 726
I1213 22:38:49.671958 15749 solver.cpp:237]     Train net output #1: label_phocs = 726
I1213 22:38:49.671974 15749 solver.cpp:237]     Train net output #2: loss = 0.00520529 (* 1 = 0.00520529 loss)
I1213 22:38:49.671983 15749 sgd_solver.cpp:116] Iteration 97200, lr = 1e-05
I1213 22:42:23.601903 15749 solver.cpp:218] Iteration 97300 (0.467455 iter/s, 213.924s/100 iters), loss = 0.749651
I1213 22:42:23.601987 15749 solver.cpp:237]     Train net output #0: label = 104
I1213 22:42:23.602010 15749 solver.cpp:237]     Train net output #1: label_phocs = 104
I1213 22:42:23.602022 15749 solver.cpp:237]     Train net output #2: loss = 1.16955 (* 1 = 1.16955 loss)
I1213 22:42:23.602031 15749 sgd_solver.cpp:116] Iteration 97300, lr = 1e-05
I1213 22:46:15.513783 15749 solver.cpp:218] Iteration 97400 (0.431198 iter/s, 231.912s/100 iters), loss = 0.784066
I1213 22:46:15.514914 15749 solver.cpp:237]     Train net output #0: label = 449
I1213 22:46:15.514937 15749 solver.cpp:237]     Train net output #1: label_phocs = 449
I1213 22:46:15.514946 15749 solver.cpp:237]     Train net output #2: loss = 0.0509087 (* 1 = 0.0509087 loss)
I1213 22:46:15.514952 15749 sgd_solver.cpp:116] Iteration 97400, lr = 1e-05
[2017-12-13 22:50:03,925, PHOCNetTrainer] Running test evaluation
[2017-12-13 22:50:03,925, PHOCNetTrainer] Evaluating CNN after 97000 steps:
I1213 22:51:41.801653 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:51:41.802075 15776 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 22:51:45,449, PHOCNetTrainer] mAP: 0.925676
I1213 22:51:45.450896 15749 solver.cpp:330] Iteration 97500, Testing net (#0)
I1213 22:51:45.451140 15749 net.cpp:676] Ignoring source layer drop6
I1213 22:51:45.451155 15749 net.cpp:676] Ignoring source layer drop7
I1213 22:53:15.759676 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:53:15.759801 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 22:53:16.215714 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 22:53:16.216174 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 22:53:16.216192 15749 solver.cpp:397]     Test net output #2: loss = 16.7704 (* 1 = 16.7704 loss)
I1213 22:53:17.481055 15749 solver.cpp:218] Iteration 97500 (0.237007 iter/s, 421.929s/100 iters), loss = 0.420711
I1213 22:53:17.481173 15749 solver.cpp:237]     Train net output #0: label = 47
I1213 22:53:17.481197 15749 solver.cpp:237]     Train net output #1: label_phocs = 47
I1213 22:53:17.481210 15749 solver.cpp:237]     Train net output #2: loss = 0.0187036 (* 1 = 0.0187036 loss)
I1213 22:53:17.481228 15749 sgd_solver.cpp:116] Iteration 97500, lr = 1e-05
I1213 22:57:05.131258 15749 solver.cpp:218] Iteration 97600 (0.439271 iter/s, 227.65s/100 iters), loss = 0.699017
I1213 22:57:05.131331 15749 solver.cpp:237]     Train net output #0: label = 747
I1213 22:57:05.131356 15749 solver.cpp:237]     Train net output #1: label_phocs = 747
I1213 22:57:05.131366 15749 solver.cpp:237]     Train net output #2: loss = 0.276583 (* 1 = 0.276583 loss)
I1213 22:57:05.131376 15749 sgd_solver.cpp:116] Iteration 97600, lr = 1e-05
I1213 23:01:06.128929 15749 solver.cpp:218] Iteration 97700 (0.414985 iter/s, 240.973s/100 iters), loss = 0.670173
I1213 23:01:06.129050 15749 solver.cpp:237]     Train net output #0: label = 177
I1213 23:01:06.129075 15749 solver.cpp:237]     Train net output #1: label_phocs = 177
I1213 23:01:06.129086 15749 solver.cpp:237]     Train net output #2: loss = 0.0363473 (* 1 = 0.0363473 loss)
I1213 23:01:06.129096 15749 sgd_solver.cpp:116] Iteration 97700, lr = 1e-05
I1213 23:05:07.396222 15749 solver.cpp:218] Iteration 97800 (0.414532 iter/s, 241.236s/100 iters), loss = 0.584772
I1213 23:05:07.397074 15749 solver.cpp:237]     Train net output #0: label = 493
I1213 23:05:07.397104 15749 solver.cpp:237]     Train net output #1: label_phocs = 493
I1213 23:05:07.397115 15749 solver.cpp:237]     Train net output #2: loss = 0.0479096 (* 1 = 0.0479096 loss)
I1213 23:05:07.397125 15749 sgd_solver.cpp:116] Iteration 97800, lr = 1e-05
I1213 23:08:49.811262 15749 solver.cpp:218] Iteration 97900 (0.449667 iter/s, 222.387s/100 iters), loss = 0.762235
I1213 23:08:49.811348 15749 solver.cpp:237]     Train net output #0: label = 685
I1213 23:08:49.811370 15749 solver.cpp:237]     Train net output #1: label_phocs = 685
I1213 23:08:49.811383 15749 solver.cpp:237]     Train net output #2: loss = 0.0875952 (* 1 = 0.0875952 loss)
I1213 23:08:49.811391 15749 sgd_solver.cpp:116] Iteration 97900, lr = 1e-05
[2017-12-13 23:12:54,003, PHOCNetTrainer] Running test evaluation
[2017-12-13 23:12:54,003, PHOCNetTrainer] Evaluating CNN after 97500 steps:
I1213 23:14:42.167845 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:14:42.167969 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 23:14:45,754, PHOCNetTrainer] mAP: 0.926708
I1213 23:14:45.755589 15749 solver.cpp:330] Iteration 98000, Testing net (#0)
I1213 23:14:45.755837 15749 net.cpp:676] Ignoring source layer drop6
I1213 23:14:45.755853 15749 net.cpp:676] Ignoring source layer drop7
I1213 23:16:19.227815 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:16:19.227857 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:16:20.460064 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 23:16:20.460115 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 23:16:20.460127 15749 solver.cpp:397]     Test net output #2: loss = 16.4978 (* 1 = 16.4978 loss)
I1213 23:16:22.596566 15749 solver.cpp:218] Iteration 98000 (0.220857 iter/s, 452.782s/100 iters), loss = 0.907505
I1213 23:16:22.596665 15749 solver.cpp:237]     Train net output #0: label = 898
I1213 23:16:22.596688 15749 solver.cpp:237]     Train net output #1: label_phocs = 898
I1213 23:16:22.596701 15749 solver.cpp:237]     Train net output #2: loss = 0.261302 (* 1 = 0.261302 loss)
I1213 23:16:22.596710 15749 sgd_solver.cpp:116] Iteration 98000, lr = 1e-05
I1213 23:20:03.236436 15749 solver.cpp:218] Iteration 98100 (0.453228 iter/s, 220.64s/100 iters), loss = 0.665725
I1213 23:20:03.236505 15749 solver.cpp:237]     Train net output #0: label = 550
I1213 23:20:03.236526 15749 solver.cpp:237]     Train net output #1: label_phocs = 550
I1213 23:20:03.236538 15749 solver.cpp:237]     Train net output #2: loss = 0.0445339 (* 1 = 0.0445339 loss)
I1213 23:20:03.236547 15749 sgd_solver.cpp:116] Iteration 98100, lr = 1e-05
I1213 23:23:54.281641 15749 solver.cpp:218] Iteration 98200 (0.432816 iter/s, 231.045s/100 iters), loss = 0.647025
I1213 23:23:54.281730 15749 solver.cpp:237]     Train net output #0: label = 575
I1213 23:23:54.281754 15749 solver.cpp:237]     Train net output #1: label_phocs = 575
I1213 23:23:54.281766 15749 solver.cpp:237]     Train net output #2: loss = 0.164802 (* 1 = 0.164802 loss)
I1213 23:23:54.281774 15749 sgd_solver.cpp:116] Iteration 98200, lr = 1e-05
I1213 23:28:00.454735 15749 solver.cpp:218] Iteration 98300 (0.406289 iter/s, 246.13s/100 iters), loss = 0.690366
I1213 23:28:00.454964 15749 solver.cpp:237]     Train net output #0: label = 412
I1213 23:28:00.454993 15749 solver.cpp:237]     Train net output #1: label_phocs = 412
I1213 23:28:00.455004 15749 solver.cpp:237]     Train net output #2: loss = 0.285876 (* 1 = 0.285876 loss)
I1213 23:28:00.455014 15749 sgd_solver.cpp:116] Iteration 98300, lr = 1e-05
I1213 23:31:47.329818 15749 solver.cpp:218] Iteration 98400 (0.440771 iter/s, 226.875s/100 iters), loss = 0.627405
I1213 23:31:47.329900 15749 solver.cpp:237]     Train net output #0: label = 250
I1213 23:31:47.329922 15749 solver.cpp:237]     Train net output #1: label_phocs = 250
I1213 23:31:47.329934 15749 solver.cpp:237]     Train net output #2: loss = 0.00681418 (* 1 = 0.00681418 loss)
I1213 23:31:47.329943 15749 sgd_solver.cpp:116] Iteration 98400, lr = 1e-05
[2017-12-13 23:35:16,447, PHOCNetTrainer] Running test evaluation
[2017-12-13 23:35:16,447, PHOCNetTrainer] Evaluating CNN after 98000 steps:
I1213 23:36:57.798449 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:36:57.798442 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-13 23:37:02,238, PHOCNetTrainer] mAP: 0.925923
I1213 23:37:02.239248 15749 solver.cpp:330] Iteration 98500, Testing net (#0)
I1213 23:37:02.239423 15749 net.cpp:676] Ignoring source layer drop6
I1213 23:37:02.239429 15749 net.cpp:676] Ignoring source layer drop7
I1213 23:38:50.866300 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:38:50.867580 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1213 23:38:52.370985 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1213 23:38:52.371042 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1213 23:38:52.371064 15749 solver.cpp:397]     Test net output #2: loss = 16.6292 (* 1 = 16.6292 loss)
I1213 23:38:55.252898 15749 solver.cpp:218] Iteration 98500 (0.233687 iter/s, 427.923s/100 iters), loss = 1.41601
I1213 23:38:55.254142 15749 solver.cpp:237]     Train net output #0: label = 844
I1213 23:38:55.254182 15749 solver.cpp:237]     Train net output #1: label_phocs = 844
I1213 23:38:55.254196 15749 solver.cpp:237]     Train net output #2: loss = 0.0196201 (* 1 = 0.0196201 loss)
I1213 23:38:55.254206 15749 sgd_solver.cpp:116] Iteration 98500, lr = 1e-05
I1213 23:42:59.952468 15749 solver.cpp:218] Iteration 98600 (0.408666 iter/s, 244.698s/100 iters), loss = 0.618967
I1213 23:42:59.952548 15749 solver.cpp:237]     Train net output #0: label = 432
I1213 23:42:59.952570 15749 solver.cpp:237]     Train net output #1: label_phocs = 432
I1213 23:42:59.952582 15749 solver.cpp:237]     Train net output #2: loss = 0.0724968 (* 1 = 0.0724968 loss)
I1213 23:42:59.952590 15749 sgd_solver.cpp:116] Iteration 98600, lr = 1e-05
I1213 23:46:50.199337 15749 solver.cpp:218] Iteration 98700 (0.434344 iter/s, 230.232s/100 iters), loss = 0.641799
I1213 23:46:50.200126 15749 solver.cpp:237]     Train net output #0: label = 341
I1213 23:46:50.200161 15749 solver.cpp:237]     Train net output #1: label_phocs = 341
I1213 23:46:50.200175 15749 solver.cpp:237]     Train net output #2: loss = 0.147838 (* 1 = 0.147838 loss)
I1213 23:46:50.200182 15749 sgd_solver.cpp:116] Iteration 98700, lr = 1e-05
I1213 23:50:35.909101 15749 solver.cpp:218] Iteration 98800 (0.443062 iter/s, 225.702s/100 iters), loss = 0.636024
I1213 23:50:35.909186 15749 solver.cpp:237]     Train net output #0: label = 617
I1213 23:50:35.909210 15749 solver.cpp:237]     Train net output #1: label_phocs = 617
I1213 23:50:35.909222 15749 solver.cpp:237]     Train net output #2: loss = 0.0295519 (* 1 = 0.0295519 loss)
I1213 23:50:35.909235 15749 sgd_solver.cpp:116] Iteration 98800, lr = 1e-05
I1213 23:54:41.630775 15749 solver.cpp:218] Iteration 98900 (0.406983 iter/s, 245.71s/100 iters), loss = 0.786593
I1213 23:54:41.631822 15749 solver.cpp:237]     Train net output #0: label = 970
I1213 23:54:41.631852 15749 solver.cpp:237]     Train net output #1: label_phocs = 970
I1213 23:54:41.631863 15749 solver.cpp:237]     Train net output #2: loss = 0.111545 (* 1 = 0.111545 loss)
I1213 23:54:41.631872 15749 sgd_solver.cpp:116] Iteration 98900, lr = 1e-05
[2017-12-13 23:58:38,028, PHOCNetTrainer] Running test evaluation
[2017-12-13 23:58:38,028, PHOCNetTrainer] Evaluating CNN after 98500 steps:
I1214 00:00:13.704007 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:00:13.704246 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-14 00:00:15,197, PHOCNetTrainer] mAP: 0.925045
I1214 00:00:15.198423 15749 solver.cpp:330] Iteration 99000, Testing net (#0)
I1214 00:00:15.198624 15749 net.cpp:676] Ignoring source layer drop6
I1214 00:00:15.198632 15749 net.cpp:676] Ignoring source layer drop7
I1214 00:01:30.096004 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:01:30.096176 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:01:32.096712 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1214 00:01:32.096760 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1214 00:01:32.096772 15749 solver.cpp:397]     Test net output #2: loss = 16.6844 (* 1 = 16.6844 loss)
I1214 00:01:34.800020 15749 solver.cpp:218] Iteration 99000 (0.242032 iter/s, 413.168s/100 iters), loss = 1.22307
I1214 00:01:34.801162 15749 solver.cpp:237]     Train net output #0: label = 216
I1214 00:01:34.801218 15749 solver.cpp:237]     Train net output #1: label_phocs = 216
I1214 00:01:34.801228 15749 solver.cpp:237]     Train net output #2: loss = 0.050448 (* 1 = 0.050448 loss)
I1214 00:01:34.801235 15749 sgd_solver.cpp:116] Iteration 99000, lr = 1e-05
I1214 00:05:28.416972 15749 solver.cpp:218] Iteration 99100 (0.428053 iter/s, 233.616s/100 iters), loss = 0.673573
I1214 00:05:28.417559 15749 solver.cpp:237]     Train net output #0: label = 713
I1214 00:05:28.417585 15749 solver.cpp:237]     Train net output #1: label_phocs = 713
I1214 00:05:28.417594 15749 solver.cpp:237]     Train net output #2: loss = 14.2305 (* 1 = 14.2305 loss)
I1214 00:05:28.417603 15749 sgd_solver.cpp:116] Iteration 99100, lr = 1e-05
I1214 00:09:29.264869 15749 solver.cpp:218] Iteration 99200 (0.415222 iter/s, 240.835s/100 iters), loss = 0.67396
I1214 00:09:29.265195 15749 solver.cpp:237]     Train net output #0: label = 457
I1214 00:09:29.265225 15749 solver.cpp:237]     Train net output #1: label_phocs = 457
I1214 00:09:29.265239 15749 solver.cpp:237]     Train net output #2: loss = 0.0245267 (* 1 = 0.0245267 loss)
I1214 00:09:29.265247 15749 sgd_solver.cpp:116] Iteration 99200, lr = 1e-05
I1214 00:13:33.609004 15749 solver.cpp:218] Iteration 99300 (0.409263 iter/s, 244.342s/100 iters), loss = 0.600549
I1214 00:13:33.609094 15749 solver.cpp:237]     Train net output #0: label = 559
I1214 00:13:33.609129 15749 solver.cpp:237]     Train net output #1: label_phocs = 559
I1214 00:13:33.609148 15749 solver.cpp:237]     Train net output #2: loss = 0.118808 (* 1 = 0.118808 loss)
I1214 00:13:33.609158 15749 sgd_solver.cpp:116] Iteration 99300, lr = 1e-05
I1214 00:17:15.652505 15749 solver.cpp:218] Iteration 99400 (0.450362 iter/s, 222.044s/100 iters), loss = 0.638197
I1214 00:17:15.653810 15749 solver.cpp:237]     Train net output #0: label = 354
I1214 00:17:15.653863 15749 solver.cpp:237]     Train net output #1: label_phocs = 354
I1214 00:17:15.653877 15749 solver.cpp:237]     Train net output #2: loss = 5.01157 (* 1 = 5.01157 loss)
I1214 00:17:15.653887 15749 sgd_solver.cpp:116] Iteration 99400, lr = 1e-05
[2017-12-14 00:21:23,737, PHOCNetTrainer] Running test evaluation
[2017-12-14 00:21:23,737, PHOCNetTrainer] Evaluating CNN after 99000 steps:
I1214 00:23:19.253782 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:23:19.253803 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-14 00:23:21,182, PHOCNetTrainer] mAP: 0.925774
I1214 00:23:21.183648 15749 solver.cpp:330] Iteration 99500, Testing net (#0)
I1214 00:23:21.183861 15749 net.cpp:676] Ignoring source layer drop6
I1214 00:23:21.183871 15749 net.cpp:676] Ignoring source layer drop7
I1214 00:24:50.714347 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:24:50.715355 15777 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:24:52.067507 15749 solver.cpp:397]     Test net output #0: label = 576.314
I1214 00:24:52.067548 15749 solver.cpp:397]     Test net output #1: label_phocs = 576.314
I1214 00:24:52.067559 15749 solver.cpp:397]     Test net output #2: loss = 16.6349 (* 1 = 16.6349 loss)
I1214 00:24:53.957006 15749 solver.cpp:218] Iteration 99500 (0.218196 iter/s, 458.303s/100 iters), loss = 0.245931
I1214 00:24:53.957096 15749 solver.cpp:237]     Train net output #0: label = 463
I1214 00:24:53.957120 15749 solver.cpp:237]     Train net output #1: label_phocs = 463
I1214 00:24:53.957131 15749 solver.cpp:237]     Train net output #2: loss = 0.238589 (* 1 = 0.238589 loss)
I1214 00:24:53.957140 15749 sgd_solver.cpp:116] Iteration 99500, lr = 1e-05
I1214 00:28:34.601213 15749 solver.cpp:218] Iteration 99600 (0.453276 iter/s, 220.616s/100 iters), loss = 0.561853
I1214 00:28:34.601311 15749 solver.cpp:237]     Train net output #0: label = 1073
I1214 00:28:34.601336 15749 solver.cpp:237]     Train net output #1: label_phocs = 1073
I1214 00:28:34.601347 15749 solver.cpp:237]     Train net output #2: loss = 4.41438 (* 1 = 4.41438 loss)
I1214 00:28:34.601356 15749 sgd_solver.cpp:116] Iteration 99600, lr = 1e-05
I1214 00:32:39.789016 15749 solver.cpp:218] Iteration 99700 (0.407891 iter/s, 245.164s/100 iters), loss = 0.736315
I1214 00:32:39.789100 15749 solver.cpp:237]     Train net output #0: label = 950
I1214 00:32:39.789125 15749 solver.cpp:237]     Train net output #1: label_phocs = 950
I1214 00:32:39.789139 15749 solver.cpp:237]     Train net output #2: loss = 0.00553111 (* 1 = 0.00553111 loss)
I1214 00:32:39.789147 15749 sgd_solver.cpp:116] Iteration 99700, lr = 1e-05
I1214 00:36:43.430001 15749 solver.cpp:218] Iteration 99800 (0.41044 iter/s, 243.641s/100 iters), loss = 0.634675
I1214 00:36:43.430081 15749 solver.cpp:237]     Train net output #0: label = 869
I1214 00:36:43.430104 15749 solver.cpp:237]     Train net output #1: label_phocs = 869
I1214 00:36:43.430116 15749 solver.cpp:237]     Train net output #2: loss = 0.0261602 (* 1 = 0.0261602 loss)
I1214 00:36:43.430124 15749 sgd_solver.cpp:116] Iteration 99800, lr = 1e-05
I1214 00:40:50.819881 15749 solver.cpp:218] Iteration 99900 (0.404247 iter/s, 247.374s/100 iters), loss = 0.636854
I1214 00:40:50.819963 15749 solver.cpp:237]     Train net output #0: label = 143
I1214 00:40:50.819986 15749 solver.cpp:237]     Train net output #1: label_phocs = 143
I1214 00:40:50.819998 15749 solver.cpp:237]     Train net output #2: loss = 0.936446 (* 1 = 0.936446 loss)
I1214 00:40:50.820006 15749 sgd_solver.cpp:116] Iteration 99900, lr = 1e-05
[2017-12-14 00:44:19,470, PHOCNetTrainer] Running test evaluation
[2017-12-14 00:44:19,470, PHOCNetTrainer] Evaluating CNN after 99500 steps:
I1214 00:45:59.768985 15776 data_layer.cpp:72] Restarting data prefetching from start.
I1214 00:45:59.783071 15777 data_layer.cpp:72] Restarting data prefetching from start.
[2017-12-14 00:46:01,995, PHOCNetTrainer] mAP: 0.926654
[2017-12-14 00:46:01,995, PHOCNetTrainer] Running post-train evaluation
Traceback (most recent call last):
  File "train_phocnet.py", line 116, in <module>
    
  File "/home/fwolf/Workspace/DensePHOCNet/src/phocnet/training/phocnet_trainer.py", line 281, in train_phocnet
    
  File "/home/fwolf/Workspace/DensePHOCNet/src/phocnet/training/phocnet_trainer.py", line 534, in _run_sgd
    for cur_label, count in zip(unique_train_labels, counts):
  File "/home/fwolf/Workspace/DensePHOCNet/src/phocnet/training/phocnet_trainer.py", line 333, in posttrain_callback
    phoc_bigrams=bigrams, bigram_levels=bigram_levels,
TypeError: %d format: a number is required, not str
